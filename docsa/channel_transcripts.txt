YOUTUBE CHANNEL TRANSCRIPTS
================================================================================

================================================================================
VIDEO ID: 3foYyPDp0Ho
TITLE: Summer of Math Exposition #4 | Teachers, I'd love to hear from you
URL: https://www.youtube.com/watch?v=3foYyPDp0Ho
PUBLISHED: 2025-05-05T15:00:08Z
STATUS: SUCCESS
================================================================================
The time of year has come for the summer of math exposition. So, this is a contest that my friend James Schllo and I started back in 2021. The idea is that there's a lot of people out there who have had at least vague thoughts of making some kind of online math explainer. Maybe that's an article, maybe that's a video. And if you offer, you know, a deadline, a little bit of a prize, and a community, it can get a lot of people over that activation energy hump. We did that first one back in 2021. It was a huge success. We called it sum one and this year we are on to sum 4. If you're keeping track of the numbers there, there was a community-driven version last year that we called sum pi which is just very delightful. The way this works is that between now and September 1st, which is going to be the deadline for this year, you can work on whatever piece of math exposition you want. Again, can be in video, can be an article, pretty much any topic, pretty much any medium. And then after that, we have a peer review session. And this is honestly the heart of the whole event. It's something where both the participants and anybody else who wants can be fed a somewhat arbitrary list of some of the entries, rate them, give some feedback, and then all of that feedback is used to create an ordering or at least a tentative ordering of all of the different videos. And in the past, what I've done is look through the top 100 or so of those videos and then I'll choose five of them to give prizes to. I've said this in past years, but even before I give any prizes, most of the benefit has already come from the entire event. Because not only does the peer review give a lot of people feedback and it gives them an incentive to even do it in the first place, it's proven to be a remarkably effective way of getting people's work out there, especially when it's a very fresh channel or just a new creator, things like that. Now, I will do cash prizes again this year, but I wanted to add just a little bit of a twist. So, I'm going to choose five winners. Um, each one is going to get $1,000. All those prizes come courtesy of Brilliant. So, thank you to them for supporting this event. But this year, I wanted to try to use those prizes to at least slightly shift the direction of what the contest is about. There's a risk with the whole peerreview structure where because a lot of the people submitting things and engaging with the community are already into math, there is a reward for content that tends to be like math for math people, right? Right? So rather than just showing the typical high school material, it's something that shows a more esoteric or more interesting or maybe more technically detailed thing. Now that can be great and one of the beauties of the internet is that you can have niches that kind of feed off of each other. But I do think it would be a little bit sad if that is all the contest ended up being because of all the topics out there, math is one where people both find it very important, right? like almost everyone has to learn it in school in some capacity and also the vast majority of the population really does not like it right there's a lot of people who struggle with this subject and I think there's a lot of potential to really help with online exposition in some way so what I want to try to do is encourage you if you're a maths savvy person and you want to make some kind of online explainer to instead of targeting people who are already into math do something that you think would be genuinely helpful to a student in a classroom for the judging Here's how I'm going to go about that. For the most part, it'll all be business as usual. We have the whole peer review process. Anyone can participate. They just rank entries and give feedback as they go. But I will also specially invite teachers, if you're any kind of math teacher, to join in this peerreview process. And as you make an account in the system, you'll have the ability to mention that you're a teacher and also mention what subjects that you teach. And then proceed forward with the same peerreview process as usual. And if you're a teacher, as you're judging the material, I want you to be asking the question, would this be helpful to my students? Can I see myself using this either to inspire and guide my own lessons or as an external resource that I can point the students to? And then after the whole peer review session is done and I'm looking through all of the entries and seeing which ones bubbled up, I will be able to filter to just seeing how the teachers ranked them. and to be able to judge whether it's a teacher whose subject is relevant to that video. When people submit their entries, we're just going to ask them to tag it with what are the subjects this might be relevant to. And then when I choose the five winners to give cash prizes to, what I will personally be trying to assess is which of these entries are going to be the most helpful for students in classrooms somewhere. Now, I'm being deliberately vague with exactly what this means. I don't want to be prescriptive about the specific age or the specific topics. I want it to depend most on where you personally feel you can be the most helpful. Now, most of this activity is going to happen at the end of the summer. I'm announcing things right now just so you can get started working on whatever you want to work on. But if you are a teacher, there are a couple things that would be really helpful right now. So, in the pinned comment of this video, I've linked to a Reddit thread where I'd love to see a discussion around what topics would actually benefit the most from more online explanation. So, if you're a teacher in any subject and you've ever thought, "Man, this topic is really hard for my students, it would be great if there was some sort of better resource online, let me know about it. I would love to see on that thread." And secondly, there's a Google form where if you think you might be interested at the end of the summer in being one of these teacher peer reviewers, no pressure, no obligation here, but it is very fun. If you could fill that out and let me know, it would be very helpful because then I have at least a loose depiction ahead of time of how many teachers we already have to work with and if I should work extra hard to try to recruit more into the system or anything like that. Everything that you need, all the details that you want are going to be at somme.b1b.co. So that is the central hub website for the whole event. That's where the peer reviewing is going to happen. It links to the Discord community where you can engage with people about your project through the summer. Until then, I will be eagerly awaiting your projects, and I'll see you at the end of the summer. [Music]

================================================================================
VIDEO ID: Dlsa9EBKDGI
TITLE: Where my explanation of Groverâ€™s algorithm failed
URL: https://www.youtube.com/watch?v=Dlsa9EBKDGI
PUBLISHED: 2025-05-04T11:45:24Z
STATUS: SUCCESS
================================================================================
Last week I put up a video introducing quantum computing, and in the final section we were stepping through something known as Grover's algorithm. And based on the comments that I saw, I think there was a very common point of confusion that reveals I clearly could have done a better job explaining a core piece of it. Right here I wanted to throw together a very quick supplement in the hopes of adding a bit of clarity. The premise was to have a function which is somehow triggered by a unique value out of a big bag of options, and the puzzle is basically to figure out how do you find that unique value just by applying the function on various inputs. Now in a classical setting, it's not a very interesting question, the best you can do is guess and check, but what we walked through was a completely different approach that you can take that becomes possible in the setting of a quantum computer. When we did this, there was a certain key step where, if I'm understanding the comments correctly, it looked to a lot of people like in order to apply this key step, you would have to already know the value that you're searching for, which would of course defeat the whole purpose of the algorithm. More specifically, we had this very high dimensional vector space, and one of the axes in that space corresponded to the value that we're searching for, and this step of the algorithm looked like flipping along that axis, multiplying any component of a vector in that direction by negative one. Now viewers were essentially asking, whoa whoa whoa, how could you know how to do that without already knowing which axis you're searching for? I genuinely tried to forestall that objection, but I think I failed, so backing up, I think the whole discussion might be clearer if we focus on a very concrete example, something like solving a sudoku. On your normal classical computer, it's not hard to write a function that checks whether a proposed solution follows all of the sudoku rules and solves the puzzle. You know, it would check the rows, the columns, squares for duplicates, things like that. If you have written this function, just because you know how to verify a solution, it's not at all obvious what the solution is in the first place. This is, after all, why a sudoku is a puzzle. The rules alone don't reveal the answer. There are other situations where this is actually a much stronger assumption. The function SHA-256, for example, is what's called a cryptographic hash function. That basically means if you want to find what input gives you a particular output, it is strongly believed that you really can't gain much insight by looking at how the function is implemented. If someone could reverse engineer it, they would be mining all of the bitcoin in the world and breaking numerous other cryptographic schemes. But it's believed that the best thing you can do when you're searching for a particular output is guess and check. So it's not that the key value is like hiding inside the function behind some curtain, it's more of a difficult-to-find emergent phenomenon of the function itself. Now the idea with Grover's algorithm is that if you have this sort of verifier function for some hard problem and you translate it into the language of quantum computing, there is a method for sifting out valid solutions which requires fewer steps than simple guessing and checking over all the possibilities. Now to be clear, it is not dramatically faster, it's only a quadratic speedup, and given the overheads for making quantum computing work, this frankly has questionable utility. In fact, let's talk a little bit more about that at the end. First, to the clarification, if you have this Sudoku verifying function, it's not like you can just run it on a quantum computer. After all, quantum computers speak an entirely different language, it's a totally different framework for computing that looks a lot more like vector manipulation. The first step to port over this verification function into the new context is to imagine that we've kind of compiled your verifier into a bunch of logic gates, things like AND, OR, and NOT. So for any proposed Sudoku solution, you would represent it all in binary, all of those bits would be processed by your web of logic gates, and the output would be a 1 if it's a valid Sudoku solution, and a 0 for all the invalid ones. And again, being able to assemble these logic gates does not require knowing ahead of time which input solves the puzzle. The logic gates distill the rules of the game, but not the strategy. Now I'm assuming everyone has watched the main video, in particular the core section about the fundamentals of the state vector, but as a quick recap, the upshot is that you think of every possible bit string as a unit vector along a coordinate axis in some high dimensional space. In the language of linear algebra, you would call these the basis vectors of your coordinate system. For example, with a 2-qubit quantum computer, you would have 4 possible bit strings, and these would all look like basis directions in some 4-dimensional space. These state vectors get very big very fast. If you have a k-qubit quantum computer, that gives you 2 to the k possible bit strings, and you think of each one of them as being a coordinate direction in some very high dimensional vector space. Now operations on a quantum computer don't spit out true or false the way you can see on a classical computer. Instead they take in a vector and spit out a new vector, both of which live in the same space. And like I said last video, you often think about them as somehow flipping or rotating the vectors in that space. Now here's the crux of the confusion. I mentioned how if you have this classical verifier function, something like a Sudoku checker that spits out a 1 or a 0, it is possible to translate it into an operation on a quantum computer that has the following behavior. If a bit string returns 1 for true up in the classical case, then down in the quantum case, the corresponding basis vector gets multiplied by negative 1, effectively flipping 180 degrees. And then if in the classical case a bit string outputs 0 for false, then in the quantum translation, the corresponding basis vector is unchanged. Now I can see three reasons that this step might have caused some confusion. First of all, I didn't explain how it actually works. I didn't step through the translation. Now my hope with that video was that it's just not too huge a leap to have you accept that in principle there exists this correspondence between returning true and false up in the classical world and multiplying by negative 1 or positive 1 down in the quantum world with vectors. Now maybe that is a leap. I could preview for you what that translation looks like. The relevant search term here is quantum compilation, but I'm going to be honest, I don't think it would add much clarity, in the same way that knowing the logic gates that implement addition don't really teach you much about how to add two numbers. Now it's not exactly like this, but loosely speaking, every time you see an AND gate, you translate it into a quantum operation that looks kind of like an AND. Every time you see a NOT gate, there's a quantum analogue that does something kind of like a NOT. I suspect the real cause of confusion originates not from a lack of low-level detail, but from how I had framed the entire setup. I opened that video by having you imagine that there was some mystery number that we're searching for, and as one commenter helpfully pointed out, this made it seem like the computer kind of knows the answer ahead of time, it's just hiding it from us. And this is almost certainly exacerbated by me briefly flashing an example function that just checks if the input is 12, and saying that we were going to treat the function as a black box. That's on me. That's a misleading way to open things. What I wanted to foreshadow is how, with Grover's algorithm, the only way you use the new quantum function is by trying it out on inputs, as opposed to maybe like reverse engineering it. So in that sense, it's treated as a black box. But to be clear, in order to translate the classical verifier into the quantum version, you absolutely need to get into the guts of the function. And if this is going to be a compelling example, it would be very silly if the only thing the function did was just check if the input equals some hidden number. The Sudoku example is much better, and a cryptographic hash like SHA-256 would be much better still. In these contexts, there is one value that will trigger the function, and we don't know what it is, but the computer also doesn't know what it is. It's not like the key value is just hiding in the source code. Whether we're up here in the classical setting, where triggering the function means returning true, or down in the quantum setting, where triggering the function means multiplying by negative one, which specific key input does this is a difficult to find and emergent property of those logic gates. It's not something that's baked in ahead of time. The other potential source of confusion, I suspect, is that I didn't appropriately emphasize the idea of linearity. In fact, this is a central enough feature of quantum computing and quantum mechanics that half of my reason for making this whole follow-up video is as an excuse to talk about it. So most vectors don't look like a pure basis direction, they look like some weighted sum of all the different basis vectors. One way you can represent this is with a column vector, where we think of each component as being associated with one of the possible bitstrings. The more common convention among physicists is to write general vectors as an explicit weighted sum of all the basis directions, each one represented with a ket. When the state vector for a computer looks like this, you say that it's in superposition, meaning it has some non-zero component associated with multiple distinct bitstrings. It's a lot like saying if someone is walking northeast, their velocity is a superposition of north and east, they're travelling both directions at the same time. A core idea from the last video is that you never actually see the coordinates of a state vector in superposition like this. When you read out from the computer, all you see is one of the bitstrings at random, and the probability of seeing it is equal to the square of the magnitude of the component of the state vector associated with that value. I'm saying magnitude here with the absolute value signs, because in general, these components can be complex numbers, but for simplicity, I'm only going to be showing real values. When I say that operations in quantum computers are linear, what I mean is that if you pass in one of these weighted sums of the different basis directions, that is to say, a superposition, then the output looks like the same weighted sum, but of the transformed versions of each vector. So here's a very small example. On a single qubit, there's an operation that we call a z-gate. What it does is it leaves the 0 direction unchanged, but it multiplies that vertical 1 direction by negative 1. These are only two out of the infinitely many possible state vectors, but they're all you need to know. If you pass in a superposition of those two, something that has a little bit of 0 plus a little bit of 1, what you do is look at what the z-gate does to each part separately, and then add those together. Again, with the same components. In this case, that means flipping the sign associated with the 1 component. Geometrically, when you draw this vector in a 2D space, the action of a z-gate looks like flipping around the x-axis. The z-gate is simple enough that just by looking at the definition, you can clearly see which direction gets flipped. But keep in mind, for more complicated functions, the definition alone might not so easily reveal how it behaves. Take a look back at the Sudoku verification function and its translation onto a quantum computer, and then say that the state of your computer is not one of those clean basis directions, but it is a combination of all the basis vectors, a superposition of every possible bit string in this context representing every possible solution to the Sudoku. To figure out what our verifier does to this new vector, what you do is look at what it would do to each basis separately, and then the output is going to be the same scaled sum of the result. In this case, most parts of that sum stay unchanged, but one of them, the one that's associated with the key input that represents a Sudoku solution, that part is going to have it sign flipped. When you do this, it's very tempting to look at it and say that the function is acting on every possible basis vector at once in parallel, and then adding the results. Now that might be true, but I invite you to reflect on whether that's necessarily a fair way to summarize it. As an analogy, if a hiker is walking northeast, and you tell him to rotate 90 degrees, that rotation is a linear operation. In other words, the final direction is the same as what you would get by rotating the north vector 90 degrees, rotating the east vector 90 degrees, and adding the two results. But that doesn't mean that you have to perform two separate rotations in parallel in order to move the hiker. The linearity is a property of the transformation, it's not necessarily a set of instructions on how to do it. It's very similar over here. The effect of the quantum translation for our verifier looks like adding together what its effect would be on all of the basis vectors, but I will leave it to your interpretation whether this means that it is necessarily acting on all 2 to the k possible bitstrings at once. Here, I've been writing the vector the physicist way, but if I write it with a column vector instead, what this operation looks like is taking one component of that vector and multiplying it by negative 1, specifically whichever component corresponds to the sudoku solution. So stepping back, hopefully this helps clear up some of the confusion there was in that last video. The starting point of Grover's algorithm is to assume that you're given a function that flips one component of a vector like this, though you don't know which one. The puzzle is to somehow figure out which direction is getting flipped, where all you're allowed to do is apply this function to some well-chosen set of inputs, and in Grover's case, it involves interleaving it with a certain other operation in the toolkit of quantum computing. I get it, that is a really weird place to start from. And it doesn't help that this is a famously confusing topic. If you find it weird to work with a state vector whose components you never actually observe and which instead acts like a kind of square root of a probability distribution, you're not alone. Everyone finds that very weird. At this point I genuinely can't tell if I'm overexplaining things or still under-explaining them, but there is one final aspect of the explanation from last time that may have added to this confusion. When we visualized the algorithm, we chose to view everything on a certain two-dimensional slice of the enormous n-dimensional vector space where all these state vectors live, and this slice, by definition, included the axis associated with that mystery value we're searching for. Now, in case that left anyone with the impression that part of the algorithm was to choose that slice, let me be very clear, it's not. The algorithm is just doing what it's going to do. It interleaves two operations that go back and forth. It doesn't have a care in the world how you and I choose to visualize it. The fact that the state vector stays confined to this particular plane, that's a happy emergent property of the algorithm. It is in no way part of the instruction set that we're giving to the computer. One very final thing that I do think deserves some added reflection is how Grover's algorithm, while very thought-provoking, is maybe just not really useful. Take the Sudoku example. The number of possible solutions will depend on how many of those 81 squares start off blank, but let's call it something like 9 to the power 60. If you tried to use your classical verifier function to find a solution by brute force, there are way, way too many possibilities to check. But even if you had a fully functioning quantum computer, sitting on your desk right now with ample qubits and no issues maintaining coherence and all that, using Grover's algorithm, this would still take around 9 to the 30 steps, which is a much smaller number, but it's still enormous. In this case, there's obviously many smarter ways to solve a Sudoku than a brute force search, but if you take something like SHA-256, inverting it by brute force takes 2 to the 256 steps on a classical computer. Using Grover's algorithm, that becomes 2 to the 128, at least up to that pi-fourths constant that we saw last video. So even in some sci-fi future where quantum computers are as far along as today's classical computers, that is still an infeasibly large number of steps. The way some people write about quantum computing, it makes it sound like the moment they arrive, everything is going to change and all of cryptography will break. And it's true that there are specific problems that have exponential speedups, and especially with RSA, some of those are relevant to cryptography, but that's not true in general. This quadratic speedup is much more representative of what you get for most problems. It's really cool, and the math is just beautiful, and there continues to be lots of interesting research in the field, but one of my hopes with this whole project is that you now have enough background to maybe see through some of the hyperbole that certain outlets are so fond of. Thank you.

================================================================================
VIDEO ID: RQWpF2Gb-gU
TITLE: But what is quantum computing?  (Grover's Algorithm)
URL: https://www.youtube.com/watch?v=RQWpF2Gb-gU
PUBLISHED: 2025-04-30T12:32:19Z
STATUS: SUCCESS
================================================================================
A lot of pop science outlets give a certain summary of quantum computing that I can almost guarantee leads to misconceptions. The summary goes something like this. In a classical computer, data is stored with bits, some sequence of ones and zeros, but in a quantum computer, you are able to represent every possible sequence of bits of some fixed length all at once in one big thing known as a superposition. And sometimes the implication of these summaries is that quantum computers can be faster by basically doing whatever a classical computer would do, but to all of these sequences in parallel. Now, this does gesture at something that's kind of true, but let me see if I can prove to you why I think this leads to misconceptions, and I'll prove it using a quiz. To set it up, I want you to imagine that I have a mystery function, and I tell you that there's a certain secret number among all the numbers from 0 up to n-1, where if you plug that value into my function, it returns true, but if you were to plug in any other value, it returns false. And let's say you can't look at the innards of the function to learn anything about it, the only thing you're allowed to do with it is just try it out on numbers. The warmup question is, how many times, on average, would you have to apply this mystery function in order to find the secret key? Well, if the setup was in an ordinary classical computer, there's really nothing better that you can do than guess and check. You go through all the numbers, and maybe you're lucky and find it early, maybe you're unlucky and it doesn't come up until later, but on average, with a list of n possibilities, it takes one half of n attempts to find the key. Now, in computer science, people care about how runtimes scale. If you had a list ten times as big, how much longer would it take? And computer scientists have a way of categorizing runtimes. They would call this one O of n, where that big O communicates that maybe there's some constants like the one half, or maybe some factors that grow slower than n, but the factor of n is what explains how quickly it scales as n grows. If n goes up by a factor of ten, the runtime also goes up by a factor of ten. Now, here's your quiz. For the equivalent of this setup, but in a quantum computer, what's the best runtime for finding the secret key? I've asked a variant of this quiz many times in a certain lecture that I've given over the years, and the options I typically offer are O of square root of n, O of log of n, O of log of log of n, and O of one, where here O of one would mean that the runtime is just some constant that doesn't actually grow as n grows. Now, to be fair, I have not defined quantum computing. In fact, doing so from the ground up is going to be the goal of this video. So without showing you what this mystery function would look like in that setting, it's kind of an incoherent question. But it's not really meant as a quiz that I'm grading you on or anything, it's just meant to be a gut check of intuition before we dive in. In principle, it's the same task. Finding a needle in a haystack, where you want to discover which value out of many options uniquely triggers some function. I asked this as a YouTube post last month, which 100,000 of you kindly answered. The most recent time I gave it live was to a group of Stanford students. I also posed it to those attending the International Math Olympiad. And in all of these and many other instances, the answer distribution looks very similar. The most common answer is always O of one. And this is wrong, and I'm pretty sure that it stems from that misleading summary. That summary implies that you would put all of the n values that you need to search into this mysterious superposition, and then you would process them all in parallel, and then somehow the answer would be revealed. The second most common answer is typically O of log of n, and this is also wrong. You would call this an exponential speedup. For example, if you increase the size of the list by factors of 10, an O of log n runtime would only tick up by the same additive increment each time. Now this wrong answer I suspect stems from a misconception about how much better quantum computers are in general. There are very certain special problems where you can achieve an exponential speedup. The most famous case is probably Shor's algorithm for factoring large numbers. But most problems are not like that. In this case, the correct answer is O of square root of n. And this is a lot more representative of the typical speedup that you could get with a quantum computer. In 1994, it was proven that a quantum computer could not possibly do any better than O of square root of n on this task. And then two years later, Lav Grover found a specific procedure that actually achieves that runtime. So searching through a bag of a million options takes on the order of a thousand steps. A bag of a trillion options takes on the order of a million. This big O actually hides something that's pretty fun, which is the constant of pi fourths in the precise runtime, and that pi has its own whole fun story to tell, which I'll get to later. You might think that this puzzle with a mystery function triggered by one specific value is super contrived. But I want you to keep in mind this is meant to be a generic stand-in for any problem where you know how to quickly verify a solution, even if you don't know how to find that solution in the first place. This describes an enormous class of problems in computer science known as NP problems. So while a square root speedup is frankly not as earth-shattering as an exponential speedup would be, and while big O runtimes are often a lot less important than other practical considerations, it is thought-provoking that something like Grover's algorithm is even possible at all, providing this catch-all method for speeding up any NP problem. My goal with this lesson is to build up to a step-by-step walkthrough of how that algorithm works. It's actually very geometric and very beautiful. But we need to build up a lot of background in order to get there. The first two-thirds or so of the video will be spent building up the fundamentals of quantum computing, not with a set of analogies, which as we've seen can lead to misconceptions, but as a piece of math, which I think offers you a pair of glasses through which you can see a much more honest depiction of the whole field. This is one of those topics that has a few premises that are just going to feel a little bit strange at first, and I should warn you they take a little getting used to. My current plan is to follow this lesson with another one about some of the underlying physics, which hopefully can help motivate a few of the odd-looking rules that you'll see here. But today the goal is to provide the minimal viable path to seeing a genuine, bona fide quantum algorithm. Let me pull up again that contrast between classical computing and quantum computing, and let's see if we can build up something of a more representative mental model. It is true of course that data in a classical computer looks like a series of ones and zeros, and at a higher layer of abstraction that might represent an actual data type, like an integer or some text, and at a lower layer of abstraction, those ones and zeros represent some actual thing in the physical world, like voltages across a capacitor or something like that. These same layers of abstraction provide a pretty helpful framing when we discuss quantum computing. Over there, there's also some underlying physical measurement, and again you represent the outcome of that measurement with some sequence of ones and zeros, and again this might implement some actual data type that you care about, like a number. This symbol that I'm showing by the way is called a ket. I'll explain it properly in a couple minutes, but for right now just think of it as conveying that something is coming from a quantum computer. Let's start things off with a description of quantum computing through the lens of that middle layer of abstraction, meaning we're going to postpone all of the underlying physics for now, which is a little bit like teaching computer science without discussing hardware. In a classical computer, there's no need to distinguish between the state of memory and what you read out from the memory, both of them just look like the same sequence of bits, but it's a very different story in a quantum computer. Our main job today is going to be to understand something called the state vector, which is continuous, this is the thing the computer actually operates on, but it has a very unusual relationship with the values that you actually read out, those discrete sequences of bits. Before I can define this state vector, you need to know one other key difference from classical computers, which is that this value that you read out, which again just looks like some sequence of ones and zeros, is random. Or to be a little more accurate, I should say it's typically random. The way you can think about this is that if you run a program on a quantum computer, that program doesn't necessarily determine a particular output, instead it determines a probability distribution across all possible outputs. So for the example I'm showing on screen, this would be a very small quantum computer where the thing that you read out has four bits, meaning that there are 2 to the 4, or 16 possible outputs, and the specific program you run determines some kind of distribution across all those possible outputs. Some programs might manage to concentrate more probability on just one of those outputs, but other programs might give a more even spread across everything. This example, by the way, where the thing you read out has four bits, would be called a 4-qubit quantum computer, and more generally, if you have a k-qubit quantum computer, that means there are 2 to the k distinct possible outputs, and any program gives a distribution across all of those, and the thing that you read out has k distinct bits. That word qubit, by the way, is another thing I'm going to define more precisely in just a minute. I do want to emphasize that this distribution is implicit. You never actually see it directly, you instead infer what it must be based on the program that you run. You never see all bit strings coexisting at once in some kind of way. You just see one of them, drawn at random, according to this distribution. At a lower layer of abstraction, what I'm describing as reading out from memory looks like a physical measurement, and the randomness stems from the laws of quantum mechanics. If you're curious about the physics, that lower layer of abstraction, that's exactly what the next video is for. Up in this layer, you just think about probability distributions over all possible bit strings. One more funny rule here, which does bubble up from the underlying quantum mechanics, is that after you read out from memory, and you see some particular value, the underlying state of the computer changes such that now all of the probability is concentrated on whatever value you read out. So if you kept reading out from memory over and over, you would just keep seeing that same value. You might imagine these programs as creating a very delicate and sensitive probability distribution, where the moment you look at it, sampling from that distribution, the whole thing collapses to one value. Now you might be wondering, where does this distribution come from? This is both the most important and the most confusing part. You think of the state of the computer as being described by a big vector. Right now when I say the word vector, you can just think big list of numbers, although as you'll see later on, it can be helpful to think of this as a direction in some super high dimensional space. Each component of this vector corresponds to one of the possible values you might read out, one of those distinct bit strings. So in this example where what you read out has 4 bits, the state vector would have 16 distinct components. The state vector is not the same thing as the probability distribution over all possible outputs, but it is very closely related. The fundamental rule, which I admit is going to look very strange at first, is that if you take the magnitude of each component in that state vector and you square it, that gives you the probability of seeing the corresponding output, the corresponding bit string. Let me just say up front, a lot of people learning quantum computing find this state vector a bit weird. What is it actually, and why are we squaring things to get probability? As it is, for the sake of simplicity, there's a certain important detail that I'm neglecting until the end of the video here. I just want to flag that for most people, this takes a little getting used to. And to be super clear on what I mean with the fundamental rule here, let's suppose that after this program processes this vector, maybe the component of it associated with some specific bit string, like 0011, happened to be 0.5. Then when you square that value, 0.5 squared is 0.25, so the observable implication of this is that when you read out from memory, you have a 25% chance of seeing that bit string, 0011. One thing I'll highlight is that it is perfectly valid for the values in this state vector to be negative, and at first you might think that has no real impact, since flipping the sign doesn't change the square, and therefore all the probabilities stay the same. It is true that the probabilities stay the same, but we absolutely consider this to be a distinct state, and as you'll see, the idea of flipping signs plays a very central role in Grover's algorithm. Here, this example with four qubits has kind of a lot on screen, with not a lot of visualization to back it up, so let's scale things down to the smallest possible case where the computer has just two possible outputs, represented with a 0 and a 1. In this simplest possible case, the state vector would only be two-dimensional, so we can actually represent it geometrically as an arrow inside a 2D space. In this case, the x-coordinate corresponds to the outcome 0, in the sense that the square of that coordinate tells you the probability that when you read out from the computer, you would read a 0. Maybe it's helpful if I add a little bar to show that probability. You'll notice that as the vector points more in the horizontal direction, more of that probability mass is concentrated on the 0. Similarly, the y-coordinate corresponds to a 1 in the same way. A more vertical state vector means you're more likely to see a 1 when you read out from the computer. Now, notice, because the two probabilities should add up to 1, after all, something is going to happen, x squared plus y squared should equal 1. Geometrically, this means that the state vector has a length of 1, so you could think of it as being confined to a unit circle. More generally, the state vector for a quantum computer will always have a length of 1, and you can think of it as living on some very high-dimensional unit sphere. This two-dimensional example has a special name, which I've already mentioned. It's called a qubit, short for quantum bit. The analogy with a classical bit is that when you read out from the computer, you see either a 0 or a 1, but other than that, it is a completely different animal. Mathematically, a qubit is a unit vector in a two-dimensional space, together with a coordinate system where these two perpendicular x and y directions correspond to the two values that you might read out when you measure. You should know there is that added bit of complexity that I'm postponing, but this is 90% of the right idea. And again, you have this funny rule where when you measure the qubit, seeing either a 0 or a 1, the vector then collapses to fall onto that corresponding direction. So unless something is done to prepare that qubit back into a diagonal direction, any follow-on observations that you make are always going to show the same outcome. It's very possible that at this point you're thinking something like, okay, grant, this is a super bizarre set of premises you're asking me to accept, and if so, you are not alone. What I'm describing, as you can no doubt probably tell, are basically the postulates of quantum mechanics. There are many systems throughout physics, like the spin of an electron or the polarization of a photon, that have this property, where the outcome of a measurement is random, and our best laws of physics have us model the state of that system using a vector, just like the one I'm describing here, where squaring the magnitudes of that vector's components give you the probabilities for seeing various possible outcomes. That actually has a special name, it's called the Born rule. This idea of a qubit is basically meant to be an abstraction over many possible systems like this, in just the same way that a bit is meant to be an abstraction over many possible physical systems that can toggle one of two directions. The symbol I've been showing, by the way, is used throughout any subject with the word quantum in its name to refer to a unit vector in this state space. What you put inside that ket is often going to give some kind of readable meaning for what that vector represents. So in our example with a qubit, the unit vector to the right is often shown with a zero inside the ket, because if that's the state vector, it means you deterministically read out a zero from the computer. Likewise, the unit vector in the vertical direction is represented with a ket that has a one inside of it. And if you go on and read more about this, something that you'll very commonly see is that instead of writing down a general qubit with a column vector, the way I've been showing you, a lot of people like to write it as an explicit weighted sum of these two unit vectors in the two coordinate directions. That's a very physicist kind of convention. Now classical computing has this idea of logic gates, certain basic operations like AND, OR, and NOT that you can use to process bits and that you can string together to create arbitrarily complicated functions. Analogously we have what are called quantum gates, which are certain fundamental operations that you can apply to a qubit or to a system of multiple qubits. And they always look like somehow flipping or rotating the state vector. Now I'm not going to delve too deeply into the details of all the different quantum gates, but if you are curious, I'll show you an example of what one of them looks like. Here's a very standard one known as a Hadamard gate. What it does is it maps the unit vector in that horizontal zero direction into the diagonal northeast direction, and it maps the unit vector in the vertical one direction into that kind of diagonal southeast direction. You would very commonly use this to take a deterministic state, something that's either a zero or a one, and turn it into something with a 50-50 equal balance, or vice versa, too. This is just one example, but there are a number of others forming the building blocks for quantum computing, and the art of writing an algorithm in this setting is to somehow compose a bunch of different quantum gates together that will progressively manipulate and flip and massage this vector until it points almost entirely in one particular coordinate direction, presumably one that actually answers a question you care about. Now down with the simplest example of a qubit, you only have two coordinate directions to work with, so you would be constrained to answer simple yes-no questions. And although I can't illustrate a geometric vector with more than three dimensions, in principle, a system with k qubits is going to have 2 to the k distinct coordinate directions, one for each bit string. So if you can somehow manage to coerce this vector to point along just one of those directions, you could potentially answer some more interesting question, carrying more information. Maybe one of them represents a prime divisor in a very large number you're trying to factor, or maybe one of them represents that secret key value from the opening puzzle of this video. Even though the potential power of quantum computers has a long tradition now of being greatly exaggerated, insofar as there really is potentially more power there, one of the key reasons is that the size of the state vector grows exponentially. As few as 100 qubits would already imply a mind-bogglingly massive state vector. But the catch is that you have no direct access to the values inside this vector. It's effectively invisible to you. The only way it can be useful is if you have a way to manipulate it in such a way that all of the probability, or at least most of it, gets concentrated on one single component, and if that component corresponds to an answer to a question that you care about. Grover's algorithm offers us a really great example to actually see how this looks, and it's high time that we get there. Let me offer you a very high-level preview for how it looks. I promise I will explain all of this in more detail, but here's the bird's eye view. It initializes this state vector in such a way that there's an equal balance of probability across all possible outcomes. One of those outcomes is going to be the secret key that you're searching for, and the tool that you'll have available, which I promise to motivate later, is to flip the sign of the state vector at that coordinate. This doesn't immediately affect the probabilities, but when you interleave this with a certain other operation, and you kind of go back and forth between the two of these, what happens is that the probability mass slowly starts to get concentrated over that secret key value, and at a certain point, almost all of it will be there, so when you read out from the computer, you will almost certainly see the secret key you're looking for. Okay, so that's the high level, but let's unpack it in some more detail. The first thing to address is this idea of flipping the sign of the component associated with the secret key. That might feel a little bit weird. Why would we assume that that operation is available to us? Backing up, remember that Grover's algorithm is meant to apply to any problem where you can verify a solution quickly, even if finding a solution in the first place is hard. Examples here would include solving Sudokus, finding a valid coloring of a map where no two border regions share a color, or countless tasks throughout cryptography, where security often depends on a certain value being hard to find, even though for pragmatism it has to be easily verifiable. We began this video with a generic stand-in for all of these problems, where you imagine some function that takes in any number from 0 to n-1 and returns true on one and only one of those. In principle, we'll think of such a function as being built out of a bunch of classical logic gates. Those logic gates act on some binary representation of the inputs, and the final output is either 0 or 1. Now here's the key point. Grover knew that given any ensemble of logic gates like this, you can translate it into a system of quantum gates so that if in the classical case the function takes in some binary input and returns a 1, for true, then in the quantum case the effect of all of these gates is to flip the sign of that state, the state associated with the same bit string. Similarly, if in the classical case the function maps some binary input to 0, for false, then in this quantum translation the effect on the corresponding state would be to leave it unchanged. More generally, because all of these quantum operations are linear, if the state is a combination of multiple pure coordinate directions, then the effect is to simply flip the sign for the component associated with whatever bit string triggers that classical function. It means that if you have any NP problem, anything where you can quickly verify solutions, you're able to create an operation on a quantum computer that flips the sign of a state vector at the position corresponding to a solution of that problem. This might feel kind of useless at first. After all, flipping signs doesn't affect the probabilities. But Grover realized that this could be used in conjunction with another step that slowly amplifies the probability of that key value. There's actually a really nice way to visualize his algorithm. To set it up, let's imagine that our state vector has only three dimensions. Obviously in principle it would be way bigger, but this lets me draw the first picture. The three directions here would correspond to the values 0, 1, and 2, and the whole problem statement here is that one of those values would be a secret key that we're searching for. Many different quantum algorithms will begin by putting that state vector into a kind of equal balance, where all of the components have the same value. I want to give that equal balance vector a name. Let's call it B. I hope you don't object too much to me simply declaring that this is possible without dwelling on the underlying quantum gates that make it happen. In this case it essentially looks like a big pile of Hadamard gates, but all you need to know is that this equal balance direction is abundantly accessible. So starting from here, the goal is to somehow coerce this vector to instead point up in that secret key direction. And what's very helpful for the visualization purposes here is that throughout Grover's algorithm, the vector only ever moves inside the 2D plane that's spanned by these two vectors. So what I'm going to do is draw everything on that two-dimensional slice. And this is going to give us a faithful representation even when the full dimension is way too big for me to draw literally. The convention I'll use here in drawing that slice will be to put the secret key direction, whatever it is, along this y-axis, and then the x-axis is going to represent something that's an equal balance of all of the other states, the non-key states. So in our very small three-dimensional example, if that secret key was the 2 state up in the z direction, that would mean this perpendicular is an equal balance of 0 and 1, which sits on the xy plane perpendicular to that z-axis. Notice the fully equally balanced state, b, has some component in that secret key direction, since by its definition it has a little bit of that secret key within it. Instead of drawing this slice from three dimensions, here's what it would look like if it was taken from some larger number of dimensions. It's almost identical, but the main difference is that that equal balance state vector gets closer and closer to being perpendicular to the secret key direction. Crucially though, this angle is never quite 90 degrees, since that balance state always has a little bit of that secret key value inside of it. In fact, calculating this angle is going to be essential for understanding the runtime of Grover's algorithm. This is the main bit of math you actually have to do for it. You can find this angle by taking a dot product between the balance state and the key direction. The components of that balance state vector are all going to look like 1 divided by the square root of n, since remember it needs to be true that when you add the squares of all of these, it would give you 1. Since the key vector is 0 almost everywhere but 1 in one of the components, it means that the dot product between these two is 1 divided by the square root of n. If you know a little about dot products, you'll know that this is also the cosine of the angle between those two vectors. I'm going to translate this fact a little to make it more useful for our purposes later. This is the same as saying the sine of the complementary angle down over here, which I'll call theta, is 1 over the square root of n. For really small angles, the sine of theta and theta are approximately the same, so if n is very large, we can safely say that this angle is about 1 divided by the square root of n, as long as it's measured in radians. This value for theta is ultimately where the square root in the runtime is going to come from. So let's remember it. I'll throw it up in the corner here. Okay, having spent a while setting up the actual picture, let me show you the procedure here. It's surprisingly simple. Remember that key operation we were looking at earlier? The one where you take the verification function for whatever NP problem you're trying to solve, and you translate it into some quantum gates, and the effect is to flip the sign associated with that key value? Well, what does that look like inside our diagram? In this diagram, if you flip the sign for the component associated with the key value, but all other components stay the same, what it looks like is flipping about the x-axis. And the final ingredient you need to know is that it is also possible to flip this state vector around this equal balance direction. I realize it might be a little unsatisfying for me to keep declaring that certain operations are available, but one thing to know is that in general, if you can clearly describe and access one of these state vectors, it's also perfectly possible to reflect around it. There are some quantum gates, they let you flip around this balance direction, but trust me that dwelling on the details of how those look isn't really going to add much clarity or intuition to the whole algorithm. The insight really just comes from geometry. Notice how if you first flip around the x-axis, and then flip around this off-diagonal direction, the state now points slightly more in the vertical direction. If you were to read out from memory now, you would have a slightly larger chance of seeing the secret key value than all the others. Here, maybe it's helpful if I show the actual coordinates, in this case where n equals 100, along with some probability bars based on the squares of those coordinates. Notice how each time I flip around the x-axis, and then flip around this off-diagonal axis, the component associated with that secret key gets a little bit larger. So Grover's algorithm is remarkably simple. All you do is repeat this over and over until the vector points as close as it can get to the secret key direction. The final bit of reasoning you have to do is to figure out how many repetitions that should be. A wonderful fact from geometry is that if you successively flip about two different lines like this, the overall effect is the same as a rotation, more specifically a rotation by two times the angle between those two lines. So in our case, applying the two operations we have available one after the other, the net effect is to rotate the state vector by two times theta, where again theta is that little angle that we calculated earlier, approximately one over the square root of n. The ultimate goal is to rotate our initial state a little under 90 degrees, or about pi halves radians. This means the optimal number of repetitions looks like pi halves divided by two theta, which is pi fourths times one over theta, and critically, because theta is about one divided by the square root of n, it means the total number of steps looks like pi fourths times the square root of n. So what Grover's algorithm says is first find whatever whole number is closest to this value and then repeat your two available flips that specific number of times. As a concrete example, let's say that n was two to the power of twenty, meaning you're searching for a secret key out of about a million options. You would be running this on a computer with at least twenty qubits, and what the algorithm would say is first compute pi fourths times the square root of this number, which is around eight hundred and four, meaning you now repeat those two operations you have available, the one flipping the sign of the key state and the one that's flipping around the balance direction eight hundred and four times. Now remember, this state vector is invisible to you. There is nothing that you can do that will read out the values that it has. You instead have to infer where it must be through reasoning, and in this case, through all the geometric reasoning, you can conclude that after this specific number of times, the vector should be pointed almost entirely in that secret key direction. So when you read out from the computer, you are almost guaranteed to see that secret key value. Now to be clear, you're not guaranteed to see it. There is some small chance that after reading out, you would see something that's not the secret key. So to be sure, you could always quickly verify the answer, since after all, the whole premise of this situation is that you have some quick way of verifying answers. You can just do that on a classical computer. Worst case, if you got unlucky and sampled a different number, you run the whole thing again, and it becomes vanishingly unlikely that you would ever need to run this more than just a couple times. To wrap up, I want to come clean about a lie that I've been telling you, and also reflect a little bit about where this speedup came from, and then highlight a surprising analogy. Before I do, now might be as good a time as any to say a thanks to the community of channel supporters on Patreon. Putting together visualized lessons like this takes an enormous amount of time. As you probably know, most YouTubers monetize their content with in-video sponsorships, but for many years now that's something that I've opted to decline. I think it makes the videos better, and the only reason it's not a wildly costly decision is that enough viewers who agree with that directly support the channel through Patreon. In exchange, I offer supporters early views of new content, which is actually very helpful for developing it, and there's other perks in there too. In general though, if you like this content, it would mean a lot if you considered joining. No pressure though, one of the big values is that the content can be free. Anyway, back to those three finishing points. The lie is a lie by omission. I've been showing these state vectors with positive and negative real number values, but more generally, these components can be complex numbers. Now my hope is to motivate why that's the case in the follow-on video about physics. The general idea is that any time you're working with waves, you care about both amplitude and phase, and a complex number is a really elegant way to encode an amplitude and phase together. So if you look at one of the components inside the state vector, the fuller picture for how to think about it is that it has some magnitude and some phase. The magnitude is the thing that you square to get the probability, and the phase is essentially a more general version of our whole discussion here around positive and negative values. Changing phase doesn't immediately affect the probabilities, but it does affect the state, which in turn affects how it gets processed and how it interacts with the world. Now needless to say, throwing in a bunch of complex numbers adds a lot of potential confusion to an already complicated topic. That's why I avoided it. But we were safe to ignore complex values for the purposes of Grover's algorithm, since very mercifully, during that algorithm, you only ever see positive and negative values. I want you to know, though, that this availability of complex values plays a crucial role in other quantum algorithms, like Shor's for factoring numbers. Next, even if you understood everything that I described with this whole algorithm, it's not easy to summarize where exactly the speedup came from. The fact that you begin by applying a certain operation to this equal balance state makes it very tempting to say that the speedup comes from parallelizing the operation over all possible inputs. But like I mentioned at the start, that summary, at least to me, just really doesn't feel right, and it definitely leads to misconceptions. As you now know, that step, on its own, does nothing to reveal the key value. I'll leave it up to your interpretation whether it feels apt to describe this first step as applying a function to many inputs in parallel, or if it feels better to say that the balance state is just its own new thing, and the function we have always applies to individual inputs one at a time, never multiple at once. It's just that those inputs are now a new kind of thing. In my view, for this algorithm, if you want the one-word summary for where the speedup comes from, I think a better choice would be Pythagoras. As a loose analogy, if you want to get from one corner of a unit square to the opposite, if you're limited to move only in the x and y directions, you have to walk two units. But if you're allowed to move diagonally, you can get there in the square root of two. And more generally, if you're up in n dimensions, you would have to walk n units to get from one corner of a cube to the opposite one if you can only move along the edges, but if you can go diagonally, you can get there in the square root of n. In the worldview of quantum mechanics, different observable states all represent perpendicular directions in some state space. So viewed from this framework, what the classical deterministic world looks like is one where you only have access to these pure coordinate directions. If you think about it, anytime you're doing computation, your computer is somehow walking through a series of different states that are available to it, and algorithmic runtime is all about understanding how many steps you have to walk in the space of all possible states. So from this quantum worldview, where classical states look like pure coordinate directions, the key difference with quantum computing is that you now also have available to you a panoply of additional diagonal directions that you can work with. Now, to be clear, the analogy is not too literal, you should take it with a grain of salt. It's not like runtime necessarily looks like a distance travelled through this particular state space. But it is true that if you follow the state vector throughout Grover's algorithm, what it's doing is slowly walking along a quarter circle arc from an initial condition to the target condition, tracing a path that would be entirely unavailable if you were limited to move only in pure coordinate directions. And the effect is to provide this square root-sized shortcut. And as the very last point before I let you go, regular viewers will know that one of my reasons for covering this topic is because of a promised analogy between this algorithm and something we covered last video, about two colliding blocks that can compute pi. In that video, we are also studying a point in a certain two-dimensional state space bouncing around a circle, and in fact, the series of bounces that it took is essentially identical to what we just saw here with Grover's algorithm. The story here is that when a physicist friend of mine, Adam Brown, saw the first version of that video, he had recently been reading up on Grover's algorithm and immediately realized that both processes were identical. Now I had this whole cockamamie plan for this video where I was going to explain quantum computing and Grover's algorithm in the context of that analogy, but it turned out to be just a terrible idea. The whole thing only really made sense if you already understood Grover's algorithm. So instead, now that you have seen both topics in isolation, what I'll do is leave up a rough outline of how the analogy looks. Think of this as an open-ended homework puzzle, where the task is to draw the connection for yourself. As an answer key of sorts, I will link to the very delightful paper by Adam Brown outlining precisely what that analogy looks like. If you want to learn more of the fundamentals of quantum computing, several years ago two very smart friends of mine, Andy Matuszczak and Michael Nielsen, put together a really nice resource for learning the topic, offering a pretty unique approach to making sure that you actually remember it in the long term. To learn some of the fundamental quantum mechanics, Mithina Yoganathan from the channel Looking Glass Universe has been putting together a very beginner-friendly course on the topic. She was actually the one to teach me how Grover's algorithm works many years ago, and honestly I owe a lot of the content of this video to many helpful conversations with her. And as a very last note to end on, one of the conversations I had while making this video was with Scott Aaronson, a very widely respected researcher and utterly delightful author on the topic. I recorded the Zoom call for notes, and there's one little piece of it which I just wanted to share with you. You know, I have this dream of writing a science fiction novel where I know it's going to be the climactic scene, where the heroes will be, you know, Ron and Grover's algorithm to try to find this cryptographic key, right? The whole fate of the world will depend on whether they can find it, OK? The bad guys have surrounded their base, you know, they're bashing down the walls. But Grover's algorithm is still running, and it has only like a 30 percent probability of giving you the solution if you measure. So the question is, like, do you measure now or do you let it run for another minute? Right? And if you measure now, you know, and you don't get it, then you've lost everything. Then you have to restart from the beginning. So this is this is not a plot that you could have with any classical algorithm. Right.

================================================================================
VIDEO ID: XX8mjBXBqz8
TITLE: Testing your intuition for quantum computing
URL: https://www.youtube.com/watch?v=XX8mjBXBqz8
PUBLISHED: 2025-04-30T12:32:13Z
STATUS: SUCCESS
================================================================================
Let me show you a quiz that most people get wrong. Imagine I have a function and there's going to be one special number where if you input it to the function it returns true, but on all other inputs it returns false. And let's say you know that special input is somewhere among the first n numbers. If you want to find that special value and the only thing you're allowed to do with this function is to simply try it out on inputs, then there's really no better method than guessing and checking. On average, this would take n half steps. And following the CS convention of disregarding constants like that 1/2, people would call this a runtime of big O of N. Now, here's your quiz for the equivalent version of this question, but in a quantum computer, where you're given a function that is in a certain sense triggered by one unique value out of the first n numbers. How many times would you have to use this mystery function to be able to find that mystery value? I threw this quiz up as a YouTube post giving the options of O of roo of N, O of log of N, O of log of log of N, and O of 1. To be fair, without defining quantum computing or defining what this function would look like in that context, the question is not really coherent, but it's meant as a gut check. In the responses on YouTube, and also many other times that I've presented this as a live talk, the two most common answers are not correct. I just put up a full video describing how quantum computers would actually approach this problem. If you just want the answer to this quiz, you can jump to the timestamp 350. Now, I realize you're probably in a little bit more of a scroll through short content on your phone mood right now, but if at some point you want a halfhour explainer for the fundamentals of quantum computing walking you through a specific algorithm, well, that full video will be there waiting for you.

================================================================================
VIDEO ID: aQwEJKWATlE
TITLE: How to measure nearby galaxies
URL: https://www.youtube.com/watch?v=aQwEJKWATlE
PUBLISHED: 2025-04-20T19:36:10Z
STATUS: SUCCESS
================================================================================
I had the joy of interviewing Terren Tao about cosmic distances. For example, here's how people first learned the distance to nearby galaxies. In a galaxy, most stars, you cannot measure the brightness of a sing of a single star because there's just billions of them all crammed at the same place. But there are some amazingly bright stars. They're called Sephi, the super giant stars that are thousands of times brighter than the sun. Some of them live in our own galaxy and some of them live in other galaxies there. They still blend in, but but you can still kind of measure their brightness. These stars are what are called variable stars. Um so most stars they stay the same intensity for all time but these sephied stars their their brightness oscillates so they have a period of intensity like every 20 days every 10 days they oscillate and it turns out that the bigger the sephiid the brighter it is the longer the period if a galaxy happen to have a seed in it you can just observe it work out its period that gave you intensity that know so now you know how bright it should be and you know how bright it looks you can measure it distance that gave the next rung of the ladder so a couple thousand galaxies where you can measure the distance. But that again is only a tiny portion of the universe.

================================================================================
VIDEO ID: aw-8BhCilj0
TITLE: Measuring the distance to Venus without radar
URL: https://www.youtube.com/watch?v=aw-8BhCilj0
PUBLISHED: 2025-04-08T13:45:00Z
STATUS: SUCCESS
================================================================================
These days, we can measure the distance to nearby planets like Venus using radar. But the way that people measure this distance for the first time in history is absolutely amazing. The basic idea here is analogous to how when your two eyes are looking at an object based on the angle that each one of them has to turn to see it, your brain can deduce how far away that object is. For some nearby object in the sky, as you sail down to the southern hemisphere, it will appear higher up in that sky relative to, say, the background constellations. The angle of this line of sight changes with position. We call this parallax. Now, the way I'm drawing it here, it makes it look almost easy. But for the real world measurement, you have to keep in mind just how far away everything is. The nearest planet, Venus, when it is at its absolute closest to Earth, it's around 39 million km away, which is over 6,000 times the radius of the Earth. So if this is going to work, your measurements have to be extremely precise and you have to be absolutely sure that both observers are really looking at the same thing at the same moment. Now at the time clocks were not good enough that they could actually just say at this specific time make it measurement. Also, you're not guaranteed that um you can even find the planet and so forth. But um there are these transits. There's this thing called the transit of Venus. Sometimes Venus travels um along the the sun. So up in the northern hemisphere, if you're watching the transit of Venus, maybe it looks something like this. and far away at some point down in the southern hemisphere. Due to parallax, Venus would appear higher up. And you essentially want to know exactly how much higher up. Now, this animation is greatly exaggerating the difference. In reality, the two would look much, much more similar, more like this. And remember, there was no photography, so it's not like they could take pictures and closely compare them. Each observer would not try to directly describe where it was. Instead, they would measure the duration of the transit, how long it takes from the moment that Venus's silhouette first appears on the disc to the moment that it leaves. Because if you compare those two durations, it'll tell you the ratio of lengths for these two lines across the sun's disc. They were very close but discernably different. And this in turn lets you deduce the ever so slight change in viewing angle. And then like we discussed that angle deviation can tell you how far away Venus is at that moment in terms of the distance between those observers. That is just really clever to me.

================================================================================
VIDEO ID: M6LUPYsjods
TITLE: Measuring the speed of light using Jupiter's moons
URL: https://www.youtube.com/watch?v=M6LUPYsjods
PUBLISHED: 2025-04-07T15:57:13Z
STATUS: SUCCESS
================================================================================
Observing the moons of Jupiter was key to one of the most important discoveries in the history of physics. You see, Io goes dark when it falls into Jupiter's shadow, which it does every cycle cuz Jupiter is just so big. As it emerges, it becomes bright again. Watching it through a telescope night after night, you can mark the exact time that it pops back into view. And if you go out with a telescope and you do this a whole bunch, what you'll notice is that these happen in 42-hour increments, like clockwork. Except that it wasn't clockwork. And different times of the of the year, Io was ahead of schedule, IO was behind schedule. So again to draw a picture, Earth goes on the sun. Jupiter also goes on the sun. Yeah. So when you imagine the orbit of Io, um it was 20 minutes ahead of 20 minutes earlier when the Earth was on the same side as as Jupiter. Then when the Earth was on the opposite side of Jupiter, it took 20 minutes longer. There was a delay in the orbit. So he measured this up after some very precise calculations and Huygens realized that the reason for this is because light was taking 20 minutes to traverse this extra distance. So two astronomical units is traversed in about 20 minutes. That's so clever. Yeah. Yeah. Yeah. Yeah. Yeah. At that time they didn't actually know the true astronomical unit. So their estimates for the speed of light frankly don't look that impressive if you see them. But at that time, it was not even obvious that light had a speed. For most experiments you could do down on Earth at that time, it just looks instantaneous. But at astronomical scales, it's actually really slow. And this very clever way to measure its speed by observing Io, imprecise though it was, laid the groundwork for more precise experiments down on Earth once people had at least a rough sense of how fast it really size.

================================================================================
VIDEO ID: mHya9J9pkq4
TITLE: The tragic tale of Guillaume Le Gentil
URL: https://www.youtube.com/watch?v=mHya9J9pkq4
PUBLISHED: 2025-03-27T16:01:04Z
STATUS: SUCCESS
================================================================================
I simply have to tell you the story of Guom Le Jantil. He was another explorer also tasked with making one of these measurements for the transit of Venus. Now remember the reason people cared so much was that having this one measurement was enough to lock in place the scale of the whole solar system. So once they had it, they would automatically know every other distance involved. Specifically, he was going for the one in 1761. But he was delayed by the 7 Years War and still at sea when the transit happened. So he was unable to make the measurement. Now, the next transit of Venus was going to be 8 years later, but after that, it wouldn't be for another 105 years. So, he decided to extend his journey, do a bunch of other explorer things, and catch the next one. And by 1769, he was all set up in the Philippines, ready to go. But on that day, it was cloudy, so he couldn't see anything. Once he finally got back to France, he found that he had been declared dead, his wife had remarried, and his relatives had all plundered his estate.

================================================================================
VIDEO ID: C8baNzpnZ7o
TITLE: Zooming out by powers of 10
URL: https://www.youtube.com/watch?v=C8baNzpnZ7o
PUBLISHED: 2025-03-26T18:37:29Z
STATUS: SUCCESS
================================================================================
this animation zooms out by a factor of 10 every 3 seconds it was made by my collaborator Paul dstep as part of a pair of videos on how we know the distances to various objects in the cosmos and on the one hand I think it does it very well notice for example how as we depart the solar system we pass through these many seemingly blank orders of magnitude before we even see the first star now on the other hand I think these kinds of powers of 10 Zoom outs can risk underselling the true Scale of the Universe if you think about it the implied camera position is moving just so so much faster than the cosmic speed limit the speed of light and it makes the distant objects like other galaxies feel almost accessible when in fact it would take around 2 and 1/2 million years to even reach the nearest galaxy if you were traveling at the speed of light I'll also be honest with you we struggled a lot with how exactly to end this zoom out cuz we wanted to remain scientifically accurate without falling too deep into that trap of doing artists Renditions of the universe ultimately what I settled on was doing a simple Point Cloud representing data pulled from the slone galactic survey which essentially Maps the distances to various galaxies at many different directions you could point in the sky I find it a mindboggling testament to the powers of Science and deduction that this is even possible that despite the fact that all these galaxies are so many millions and billions of light years away from each other that they are completely beyond our grasp we can nevertheless map them and and study patterns like the Clusters and strands that these billions of galaxies form in the vast reaches of unfathomable space

================================================================================
VIDEO ID: 6dTyOl1fmDo
TITLE: There's more to those colliding blocks that compute pi
URL: https://www.youtube.com/watch?v=6dTyOl1fmDo
PUBLISHED: 2025-03-13T15:36:52Z
STATUS: SUCCESS
================================================================================
In 2019, I put out a video about how two colliding blocks can compute pi. It's very fun, very surprising, and if you include the adaptations into shorts that I've posted since then, it is the most popular thing that I've put on the internet, and by a pretty wide margin. This year, for Pi Day, I want to revisit this topic, because there's actually a lot that I never talked about in the original video, including a fact that I didn't know when I first posted it, and which I suspect no one in the world knew, which is how this is all secretly connected to quantum computing. More specifically, something known as Grover's Algorithm for Search. Also, the whole crowd pleaser is that this is connected to pi, but very technically speaking, that full connection to pi is an unsolved problem. I'll explain what I mean at the end here. Just to recap, in case you haven't seen it, the setup of that original video was to have two blocks on a frictionless plane. At the very beginning, the one on the left is stationary, and we'll think of it as smaller, maybe 1 kilogram, and the block on the right is coming in with some speed. The two blocks bounce off of each other, there's a wall to their left, and the puzzle is to figure out how many total collisions would take place, including the collisions with that wall. So for example, in the smallest case, where both blocks have the same mass, with each collision all of the momentum gets transferred from one block to the other, and including that one clack against the wall, the final count is 3. If that right block is bigger, maybe 100 kilograms, it means it has a lot more momentum when it's coming in, so it takes a lot more collisions to fully redirect that momentum. In this case, with a mass ratio of 100 to 1, the total number of collisions is 31. For an even bigger mass ratio, let's say 10,000 to 1, that little block ends up getting really crammed up against the wall, and almost all of the collisions happen in this rapid burst right in the middle. In this case, it takes over 300 in total to turn that big block around, and after another nice, long pause, as if the universe has a strong taste for drama, we see that the exact answer rolls in at 314, a number with eerily familiar digits. I do want to highlight a couple unrealistic things about this puzzle, the kind of nuances you can't fit into a short. When this big mass is growing, that burst of collisions in the middle just gets more and more concentrated. So in order to get the delightful result here, we have to make a number of idealizing assumptions. One assumption is that no energy is lost in the collisions. Physicists would call those perfectly elastic collisions. And the astute viewers would then be raising their hands and complaining, well hang on, shouldn't that mean we don't hear any sounds? And this is true. I'm throwing in the sounds as an artistic choice, partly because I like it and it makes it kind of fun. But more substantively, I think it's otherwise really hard to communicate purely visually just how dense that burst of collisions in the middle is. Like here for example, with a mass ratio of a million to one, that burst contains almost 3,000 collisions, and the final count comes in at 3,141. Now as that big mass gets even more massive, that little block would have to move so quickly during that little burst that a physically accurate analysis should start to take into account relativistic effects. And there's just so many other practical realities that would cause everything here to break down completely. But we're going to be ignoring all of that. We'll only be treating this as a pure, overly idealized classical physics puzzle. Because when you do, the big surprise is that as that large mass grows by powers of 100, the total number of collisions always has the same digits as pi. Now, even if this gets unrealistic for big mass ratios, you can actually see it in practice for smaller ratios. This footage here for example comes from a group of students at the University of Bonn demonstrating how when the mass ratio is 100 to 1, you really do get 31 collisions. Also, Matt Parker just put up a video about the attempts that he and I and a couple others had to do so at Cambridge. Like I said, this pure puzzle, unrealistic though it might be, is secretly connected to quantum computing. And believe it or not, studying this I think puts you in a good position to understand what quantum computing even is. As a little bit of foreshadowing, some of you might have been wondering why it is that to see pi you have to increase by powers of 100 as opposed to powers of 10, since we work in base 10, maybe that's what you would expect. And the answer to that question is intimately connected with the fact that for quantum computers, search algorithms can be faster than they are for classical computers. I recognize that sentence probably sounds like complete nonsense, but bear with me here. I promise you, I will do my best at explaining this connection, but the thing is, the only way to do it is to have the solution to the original block collision puzzle loaded in your head, ready to make comparisons. So here's the game plan. I'm going to break this all down into two different parts. In this video, you and I will step through how you could discover for yourself what this number of collisions is, and, pertinently, why it would have anything to do with pi. This is essentially a second edition of the solution video I put out back in 2019. I wanted a chance to explain it better, tee things up for that quantum connection, and also to highlight a number of details that I neglected in the first one, like the sense in which this is technically an unsolved problem. Then in the next video, with some help from my theoretical physicist friend Adam Brown, who noticed this connection, I'll explain the basics of quantum computing, what Grover's algorithm is, and how these two seemingly completely unrelated topics are secretly the same thing. What makes this puzzle great, aside from the surprising pi, of course, is how well poised it is to be a general problem solving lesson. Very often when I present this as a lecture, I like to start by inviting the audience to begin by listing out a few general problem solving principles. You might enjoy thinking of a few of your own, and as we go through, I'll highlight a couple that I have written down here. For example, one that's seemingly trivial but surprisingly useful is that if you're stuck on a hard problem, and I would consider this a hard problem, it never hurts to just list any equations or theorems that might somehow be relevant. So for this puzzle, where we have some colliding blocks, two relevant laws that might come to mind, especially if you have a recent physics class somewhere in your history, would be the conservation of energy and the conservation of momentum. The energy of one of these moving blocks would be Â½ times its mass times its velocity squared. So let's say we call the mass of the big block m1 and call its velocity v1, and likewise the mass of that little block will be m2 and its ever-changing velocity will be v2. Then the total kinetic energy between these two blocks is what you get by plugging in the numbers and adding these two quantities. The conservation of energy essentially says this number won't change throughout the experiment. Those two velocities will change, but they have to do so in such a way that this whole expression equals the same number. This is all, of course, assuming that no energy is lost to friction or to the collisions. The other quantity that's conserved is momentum, and the momentum for each block looks even simpler, it's just its mass times its velocity. So again, when you plug in the numbers and compute this expression, you'll get something, and what the conservation of momentum tells us is that whatever that number is, it doesn't change even after the blocks collide with each other. Now, unlike energy, this momentum expression will actually change after that little block collides against the wall, because really what's going on is it's transferring some of its momentum into that wall. Technically speaking, that should mean the wall starts moving a tiny amount, but again, we'll be idealistic and assume the wall is supermassive or fixed into the earth, and any movement that it has is negligible. Another principle I have up here is to just draw pictures. When you're trying to figure something out, actually make some figures. Visual intuition can help to think about things in different ways, and sometimes staring at the right diagram can expose a solution. So in this context, where the two values that are changing are v1 and v2, you might be inspired to draw a coordinate plane, where the x-coordinate encodes this value v1 and the y-coordinate encodes this value v2. Just to be crystal clear on what I mean by that, as the experiment unfolds and the blocks collide with each other and their two velocities change with each collision, this little point inside our space is going to move around that space as those two velocities change, always doing so in such a way that its coordinates tell you what v1 and v2 are. The hope is that as the whole experiment unfolds and we consider how exactly this point bounces around this slightly abstract velocity space, studying the path of that point can maybe yield insights about the underlying dynamics for the blocks. Even though we're just getting warmed up, this really is the key step in our whole problem solving process, and it's a pretty common thing to do throughout physics, where if you have some dynamical situation with multiple numbers that are changing, when you package all those numbers together as a single point in a higher dimensional space, studying how that point moves through the space has a way of clarifying the whole problem. You could call this a state space, and this particular state space for us holds within it the key connection to the quantum computing parallel that we're going to be building up to. Now, in the context of this abstract velocity space, take a moment to think about what this conservation of energy equation is really telling us. When you take some number times x squared plus some number times y squared and set it equal to a constant, this is the equation for an ellipse. Our specific ellipse will be more squished in the x direction, since that number sitting in front of x is larger than the number sitting in front of y, and the size of the ellipse will depend on the total energy of the system. And this comes from what the initial velocity of that big block was, and interestingly, I never told you that velocity. It doesn't actually change the final answer. Whether it comes in fast or it comes in slow, you get the same total number of collisions, the experiment just unfolds more quickly or more slowly. As our experiment unfolds and that pair of velocities changes, it always does so in such a way that this point inside our state space stays constrained to this ellipse. If it landed anywhere else, it would mean energy was not conserved. Another principle I want to bring up here is how math and math-adjacent fields tend to reward you when you respect their symmetries. In this case, we already know that pi is going to be somehow relevant to the answer, and pi has everything to do with circles, relating distances around the circumference of that circle to the radius. On our hunt for pi, it's tantalizingly close to be working with an ellipse like this, and you might feel like it would be all the more natural and maybe more promising if this was instead a circle. We can actually make this into a circle just by changing what the coordinates of that state space represent. Here's what I mean by that. The equation for a circle looks like x2 plus y2 equals some constant, without any numbers sitting in front of those variables. If I let x not represent v1, but I let it represent the square root of m1 times v1, then x2 gives us something that looks like 2 times the kinetic energy. And similarly, if y represents the square root of m2 times v2, that y-coordinate also more directly captures the energy of the little block. This equation for the circle, x2 plus y2 equals some constant, now captures the conservation of energy, but in this rescaled coordinate system. Like I said, the hope is that adding a little more symmetry will make our problem easier to solve, and in a moment you'll see how this is true. Let's take a minute to get a little familiar with what this diagram is really telling us. For example, at the very beginning, that big block has a negative velocity, so we must be somewhere on this left half of the plane, and that little block starts off stationary, meaning the y-coordinate is zero, and so we have to start out at the leftmost point of this circle, that's the initial condition. Now after they collide with each other, what happens? Where do we end up? Well, physical intuition tells us that that little block picks up some kind of negative velocity, so we're going to have to end up somewhere where the y-coordinate is negative, and that big block loses some of its momentum, so the x-coordinate is going to get a little closer to zero from where it was, even if you don't know exactly how much. And again, we have to stay somewhere on this circle. The circle represents all the points that have the same total energy, and so you might guess that our point lands somewhere on like this arc right here. To be more exact, we need to introduce the second conservation law, the conservation of momentum. Keep in mind though, at this point I've changed what the coordinates mean. So in our new coordinates, the momentum of the first block looks like the square root of m1 times x, and the momentum of the second looks like the square root of m2 times y. It's all saying the same thing, it's just a different coordinate system, and those masses are just constants anyway. The significance is that this whole equation is a linear equation in x and y, so in our diagram it's going to look like some kind of line. More specifically, you can work out it's a line whose slope is the negative square root of the big mass divided by the small mass. Now this slope is going to be very important for us, it's the key quantity that we'll use to get the numerical answer that has digits looking like pi, and that square root is going to be very important for us later when we get to the quantum computing case. So remember this expression. Where this momentum line sits left and right depends on what the total momentum of the pair of blocks is. We know that we start off on this leftmost point of the circle, so the line has to pass through that point. Every other point on this line is telling us every other pair of velocities that would have the same net momentum. And as you've no doubt noticed, this line intersects the circle at exactly two places, meaning there are only two pairs of velocities out there with this same kinetic energy and the same momentum as the initial condition. So after the blocks bounce off of each other, we must hop over to this other point. And honestly, that is most of the physical reasoning for this whole problem. Everything that's left is to just see how this unfolds and try to reason through what it implies. For example, that little block bounces off the wall, and all that does is flip the sign for the y coordinate. It goes from being negative to positive, the x coordinate doesn't change because nothing has influenced the big block. This has caused a change in the net momentum since some of it went into the wall, so our momentum line actually has to move over to the right however far it needs to move so that it passes through this new point. And then when the blocks bounce off each other, again we look for the other place where that diagonal line intersects the circle. And you basically keep playing this game. Little block bounces off the wall and that moves you up, blocks bounce against each other, that moves you down and to the right, and you just keep going untilâ€¦ well, until what? Exactly. The experiment can't be done until both blocks are moving to the right, so you have to be in this quadrant here where the x and y coordinates are both positive. And also to be done, that little block has to be moving slower than the big block, meaning you sit somewhere below this line where v1 equals v2. Inside our new coordinate system, that's a line who has a slope equal to the square root of m2 over m1, it's actually a line perpendicular to those down and to the right ones that we had been drawing. And let's go ahead and label this little green region the end zone, meaning when our state space point lands here, the whole experiment is done. With all of that, what we've done is translated a physics question into a pure geometry question, one that's hopefully a lot easier to solve. Our new puzzle is this. Imagine I said we have a circle. You start at the left most point of that circle and your first move is to travel down and to the right along a line with some specific slope. Here I'm drawing a slope of 4, but it could be anything. Then you move straight up until you intersect the circle, and then down and to the right with that same slope, then straight up, down and to the right, over and over and over until you end up inside this end zone. The puzzle is, how many lines do you draw? How many times do you zig and zag throughout this process? Of course, the answer depends on the slope. If you have a steeper slope, you end up with more total lines. And the one connection that we have to the original physics is that this slope comes from the negative square root of the mass ratio. For example, when the big mass is 100 and the little mass is 1, that square root of the mass ratio looks like 10, so the slope is negative 10. And in fact we do get 31 lines, corresponding to the 31 collisions that those blocks have. It still might not be obvious how you count those lines, but it's certainly a lot less surprising that pi is relevant to the answer, and abstracted away from the physics, it is an easier question to solve. If you just stare at this diagram and you're the right combination of lucky and clever, here's something you might notice. Consider all of the points where these lines hit the circle, and consider all of the arcs along the circle in between those points. You might notice those arcs seem to be about the same size, and you might hypothesize that all of these arcs are in fact exactly the same size. This does turn out to be true, and you can prove it using the ever useful and ever delightful inscribed angle theorem. For anybody who's a little bit rusty on this one, the setup is to have three points on a circle, which I'll call P1, P2, and P3, and we care about the angle between the line from P1 to P2, and the line from P2 to P3. It turns out, no matter where you place these points, that angle is exactly half of this angle right here, from P1 to the center to P3. It's really quite fun, you can imagine moving around these points however you want, you just have to make sure P2 never goes on that arc between P1 and P3. In our little circle puzzle, think about how this might be relevant. And maybe it helps if you focus on two different lines and the one arc of the circle connecting their endpoints. These lines are separated by some angle, I'm going to call it theta, that angle is dependent just on the slope of the line, and using the inscribed angle theorem, we know that that arc along the circle must run across an angle of exactly 2 times theta. Critically, it didn't matter which two lines I happened to highlight here. In all cases, that angle between the vertical line and the ones down and to the right is the same, since the slope was always the same, which means all of these little arcs along the circle cover an angle of exactly 2 theta. You might ask why this is helpful, how does this expose the number of lines? And here's a way to think about it. As you play this game of bouncing down and to the right, going straight up, down and to the right, with each one of your moves, you can imagine dropping down one more of these arcs, one more little segment of circumference covering 2 theta radians of angle. Now it's not too hard to show that this condition of falling into the end zone, a region bound by this line perpendicular to all of our down and to the right lines, well that happens exactly when you've dropped so many arcs that if you tried to drop one more with the same length of 2 theta, you would necessarily cause some overlap. Essentially, it happens when you've filled up the circle as much as you can using pieces of this size. So how many arcs in total have we dropped down? Well that's the same as asking how many times can you add some little value 2 theta to itself up until the point where adding one more would bust you over the total circumference of the circle. And that total circumference covers an angle of 360 degrees, or 2 pi radians. Phrasing things slightly differently and dividing out by that too, what is the biggest number that you could multiply by this angle theta such that it stays smaller than pi? For example, imagine we were in a situation so clean and so beautiful that that little angle theta worked out to be exactly 0.01 as measured in radians. The biggest number we could multiply it by would be 314, because that gives us 3.14, and if we tried to bump up the number one more, that would be 3.15, which is bigger than pi. And more generally, if that little angle is some small power of 10, then this maximum number has the same digits as pi. I mean, this is what digits even mean. When you say pi is equal to 3.141, what you're saying is you can fit in 3,141 thousandths and adding one more would bust you above pi. At this point, maybe you're stepping back and saying, great, I see where this is going. In the case where the mass ratio is a power of 100, it's going to work out that that little angle is a clean power of 10, and because of all of this state-space circle-puzzle reasoning, that will explain why we see pi. This is almost true, but that's just not quite how it works out. And to make sure all of this is genuinely satisfying, let's take a little moment to really think through the last step here. Remember how I said that the slope, not the angle, mind you, but the slope, looks like the negative square root of the mass ratio? So in our example where that mass ratio was 100 to 1, the slope looks like negative 10. Well, what is slope? What is that telling us? It's the rise over run, which is the change in y divided by the change in x as you move along this line. Now, how does that relate to that little angle that I drew before? Well, the tangent of that angle, opposite over adjacent, is going to look like that change in x divided by the change in y. I'm putting a little negative sign in front of that y because in this diagram, that change in y is negative, so we want to counteract that. The tangent of this angle should be a positive number. This looks very similar to the slope. It's basically just flipping the expression and adding a negative sign. So the tangent of theta is equal to the square root of m2 divided by m1. So with a mass ratio of 100 to 1, the tangent of the angle is 0.1. This means that the angle itself would be the arctangent of 0.1. So in other words, it's not quite the case that our angle is so pretty and beautiful as being a small power of 10. It's instead the arctangent of a small power of 10. But if you go and you graph the arctangent, you might notice that the arctangent of a small number is almost equal to that number itself. And the key idea is that for the purpose of our question, where we're saying what's the biggest whole number that you can multiply by this little angle that keeps it from surpassing pi, these numbers are so close that they might as well be the same. You get the same whole number answer. In the example shown on screen, 3141 keeps you below pi, but adding one more would bust you above pi. This idea that the arctangent of a small number is the same as the number itself is equivalent to saying the tangent of a small number is close to that number itself, and this is known as a small angle approximation. There is an international law saying that when you're doing physics for more than a half hour, you must use at least one small angle approximation. And if you've never seen these before, there's a really nice geometric reason why you would expect this to be true. If you think about a circle with a radius 1, a unit circle, and you consider a point an angle theta off the horizontal, what the tangent of that angle is telling you is the y-coordinate divided by the x-coordinate of that point. Now if your angle is really small, then that x-coordinate is basically the radius, it's basically just 1, and that y-coordinate is really really close to the arc length along the circle between the x-axis and the point we're looking at. And since it's a unit circle, that arc length is the angle, it is theta. So rolling everything back, using a small angle approximation, this critical value theta that we care about is close enough to a power of 10 that it explains why our answer would have the same digits as pi. That in turn explains why the number of lines we draw in this circle diagram must have the same digits as pi. And this circle diagram arose from a certain state space describing the colliding blocks, where at a very high level, if you want to say, why did pi have anything to do with this, it's because the conservation of energy for a two-body system like this simply looks like a circle in that state space. But a few sticklers could be raising their hands and saying, are we positive that small angle approximations are really enough here? Can we be absolutely sure that there's not going to be a little off by one error because of the deviation here? And for any calculus students among you, the more rigorous way to do this analysis would be to pull up the Taylor's approximation for the tangent of theta, where you can see that the error between the tangent of theta and theta itself is on the order of theta cubed. So for example, if theta was a number like 1 one hundredth, then when you approximate the tangent of this value as being just 1 one hundredth itself, the error term is on the order of 1 one millionth. Now that's very small, and so as you multiply by this, that error doesn't really accumulate very much, but it is possible for the final answer to our question to be an integer whose digits aren't quite the same as pi, but off by one, if the following was true. If at any point when you're looking at all the digits of pi, and you consider the first n of those digits, if it ever happens that the next n digits are all nines, then you get this off by one error. For all of the digits of pi that we know, this is not true. Considering how many we know, and therefore how many nines you'd have to see in a row, it seems absurdly unlikely that something like this would be true. However, rigorously proving that this is true of the digits of pi is beyond the scope of what the current tools of math can prove. So very technically speaking, this fact that colliding blocks with a mass ratio that's a power of one hundred can compute pi for you is an unsolved problem. Of course, the block collisions themselves are something you and I now understand very well. You can, if you want, write an exact formula to answer it. And if you like to pause and ponder, you might enjoy taking a moment to think about how there's nothing special about powers of one hundred. If you were working in another base, like base two, then mass ratios with a power of four would count up to something that has the same bits as pi, written in binary. Now before you leave, it would be a shame to finish all this without highlighting why this puzzle is worth studying at all. I mentioned already how Matt Parker's Pi Day video this year is all about putting this block collision process into practice, and suffice to say, you run into practical issues very quickly in the attempt. So some of you might complain, you know, is everything that we just did over-idealized to the point of pointlessness? And there's two justifications I could give you for stripping away the messiness of the real world, one that's straightforward and another that's a little more thought-provoking. The first is that if you want to solve any problem, it's often helpful to start with the simplest possible variant, and then once your teeth are sunk into that, you often have a first approximation of reality, and very often when you want to account for the added details and messiness of the real world, the way that works is to start with the simplistic solution and slowly modify it step by step to be more accurate. Here, for example, if you want to take into account the energy loss in each collision, that might look like having the circle shrink with each one of those clacks. Now the deeper reason for abstracting away from the messiness of the real world is that purity can expose hidden connections. This whole video is already about one hidden connection between blocks and pi, but the original paper that described this phenomenon by Gregory Galperin presented it in the context of yet another connection, a beautiful analogy between these colliding blocks and the way that a beam of light would bounce between two mirrors at an angle. If you want the details, another one of the videos I made back in 2019 is all about that perspective. If you liked this, you will almost certainly enjoy that video. But even more surprising is what I referenced at the beginning, how this whole solution is secretly mirrored inside an algorithm within quantum computing. There's a lot to unpack to explain what that is, which is why I'm pulling that out into a separate video that we'll do next, but for right now I just want to leave you with one point. When pure mathematicians pull out the messiness of reality from their problems, it's not just out of laziness. I mean, it's a little bit laziness, but it's not just that, and it's not out of apathy for applications. It's because distilling a problem into its core essence can expose hidden connections, and it's through those connections that mathematicians make progress. A hard problem in one context, where it might seem deeply confusing, sometimes can look clearer in another setting, but the analogy may not be obvious, and a lot of the progress of math through history has looked like developing a richer and richer web of hidden connections.

================================================================================
VIDEO ID: TZAC0WFemvE
TITLE: When being beautifully wrong leads to discovery
URL: https://www.youtube.com/watch?v=TZAC0WFemvE
PUBLISHED: 2025-02-28T15:00:44Z
STATUS: SUCCESS
================================================================================
Kepler wanted to prove the most elegant theory in astronomy the idea was if you imagine a sphere inscribed in an octahedron and then you fit the smallest possible sphere around that and then fit the smallest possible icosahedron around that then layer on another sphere and then a do decahedron one more sphere then a tetrahedron one more sphere a cube and then one final sphere you get these six spheres and the ratios between the sizes of those spheres Kepler believed would match the ratios of the the Orbits for the six known planets since these are the platonic solids it somehow feels like a very natural or Universal set of ratios eventually he was able to get his hands on some orbital data to try to confirm his theory and the way he did it was completely heroic by the way but that's beside the point and he couldn't get the theory to fit it was always off by a few percent but even though he started with a wrong premise this is what led him to be the first person to understand how planets actually move around the Sun and to develop his famous aonomus laws and

================================================================================
VIDEO ID: YP1mMXRCnaI
TITLE: Why the ancient Greeks rejected heliocentrism
URL: https://www.youtube.com/watch?v=YP1mMXRCnaI
PUBLISHED: 2025-02-27T15:00:48Z
STATUS: SUCCESS
================================================================================
cernus was not actually the first person to propose a heliocentric model it was arist starus who did this in 300 BC but his idea wasn't accepted the other Greeks um dismissed him for good mathematical reasons they said that it doesn't make sense for the earth to go around the sun because if the Earth would gr on a sun the position of the shape of the constellations would shift as you go from one side of the Sun to the other and we don't see that so if you've got a bunch of stars sitting here in three-dimensional space and you picture yourself as an observer staring at the stars and you move around through that three-dimensional space then the apparent relative position of those Stars shifts around as you move we call this Parallax it's the same phenomenon where if you're on a car in the highway and you look out all of the nearby trees seem to be moving much more quickly than the background mountains so when aristarchus says Hey guys maybe the Earth is going around the Sun all of his fellow Greeks are like well if that was true and you've got this Earth Sun System sitting among a bunch of stars then for us The Observers sitting here on the planet Earth as we move around through space from Winter to Spring to Summer and it's going to be quite a bit of movement through space since evidently the sun is supposed to be quite far away from the earth then because of this Parallax we should see a change in the pattern of the Stars the nearby Stars should be moving a little bit more than the background stars and the overall shape of the constellations should slowly drift through the seasons but that's not what we see the constellations seem to be the same shape between the summer and the winter and that would only be possible if the stars were much much much further away than we currently think they are so arus if you were to accept your model we must make the universe thousands and thousands times bigger therefore we were not going to we're going to dismiss your theory it shows you that that even when you have the math right you don't necessarily get to the truth

================================================================================
VIDEO ID: gzbFNnTCkqQ
TITLE: How to estimate the distance to the sun
URL: https://www.youtube.com/watch?v=gzbFNnTCkqQ
PUBLISHED: 2025-02-26T15:01:03Z
STATUS: SUCCESS
================================================================================
how could ancient Greeks figure out the distance to the Sun without knowing its size and how could you do this on your own you again use the moon you look at phases of the moon so the sun illuminates half of the the moon at any given time and so we on Earth we also see half the moon but it's a different half um and so because of that we get phases of the moon so sometimes you get a full moon sometimes you get a new moon over here um and sometimes sometimes you get a half half moon you can pretty much ReDiscover for yourself a way to estimate the distance to the Sun by asking when exactly a Half Moon occurs from the name you would guess that it's halfway between a new moon and a full moon but that's actually not true Half Moon occurs not not when the Moon and the Sun make a right angle at the Earth but actually when the Earth and the Sun make a right angle at the Moon hopefully this makes some sense for us to see a half moon it means that the side of the moon that we see facing Us overlaps by exactly 90Â° with the side of the Moon being illuminated by the sun which in turn means we have have a right angle at the spot labeled here half moons are slightly closer to new moons than they other full moons of course in this graphic the effect is very exaggerated because the sun is being drawn so close to the Earth how far away the sun is determines when exactly that Half Moon occurs the farther away the closer it is to the true halfway point and if you can walk out that angle you have worked out the angle of a right angle triangle involving the distance of the Moon this is the Sun and

================================================================================
VIDEO ID: drmphB3rdHY
TITLE: How Aristarchus deduced the distance to the moon
URL: https://www.youtube.com/watch?v=drmphB3rdHY
PUBLISHED: 2025-02-25T15:00:57Z
STATUS: SUCCESS
================================================================================
the ancient Greek arist starus was able to figure out how far away the Moon is at least as a multiple of the size of the Earth people didn't yet know the size of the Earth but they would figure that out soon enough when you have a lunar eclipse so when the sun is over here the Earth shadow um has size basically twice the radius of the Earth lunar eclipses they last no longer than 4 hours and this they knew from many many observations the moon actually takes one one Luna month to Traverse orbit and so again by taking the ratio between 28 days and 4 hours you can work out the relation between a distance to the Moon and the radius of the Earth um aarst did this it measured that the the distance to the Moon is about 60 Earth radi and actually the orbit varies between like um 58 and 62 or something so actually it's really good as good as you could hope

================================================================================
VIDEO ID: hFMaT9oRbs4
TITLE: How to measure the universe | The Cosmic Distance Ladder Part 2
URL: https://www.youtube.com/watch?v=hFMaT9oRbs4
PUBLISHED: 2025-02-23T14:54:42Z
STATUS: SUCCESS
================================================================================
This animation is zooming out by a factor of 10 every 2 seconds. Maybe you've seen things like this before, conveying the mind-boggling scale of our universe, but here, in this video, you and I are going to continue the saga through the many moments of delightful ingenuity throughout Human history that led us to first discover how far away objects in the cosmos really are. Appreciating how we know these distances is to me more amazing than the distances themselves. This is part 2 of a collaboration with Terrence Tao, and it's okay if you haven't yet seen part 1. Each video should be relatively self-contained, but for context, we left off with Kepler's ingenious method for deducing the shapes of all of the orbits of the planets around the Sun. So people knew what the Solar System looked like, but they still didn't have an exact sense of scale, and this left astronomers hungry to measure any distance that they could in this system, like maybe how far away a given planet is from Earth at a given moment, since that would be enough to lock everything else into place. Now, I'll admit, while I had vaguely learned about how this was done before, I definitely had not appreciated the cleverness of the details. You could measure distances to a planet like Venus, take two measurements on different sides of the Earth, around the time of Captain Cook, when they were travelling to discover Australia and so forth. Part of the reason for this was the scientific mission. I mean, they wanted to know the distance to Venus and Mars and so forth. They wanted people to take precise measurements, say one in Greenwich in the UK and one somewhere in the southern hemisphere, at exactly the same time of the same object. The key idea here is that as you sail down to the southern hemisphere and you observe a given object up in the sky, its position in the sky, say relative to the background constellations, will appear to shift up as the angle of your line of sight slowly changes with your position. We call this parallax. It is the same parallax that we use with binocular vision. Our eyes are a certain distance apart, and so we can determine depth for any distance that's not too much larger than the distance between our eyes. So now we figured out how to make two eyeballs on different sides of the Earth. Now if you want to turn this into a measurement, you first need to understand this line right here, connecting the two different observation points, both its distance and its direction. Because people knew the size of the Earth, and they could tell where they were on the Earth, that would be taken care of. Then the hard part is for the first observer to take a precise enough measurement of the viewing angle to this object. They need to deduce this angle here, and for the second observer to do likewise. If you can do that, you have a triangle where you know all three of the angles, and you also know one of the side lengths. This means with just a little bit of trigonometry, you can figure out any other side length, which for example tells you how far away this object is from one of the observers. Now the way I'm drawing it here, it makes it look almost easy. But for the real-world measurement, you have to keep in mind just how far away everything is. If we zoom out so that they're both looking at something as far away as the Moon, it would look something like this. But the Moon, cosmologically speaking, is really quite close. So even if both of them are looking at the nearest planet, Venus, when it is at its absolute closest to Earth, it's around 39 million kilometers away, which is over 6,000 times the radius of the Earth. So zooming back in to those two observers, even if they were as far away as you could get them, one at the top of the Earth and another at the bottom of the Earth, these two lines of sight would be almost parallel. If you work out the little bit of trigonometry, if they're both looking at Venus at its absolute closest point, the difference in angle between these two lines is about 1 arcminute, which is 1 sixtieth of a degree. So, if this is going to work, your measurements have to be extremely precise, and you have to be absolutely sure that both observers are really looking at the same thing at the same moment. Now at the time clocks were not good enough that they could actually just say at this specific time, like this measurement, also you're not guaranteed that you could even find the planet and so forth. But there are these transits, there's this thing called the transit of Venus. Sometimes Venus travels along the Sun, and so you can just time exactly when Venus hits the edge of the Sun. This is the part I had not appreciated, in particular how sensitive everything really is. So, up in the Northern Hemisphere, if you're watching the transit of Venus, maybe it looks something like this. And far away, at some point down in the Southern Hemisphere, due to parallax, Venus would appear higher up, and you essentially want to know exactly how much higher up. Now, this animation is greatly exaggerating the difference. In reality, the two would look much, much more similar, more like this. And remember, there was no photography, so it's not like they could take pictures and closely compare them. When you look at the Sun up in the sky, it spans around 32 arcminutes of viewing angle, and this is something they would have been able to measure. The deviation in viewing angle to Venus for these two observations would be a fraction of an arcminute. So to measure exactly what that fraction was, each observer would not try to directly describe where it was. Instead, they would measure the duration of the transit, how long it takes from the moment that Venus's silhouette first appears on the disk to the moment that it leaves. Critically, they also would have known how fast Venus and the Sun are moving through the sky at this time, and this would let them calculate how long it should take Venus's apparent position to traverse the distance of, say, one Sun diameter. It turns out to be around seven hours. I won't dwell too much on the details for how to calculate this, but at a high level, if you think about Earth and Venus both orbiting the Sun, the angle of this line of sight right here, from Earth through Venus, is something they would have understood well, since, thanks to Kepler, they knew the relative shapes of the orbits and how long it takes each planet to go around the Sun. So in principle, they could calculate how long it should take for this line to scan over those 32 arcminutes in the sky that the Sun occupied. The point is that by measuring the durations of the transit from these two different locations, that could tell you the lengths of these two lines drawn across the Sun's disk. These are very similar, but measurably different, and with a little bit of circle geometry, the lengths of those lines will tell you how far apart they are, that fraction of an arcminute separating the two observations. And then this, in turn, from everything that we discussed before, lets you deduce how far away Venus is in terms of the distance between those observers. That is just so clever to me. It was Edmund Halley who originally came up with this idea, but sadly he didn't live long enough to see it come to fruition. Before moving on, I simply have to tell you the story of Guillaume Le Gentil. He was another explorer, also tasked with making one of these measurements for the transit of Venus. Specifically, he was going for the one in 1761, but he was delayed by the Seven Years' War, and still at sea when the transit happened, so he was unable to make the measurement. Now the next transit of Venus was going to be eight years later, but after that it wouldn't be for another 105 years, so he decided to extend his journey, do a bunch of other explorer things, and catch the next one. And by 1769, he was all set up in the Philippines ready to go, but on that day it was cloudy, so he couldn't see anything. Once he finally got back to France, he found that he had been declared dead, his wife had remarried, and his relatives had all plundered his estate. Now remember, the reason people cared so much was that having this one measurement was enough to lock in place the scale of the whole solar system, so once they had it, they would automatically know every other distance involved. This was important actually because you need to do this in order to work out the distance to the Sun. The distance to the Sun is the most important rung of the ladder. It's called the astronomical unit. Almost everything beyond the solar system is measured in terms of the astronomical unit. And so they really needed really accurate estimates. Given what we just saw, you might be able to guess how you can use this astronomical unit to measure the distance to nearby stars. But before we get to that, there's actually one more clever deduction that you can make once you know this distance, a little closer to home, and incredibly important for physics. Romer was measuring Jupiter, and Jupiter has a small moon called Io. Io orbits Jupiter really, really fast because it's really close to Jupiter. Our moon takes 28 days to go around the Earth. Io takes 42 hours. Let's whip it. Yeah, it's extremely fast. If you observe Jupiter on a telescope, you see Io, which is this white dot, go in behind Jupiter's shadow, and then out, in, out, in, out. Romer was marking down one precise moment for each one of these cycles. You see, Io goes dark when it falls into Jupiter's shadow, which it does every cycle because Jupiter is just so big. As it emerges, it becomes bright again. Watching it through a telescope night after night, you can mark the exact time that it pops back into view. And if you go out with a telescope and you do this a whole bunch, what you'll notice is that these happen in 42-hour increments. Like clockwork, except that it wasn't clockwork. So, Romer was observing Io go back and forth, back and forth for months, and he observed that at different times of the year, Io was ahead of schedule, Io was behind schedule. So, I'll give you a picture. Earth goes on the Sun, Jupiter also goes on the Sun. So, when you're measuring the orbit of Io, it was 20 minutes earlier when the Earth was on the same side as Jupiter. Then, when the Earth was on the opposite side of Jupiter, it took 20 minutes longer. There was a delay in the orbit. So, he measured this after some very precise calculations. And Huygens realized that the reason for this is because light was taking 20 minutes to traverse this extra distance. So, two astronomical units is traversed in about 20 minutes. That's so clever! Yeah, yeah, yeah, yeah, yeah. Historically, this was all before the measurement to Venus. So, at that time, they didn't actually know the true astronomical unit. So, their estimates for the speed of light, frankly, don't look that impressive if you see them. But, at that time, it was not even obvious that light had a speed. For most experiments you could do down on Earth at that time, it just looks instantaneous. But at astronomical scales, it's actually really slow. And this very clever way to measure its speed by observing Io, imprecise though it was, laid the groundwork for more precise experiments down on Earth, once people had at least a rough sense of how fast it really was. I also really like this because it comes back around to the distance ladder. These days, with technology, the more accurate way that we measure the distances to planets like Venus is not with parallax, but using radar. But this, of course, relies on knowing the speed of light. And now, let's finally leave our solar system and measure the nearby stars. Again, you can use parallax. It's essentially identical reasoning for how we got the distance to Venus, only this time, the two observation points are not opposite sides of the Earth, they're opposite sides of Earth's orbit. That is, you measure the star at one time of the year, and then you wait six more months for the Earth to be on the other side of the Sun, make another measurement, and compare the two angles. Again, for demonstration purposes, I'll be drawing this star unrealistically close. In principle, over the course of six months, the line of sight from the Earth to a star slowly changes angle, so the position of that star in the sky should slowly drift over those months. And it's very subtle, but you can actually see this in practice. This right here is a time lapse of a very zoomed-in view for our nearest neighbor, Proxima Centauri, taken over six months. And you can see that over that time, it does gently drift with respect to the background stars. But as before, the mind-blowing part is to appreciate just how subtle the effect is, and therefore how impressive it is that people were able to use this for calculation back in the 19th century. Let's actually work out the math here. Suppose a star is a given distance d away, and to make everything easy, let's assume it's perpendicular to this connecting line between our two observation points. This angle right here represents half of the change in viewing angle between those two observations. The tangent of that angle, opposite over adjacent, gives you the ratio between one astronomical unit and the distance between that star and our Sun. Rearranging a little bit, this change in angle looks like two times the inverse tangent of that ratio. So, what is that ratio? Well, for that closest star that I mentioned, Proxima Centauri, it's over 40 trillion kilometers away, which is over four light-years, and around 260,000 times an astronomical unit. Now if you plug that in, it means that this change in angle from the two observation points is a tiny, tiny portion of a degree. Let me see if I can show you how small this is. This right here is a circle representing 360 degrees of full viewing angle. And if we zoom in real close to one degree, you'll remember I mentioned earlier that the Sun, and also the Moon for that matter, take up about half a degree of viewing angle, and we often think of this as being divided into 60 arc-minutes. Well, if you zoom in even further to one arc-minute, this is commonly divided into 60 arc-seconds. At its largest, Jupiter will span about 50 arc-seconds of viewing angle. So, this parallax for Proxima Centauri, the nearest star, is only about 1.5 arc-seconds. As another way to put that in perspective, this is about the same angular size as if you held out a dime in front of you, but two and a half kilometers away, a mile and a half down from where your eye is. And that's the closest star. It only gets worse from there. The first measurement of this kind was successfully done in 1838 by Friedrich Bessel. It wasn't Proxima Centauri. They wouldn't have been able to know which star was closest. But over the course of the next century, there was a monumental effort for many more measurements to try to catalog as many stars as we could. But this parallax idea only really works for a tiny portion of our galaxy. So to figure out the full size of the Milky Way, that requires a new idea. Roughly speaking, the Milky Way is this... I can't draw a spiral. Okay, this is again maybe a place where your graphics are going to be much better than what I draw here. Alright, so our sun is on one of the arms. So by using parallax, by about the 19th century, there was about maybe a thousand stars close enough to the sun that they knew how far away these stars were. Maybe about 10, 100 light years away. So they knew how far away these stars are, and they knew how bright they looked. And so they knew how bright they were by the inverse square law of light propagation. Just to spell this out a little more explicitly, if you imagine you have some star in space emitting a bunch of light in all directions, then at a given distance away, all of that light is evenly spread along a sphere. So if you're that distance away and you're measuring the brightness with some little patch of area, maybe that represents your camera or a photo sensor or your pupil, something like that, the amount of light you're receiving depends on the proportion of this total sphere that your little area represents. So for example, if you were twice as far away, that same beam of light that you had been measuring up close is now spread along four times the area. So out at this distance, if you used the same photo sensor with the same area as before, it would only be measuring a quarter as much light. In general, the amount of light that you see, the apparent brightness of the star, is proportional to its absolute brightness, the total amount of light it's giving away, divided by the square of the distance between you and that star. So for all of those stars whose distance we could measure using parallax, by also measuring the apparent brightness, astronomers could know their absolute brightness. The other thing they could observe is the color of all of these stars, the frequency of light that they're emitting, which is actually incredibly helpful. For example, you can start looking for patterns in this data. Imagine you organize all of your stars onto a plot, where in the x direction, we're going to sort them by the color. The common kind of backward-seeming convention is for higher-frequency light like blue to go on the left and lower-frequency like red to be on the right. Then in the y direction, you can sort according to the absolute brightness of these stars, which again, you can deduce by knowing their distance and using the inverse-square law. A thousand points of data of intensity and color. And this is main sequence. Most stars live on the sequence. This is known as the Hertzsprung-Russell diagram, initially created around 1911. The data that went into it though represents decades of effort, a lot of it coming from this group of women at the Harvard College Observatory, commonly known as the Harvard computers. The diagram exposes how the color of a star can tell you something about its absolute brightness. This main sequence represents one very common type of star, it includes our Sun, during a phase of its evolution when it's burning hydrogen in its core. Stars in this category that are bigger and brighter also tend to burn hotter, and they have blackbody radiation more in the blue direction, while those that are smaller burn cooler and they radiate more in the red direction. So, if you see some star very far off, way too far for parallax measurements, and if you also know that it should fall into this main sequence, more on that in a moment, its color can tell you its absolute brightness, you fit it to this curve. And then by using its apparent brightness with the inverse-square law, you can deduce how far away it is. Now you might ask, how would you know that a star should fall in this main sequence? The full diagram is much more splotchy than a clean line, it's got a lot of different components representing different types of stars. The thing to keep in mind is that the color information you get from a star is much richer than what a single number on this x-axis could convey. For example, this right here represents all of the relative intensities for light that we get from our Sun across many different wavelengths. It's what we call its spectrum. This is the usual pattern you see, you have a general lump representing the blackbody radiation, with certain wavelengths greatly reduced. Those correspond to the wavelengths of light absorbed by the atoms in the Sun. And where specifically those absorption lines fall will tell you what the atoms are in the star. And from that, it helps classify what kind of star it even is. So for example, while those Harvard computers were doing a bunch of detailed analysis of spectra from all these stars, some of them, including Antonia Maury and Annie Cannon, came up with very useful classification systems for these stars based on the spectra. You can then use that classification scheme to tell you which cluster you would expect a given star to fall in in this Hertzsprung-Russell diagram. For example, whether it should be in this main sequence, or if it's something else entirely, like a red giant. And then once you have this law, you can then go all throughout the galaxy, and you can out-measure. But it stops working past the galaxy because each individual star becomes too faint. The galaxy is only a really tiny portion of the full universe. Okay, so we have one tiny little galaxy here. So there's all the other galaxies all over. Yeah, and so in a galaxy, most stars, you cannot measure the brightness of a single star, because there's just billions of them all crammed in the same place. But there are some amazingly bright stars, they're called Cepheids, they're supergiant stars that are thousands of times brighter than the Sun. Some of them live in our own galaxy, and some of them live in other galaxies. They still blend in, but you can still kind of measure their brightness. These stars are what are called variable stars. So most stars, they stay the same intensity for all time. But the Cepheid stars, their brightness oscillates, so they have a period of intensity. Like every 20 days, every 10 days, they oscillate. And it turns out that the bigger the Cepheid, the brighter it is, the longer the period. Henrietta Swan Leavitt, who was a 20th century astronomer, she measured all the Cepheids that she could in her own galaxy, and she plotted the period against the intensity, and she found basically a linear law that the brighter the Cepheid, the longer it took. That, like the Hertzsprung-Russell diagram before, gave a standard candle. That if a galaxy happened to have a Cepheid in it, you could just observe it, work out its period, that gave you this intensity. So now you know how bright it should be, and you know how bright it looks, you can measure its distance. That gave the next rung of the ladder, so a couple thousand galaxies where you can measure the distance. But that again is only a tiny portion of the universe. You ever seen powers of ten? Oh yeah, yeah, kind of zoom and zoom and zoom. So now this is a local cluster where, thanks to Levitt, you could work out the distances. And then there's the rest of the universe. But it's enough to get data of some kind. Yes, yes. And so, Hubble, Edwin Hubble, was measuring all these galaxies, and they have certain spectral lines. For example, there's a lot of hydrogen around each of these galaxies, and so there's certain spectral lines of hydrogen that get absorbed. And so there's certain lines that are missing, almost missing in a spectrum. But he noticed that for some of the galaxies, the spectrum was shifted to red from where it should be, but not all of them. And so he measured it. So he measured this redshift against distance, and again he got a linear relationship. There's actually a famous plot in his paper, which is now called Hubble's law, that the redshift is proportional to the distance. Nowadays we know why this is true, because general relativity predicts that the universe is expanding at a uniform rate. And the further away things are, the more they recede and the faster they recede, the more redshift they have. But again, this is a predictable law. So if you have a galaxy far, far away, if you know what its redshift is, it just measures a spectrum, you apply this law, you can work out its distance. So this is the largest rung of the ladder that we know to date. The entire bubble of the observable universe, which we think is about 20% of the whole universe, we don't know. Pretty much every object in the universe that emits light or some sort of radiation, we can now measure the distance, usually by seeing how spectral lines shift. And so you can start mapping things, you can do 3D pictures of the universe. There's something called the Sloan Galactic Survey, which is trying to do this. For this visualization, what I did is read in some data from the Sloan Digital Sky Survey, which aggregates data about a huge number of galaxies, including their angle in the sky, and then critically their distance away, as measured by redshift. This set doesn't include all of the angles in the sky, that's why it has this kind of wonky shape. This represents about half a million different galaxies, visualized as a simple point cloud. And in a sense, what you're looking at is a snapshot of our little corner of the universe, measured out to a radius of about 1.6 billion light years. And one thing that has been discovered is that galaxies are not just randomly strewn out in space, they form these filaments, they form these massive structures. So a galaxy is itself part of these much larger structures. The thing is, that's actually predicted by theory, or at least by experiment. So we can run in a computer billions of virtual galaxies, opening by gravity for billions of years. And what we have found with simulations is that the galaxies, as they evolve, do organize into strands that do resemble the strands that we're beginning to see. So that is, in some sense, some confirmation that all our theory is basically correct. If you're using redshift, what's the error that it'll give you on the distance? That's a good question. It's hard to calibrate at very large scales because we have very few other ways to measure the distance. The gravitational black hole things, those are the most exciting. Normally to measure distances at this distance, you need to stack together a huge amount of rungs of the ladder. First of all, the distance of the Sun, and then from that parallax to work out distance to nearby stars. And then from that, you can work out using main sequence fitting distance to other stars in the galaxy, and then Hubble's law, no, there's a sefis between that, and then Hubble's law. You can use the gravitational measurements to directly measure the distance. Unfortunately, I don't quite remember, they're kind of like standard sirens, that's what they're called. There's a certain amount of energy that's released by a black hole collision, and so you kind of know how loud they are in absolute terms. But you can also measure how loud they are from the observatory. And they're billions and billions of times fainter at that point because of the vast distance drop, but they can use that to infer the distance. That, they cross-checked against the Hubble, the redshift calculations. It matched within like 10%. That's reassuring. Yeah, yeah, no, it is very reassuring. Although that 10% is controversial. It seems like there's something a bit wonky with Hubble's law at very large scales. Like, the same 10% is showing up elsewhere too. It's an ongoing mystery exactly what is the cause of this 10% anomaly. And is one of our laws of physics wrong? There's something very basic called the Copernican principle that is an article of faith now since the Copernican revolution that we believe the laws of the universe are pretty much the same everywhere in the universe. And this is a fundamental assumption that allows us to extend the latter. And it's always rewarded us in the past. It always fits at least in the rules of physics. It's ever been self-consistent. But there's this slight 9% anomaly, 10%, and it's an ongoing area. The subject is a living subject, astronomy. But we've gotten a long way from that poor graduate student walking down the... A long walk down Egypt. Yes. Maybe this goes without saying, but the cosmic distance ladder is too broad a topic for two videos to fully convey. After showing an early view of this on Patreon, for example, a number of people expressed sadness that there was no discussion of type 1a supernovas. And fitting a story like this into an hour necessarily involves at least a little simplification along the way. Luckily for the extra curious among you, Terry has kindly put together an FAQ with a lot of added details and corrections from the discussion. And he's also working on a book about the topic with a collaborator, Tanya Clowden. So you can keep an eye out for that.

================================================================================
VIDEO ID: 9s0srZneJ38
TITLE: How Earth's size was computed by Eratosthenes
URL: https://www.youtube.com/watch?v=9s0srZneJ38
PUBLISHED: 2025-02-12T15:00:17Z
STATUS: SUCCESS
================================================================================
do you remember the first time you ever learned about you know the technique for measuring the radius of the Earth I think I saw so there's this old TV series called Cosmos and uh the way the story goes is that he had read somewhere of this well in this town called sinin in Egypt uh where on one day of the year the summer soltice you could look down in the well and you could see the sun reflected in the water underneath and he said oh that's kind of cool uh um I don't live there but I have a well in my own Town Alexandria I'm going to go try the same thing so he wait until the summer solstice and he at noon he went down and looked at the well and there was no reflection of the Sun and he knew from Aristo and the other the Earth was round let's think of the Sun as far enough away from Earth that all of its rays of light are effectively parallel at any given moment if you draw a line from the center of the earth straight to the sun it passes through some point on the surface which must be experiencing this phenomenon where the sun is directly overhead but if you were someone in aatosan time it would be very difficult to know exactly where this was happening at a given moment so what makes the summer solstice special is that on that day the axis of Earth's rotation is tilted directly towards the Sun and as a result on this day as the Earth revolves around that axis over 24 hours there's a consistent line of latitude where all of the locations on this line predictably experience this phenomenon this line has a special name it's called the Tropic of Cancer and the town cine that aatosan had read about sits on this line now aatosan himself was in Alexandria which is a bit north of that so the direction that he perceives as straight up is going to sit at a certain angle away from the Rays of that Sun so by measuring that this angle was about 7Â° he could reason that the arc along the planet Earth between his Town Alexandria and Cen is about 7Â° so if you take the ratio between this angle and the full 360Â° around a circle that should be the ratio of the distance between his town and Cen and the full circumference of the earth so if you know that distance you can deduce the size of the Earth

================================================================================
VIDEO ID: YdOXS_9_P4U
TITLE: Terence Tao on how we measure the cosmos | The Distance Ladder Part 1
URL: https://www.youtube.com/watch?v=YdOXS_9_P4U
PUBLISHED: 2025-02-08T13:35:15Z
STATUS: SUCCESS
================================================================================
Einstein once wrote an introduction to a book on astronomy. He mentioned this idea, he called it an idea of pure genius. This is Terence Tao, one of the world's most renowned mathematicians. What he's referencing right now is how Kepler deduced the shape of Earth's orbit,  which was astoundingly more clever than I had realized. But I'm getting a little ahead of myself. A lot of math enthusiasts will be familiar with Tao as a story of  prodigy-turned-prodigious mathematician, but one of the most remarkable features of  his career is how collaborative it's been, spanning an unusually wide breadth of  topics within math. I had the chance to sit down with him, and I asked if there were  any topics that he believed would benefit from some strongly visual presentation,  and I fully expected an answer from pure math. But I was pleasantly surprised when he proposed instead a story of cosmic distances. It's the story of how humanity first figured out the sizes of objects  from the size of the Earth to that of the solar system on up to the universe,  and how each measurement unlocks a path to the next one. I always liked astronomy as a child. Just found red dwarfs and neutron stars and so forth fascinating. Then I had a little telescope. As a kid, I just read all these books and said, you know,  the distance to Mars is 18 million miles or whatever,  and I just sort of accepted, oh, they figured out some way to do this. I never knew how they did it. Science communication at its best is, to me, less about presenting facts in  a memorable way, and more about showing how it is that we know what we know. When it comes to cosmic distances, it's very easy to  be awestruck by the sheer unfathomable scales involved. But what deserves just as much awe, and is much less commonly highlighted in  pop science documentaries, is how clever the reasoning can be at each step. And I realized, oh, it was always some mathematical trick. And it was always a cool trick. Like, if you want to measure the distance to x, you can never just look at x. You have to look at y and how x impacts y. So the idea is clever, and then you have to have data,  which needs technology and so forth. But then it's just mathematics. In this video, we'll cover the steps of the ladder up to the planets,  that moment of sheer genius that Kepler brought. And in the next part, we'll continue on up to the most distant galaxies. The very first measurement of the ladder is the radius of the Earth,  a somewhat classic tale. But to even ask this question presumes that the Earth is a sphere,  or at least roughly spherical. So you might wonder how the ancients first deduced the shape of the Earth. The first really convincing proof came from the Moon. And this is the constant theme in the distance ladder. If you want to measure one object, in this case the Earth,  you have to use a reference object that is some distance away. See, the thing is that we're stuck on the Earth. Like, if we could step away, if we're looking for many different angles,  you could see that it's round. If you only saw from one angle, it could be a flat disc. Flat disc, if you look at it from a different angle, it would look like an ellipse. But you can actually prove there's a nice little geometric argument actually,  that if there's a convex body and every single projection is a circle,  then it has to be a sphere. I'm going to guess that most of you find this pretty intuitive. After all, if every shadow of a given shape is a circle,  what could that shape be other than a sphere? But of course, a mathematician always keeps a keen  eye out for those strange counterintuitive exceptions. And he shared with me a nice proof of this fact after the interview,  which I'll link to in the description. In two dimensions, what I just said is not true. So there are two shapes which every projection is an interval of the same length,  but they're not round. But in 3D, there's enough perspective, as it turns out. If you could look at the Earth and you could always see that it was round,  that tells you the Earth is a sphere. NASA can do this, okay, but Aristotle could do this. And he used the Moon because he knew about lunar eclipses. Lunar eclipses happen when the Moon falls onto the Earth's shadow. And the Earth's shadow, as you can just visibly see, it's always a circular arc. So there's a picture I can show you. This is not my photo, but someone took several images of the Moon entering  and exiting a lunar eclipse and it composited them together into a single shot. You can see the shadow of the Earth. This is visible proof that the Earth is round. And you don't need telescopes, sextants, spacecraft. You just need to look at the Moon. Something else very cool, revealed by these kinds of compositions,  is how you can just see the relative size of the Earth and the Moon. We'll get to that in a moment, but first things first,  how do we figure out how big the Earth is? The first person to do this that we know of is Eratosthenes. The way the story goes is that he had read somewhere of this well in this town  called Syene where on one day of the year, the summer solstice,  you could look down on the well and you could see the Sun reflected in the  water underneath. And he said, oh, that's kind of cool. I don't live there, but I have a well in my own town, Alexandria. I'm going to go try the same thing. So he waited until the summer solstice. At noon, he went down and looked at the well and there was no reflection of the Sun. So I think like if you are a regular person at this point, we say, oh,  you know, that story is fake news or whatever, whatever the film is at the time. And he knew from Aristotle and the others that the Earth was round. The reason what was happening was that the Sun was not actually vertical. Let's think of the Sun as far enough away from Earth  that all of its rays of light are effectively parallel. At any given moment, if you draw a line from the center of the Earth straight to the Sun,  it passes through some point on the surface, which must be experiencing  this phenomenon where the Sun is directly overhead. But if you were someone in Eratosthenes' time,  it would be very difficult to know exactly where this was happening at a given moment. So what makes the summer solstice special is that on that day,  the axis of Earth's rotation is tilted directly towards the Sun. And as a result, on this day, as the Earth revolves around that axis over 24 hours,  there's a consistent line of latitude where all of the locations on  this line predictably experience this phenomenon, where at high noon,  it's the highest of all high noons where the Sun is overhead. This line has a special name, it's called the Tropic of Cancer,  and the town Syene that Eratosthenes had read about sits on this line. Now Eratosthenes himself was a bit further north than that, in Alexandria. So on that day, at exactly noon, the direction he perceives as straight up,  which I'll draw with a pink line here, is not pointed towards the Sun. It sits at some angle with all of those rays. He had what's called a gnomon, which is kind of like an ancient protractor or sundial,  portable sundial, basically. He measured that the Sun was actually about 7 degrees off of the vertical. Critically, because he could also know that at this exact moment, down in Syene,  many many many miles away, the Sun was directly overhead,  he deduced that this means the arc length along Earth between Alexandria and  Syene is about 7 degrees. This in turn means the ratio between 7 degrees and the full 360  degrees of a circle must be the same as the ratio of the distance  between those two towns and the full circumference of the Earth. Now keep in mind, in the records that we have,  it's not like he's reporting this distance in miles or kilometers. The units they were using back then were stadia,  where a single unit is something like the length of a stadium. So the distance was about 5000 stadia, which is about 500 miles. How accurate is our conversion between stadia and miles? That's a good question. We are not completely certain, so with the conventionally accepted conversions,  I think the accuracy of Eratosthenes' estimate is about 10%. You can find sources online that claim his estimate was more accurate than this,  but just keep in mind if you selectively choose which of the many possible conversions  between stadia and miles to use, you can kind of p-hack your way into a better number  here. Still, 10% is pretty good with no technology, but of course all of  this hinges on actually knowing the distance between these two towns. So the natural question you might ask is, how would he know that? This is not recorded. There are some theories. One is that there are merchants that go up and down the Nile,  and they know that in a certain day that their sailboard can  travel so many stadia and it takes them so many days next to Y. And so from that, they have some estimates. The joke is that he basically hired what we would now call a  graduate student to pace the distance from a graduate student. Carefully counting the road steps. That 5000 stadia is the only direct measurement. Just from that one graduate student, you can actually get  all the way to the measure of the diameter of the universe. Right, now that's not actually what we do nowadays. I mean, because the errors stack up. But in principle, you could do that. If you have a sense for how big the Earth is, one of the first cosmological distances  that you can deduce from this value is the distance between the Earth and the Moon. You can use eclipses again. So shadows are what let you observe things from a different location than the Earth. When you have a lunar eclipse, so when the Sun is over here,  the Earth's shadow has sized basically twice the radius of the Earth. It's a little trickier than that. There's something called the penumbra and the umbra, but as a first approximation. Lunar eclipses, they last no longer than four hours. And this they knew from many, many observations. The Moon actually takes one lunar month to traverse its orbit. And so again, by taking the ratio between 28 days and four hours,  you can work out the relation between the distance to the Moon and the radius  of the Earth. To be slightly more accurate, during the full eclipse between first and last contact,  the distance that the Moon passes through would not only be those two Earth radii,  but it would also include two Moon radii. So if you want to measure how long it takes for the Moon to traverse one  Earth diameter in space, it might be more like the time between the first  moment the Moon hits the shadow and the first moment that it starts to exit it. Another thing to keep in mind if you were to go out and try this  yourself on the next lunar eclipse is that lunar eclipses don't  necessarily go through the center of Earth's shadow like this. So the measurements that the Greeks would have had to  use would be with respect to the longest known eclipses. In either case, the slightly more accurate number to  put in here would be more like three and a half hours. And then when you work it out, this ratio between the length  of a lunar month and the length of a lunar eclipse,  all divided by pi, would tell you how many Earth radii away the Moon is. Aristarchus did this. It measured that the distance to the Moon is about 60 Earth radii. And actually the orbit varies between like 58 and 62 or something. So actually it's really good. As good as you could hope. Yeah, yeah, yeah. I brought up earlier how with these lunar eclipses  you can see the relative size of the Moon and the Earth. The Moon is about a quarter as wide as the Earth is. Now in practice it's difficult to make this a precise measurement without photography. So the Greeks had a different way that they could deduce the size of the Moon. Next time you see a full Moon rising, try to measure how long it takes. What you should find is that it's around two minutes. What you're watching is not so much the Moon moving through the orbit. Instead it's that as you and the Earth are rotating,  your line of sight over the horizon is scanning over the Moon. The Moon basically takes 24 hours to cycle around the Earth,  as observed by us because of the Earth's rotation. Actually it's slightly less because the Moon's also moving, but basically 24 hours. And so therefore you can work out the ratio between the radius of the Moon and  the distance to the Moon, just by taking the ratio between two minutes and 24 hours. So because they knew the distance to the Moon,  they could use this to figure out the radius. Now keep in mind both of their estimates could be at best approximately true,  since the real orbit of the Moon is an ellipse, it's not a perfect circle. But the point is that with almost no technology,  they had pretty decent estimates for the size of the Moon and how far away it was. The Sun was trickier. So at the time they thought the Sun went around the Earth. But it actually doesn't matter for the argument whether the  Sun goes around the Earth or the Earth goes around the Sun. Again there's these two numbers, there's the size of the Sun and the distance of the Sun. You can compute the ratio again because of eclipses. And there's this weird coincidence, I mean there's no reason why it should be true,  but when there's a solar eclipse, the Moon and the Sun are almost exactly the same size. I guess it's not true for lunar eclipses, for lunar eclipses as we saw,  Earth's shadow is much bigger. But for some reason they are almost the same size. What this means is that if you look at the ratio between the radius of the Moon and  the distance that it is away from the Earth, which is what determines how big it  looks to us up in the sky, because of this solar eclipse coincidence,  that has to be the same as the ratio between the radius of the Sun and its distance  away from the Earth. As we saw, the Greeks already knew that ratio for the Moon. The point is that they could get at least an approximate sense for the  size of the Sun if they could figure out how far away it is, or vice versa. The animation I'm showing right now is very grossly not to scale. You and I both know that the Sun is actually much, much farther away than the Moon is. But of course that's not obvious when you just look at it in the sky. And so you might wonder, how could you conclude that it has to be so far away? In ancient times, for all people new, seeing that it was roughly the same size as the  Moon in the sky, it could be, say, twice as far away as the Moon is,  and only twice as big. In fact, for the animation I'm going to go ahead and leave it unrealistically  close like this, because it helps clarify how the next logical step works. How do you work out the distance to the Sun? You can use the Moon, that's almost the only available object you can use. But you do something else, you look at phases of the Moon. The Sun illuminates half of the Moon. And so we on Earth, we also see half the Moon, but it's a different half. And so because of that we get phases of the Moon. This is also, by the way, why we know the Moon is round. If the Moon was flat, we would not get phases. We would get either a dim Moon or a lit Moon, but we wouldn't get these phases. Sometimes you get a full Moon. If the Moon is over here, you see the whole lit thing. Sometimes you get a new Moon over here. And sometimes you get a half Moon. You can pretty much rediscover for yourself a way to estimate  the distance to the Sun by asking when exactly a half Moon occurs. From the name you would guess that it's halfway between a new Moon and a full Moon,  but that's actually not true. Half Moon occurs not when the Moon and the Sun make a right angle at the Earth,  but actually when the Earth and the Sun make a right angle at the Moon. Hopefully your graph will be better than what I'm drawing here. Hopefully this makes some sense. For us to see a half Moon, it means that the side of the Moon that we see, facing us,  overlaps by exactly 90 degrees, with the side of the Moon being illuminated by the Sun. Which in turn means we have a right angle at the spot labelled here. As your lovely illustration will show, half Moons are  slightly closer to New Moons than they are to Full Moons. Of course, in this graphic the effect is very exaggerated  because the Sun is being drawn so close to the Earth. How far away the Sun is determines when exactly that half Moon occurs. The farther away, the closer it is to the true halfway point. In fact, you can make this a little more quantitative,  where if you measure the angle separating that halfway point between New Moons  and Full Moons from the point of a half Moon, which again is confusingly not  the same thing, then intuitively you can see how a smaller angle means a larger  distance to the Sun. And more precisely, when you do the little bit of trigonometry here,  you can conclude that the distance to the Sun is the same as  the distance to the Moon divided by the sine of that angle. This is where the Greeks started hitting a wall of technology. What they did is that they knew that the Moon took 28 days to go around the Earth,  and so they had to measure exactly when a half Moon occurred and what the deviation is. Now Aristarchus, he thought that the distance was 6 hours. Half Moons occurred 6 hours before the midpoint between the Moon and Full Moons. He doesn't write how he came up with this. And it's wrong. The actual discrepancy is half an hour. He's off by a huge factor. So the thing is, well, A, we have clocks, which work in the dark. They had sundials which don't work in the dark. They also did not have telescopes. Mathematically the method was sound. Technologically it was just not possible for this method to work. No, but it worked well enough. So he was off by basically a whole order of magnitude. He thought that the Sun was 20 times further away than the Moon. The true answer, based on the slight change to that angle that he was trying to measure,  is more like 370 times the distance to the Moon. And he thought that the Sun was 7 times bigger than the Earth,  when in fact it is 109 times bigger. Even with that lousy measurement, Aristarchus was the first to make a really  important conclusion, which is that the Sun did not move around the Earth. The Sun is 7 times, well he thought the Sun was 7 times larger. Why would the Sun go around the Earth? So the Earth should go around the Sun. Qualitatively his conclusion was correct. It says that the Sun is much, much larger than he thought. But he was the first. And it's not obvious, you know, you look at the Sun and it's this big. But it's actually 100 times bigger than the Earth. So he was the first to propose the heliocentric model. If you look at Copernicus' famous book, he says,  you know, Aristarchus proposed the heliocentric model. And the other Greeks dismissed him, for good mathematical reasons,  but again they were limited by the technology. They said that it doesn't make sense for the Earth to go around the Sun,  because if the Earth were to go around the Sun,  the position of the shape of the constellations would shift as you go from one side  of the Sun to the other, and we don't see that. This is an important point to emphasize, because it's going to come  up again for us later when we figure out the size of the galaxy. So if you've got a bunch of stars sitting here in three-dimensional space,  and you picture yourself as an observer staring at those stars,  and you move around through that three-dimensional space,  then the apparent relative position of those stars shifts around as you move. We call this parallax. It's the same phenomenon where if you're on a car on the highway and you look out,  all of the nearby trees seem to be moving much more quickly than the background mountains. So when Aristarchus says, hey guys, maybe the Earth is going around the Sun,  all of his fellow Greeks are like, well, if that was true,  and you've got this Earth-Sun system sitting among a bunch of stars, then for us,  the observer sitting here on the planet Earth,  as we move around through space from winter to spring to summer,  and it's going to be quite a bit of movement through space,  since evidently the Sun is supposed to be quite far away from the Earth,  then because of this parallax, we should see a change in the pattern of the stars. The nearby stars should be moving a little bit more than the background stars,  and the overall shape of the constellations should slowly drift through the seasons. But that's not what we see. The constellations seem to be the same shape between the summer and the winter. And that would only be possible if the stars were much,  much, much further away than we currently think they are. So Aristarchus, if you were to accept your model,  we must make the universe thousands and thousands of times bigger,  therefore we're going to dismiss your theory. It shows you that even when you have the math right,  you don't necessarily get to the truth, because of course the universe is in  fact not just thousands of times larger than the theory,  but actually billions and trillions of times larger. This is not an obvious fact. At this point, let's jump ahead quite a bit in history up to Kepler. Perhaps the best part of this whole story. This is the most genius step of the ladder. The first time you climb from one step to the next, it's always heroic. Because the first time, you're at the edge of what  the data and the math and the technology can give you. Now Kepler was not working from a blank slate. He was building off of the work of others, most notably that of Copernicus. So Copernicus had already worked out that the planets move around the Sun. He said that the planets move around the Sun in circular orbits. And he even figured out the period, how long it  takes for each planet to go around the Sun. So for example, we know that the Earth takes exactly one year to do a full orbit,  and Copernicus had figured out that Mars takes 687 days for its orbit,  and likewise for all the other known planets. He gets all the fame because of heliocentrism,  but these numbers were arguably his most important contribution. You'll see in a moment why they are critical. The way he computed this was that he had all this Babylonian data. Essentially the way this worked was by compiling centuries of observations for  where the planets appear among the stars, then figuring out when those patterns repeat,  and then very importantly factoring in the movement of Earth in that time. Kepler was interested in figuring out the relative sizes of all of these orbits. He had this funny little pet theory that was linked to the five platonic solids. The idea was if you imagine a sphere inscribed in an octahedron,  and then you fit the smallest possible sphere around that,  and then fit the smallest possible icosahedron around that, then layer on another sphere,  and then a dodecahedron, one more sphere, then a tetrahedron, one more sphere,  a cube, and then one final sphere, you get these six spheres,  and the ratios between the sizes of those spheres, Kepler believed,  would match the ratios of the orbits for the six known planets. Since these are the platonic solids, it somehow  feels like a very natural or universal set of ratios. It would have been a beautiful theory if this was true. So hungry to prove his very beautiful theory, he needed to look at  the historical data for where all the planets appeared in the sky. There was this astronomer at the time, Tycho Brahe, who was this very wealthy,  eccentric aristocrat who had an interest in astronomy,  and so he convinced the government of Denmark to give him an island,  complete with peasants, to build him an astronomy, it's called Uraniborg. And he just made decades and decades of observations of all kinds of things,  including all the planets. Kepler wanted his data, but Tycho Brahe wouldn't give it to him. He stole the data. They weren't on the best of terms. Anyway, he took all his data and he wanted to use it to confirm his theory. And it was off by a couple percent. He could not make the theory fit. In fact, not only could he not make his own theory fit,  he couldn't even make Copernicus' theory fit. He could not make circular orbits match. It's really important to understand that once you throw out the assumption that  orbits are circular, it is very difficult to make sense out of the observational data. It's not like what Tycho Brahe was recording is the  exact position in 3D space for all the planets over time. They didn't know the distances to the planets. The only thing that you can see is where in the sky a given planet appears,  what constellation it's inside on a given date. From that information alone, just a sequence of angles in the sky,  basically, Kepler managed to deduce the shapes of all of these planets' orbits,  including the shape of Earth's orbit. The sun is fixed. Earth is moving around in some orbit, not quite circular. And Mars is also moving around by some orbit, not quite circular. And we don't know what the orbit is. About the only thing we can do is at any given time on Earth,  you can work out where you are with the sun and you can work out this direction. But you have no notion of distance. You only have direction. Imagine that you had observed Mars night after night. Each night you can see where Mars is with respect to the constellations. And this tells you basically the direction from  Earth to Mars with respect to the celestial sphere. But you don't know exactly where Earth is. And you also don't know how far away Mars is. You do know the direction to the sun, even if  you can't literally see it in the constellations. You know this because of what date of the year it is,  since that tells you how far the Earth has gone around. Keep in mind, although Aristarchus had his estimate for how far away the sun was,  people still didn't really have a precise measure for that distance. Aristarchus's method is just too error-prone for anything exact. So all you really know are these two different angles,  and you want to figure out these two unknown orbits. That doesn't seem like enough information. Even if you assume everything's on a plane, which you more or less can,  all the planets live on a zodiac. So it's pretty much a planar diagram. This looks unsolvable. In math, if you can't solve a problem, you first try to solve a simpler problem. So let's solve a simpler problem. Now suppose Mars doesn't move. Suppose Mars is actually nailed to space. Then you can at least work out the orbit of the Earth. If Mars was fixed in space like this, then these two directions are  at least enough to tell you where the Earth is,  at least with respect to that fixed location for Mars and the fixed location for the sun. You would essentially draw these two lines and find the intersection. So if you have the data for many different nights in this idealized hypothetical,  you could plot where the Earth is on each night and so see how it moves around the sun,  at least with respect to these two fixed locations for Mars and the sun. You still don't know absolute distances. So if you had two fixed sun and Mars, then you can work out the orbit of the Earth. But Mars does, of course, move. So how do you triangulate when something moves? So this is the genius thing. Kepler knew because of Copernicus that every 729 days,  Mars comes back to where it was before. So if he takes, tackles data, but takes a time series spaced at spacings of 729 days,  then in that time series, Mars is a reference point. Brahe observed for 10 years, Mars, there was just enough data in this data set. It is perhaps worth being extra clear about how exactly this works. Like we said, on a given night using these two different directions,  you can figure out Earth's location with respect to where Mars happens to be. So if you wait 687 days and Mars is back in that same location,  you get another data point for Earth with respect to that same spot. Using 10 years worth of data, this gives you five different locations for where Earth is. But again, this depends on exactly where in space Mars is. If you jiggle it about, it jiggles around the implied five points for Earth. I'll go ahead and give those a slightly different color,  and then have you imagine looking just a couple days later to a different location  of Mars, and then taking a similar time series, again spaced out by this Martian year,  to get five more positions for Earth, but now they're dependent on that different  location for Mars. Of course, you don't know exactly how Mars moves,  so you don't know exactly where these five points are, but if it's just a day later,  Mars only will have moved a little bit, and you know those five points should  only have moved a little bit. So what Kepler has is essentially like this massive jigsaw puzzle,  where each piece looks like five points for where Earth is,  conditioned on a mystery location for Mars. Knowing that all of those pieces have to fit together about a day apart,  he was able to piece them all together to get a coherent orbit for Earth,  with respect to a certain coherent orbit for Mars. To be clear, nothing about this tells you absolute distances,  it's just giving you the shape of the orbit, but even still he was able to see what  no one before him had ever seen, which is that this orbit is not a circle,  it's an ellipse, and he was even able to find other neat facts,  like how the area the Earth sweeps out as it goes along this orbit is the same for a  given time period, no matter where on the ellipse it sits. And once you have a sense for the shape of Earth's orbit,  it makes it a lot easier to deduce the orbit of Mars, or any other planet. You can do this in reverse, if you take one fixed point of Mars,  you can take measurements from Earth, and you can now work out the location of Mars. This angle measurement may not tell you the distance to Mars on one night,  but if you take five separate nights spaced out by 687 days,  meaning you know that Mars is at the same point in space on those five different days,  then you get these five different angles that are more than enough to help  you triangulate where Mars is, at least with respect to Earth's orbit. When you do this for many different adjacent time series,  you can draw out the exact orbit of Mars over the course of those 687 days. Einstein once wrote an introduction to a book on astronomy,  and I think he mentioned this idea, he called it an idea of pure genius. He needed the data, he needed, not just Tycho's data,  but Copernicus's data, which came all the way from the Babylonians. So the period of Mars, that was the period of centuries. But he could put it all together with what we would now call data analysis. Again, you still don't know the absolute distances. This gives you the shapes of both orbits, and doing something similar you  can get the shapes of all the other planets' orbits relative to Earth's. But to Kepler and his contemporaries, the exact  scale of the solar system remained a mystery. It's like they could draw the exact picture, but they didn't know the size of the paper. So from this point on, astronomers were on a hunt to figure out  a way to measure any distance they could in this solar system. Because if they could do it precisely, just one distance  would be enough to lock everything else into place. In the next part, we'll continue with the interview,  and you'll see how this was first done, and how once you finally have an accurate  measure for the distance between the Earth and the Sun,  you can use it to deduce the speed of light, the distance to the nearest stars,  and ultimately the distance to the farthest observable galaxies. If you want to stay updated for the next part,  make sure to follow 3Blue1Brown on whatever platform it is that you most  like to follow Steph on. There's an email list, just going to throw that out there.

================================================================================
VIDEO ID: uT4-WVa-YfU
TITLE: Measuring the earth with Terence Tao
URL: https://www.youtube.com/watch?v=uT4-WVa-YfU
PUBLISHED: 2025-02-08T13:35:06Z
STATUS: SUCCESS
================================================================================
in the 10th Century there's an Arab matian aloni who measured the the radius of the Earth to within 1% what he did was that he climbed a mountain with an ASE he measured The Horizon The Horizon was not quite horizontal it was it was dipped at an angle here's the Earth and here's a mountain not a scale okay so so if you're standing on top of a mountain the The Horizon is actually not horizontal it's at an angle right yeah here's the raise of the earth and you have a right angle triangle here you have a right angle triangle the hypotenuse is uh the radius plus the height of the triangle and if this angle is Theta then by trigonometry this angle is also Theta and so uh there is an equation I think uh R is equal r + H * cosine [Music] Theta just from elementary trigonometry you can relate the radius of the Earth plus the height of the mountain to this angle and so you can compute the radius I think it's something like H Co so there's a formula that you can comp be the r of the Earth from the height of your mountain and the angle of declination how did you know the height of the Mountain uh that's a good question uh I guess you could you could walk around a bit and take angles and that part I don't actually know with enough trigonometry you can do it this comes from an interview with teren to about all of the clever ways that Humanity has measured distances in the cosmos from the size of the Earth up to the most distant galaxies if you want the full story click the link at the bottom of this short

================================================================================
VIDEO ID: K-pGGb0f3tc
TITLE: The topology of two-note chords
URL: https://www.youtube.com/watch?v=K-pGGb0f3tc
PUBLISHED: 2025-01-30T15:00:25Z
STATUS: SUCCESS
================================================================================
there's a sense in which every two note chord naturally lives on a mobia strip here we're not going to draw any distinction between octaves so we'll naturally think of all of the musical notes as living on a circle like this so every two note chord effectively looks like an unordered pair of points on this circle and the question is what mathematical space describes that you might start by labeling all of the points on a loop with values ranging from 0 to 1 because it's a loop it ends where it starts so the labels 0 and one would have to really refer to the same point then a pair of points would have a pair of numerical labels that you could think of as XY coordinates describing some single point in this unit Square here of the XY plane but again because 0o and one really refer to the same point what you should do is glue this left edge of the square to the right Edge since really they refer to the same thing likewise you'd want to glue the bottom Edge to the top Edge since y-coordinates of 0 and 1 are really the same thing and when you glue all of those together what you end up with is the surface of a donut known as a Taurus but this isn't really the answer that I want what I asked for was an object that encodes unordered pairs of points that is if you swap the two points like swapping two musical notes it should really be considered the same thing in our unit square if you glue every point with coordinates X Y to the point YX what it looks like is folding along this diagonal after that you still have to glue the arrows together as a way to remember that zero and one refer to the same thing but now it feels impossible the trick is to cut along another diagonal adding new arrows when you do to remember to glue it back together this lets you glue those purple arrows and now to stitch together the remaining ones you need to introduce a half twist so the true answer here is a mobia strip this was a construction that came up in a recent video where we use this fact that mobia strips naturally encode unordered pairs of points in a genuine mathematical proof and it's related to a classic solved problem

================================================================================
VIDEO ID: 0TdBP9m4R74
TITLE: The barber pole optical mystery
URL: https://www.youtube.com/watch?v=0TdBP9m4R74
PUBLISHED: 2025-01-06T15:37:38Z
STATUS: SUCCESS
================================================================================
this is one of the most interesting Optical phenomena I think I've ever seen right here is a tube that's full of a very dense sugar water mixture when you shine in white light through a polarizing filter into this mixture you notice these colored diagonal Stripes fully explaining these Stripes is really challenging but here's the basic idea when you have sugar water and you shoot polarized light through it meaning the light wave is wiggling up and down in Just One Direction as it passes through the mixture interaction with those sugar molecules causes this direction of polarization to slowly twist as it goes down the tube so for example if it started polarized up and down by the time it gets to the end of the tube it might be polarized horizontally or at some other Angle now critically the rate at which it twists depends on the frequency of the light higher frequency light like purple is getting twisted faster than lower frequency light like red so if you shine white light in at the beginning by the time you get to the end of the tube all of the different pure frequencies have distinct directions of polarization now you wouldn't be able to notice this just by looking down the other end of the tube the light still looks white because it contains this mixture of all the frequencies so one of the big Mysteries here even if you're an expert in Optics is why you see any evidence of that color separation looking at it from the side because it's not like we're passing the light through another polarized filter it's still white light in the middle of that tube the idea there is that when light bounces off of molecules you know the water molecules air molecules sugar molecules anything like that and comes towards your eyee the direction that it bounces is not uniformly random in all possible directions it depends on the polarization direction of that light there's a lot more light that scatters perpendicular to that polarization Direction and in an idealized situation no light is scattering along the direction of that polarization so for some point in the middle of the tube light with a certain color like red might be wiggling perpendicular to your line of sight meaning you're more likely to see more red while of other frequencies like purple might be at different directions more aligned with the line of sight meaning less light would scatter towards you this explains the variation in color as you scan your eyes from left to right along the tube but that would seem to imply the stripes should be vertical the fact that they diagonal tells us there's also variation as you scan your eyes up and down this depends on the fact that the tube is circular and that the light is getting bent at different angles as it goes from the water through the glass tube and into the air last year I got sucked pretty deeply into the rabbit hole of explaining each component of this mystery and the result was a collection of videos about certain fundamental ideas in Optics like the very origins of what causes light or what exactly we mean when we say light is slowing down when it goes through glass or water and why that would depend on color and I just love this how you can start with a seemingly simple mystery but if you tug on that thread with enough curiosity it kind of forces you to wrap your mind around very foundational topics useful to all sorts of other Mysteries that you might encounter

================================================================================
VIDEO ID: zxOK2vKVfQM
TITLE: Monge's Theorem
URL: https://www.youtube.com/watch?v=zxOK2vKVfQM
PUBLISHED: 2024-12-29T16:00:54Z
STATUS: SUCCESS
================================================================================
here's a fun geometry puzzle with a very surprising solution imagine you have three circles and for each pair of them you look at these two lines here the ones tangent to both circles on the outside and you consider where those tangent lines intersect each pair of circles with its corresponding pair of external tangents gives us one such point in the plane now if I play around with the positions and sizes of those three circles you'll notice that those three different points always seem to sit on a line now if these or three random points in the plane the odds of this happening are zero so the question is why it must be true for this construction this is known as monges theorem and I'll give you a hint about one very clever solution which is that it involves a step into the third dimension I'll also say that if you think you know the answer because you saw a number file video on this there's actually a slight mistake in the argument there you can see the full Solution by clicking the link at the bottom of the screen the discussion for this particular problem starts about 10 minutes in

================================================================================
VIDEO ID: DgMhayP2NPU
TITLE: Thinking through double slits
URL: https://www.youtube.com/watch?v=DgMhayP2NPU
PUBLISHED: 2024-12-26T16:48:04Z
STATUS: SUCCESS
================================================================================
a lot of people have heard of double slit interference but have you ever thought about exactly what it is why it has the pattern that it does and while you don't observe it with things like white light right here is a nice physical demo at the Exploratorium where a laser is shot through two very thin slits and down on a wall several feet away from the slits you don't just see two bright spots you see many let's go ahead and pull up a simplified simulation to try thinking through what's happening if the slits are thin enough you can model each one of them as a point source and it's important for what follows for the light coming from each one to be a pure sine wave with just a single wavelength think about a point on the middle of the wall behind these slits the distance to each slit is the same so those two waves are in Phase with each other and this gives what we call constructive interference so you see a bright spot but if you shift a little to the side to a point such that the distance to one slit is exactly half a wavelength longer than the distance to the other then the two waves actually cancel out the peaks of one line up with the troughs of the other the net result is nothing and you get a dark spot when you think about it this actually feels really bizarre at first because it means when you go from having one slit to opening a second this specific point of the wall will actually become darker despite more Total light being let through it's weird but it's a consequence of the fact that you're adding waves similarly if you scan from left to right these waves fall in and out of sync with each other giving oscillations between bright and dark spots but but that specific pattern depends a lot on the specific wavelength of the light it changes if you change that wavelength this is why if you tried it with white light which is a mix of a lot of different pure sine waves you wouldn't see the distinctive pattern they would all kind of blur against each other which is why it took until 1800 for anyone to notice this phenomenon

================================================================================
VIDEO ID: LuVUnd0C07U
TITLE: The inscribed square problem
URL: https://www.youtube.com/watch?v=LuVUnd0C07U
PUBLISHED: 2024-12-24T18:46:12Z
STATUS: SUCCESS
================================================================================
here's a question that nobody in the world knows the answer to suppose you have some closed continuous curve if you can find Four Points somewhere on this Loop that make the vertices of a square it's called an inscribed square of the loop and the unsolved question is whether every possible closed continuous loop like this necessarily has an inscribed Square the question was originally posed by autot topits in 1911 and it's commonly known as the inscribed Square problem one of my all-time favorite pieces of math easily in the top five is a very beautiful proof for a simpler version of this question asking instead whether you can necessarily find an inscribed rectangle the argument is originally due to Herbert vau and as a spoiler our discussion here is going to lead you to think about this shape right here what's known as a Klein bottle but it won't come up as some curiosity or a trinket it arises as a natural problemsolving tool [Music]

================================================================================
VIDEO ID: IQqtsm-bBRU
TITLE: This open problem taught me what topology is
URL: https://www.youtube.com/watch?v=IQqtsm-bBRU
PUBLISHED: 2024-12-24T17:50:32Z
STATUS: SUCCESS
================================================================================
Here's a question that nobody in the world knows the answer to. Suppose you have some closed continuous curve, which essentially means some squiggle you could draw on paper without lifting the pen, that ends where it starts. If you can find four points somewhere on this loop that make the vertices of a square, it's called an inscribed square of the loop. And the unsolved question is whether every possible closed continuous loop like this necessarily has an inscribed square. The question was originally posed by Otto Toeplitz in 1911, and it's commonly known as the inscribed square problem. One of my all-time favorite pieces of math, easily in the top five, is a very beautiful proof for a simpler version of this question, asking instead whether you can necessarily find an inscribed rectangle. The argument is originally due to Herbert Vaughan, and as a spoiler, our discussion here is going to lead you to think about this shape right here, what's known as a Klein bottle, but it won't come up as some curiosity or a trinket. It arises as a natural problem-solving tool. One of the earliest videos that I made for this channel was actually about this proof, and I'm making this video as a kind of second edition to that one. I realize second editions are much less of a thing for YouTube videos than they are for books, but part of my motivation here is that there's been more research since that original video that's very much worth discussing. Another motivation is that there's numerous caveats and interesting connections both beautiful and mind-broadening that are definitely worth including. Aside from that, given that it's one of my favorite pieces of math, I kind of just want to take a stab at animating it and motivating each one of the steps as best as I know how. Some of you might ask why on earth anyone would care about proving that any closed loop has an inscribed rectangle. I personally don't know of any application. Frankly, I would be surprised if there was one. But I think many of you know that engaging with challenging puzzles, even when they're pure puzzles, has a way of sharpening your problem-solving instincts in a way that can be carried over to other practical applications later. But I can also give you a much more specific reason why I love this particular proof. It's something I first saw a long time ago, and I remember it being the first time that I felt a sense for what topology is actually all about. You see, in a lot of recreational math settings, topology is sometimes presented as something like a study of bizarre shapes. A common classroom activity might be to apply a half-twist to a thin piece of paper and glue the ends together, forming what's called a MÃ¶bius strip. You might be told this is what's called a non-orientable surface. Loosely speaking, this means there's no notion of an inner side or an outer side. The whole thing just has one side. Topology is also often presented as a sort of rubber sheet geometry, where shapes are considered the same if you can deform one into another without tearing it. Neither of these notions, in my opinion, really captures what it's actually about. And when I was growing up, I remember these kinds of examples left a frustrating open question. How is this math? How does any of this actually help you solve problems? If you stick with me to the end here, you'll see how these shapes and their bizarre properties are not just idle curiosities, but they're actual tools for logic and deduction. The first step in proving that any closed loop contains a rectangle is going to be to reframe the question just a little bit. Instead of thinking about four points that are the vertices of a rectangle, think about searching for two distinct pairs of points, such that the lines connecting each pair have the same midpoint and they have the same length. Hopefully it's not too hard to convince yourself that this really is the same thing as searching for a rectangle. If I told you, hey, I found two line segments somewhere out in space, and I further specify that both of them have the same center, and also that both segments have the same length, then the four endpoints of those two different lines have to form a rectangle. If you want, you could try to pause and ponder to rigorously prove this. It's a relatively straightforward geometry exercise. Given some arbitrary closed loop, what you and I are going to do is somehow think about all possible pairs of points on that loop. For any one of these pairs, we care about two things. The first is where its midpoint sits, which you might think of as two numbers worth of data. The xy coordinates on the plane where the loop sits. The other thing we care about is the distance between those points, which is another data point. Now if you're a mathematician and you see three numbers worth of information like this, it is a very natural step to try packaging them together and think of that data as being a single point in a three-dimensional space. In our example, if you imagine the loop sitting on an xy plane inside that space, and its midpoint has some coordinates xy, then this 3d point that we care about, the one packaging x, y, and d, could be thought about as a point directly above that midpoint, such that the distance off the plane matches the distance between the pair of points on the loop. Some other pair of points on the loop would correspond to some other point in three-dimensional space. And in essence, what we have here is a mapping. A mapping from pairs of points on the loop to three-dimensional space. The important feature of this mapping that we're going to rely on is that it's continuous. And essentially what this means is if you just slightly wiggle the input, slightly nudging that pair of points, the output only slightly wiggles as well. There are never any sudden jumps. In our search for inscribed rectangles, with respect to this mapping, it amounts to searching for a kind of coincidence when two distinct pairs of points map to the same output, since by definition that would mean they have to have the same midpoint and be the same distance apart, which, like I said, means they have to form a rectangle. So if you imagine yourself as a mathematician mulling this over, you want to know how you can prove that this kind of collision would happen. Looking over all possible pairs of points on the loop and all their corresponding three-dimensional outputs, how could you know for sure that a collision must happen? You might complain that this all feels like stating the same question just in more complicated language, but where it really starts to feel qualitatively different is if I invite you to think about the set of all possible outputs of this map, every possible point in 3D space that corresponds to some pair of loop points like this. Taken together, they form this kind of wild surface, which looks like some incredibly beautiful but complicated Frank Gehry architectural design. Even when I render this out, personally I find it kind of hard to even wrap my mind around what exactly I'm looking at. What I found helpful was to look at cross-sections. Near the bottom, the cross-sections of this surface look approximately like the loop itself, which is a surprisingly important fact that we'll get back to. And then let me pull up those two pairs of points again and position them so that they sit on some rectangle vertices. Then if I bring up the cross-section to the height of that corresponding output, notice what it looks like. Around that point, it kind of feels like the surface is crossing through itself. And in fact, for the example I'm showing, there's not just one point of intersection, there's this continuous curve of self-intersection points corresponding to a continuous family of inscribed rectangles in the loop. This is a really cool way to think about inscribed rectangles. Every point you see in the surface that feels like self-intersection in this way corresponds to some inscribed rectangle in the loop. So far, all of this has just been illustrated with a single example loop, but keep in mind, every possible loop that you could draw on the plane has its own corresponding unique surface sitting above it. Proving that this kind of self-intersection has to happen no matter what loop you start with really comes down to getting to know this surface and who it really is and what it's all about. In the first edition of this lesson, many commenters asked, what would this surface look like for a circle? And in this case, the result is deceptively simple. It looks something like a dome. And at first, this might seem like it has no self-intersection. But the imperfections with how the surface is being rendered do give a little bit of a hint that something funny is happening near the very top of that dome. And if you think about it, a circle certainly has inscribed rectangles. In fact, it has infinitely many of them. And all of them have a midpoint at the center of that circle. And the length of the diagonal for those rectangles is always equal to the circle's diameter. So what this means is that the function we define from pairs of loop points into 3D space maps many many different points, infinitely many, onto this single point on the top of the dome. So we certainly have the collision that we're looking for, infinitely many in fact. But for this example, it doesn't have that same look of a ghostly sheet kind of passing through itself in space. If I squish the circle to become an ellipse, you can see how that single point of many intersections becomes a vertical line of self-intersections. And I'll invite you to pause and ponder to think about why that might be the case. The point is, just keep in mind when I use this phrase, self-intersection, what I'm really getting at is the idea of two different pairs of points mapping to the same output. In almost all cases, that looks like a surface passing through itself, but it's possible for it to look different. Another point that's maybe worth emphasizing is that the surface you're looking at is not a function graph. A function graph in three dimensions comes from functions that have two numbers as an input and one number as the output. Right here we have something notably more complicated. The inputs of the function are pairs of points on the loop, and the outputs are triplets of numbers, full points in 3D space. What you're looking at is the set of all outputs, it's not a graph. There's a famous quote from the author Anton Chekhov giving advice about writing, where he says, if in the first act you have hung a pistol on the wall, then in the following one it should be fired. His main point is about only including strictly necessary information, but another principle, implicit, is that the seeds for dramatic action should be planted early. In our story here about topology and proving inscribed rectangles, I want to draw your attention to a certain gun hanging on the wall. I mentioned how near the plane of the curve, the cross sections of the surface look approximately like the curve itself. Why is that? Well, think about a pair of points that are really close together. Because the distance between them is small, the output has a very small z-coordinate, and the midpoint is close to both of those points themselves. In the extreme, if you have a pair of points that's really just the same spot on the curve, listed twice, then the output of this mapping is that same point on the curve. Remember that. All pairs that look like x,x correspond to points on the curve itself. So we have this wild surface, we're trying to prove self-intersections, and the next step for how we're going to do this is to come up with a second, very natural way to associate pairs of points on a loop with a certain other surface. The final argument is then going to come down to understanding how this other mystery surface can or cannot be embedded into three dimensions without self-intersection. To set this up, it helps to give the loop a kind of internal coordinate system, let's say associating each point on the loop with a number between 0 and 1. Geometrically, an association like this is a little bit like snipping the loop at some point and then flattening it out onto the unit interval of the number line. Every point of the loop is associated with a unique number from 0 to 1, and vice versa, with the single exception of the fact that both 0 and 1 map to the same point of the loop. So for this to be a continuous association in both directions, something we're going to care a lot about, you might imagine wanting to glue that number 0 to the number 1. You'll see in a moment why this is important. Now of course we don't care about single points on the loop, our whole study here is about pairs of points on the loop, and if you have some second point, naturally you might think of a second unit interval maybe along a y-axis. So here the x-axis gives a coordinate for the first point, and the y-axis gives a coordinate for that second point, and the pair of points taken together would correspond to a single point in this unit square, where the two-dimensional coordinates of that point essentially encode which two points on the loop we're talking about. This association between individual points in the square and pairs of points on the loop is almost a continuous one-to-one map, but again there's some awkwardness around the edges based on the fact that the coordinates 0 and 1 really describe the same thing. For example, look at all of the points on the left here where the x-coordinate is 0, corresponding to this vertical line. All those points really represent the same loop pair as the ones on the right side, where the x-coordinate is 1, this other vertical line here. I'll color both of them blue and I'll put some arrows on there to help remember the orientation. Similarly, all of the points whose y-coordinate is 0, this bottom line here, represent the same loop pairs as the point whose y-coordinate is 1, up at the top. If you're thinking topologically, you don't just want to record this, you want to somehow represent it geometrically. And the way we'll do this is to glue both of those blue lines together, which you might think of as giving this tube. The green lines have now turned into these circles at the end of the tube, and to glue those together it requires curling the tube around on itself, giving us this surface of a donut shape, which is commonly called a torus. And I want to point out it's not like we landed here because of some random pondering about donuts and coffee cups. The surface seems to be a really natural representation of all possible pairs of points on the loop. And what I mean when I say natural here is essentially two things. First of all, the mapping goes both ways. Every point of the torus corresponds to a unique pair of points on the loop, and each pair of points on the loop gives us a unique point on the torus. Secondly, the association is continuous, meaning if I wiggle some point on the torus, it results in only a slight wiggle to the corresponding pair of points on the loop, and vice versa, there are never any sudden jumps. But actually, the torus is not quite the right surface for our purposes. Remember why we're doing any of this. We're looking for two distinct pairs of points on an arbitrary loop that have the same midpoint and the same distance apart. But it matters whether we care about the order of a pair of points. If you consider the pair a,b to be distinct from the pair b,a, then that would give you a trivial example of two distinct pairs of points that have the same midpoint and the same distance apart. But this is like saying that you can always find an inscribed rectangle as long as you're okay with an infinitely thin rectangle. Clearly what we want is to prove that there are non-trivial rectangles, and for that you need to think of the pair of points as being unordered, in the sense that a,b and b,a should really refer to the same thing. Looking back at our unit square, you now want to somehow record the fact that every point with coordinates x,y should really be considered the same as the point with coordinates y,x. If you take a moment to think about it, what you essentially want here is that all of the points on the square that are reflected along this diagonal line should be considered as representing the same pair of points on the loop. And again, you can think of this with a kind of gluing, where we're going to fold the square along that diagonal line, kind of like a grilled cheese sandwich. And when you do this, I want to draw your attention again to that gun hanging on the wall. Every pair of points that looks like x,x corresponds to a point somewhere on the crease of this fold, this diagonal line, which from this point on I'm going to be coloring in red. You still need to glue the edges together, as a way to remember that 0 and 1 really map to the same point on the loop. But after our diagonal fold, we're faced with a real puzzle here. Notice the orientation. How exactly to do this is puzzling enough to almost feel contradictory. But sometimes with topology, you have to take a step back in order to take a step forward. The trick here is to cut this piece along another diagonal, and we're going to add some new arrows to remember to glue that cut back together in a moment. Doing this lets you glue together the original two arrows, which gives us this square with two edges that still need to be glued. But notice that the orientation of the remaining arrows are reversed. So to glue those back together, what you need to do is somehow introduce a single half twist, and this is exactly the construction for a MÃ¶bius strip. That is really cool to me. And again, I want to emphasize this is not some arbitrary play task with construction paper. This shape arose for us very naturally. It's a way to geometrically represent all possible unordered pairs of points on a loop. And again, what I mean by natural here is that each point of the strip corresponds to a unique pair on the loop, and vice versa, and the relationship is continuous. Small nudges on one side correspond to small nudges on the other. The other thing I want to draw your attention to is the red edge of that MÃ¶bius strip. Originally, this is what came from the diagonal in that unit square. It represents all pairs of points that look like x comma x. That is, pairs that are really the same point but just listed twice. As a final step, connect this with what we were doing earlier, where we constructed that strange Frank Gehry-looking surface, encoding all of the loop pair data that we cared about. Now, you also know that unordered pairs of points have this natural correspondence with a MÃ¶bius strip, in the sense that you have a two-way continuous association. What that means is there's necessarily a continuous function from the MÃ¶bius strip onto this surface in 3D space. To animate this, let me show you what it looks like if I move every point of that surface back to its corresponding point on the MÃ¶bius strip, the one associated with the same pair of loop points. And here it is going the other way, very explicitly showing the map from the MÃ¶bius strip onto this surface. But it's not just any map. Focus one last time on the gun hanging on the wall. The edge of this MÃ¶bius strip, which, remember, corresponds to all the pairs that look like x comma x, that has to land on the loop itself, meaning it has to end up confined to the xy-plane. And if you take a moment and play around with the idea in your head of MÃ¶bius strips and how they can fit into 3D space, you might find it entirely believable that it's impossible to embed a MÃ¶bius strip into 3D in such a way that its edge stays confined to a plane like this, at least not without somehow crossing through itself. If this claim is true, we have our desired result. Self-intersection in this context means two distinct points from the strip have to land on the same point of the surface. And in turn, that means there's two distinct pairs of points that have the same midpoint and the same distance, and hence they form a rectangle. While this claim is very believable, proving this kind of statement from scratch can be a little bit tricky. In fact, not only is it tricky, but stated so far the claim is not even true. After the first edition of this lesson, the mathematician Dan Asimov reached out to me, a construction that he made for embedding a MÃ¶bius strip into three dimensions in such a way that its boundary not only ends up on a plane, but it ends up equaling a circle. Here, that's a little bit of a mind warp. Let me play it for you one more time. For me at least, I find this very trippy to think about, and even after seeing the transition, I have trouble getting my brain to parse that what I'm looking at is a MÃ¶bius strip. But that's what it is. The more familiar strip-with-a-twist shape that we often see is just one out of infinitely many ways that you could represent what this mathematical object really is. This bizarre snail-shell looking thing is no less valid. The existence of an embedding like this would provide a fatal counterexample to our desired result, but notice how in this example, the interior of the surface goes both above and below the circle. But in the surface we constructed with the loop pairs, all of the points are necessarily above the xy plane, by definition. So what we really want to prove is that it's impossible to map a MÃ¶bius strip into 3D in such a way that its edge is confined to the xy plane, and the interior of the strip is strictly above the plane. If that's impossible, at least not without self-intersection, we have our result. Again, proving this rigorously from scratch can be tricky, but what I can do is offer a connection to something that many of you might have seen before. So far, what we know is that this strange surface is really a MÃ¶bius strip, and I want you to consider the reflection of the surface underneath the plane. Taken together, this surface and its reflection underneath form some new closed surface. Essentially, it's whatever you get if you glue the edge of one MÃ¶bius strip to the edge of another. So this raises the question, what do you get when you glue together the edges of two MÃ¶bius strips? Well, one really nice way to think about this is to look back at the diagram that we had earlier, the one that we eventually cut and glued to be the strip itself. If you take a reflection of that, giving us another thing that will become a MÃ¶bius strip, you can nicely glue these together along that red edge. To figure out what surface this represents, you basically do the same trick that we did earlier. You first cut along this other diagonal, recording the new cut with some new colored arrows, reminding us how we're going to glue later. This lets you flip one of the pieces so that we could glue, for example, the teal edges together. And what you're left with is something very similar to the torus diagram. You can start the same way, where you curl it around to glue, for example, those pink edges together, making a tube. But the difference between this and a torus is that those circular ends have opposite orientations, which makes it kind of awkward to glue them together, maintaining that orientation. One way that you could do this is to pass one side of that tube through the tube itself so that it can meet up with the other end kind of coming from the other direction. What you get as a result is known as a Klein bottle. This is kind of a celebrity shape in math, very famous because of the bizarre way that it has no clear interior or exterior. Any point that seems to be on the inside could be moved around in some way to end up on the outside. If you know about Klein bottles, one of the main things you might know is that it's impossible to properly represent them in three dimensions without somehow having the surface intersect itself. In higher dimensions, it can live much more comfortably, but down here there's just no way to make it work. This is a more general fact about any closed, non-orientable surface. And what's very satisfying in my opinion is how, for us, right here, this fact is relevant for an actual proof. If you believe that Klein bottles can't be represented in 3D without self-intersection, it means that the surface we constructed over our loop, viewed together with its reflection, must have some kind of self-intersection. And based on the construction of the surface, that means we have two distinct pairs of points with the same midpoint and the same distance apart, and hence a rectangle. For the extra curious among you, I'll leave up on screen an argument for why exactly any closed, non-orientable surface cannot exist in 3D without intersecting itself. Stepping back though, I want to talk a little bit more about the unsolved problem, proving that any loop necessarily has not only an inscribed rectangle, but specifically an inscribed square. Given the entire proof that we just went through, a natural thought that you might have is to focus not only on the midpoint and the distance between a given pair of points, but to also record the angle of that line segment. Because if you had two such line segments that not only share a midpoint and a length, but also differ by 90 degrees, that would necessarily mean that they form a square. If sitting there watching this right now, that gives you an instinct to somehow think about embedding MÃ¶bius strips into four dimensions, since this now has four numbers worth of information, well then you would have very good instincts indeed. In 2020, the mathematicians Joshua Green and Andrew Lobb proved a really nice extension of this result in the specific case of smooth curves, which is contrasted with rough ones like fractals. I'll talk a little bit more about smoothness in a moment, but what Green and Lobb showed was how in this special case, not only can you always find a square that had actually been known for a while, but you can find rectangles of every possible aspect ratio. And if you look into their paper, which I'll link to in the description, it involves discussion of embedding MÃ¶bius strips and Klein bottles into a certain four-dimensional space. And while that would sound just weird and kind of wild without any background, hopefully now you have an instinct for why that kind of approach is not only sensible, but utterly reasonable. If you understand the rectangle proof, the one that we walked through in this video, you can also have some instinct for why smoothness would make the question easier. What smoothness means in a technical sense is that you can take as many derivatives of your curve as you want, but geometrically one of the bits of significance here is that for smooth curves, every point has a well-defined tangent line. Now in our proof, think about how much it mattered that we had clean limiting behavior as the pair of points got closer and closer together. This was the gun hanging on the wall. It was the constraint for where the edge of the MÃ¶bius strip had to land, which was critical for the final result. Now if in addition to tracking the midpoint and distance, you're also tracking the angle of that line connecting the pair, then for smooth curves the angle also has some clean limiting behavior as the pair gets close together, namely it approaches whatever the angle of the tangent line at that point is. But for a rough curve, something like a fractal, there might not be limiting behavior for that angle. What really makes the inscribed square problem hard, the reason it remains unsolved, is the case of all of the rough curves like this. The main thing I want you to take away from this lesson is a sense that when mathematicians talk about shapes like MÃ¶bius strips or Klein bottles or even stranger higher dimensional objects, they aren't just studying bizarreness for its own sake. Sometimes when you're solving a problem and you're coming up with structures to help you in that process, some of those structures are very mind-bending to ponder, and sometimes they're so fun to think about that those objects trickle their way out of research and into recreational math outlets. And sometimes in the process the original problem-solving relevance gets a little bit lost. Another takeaway I hope you have is that a MÃ¶bius strip is not really any one particular surface. This, this, and this are also MÃ¶bius strips, as is the more abstract idea of unordered pairs of points on a loop. Another case where that one might come up is in describing every possible musical interval. This is getting at the idea of a topological space, which is not so much a particular shape as it is an infinite family of shapes all connected by a certain notion of equivalence. Defining what exactly a topological space is, and what topology is for that matter, is a little bit subtle, and it's one of those things where the formal definitions don't really shed a lot of light on it, at least not immediately. But one way to describe what topology is about is that it's a game of understanding continuous associations between things, and understanding what is or is not possible under those associations. All of the famous shapes from this field of study are better thought of as representatives of huge families of shapes that all have essentially the same kind of behavior under continuous maps. And the reason that mathematicians get really excited about bizarre properties and impossibilities is not just aesthetic. It's because when you're looking for logical proofs, constraints and impossibilities are your fuel for progress. If you enjoy this kind of video, there's a playlist I put together on this channel full of a lot of other neat proofs and puzzle solutions that come out of left field.

================================================================================
VIDEO ID: y9BK--OxZpY
TITLE: The meaning within the Mandelbrot set
URL: https://www.youtube.com/watch?v=y9BK--OxZpY
PUBLISHED: 2024-11-24T17:00:57Z
STATUS: SUCCESS
================================================================================
the mandal BR set is one of the most iconic images in all of math but do you know how it's defined you start with some complex number c which will visualize with this movable yellow Dot and then you recursively Define a sequence of complex numbers where the sequence starts with zero and each new value is defined to be the square of the previous Value Plus C so for example on the very first iteration you take 0^2 + C meaning Z1 is just C and then for the next iteration you take that number squared plus C meaning Z2 is c^2 + C and in the picture you can see how as I change the choice of C the second value will change in lock step and in general you keep going each new value is the square of the previous Value Plus C creating this infinite sequence in the complex plane which as you can see changes as I change the value of C now for some choices of C the sequence stays bounded but for other choices the terms blow up and go to Infinity if you color all of the values of c that cause this process to stay bounded black and you apply some gradient of colors to the other values where the color depends on how quickly the process blows up to Infinity you get this iconic cardioid with bubbles shape and you can say a little more the main cardioid in the middle corresponds to all of the values of c where this process will approach a single limit point and this big circle on the left corresponds to all the choices of C where the process tends to approach a state where it kind of bounces back and forth between two values and then the circles on the top and the bottom of the picture each correspond to choices of C where the process will get caught in a cycle between three values and in general each part of this image corresponds to some qualitatively distinct behavior of the sequence

================================================================================
VIDEO ID: qSn8dVI9V5I
TITLE: The scale of training LLMs
URL: https://www.youtube.com/watch?v=qSn8dVI9V5I
PUBLISHED: 2024-11-20T15:07:29Z
STATUS: SUCCESS
================================================================================
the scale of computation involved in training a large language model is mindboggling to illustrate imagine that you could perform one billion additions and multiplications every single second how long do you think that it would take for you to do all of the operations involved in training the largest language models do you think it would take a year maybe something like 10,000 years the answer is actually much more than that it's well over 100 million years

================================================================================
VIDEO ID: LPZh9BOjkQs
TITLE: Large Language Models explained briefly
URL: https://www.youtube.com/watch?v=LPZh9BOjkQs
PUBLISHED: 2024-11-20T15:07:15Z
STATUS: SUCCESS
================================================================================
Imagine you happen across a short movie script that describes a scene between a person and their AI assistant. The script has what the person asks the AI, but the AI's response has been torn off. Suppose you also have this powerful magical machine that can take any text and provide a sensible prediction of what word comes next. You could then finish the script by feeding in what you have to the machine, seeing what it would predict to start the AI's answer, and then repeating this over and over with a growing script completing the dialogue. When you interact with a chatbot, this is exactly what's happening. A large language model is a sophisticated mathematical function that predicts what word comes next for any piece of text. Instead of predicting one word with certainty, though, what it does is assign a probability to all possible next words. To build a chatbot, you lay out some text that describes an interaction between a user and a hypothetical AI assistant, add on whatever the user types in as the first part of the interaction, and then have the model repeatedly predict the next word that such a hypothetical AI assistant would say in response, and that's what's presented to the user. In doing this, the output tends to look a lot more natural if you allow it to select less likely words along the way at random. So what this means is even though the model itself is deterministic, a given prompt typically gives a different answer each time it's run. Models learn how to make these predictions by processing an enormous amount of text, typically pulled from the internet. For a standard human to read the amount of text that was used to train GPT-3, for example, if they read non-stop 24-7, it would take over 2600 years. Larger models since then train on much, much more. You can think of training a little bit like tuning the dials on a big machine. The way that a language model behaves is entirely determined by these many different continuous values, usually called parameters or weights. Changing those parameters will change the probabilities that the model gives for the next word on a given input. What puts the large in large language model is how they can have hundreds of billions of these parameters. No human ever deliberately sets those parameters. Instead, they begin at random, meaning the model just outputs gibberish, but they're repeatedly refined based on many example pieces of text. One of these training examples could be just a handful of words, or it could be thousands, but in either case, the way this works is to pass in all but the last word from that example into the model and compare the prediction that it makes with the true last word from the example. An algorithm called backpropagation is used to tweak all of the parameters in such a way that it makes the model a little more likely to choose the true last word and a little less likely to choose all the others. When you do this for many, many trillions of examples, not only does the model start to give more accurate predictions on the training data, but it also starts to make more reasonable predictions on text that it's never seen before. Given the huge number of parameters and the enormous amount of training data, the scale of computation involved in training a large language model is mind-boggling. To illustrate, imagine that you could perform one billion additions and multiplications every single second. How long do you think it would take for you to do all of the operations involved in training the largest language models? Do you think it would take a year? Maybe something like 10,000 years? The answer is actually much more than that. It's well over 100 million years. This is only part of the story, though. This whole process is called pre-training. The goal of auto-completing a random passage of text from the internet is very different from the goal of being a good AI assistant. To address this, chatbots undergo another type of training, just as important, called reinforcement learning with human feedback. Workers flag unhelpful or problematic predictions, and their corrections further change the model's parameters, making them more likely to give predictions that users prefer. Looking back at the pre-training, though, this staggering amount of computation is only made possible by using special computer chips that are optimized for running many operations in parallel, known as GPUs. However, not all language models can be easily parallelized. Prior to 2017, most language models would process text one word at a time, but then a team of researchers at Google introduced a new model known as the transformer. Transformers don't read text from the start to the finish, they soak it all in at once, in parallel. The very first step inside a transformer, and most other language models for that matter, is to associate each word with a long list of numbers. The reason for this is that the training process only works with continuous values, so you have to somehow encode language using numbers, and each of these lists of numbers may somehow encode the meaning of the corresponding word. What makes transformers unique is their reliance on a special operation known as attention. This operation gives all of these lists of numbers a chance to talk to one another and refine the meanings they encode based on the context around, all done in parallel. For example, the numbers encoding the word bank might be changed based on the context surrounding it to somehow encode the more specific notion of a riverbank. Transformers typically also include a second type of operation known as a feed-forward neural network, and this gives the model extra capacity to store more patterns about language learned during training. All of this data repeatedly flows through many different iterations of these two fundamental operations, and as it does so, the hope is that each list of numbers is enriched to encode whatever information might be needed to make an accurate prediction of what word follows in the passage. At the end, one final function is performed on the last vector in this sequence, which now has had a chance to be influenced by all the other context from the input text, as well as everything the model learned during training, to produce a prediction of the next word. Again, the model's prediction looks like a probability for every possible next word. Although researchers design the framework for how each of these steps work, it's important to understand that the specific behavior is an emergent phenomenon based on how those hundreds of billions of parameters are tuned during training. This makes it incredibly challenging to determine why the model makes the exact predictions that it does. What you can see is that when you use large language model predictions to autocomplete a prompt, the words that it generates are uncannily fluent, fascinating, and even useful. If you're a new viewer and you're curious about more details on how transformers and attention work, boy do I have some material for you. One option is to jump into a series I made about deep learning, where we visualize and motivate the details of attention and all the other steps in a transformer. Also, on my second channel I just posted a talk I gave a couple months ago about this topic for the company TNG in Munich. Sometimes I actually prefer the content I make as a casual talk rather than a produced video, but I leave it up to you which one of these feels like the better follow-on.

================================================================================
VIDEO ID: nAT-MCsJeik
TITLE: This puzzle is trickier than it seems
URL: https://www.youtube.com/watch?v=nAT-MCsJeik
PUBLISHED: 2024-11-19T19:06:45Z
STATUS: SUCCESS
================================================================================
I posed a certain puzzle in a recent video and based on a couple comments I realized that I could have been clearer about what makes this puzzle tricky the question starts by supposing that you have a disc with radius one and you cover it with a whole bunch of strips when I say strip here I mean a region that's Bound by two parallel lines and the quantity that you'll care about is the width of that strip the distance between those lines the question is supposing that your strips completely cover the disc what is the smallest possible value for the sum of all of those widths for example if you just used a bunch of parallel strips then the sum of all of the widths would be the diameter of the circle which is two Now spoiler alert it turns out that two is the smallest that you can get and a couple commenters claimed that they don't see the point this is obvious parallel strips should be optimal CU otherwise you would have some kind of overlap and overlap is clearly wasteful that would be true if we were trying to minimize the total area that these strips have in that case overlap is necessarily a waste of area but that's not the challenge the tricky part here is that the width of a strip is not proportional to the area it's perfectly possible to have a very fat strip near the edge of the circle with a bigger width but a smaller area than a thinner strip near the center of the circle so for all you know there might be a clever covering that has a little overlap here and there which trades off an inefficient use of area for a more efficient use of the total width the challenge is to find find a rigorous way to prove that this is not possible that the total width of the strips really cannot be lower than the diameter of the circle it's really not an obvious fact and if you appreciate this it makes the solution that we cover in the main video all the more beautiful

================================================================================
VIDEO ID: EPDZTLavmcg
TITLE: Sphere surface area proof sketch
URL: https://www.youtube.com/watch?v=EPDZTLavmcg
PUBLISHED: 2024-11-17T16:00:10Z
STATUS: SUCCESS
================================================================================
The surface area of a sphere is 4Ï€ times its radius squared,  exactly 4 times the area of a circle with the same radius. But why? Archimedes had a very beautiful proof that this surface area is the same as the area of  a cylinder that encloses that sphere, if you disregard the circular caps of that cylinder. The idea is that if you shine some light from the z-axis perpendicular to that axis,  then if you compare the area of a small rectangle drawn on that sphere to the area  of the shadow cast on that cylinder, those two areas turn out to be the same. This isn't obvious, but when you work it out, that shadow is a copy of the original  little rectangle, but squished down in one direction and stretched out in another. When you analyze the relevant geometry, the two effects actually cancel out perfectly. Treating the sphere as a sum of all of these little patches,  and the cylinder as a sum of all of those shadows,  we can infer that the surface area of the sphere is the same as the area of that cylinder. Now the cylinder is something you can unwrap into a rectangle,  where one side length corresponds to the circumference, 2 pi r,  and the other corresponds to the height of the sphere, 2 times its radius. This gives us the area we want, 4 pi r squared. And if you're also familiar with the trick of showing a circle's area,  by unwrapping it into a triangle, one whose height is r and whose base is 2 pi times r,  you can see how four of those unwrapped circles fit perfectly into this unwrapped shape.

================================================================================
VIDEO ID: LOulCFdVOGY
TITLE: Newtonâ€™s Fractal is beautiful
URL: https://www.youtube.com/watch?v=LOulCFdVOGY
PUBLISHED: 2024-11-16T16:53:52Z
STATUS: SUCCESS
================================================================================
I want to explain the image that you're looking at right now,  which is known as Newton's fractal. A little more accurately, it's an infinite family of fractals. And aside from being this beautiful, mesmerizing, infinitely detailed mess,  what's really cool about the image is how it naturally pops out from something that  any of you who've taken a calculus class might have heard of, known as Newton's method. A lot of math is about solving equations, and Newton's method is a really  powerful tool for finding approximate solutions to essentially any equation. If you rearrange the equation so that it looks like setting some function  of x equal to zero, then visually what it means to solve such an equation  is to find a point where the graph of that function crosses the x-axis. Now the way that Newton's method works is to start by making an arbitrary guess. And of course the guess is almost certainly not a solution. But if you draw a tangent line to the graph at that guess,  and you ask where does that tangent line intersect the x-axis,  something much easier to solve explicitly, very often it takes you closer  to a true solution. If you wash, rinse, and repeat doing this multiple different times,  you often converge towards a solution especially quickly. If you do all the calculus and you work it out,  there's a certain formula for how big your step size should be based on this process. And I won't go into the details, but just know that it is a  formula and you can plug in one value, and what comes out is  usually something closer to a true solution of the equation. For our purposes, instead of considering a function with real number  inputs and real number outputs like we're used to,  consider all of the complex number inputs and the corresponding complex number outputs. Now we can't visualize Newton's method with tangent lines and  intersecting the x-axis anymore, but the formula still works. It's still a valid rule that tells you how you can adjust  one guess to push it closer to a true solution of the equation. Maybe that feels a bit bizarre, I realize not everyone  loves complex numbers the way I do, but here's the cool part. Watch what happens if we apply this idea to many many different possible initial guesses. On each iteration, each of those dots is taking a step based on this Newton's method rule. With the example I'm showing, where our function is a degree 5 polynomial,  there are five distinct solutions to the equation somewhere in the complex plane. After many different iterations, most of our dots  have zeroed in towards one of those solutions. What I'm going to do is color each one of those dots based on which of those five  solutions it landed on, which one it ended up closest to,  and then we'll kind of roll back the clock to see where each dot came from in the first  place, giving us a certain color pattern. If you do this at a very fine resolution, treating each pixel of the  screen as a possible initial guess, and going through the same game,  coloring it based on which route that guess would end up landing on,  the pattern that emerges is the image that I showed you at the start. Isn't that wild? On the full video, I talk much more about why you see a pattern like this,  and what it implies about using Newton's method in practice,  and how it connects to things like the Mandelbrot set. But for now, it's fun to just gawk at the beauty of math.

================================================================================
VIDEO ID: JNVZK4ofW-Y
TITLE: The Triangle Of Power
URL: https://www.youtube.com/watch?v=JNVZK4ofW-Y
PUBLISHED: 2024-11-15T15:58:23Z
STATUS: SUCCESS
================================================================================
Has it ever bothered you how with exponents, logs, and roots,  we have three completely different types of notation to write the same fact? If you write 2 cubed equals 8, it's the relative  position of the 3 over the 2 that indicates the operation. But when you write the cube root of 8 equals 2,  which is the same fact, you introduce this new squiggly radical symbol. And then writing log base 2 of 8 equals 3, again the same fact,  you write out a word for the operation. This weird discrepancy in notation isn't just counterintuitive,  I think it's counter-mathematical. Rather than making seemingly different facts look the same, which is what math should do,  it makes three facts that should obviously be the same look artificially different. I came across a really nice suggestion on math  stack exchange for a more symmetric notation here. In our example, the way this would work is you write a triangle with  a 2 in the lower left, a 3 on the top, and an 8 on the lower right. To express the operation 2 cubed, you remove that bottom right corner,  and the symbol as a whole represents the value that should go in that missing corner. To express log base 2 of 8, which is asking the question 2 to the what equals 8,  what you do is remove the top number. Again, the symbol as a whole represents the value that should go in that missing corner. You can guess the third case. If you want to express the cube root of 8, you remove the lower left corner. Once again, the symbol as a whole represents the  value that should go in the missing corner. This much more clearly expresses the relationship of all three operations. The definition alone is mildly pleasing, but where it becomes useful is in  seeing how the rules for exponentiation logs and radicals are all really the same. The most extreme example might be how with our current notation, there are six,  six distinct ways to express the various inverse operations,  and it looks like a complete mess. If you use the triangle of power, all of these  operations follow the same basic aesthetic pattern. Admittedly, it looks a little bit weird when your brain has already been trained with  the traditional notation, but our brains are really good at picking up on patterns. And in this case, once you get used to it a little,  you only need to remember one pattern which unlocks all six of these cases. Essentially, any rule that's associated with exponents logs and radicals  becomes essentially three times faster to learn and to recognize. If you have a pencil and paper, I highly encourage you to just take a  moment and mess around with what some of these rules for exponents look like. It's weird at first when you're trained with the traditional notation,  but it's super satisfying once it all clicks.

================================================================================
VIDEO ID: 0W243LGSJFU
TITLE: The twirling tiles puzzle
URL: https://www.youtube.com/watch?v=0W243LGSJFU
PUBLISHED: 2024-11-13T18:01:06Z
STATUS: SUCCESS
================================================================================
here's a really nice puzzle suppose that you create a tiling pattern of a hexagon here each of those tiles is going to be a little rhombus whose internal angles are 60 and 120Â° and the side length of the hexagon will be some whole number multiple of the side length of the tile whenever you see three of those little rhombuses make a little hexagon you could create a slightly different tiling by rotating that little hexagon 60Â° when you do this sometimes it creates a different little hexagon that wasn't there before but which now can then be rotated to create yet another pattern the question is using only these moves can you necessarily get from any tiling of the hexagon to any other the full video that this comes from was really fun to make it involves a number of very nice puzzles with unexpected Solutions and this puzzle in particular is fun because if you squint your eyes and see it in just the right way the key insight for answering kind of Pops right out at you if you want to see that full video click the link at the bottom of the screen

================================================================================
VIDEO ID: Pny70rNPJLk
TITLE: A bizarre probability fact
URL: https://www.youtube.com/watch?v=Pny70rNPJLk
PUBLISHED: 2024-11-12T23:09:05Z
STATUS: SUCCESS
================================================================================
Matt Parker recently showed me this fact that seems completely wild. Say you sample two random numbers, each one uniform in the range from 0 to 1,  and you compute their maximum. Then the result is of course another random number with this bias towards being larger. A seemingly completely different thing you could do would  be to take one of those numbers and compute its square root. When you square a number that's smaller than 1, it becomes smaller,  so that means when you take its square root, it becomes bigger. So this is another process that would give you  a random value with a bias towards being larger. The surprise is that both of these are the same,  in the sense that the distribution describing your result is identical for  both of these procedures. At first it just feels really wrong that computing a maximum and  a square root could give you the same thing like this,  but there's actually a really nice way to visualize why this should be true. Well think about one of these random numbers as existing somewhere on an x-axis between  And the other random number is going to exist on a y-axis, again uniform between 0 and 1. So thinking of the pair of these numbers as a set of coordinates,  when you sample both at random, you're basically sampling a random point inside this  1 by 1 unit square. So take a moment to think about what it looks like for the  maximum of these two values to be a particular number, like 0.7. Well either x1 is equal to that value and x2 is smaller than it,  which puts you somewhere on this line, or x2 equals that value  and x1 is smaller than that, putting you somewhere on this line. In general, with continuous values, it's not very helpful to ask the probability  of equaling a certain number, since the answer tends to be infinitesimal. But what is helpful is to ask the probability that your  random value is less than or equal to a certain number. In this case, what it looks like to be less than or equal to 0.7 is that  you fall somewhere inside this square here, and so because everything is uniform,  the probability of landing in that region is the area of that region. In general, the probability that this maximum  is less than some number r looks like r-squared. This actually has a fancy name, it's called the  cumulative distribution function for the random variable. But now, think about the other case, where you're taking a square root. What is the probability that the square root of  one of these values is less than some number r? That's the same thing as asking for the value itself to be less than or equal  to r-squared, and since it's all uniform, the answer there is again r-squared. So both of these processes have the same cumulative distribution function,  that's why they're identical. Essentially, identical reasoning will show that if you take the maximum of three  such random variables, it has the same effect as taking the cube root of one of them.

================================================================================
VIDEO ID: piJkuavhV50
TITLE: Five puzzles for thinking outside the box
URL: https://www.youtube.com/watch?v=piJkuavhV50
PUBLISHED: 2024-11-08T13:34:50Z
STATUS: SUCCESS
================================================================================
Today I have a small series of puzzles for you, and if you even remotely like math, I can essentially guarantee that the solution to each one will delight you. At the end, you and I will circle them all together into a broader theme about higher dimensions, both in the sense of why we care, and also why it's a little bit sad to think about them. But for the first half of this lesson or so, nothing that we do is going to touch four or more dimensions. This will start simply as a set of pure geometry puzzles with delightful and surprising solutions. For the first puzzle here, I want you to consider this rhombus shape, where the internal angles are 60 degrees and 120 degrees. If you take a lot of copies of this shape, you can tile the plane with it. And that's not unique to this rhombus, it could have different internal angles, but what's nice about this one is that there are a lot of distinct ways, with a kind of pseudo-hexagonal pattern, that you could also tile the plane. I've seen this pattern all the time out in the wild on floors or on furniture, and each time it reminds me of the puzzle I'm about to show you. If you take one of these tilings, and you ever notice that three of those rhombus shapes make a little hexagon like this, it gives you a chance to generate a slightly different tiling by rotating those three tiles 60 degrees. The result is almost the same as what you had before, but just a little bit different. And when you do that, you might notice that sometimes that creates a new hexagon that wasn't there before, that you could also rotate, taking a step to yet another one of these tilings. So a natural question you might wonder is, is it possible to get from any one of these tiling patterns to another one just by using these little hexagonal rotation steps? With a little thinking, you can see pretty quickly that the answer has to be no, because for example, that very first tiling I showed you, which is like a squished rectangular grid, has no hexagons at all, meaning you can't take one of these steps into or out of this pattern. But what if we restrain things a little bit? What if instead of tiling the infinite plane, I present you with a hexagon, and all the side lengths of this hexagon are going to be some whole number, like 4 in this case, and I have you fill that hexagon with these little tiles, assuming each of those tiles has a side length of 1. Now let me ask you, is it possible to get from any tiling of this finite hexagon to any other tiling using these moves, where every time you find a small hexagon with just three of those tiles, you rotate it 60 degrees? If the answer is no, you have to show two distinct patterns and explain why you can't get between them, and the natural follow-on question would be, how many fundamentally distinct patterns are there? If the answer is yes, you have to explain how to get from any one to another, and the natural follow-up question would be, which two states are the farthest apart, in that it requires the maximum number of moves to get from one to the other? And what is that number? As a function of the size of the hexagon, what is the maximum possible number of steps that it could take to get from one state to another? That's puzzle number one, and before just giving away the answer, let me present the second puzzle for you, and maybe you can mull it over in the back of your mind. The second one is called the Tarski-Planck problem, and it has to do with a circle, say just with a radius 1, and we're going to consider strips along that circle. And what I mean by a strip here is any region that's bound by two parallel chords, and the quantity we'll care about is the width of that strip, so the distance between those two chords, which I'm going to denote with the letter d. You might drop down multiple distinct strips on this circle, and they could be at various different angles, kind of crisscrossing with each other. And for the question, suppose that you've dropped down enough of these strips that they completely cover the area of the circle. Every square inch of the circle has some strip covering it. Then imagine adding together the widths of all of those strips, so summing over this value d for every one of those strips. And the question is what is the minimum possible value for this sum? So across all of the distinct ways that you could cover the circle with a bunch of strips, what's the smallest that you could make this sum? For example, a very trivial way that you could cover it is to take one really fat strip whose width is 2, the diameter of the circle. That entire strip covers the entire circle, so the sum of all of the widths would be 2. Very similarly, if you just subdivided this into a whole bunch of parallel strips, the sum of the widths is going to just be the diameter of the circle, so that is still just 2. So really the question here is can you do better than 2, and by how much? Okay, so that is puzzle number 2. Before telling you 3, 4, and 5 though, let's circle back to talk about that first one, where we are tiling the hexagon. On the face of it, this is very tricky to think about, but there is a trick if you kind of squint your eyes, and if I suggestively color all of these tiles based on their orientation, where instead of thinking of this as a tiling in two dimensions, you can think of it as a kind of projection of a stack of cubes. It's not too hard to see that any stack of cubes inside an n by n by n frame like this necessarily gives you one of these rhombus tiling patterns, but the curious viewers might enjoy taking a moment to pause and ponder and convince themselves it goes the other way around. Any tiling of rhombuses necessarily has a corresponding stack of cubes. If you do that, take a moment to think about the significance of this fundamental move in the puzzle, where you identify a hexagon and rotate that hexagon 60 degrees. If you think of that little hexagon as the projection of a little cube, notice how if I kind of grab that cube and remove it from the diagram, what's left behind, this indent of that cube, involves those same three rhombuses except rotated 60 degrees. This move of rotating hexagons when you find them is really the same thing as adding or removing cubes, and that makes this way easier to think about. For example, it becomes very clear that you can get from any pattern to any other pattern, because you could start by saying take all of the cubes in this diagram and remove them so that you get to a kind of neutral position that looks empty, and then add back whatever cubes you need to to get to whatever other pattern you desire. It also makes it easy to think about the more quantitative follow-on question, which is what is the maximum number of steps that it might take to get from one configuration to another. Realizing that each move corresponds to adding or removing a cube, the biggest number of steps is to go from the empty configuration to the full configuration, and that requires n cubed different steps. What I like about this is that we have this purely two-dimensional question, and a very nice insight came from thinking as three-dimensional creatures, but the fact that the numerical answer to this question has that little cube in it is an indication that the three-dimensionality really is baked into the puzzle itself, it's not coming from some bias that we have as three-dimensional creatures. With this idea of stepping into a higher dimension in mind, now take another look at that second puzzle that we have, covering the unit disk with a bunch of strips. If you do pause and take a moment trying to think about this puzzle, and you explore alternate strategies to the parallel strips, what you might find is that it's very hard to find anything that gets even close to 2, much less lower than it, so you might suspect that the parallel strips are the best that you can do, that 2 is the minimum possible value for the sum. But how would you prove something like that? When you're in this vast space of all possible coverings, how could you prove that there's not some extra clever strategy that you're just missing? This main constraint that the strips have to cover the circle, means that the area of all of those strips, if you add them together, has to be at least the area of the circle, which is pi. So that's something to work with, but it's a little bit awkward, because you can't directly relate the area of the strip to its width without knowing where on the circle it sits. A strip with a given width would have a bigger area near the center than if it was close to the edge. What would be really helpful is if the area of that strip was simply proportional to its width, because in that case you could directly relate the sum of all of the areas to the sum of all of the widths. And while this is not true in two dimensions, the magic is that it becomes true if you project everything up onto a hemisphere sitting above the circle. This is not at all obvious, but if you look at the width of this strip on this three-dimensional hemisphere, which we'll call d, the area of that strip up in three dimensions like this happens to be pi times d. Importantly, it doesn't matter where the strip is, it could be going over the center or closer to the edge, the area only depends on the width. This might feel like a fact drawn completely from out of the blue, but regular channel viewers will have at least some chance to recognize this, because it's related to a really nice proof for the surface area of a sphere. This was a proof due to Archimedes, we covered it in a different video. The big idea there is to consider a cylinder with the same radius as that sphere, sort of hugging tightly around the sphere, and then to analyze how if you look at a little patch of area on the sphere, and you project it outward onto this cylinder, the area actually won't change. The high-level idea is that along lines of latitude, that little patch of area gets stretched out, but along lines of longitude, it actually gets squished down because of the angle that it sits at, and those two effects happen to cancel out precisely. And then once you know that projecting out onto this cylinder preserves areas, analyzing those areas becomes a lot simpler. So looking back at our little strip, let me go ahead and draw the rest of the sphere, sort of doubling the area of that strip, and then reorienting it to match the animations I was just showing. If you know that projecting this out onto the cylinder preserves the area, then it becomes very clear that it doesn't matter where on the sphere that strip is. Whether it's close to the pole or close to the equator, the area of that projection onto the cylinder is the circumference times the thickness, 2 pi r times the width. So wrapping it all up, the way this is relevant to the original puzzle is you say, consider any covering of the circle with a bunch of strips, which you can project upwards to be a covering of the hemisphere with all of these projected strips. The sum of all of those areas looks like adding up pi times d for each one, and you can factor out that pi, but you also know that the sum of those areas has to be at least the area of the hemisphere, which will be 2 times pi. Therefore, the sum of the widths can never be below 2, and once again, we've taken this problem which is very tricky to analyze directly, but leveraged intuitions glean from living lives as three-dimensional creatures. This next example has a little bit of a story behind it. So I was at the International Math Olympiad earlier this year, I was giving some lectures to the students participating in the contest, and one of those lectures was essentially the video I'm giving you now, kind of going through these examples of puzzles where you're in one dimension but you have to step up. And in the middle, I asked the students in the audience for more examples like this. And I was reasonably confident that at least one of them would mention the example I'm about to show you, because there's a really nice Numberphile video about this one, it's by Tadashi Tokeda, who is always great, but as you'll see, there was actually a little bit of a wrinkle that I wasn't anticipating here. The setup for this problem is that we have three different circles, just in two-dimensional space, and what we're going to do is draw the external tangents to each pair of them. So for example, here on the green and the red circle, we've got these external tangents, and the thing we care about is where they intersect. Similarly, I'll take the intersections of the external tangents for that blue and red one and the external tangents on the green and the blue one. And if I take a moment to just play around with the positions of these circles and invite you to notice those three different points of intersection, anything special about it, you might be able to guess what the relevant theorem or the puzzle here is. Basically, no matter where I position them, all three of those points seem to fit on a given line. The notion of external tangents doesn't really make sense when one circle is inside the other so let's assume that that doesn't happen, though we can revisit that a little later. And another assumption you might want to make is that no two circles have the same size, because if two of them did have the same size, those external tangents are parallel, they don't intersect. You could make this sensible with the notion of projective geometry, which takes seriously the idea of points at infinity, but for our purposes, think of three circles that don't intersect and don't have the same size. The claim, the theorem, the thing you need to prove is that those three intersection points of the external tangents always fall on the same line. At this point, you know the theme, we're going to take a step up into the third dimension. Namely, imagine that each one of these circles is the equator of some sphere. Now around any given pair of those spheres, like this green one and the blue one for example, there are a whole bunch of different external tangents that all intersect at the same point. You essentially just rotate the two that we had about the axis between these two. And then similarly for each other pair of spheres, like that blue one and the red one, there's this cone of external tangents all intersecting at that point, and between the red and the green one, another cone of external tangents. You might ask, why on earth would this be helpful? And the key is to think about a plane that's kind of resting on top of all three of those balls. I claim that this plane goes through the three different points that we care about. And the reason basically is if you draw this line between the tangency point of the plane on the green sphere, let's say, and the tangency point on the blue sphere, that's one of those external tangents that goes through this little intersection here. And then similarly, if you draw the line on the tangency point of the sphere for the red and the green, it's one of those external tangents that goes to the other one, and likewise over here. We have another line on that plane that passes through the point, so in particular the plane itself has to go through all three of these points. But those three points also live on a different shared plane, namely the plane of the original problem where the three circles lived. So they have to live somewhere on the intersection between these two planes, and any two planes in 3D space that aren't parallel to each other intersect along a line. Therefore, the three points that we care about have to always sit on a line. This is more or less the content of that Numberphile video, and leave it to one of those clever IMO students to point out how it's actually not quite a valid argument, in the sense that it's not fully general. One of the students raised her hand and pointed out that if you have a setup where one of the spheres is smaller than the other two, and you place it somewhere in the middle here, then if you try to play this game, there is no way for that plane to rest on top of all three of them. You might imagine kind of rotating it around those two big ones. So in other words, the argument does work for certain positions of those three circles, but it doesn't work for all of them. And then after that talk, the deputy leader for the Slovakian team mentioned to me that there is actually a way that you can save this proof and preserve the overall lesson of taking a step into the third dimension. The key is that instead of using spheres, we should really be using cones. So now we have these three different cones, each of which has a base at one of the circles, and the only thing that we need is that the angles at the top of each one of them are the same, so that they're three different similar shapes. Now consider the line passing through the tip of two different ones of those cones. I claim that that line also passes through the intersection point between the external tangents of the circles that we care about. The reason is that this point is what's called, the center of similarity for those two shapes. What I mean by that is that if you scale the big version of this shape about that point, then at some point along the way, it coincides with the smaller version of that shape. From this perspective, you can see how the line through the tips of those cones has to pass through that center of similarity. If we look from above, you can see how the external tangents also pass through that center. Essentially the diagram that consists of this little circle with those external tangents intersecting at that point is a scaled-down version of the diagram consisting of this big circle and those external tangents intersecting at that point. And then similarly, if you look at the lines passing through the tips of any other pair of cones, those lines will correspond to another one of those intersection points. Now we can talk about the plane that passes through the tips of all of these three cones. And there's no more worry about generality, because any three points in space, no matter where they are, have some plane that passes through them. For example, if we move that smaller circle into the problem position from earlier, there's no issue. The three different tips of the cones uniquely determine a plane. That plane intersects with the xy plane, at least assuming the three cones don't all have the same size, and the line of intersection is exactly the line that we're trying to prove exists. If any of you know the origin for this fixed version of the argument, let me know. That leader of the Slovakian team mentioned that he had heard it from someone else but couldn't quite remember from where. There's another benefit you get by shifting the focus to the center of similarity rather than describing these points as the intersection of external tangents. In this framing, it's perfectly sensible for one circle to sit inside the other. Even if you can't draw external tangents, there's still some point such that if you scale one circle about that point, it will coincide with the other. This actually made it way easier to program. Notice how wherever I put these circles, we always get these three points that fall on a line. In fact, these don't even need to be circles. They could be any three similar shapes as long as they're all in the same orientation. And you can say those three centers of similarity always must fall on a line. And you can use essentially that same argument using cones to show this, except instead of cones, you would have some kind of pyramid shape. At this point, having logged three wonderful examples of two-dimensional puzzles that somehow leverage a three-dimensional insight, a natural question you might ask is whether there's a three-dimensional puzzle that somehow involves stepping up into four dimensions to answer it. The last two puzzles I want to bring up offer attempts at an answer to that. For this next one, imagine that you have four different points in three-dimensional space and they form the vertices of a tetrahedron, basically the shapes such that those four different points are its corners. In principle, if you know the coordinates of those points, you know everything you need to about this shape. But the challenge I present to you is to write an explicit formula for the volume of this tetrahedron in terms of the coordinates of those four different points. And this time, I'm actually not going to show you the full answer to this puzzle. I will give you a major spoiler, which is that one elegant way to view it involves thinking about the determinant of a certain 4x4 matrix, and I'll also suggest that it would be very helpful to try thinking about the analogous puzzle one dimension lower, where you're finding the area of a triangle given the coordinates of its corners. The main reason I don't want to give the full answer right away is that solving this puzzle and its analogs in various different dimensions actually offers a really nice explanation for why the formula for the determinant is what it is. And as such, I think that distilling that into its own little video should make a really nice addition to the linear algebra series. So skipping now to the very last example, rather than beginning with a puzzle and seeking an insight, what we're going to do is start with the insight and see if we can try to construct the puzzle around it. Looking back at the first puzzle that we did, you might have the idea that it would be fun to try finding an equivalent of this but one dimension higher. What is the three-dimensional tiling pattern where a four-dimensional creature could stare at it, squint their eyes, and somehow see it as a stack of four-dimensional hypercubes? And instead of asking about rotating these hexagons whenever we find them, what is the equivalent move that we could understand as 3D creatures, but which the 4D creature could somehow think about as adding or removing hypercubes from that stack? This is certainly a very mind-bending exercise, and the puzzle that we'll ultimately construct is maybe a little contrived, but I found it super fun to think through, and it definitely gave me a new intuition for a certain 3D shape that I had not had before. To start off, it helps to put some numbers to the way they were thinking about a cube, where one natural choice is to put it in 3D space such that one vertex sits at the origin, coordinates 0, 0, 0, and then all of the other vertices are kind of every combination of 0s and 1s that you can come up with. And notice how I'm drawing an edge between two different vertices whenever they only differ in one coordinate, for example, differing only in the x-direction or only in the y-direction. For a four-dimensional cube, you could do the same thing in principle. Your coordinates are lists of four numbers, and all of the vertices of the cube are going to be every possible combination that involves 0s and 1s. What I'm showing right now is just the three-dimensional base of that hypercube. It's analogous to the base square on our cube, where the z-coordinate is all 0. Notice how here that last coordinate is 0 for all of them. Even if we struggle to visualize it, in principle the rest of the hypercube comes from increasing that last coordinate by one unit, stepping in some direction that we can't quite imagine, which gives us this other 3D cube, which is the analogue of the top face that we might have looked at earlier. And again, the rule with the edges is to connect any pair of vertices that differ only in one of those coordinates. The tiling puzzle we did involved looking at these cubes from a very specific direction, where we were kind of staring down this diagonal direction, and the way it projects onto our eye looks like a hexagon. One way to think about this that lends itself to actually coding it up for a higher dimension is to consider the vector with coordinates 1, 1, 1 sitting in that diagonal direction, and projecting everything onto the plane perpendicular to that vector. You can write an explicit formula for this that basically takes any point and kind of subtracts off its component along that direction. More generally, if you had a whole stack of cubes and you project them all down on this direction, it creates for you this hexagonal grid. With the 4D cube, even though again we struggle to really think about what it looks like, we can at least have the computer play the same game, where I'll consider the 4-dimensional vector 1, 1, 1, 1, and project everything onto the space perpendicular to that vector, which will be a 3-dimensional subspace of 4 dimensions. When I do that for this wire frame of the 4-dimensional cube, here's what it looks like. It's this very beautiful and symmetric shape, and if instead of the wire frame I make it solid, this has a special name, it's called a rhombic dodecahedron. There's a really nice video with Matt Parker and Adam Savage featuring a rhombic dodecahedron, where they construct this beautiful lightbox that features the fact that you can tessellate 3-dimensional space using this shape. That's really not obvious, at least to me, when I just look at it, but if you know that this is a natural projection of a hypercube, that actually tells you that it must tessellate 3D space, because you could project down a stack of those hypercubes. In our puzzle, we weren't just looking at the wire frames for these cubes, they had actual square faces, and when we stare down one of these corners, we only really see three of those faces. When there is a cube, it's the three faces pointed out, and when there was no cube in that position, we had the kind of indent, which is like the three faces of the cube on the inside. Projecting those three faces down is what gives us those three rhombuses that form a hexagon. To think through the analog of this one dimension up, again it helps to put some numbers to things. Let me draw these three different basis vectors that span the cube, the unit vectors in the x direction, the y direction, and the z direction. Notice how each one of these inner faces corresponds to a pair of those basis vectors. The analogous game that we can play one dimension up is to take the four different basis vectors up there and project them down to 3D, again along this diagonal direction. This is analogous to projecting those three basis vectors into the hexagon so that they all sit 120 degrees apart. And now, instead of talking about the square faces of the cube getting projected as rhombuses, we think about the cubical cells of that hypercube. Each one in this case corresponds to a way that you could choose three out of those four basis vectors. Each of them is this kind of squished cube shape, and the four of them together fit very nicely to create this rhombic dodecahedron. Now, in our original puzzle, the game was whenever you see this hexagon built out of the three rhombuses, you rotate it 60 degrees. But we're going to have to change how we think about that move. Notice how when I go from the inner faces of the cube to the outer faces, I can slide each one of them in a direction perpendicular to that face. Down on the projection, what that looks like is sliding each one of these rhombuses through the origin. We can play the same game with the projections of those cubes in four dimensions, where if you take each one of these four and let it slide through the origin, it gives you a distinct way to tile that rhombic dodecahedron. So with all of that as setup, here is the absurd puzzle that you could present to someone next time you find yourself at a nerdy cocktail party. First you describe this squished cube shape here. It involves taking six of those rhombuses that we had earlier and forming a polyhedron out of them. You say, imagine this has a side length of one, and you're going to use many copies of this shape to tile a big rhombic dodecahedron with some kind of integer side length. The game is that every time inside this big tiling you find a small 1x1x1 rhombic dodecahedron, you make this move where each piece can slide through the middle. And then for the puzzle, you ask what is the maximum number of moves that it might take to get from one tiling to another. This is absurdly confusing to think about, but if you somehow know that this is all a projection of a stack of hypercubes, it can lead you to conclude the answer has to be the size of that big rhombic dodecahedron, let's call it n to the power 4. Zooming out a bit, all of these puzzles are really just for fun. Aside from sharing them with nerdy friends at parties, there's not really a lot of direct utility. But they illustrate a much broader phenomenon in math, where constructs in some higher dimension can be bizarrely relevant to solving problems more easily, either in a lower number of dimensions, or even solving problems that don't seem geometric at first. For example, there's an extension of the complex numbers that naturally live up in four dimensions, they're called the quaternions, and they offer a really elegant way to encode and to work with three dimensions. You don't have to understand four dimensions to work with them, in the description I'll give you some links to some really nice videos to show practically working with quaternions, but they are doing something very special up in four dimensions, rotating a hypersphere in a way that's not just rigid motion, but a kind of extra rigidity unlike anything we know in two or three dimensions. If you're curious, I made a whole video and then a sequence of interactive videos a while back trying to understand what exactly that 4D motion is. Another example, if you step up into 24 dimensions, is how there's this unusually elegant way to pack spheres together, and that weird high dimensional sphere packing is very closely tied to a type of error correction code that was actually used on the Voyager spacecrafts. If you scale up your dimensions even further, something funny starts to happen with the statistics of random vectors, where a pair of random vectors will have a very high chance of being nearly perpendicular. In the series on neural networks, I mentioned how this fact could be relevant to explaining why large language models perform so much better at scale, and this is a fact that's also very relevant to a number of compression algorithms. But the reason that these puzzles I've laid out make me feel a little sad thinking about four dimensional geometry is that there's a difference between analysis and intuition. You and I can stare at this tiling of rhombuses, squint our eyes, and somehow think of it as a stack of cubes. If you've ever pondered spheres and their surface area, you have at least a chance for making this creative leap when you're faced with that puzzle about strips on a circle. In trying to prove that three points sit on a line, you and I can think about a line as an intersection of two planes in 3D space. That's not some opaque consequence of linear algebra, it's something we can really picture in our mind's eye. All of the examples I know of that use even higher dimensions to solve problems don't really involve intuition in quite the same way. There might be an analogy with lower dimensions, and analogies can be kind of dangerous, but the line of reasoning ultimately has to be purely analysis. To be clear, that's not a bad thing. Ultimately all of the rigor in any argument you make has to come from analysis. But analysis without intuition is daunting. The space of all possible logical moves you can make in the pursuit of a proof is often too vast to explore in a reasonable time. Intuition is what offers the guiding lights telling you which paths are worth trying. What I'm jealous of, and a little bit sad about, is the thought that there might be problems in three dimensions where somehow squinting your eyes as a four-dimensional creature or even higher would offer some guiding light that, to you and me, is inaccessible. Quick note for those of you supporting on Patreon, or for those of you who have thought about maybe joining to support the channel, I made a quick bonus supplement video to this one showing two more puzzles that have the same vibe where there's a question in two dimensions but the answer somehow involves three-dimensional thinking. It's quick and casual, but I think you'll like the problems, so see the links below.

================================================================================
VIDEO ID: KHEtJUlpqcg
TITLE: LLMs are next-word predictors
URL: https://www.youtube.com/watch?v=KHEtJUlpqcg
PUBLISHED: 2024-11-04T15:24:37Z
STATUS: SUCCESS
================================================================================
a large language model is a sophisticated mathematical function that predicts what word comes next for any piece of text to build a chatbot what you do is lay out some text that describes an interaction between a user and a hypothetical AI assistant you add on whatever the user types in as the first part of that interaction and then you have the model repeatedly predict the next word that such a hypothetical AI assistant would say in response and that's what's presented to the user instead of predicting one word with certainty though what it does is assign a probability to all possible next words in doing this the output tends to look a lot more natural if you allow it to select less likely words along the way at random so what this means is a given prompt typically gives a different answer each time it's run

================================================================================
VIDEO ID: rbu7Zu5X1zI
TITLE: How I animate 3Blue1Brown | A Manim demo with Ben Sparks
URL: https://www.youtube.com/watch?v=rbu7Zu5X1zI
PUBLISHED: 2024-10-12T13:00:39Z
STATUS: SUCCESS
================================================================================
The most common question I get about 3Blue1Brown is, what do I use to animate the videos? The short answer is that I wrote a custom Python library,  its name is Manim, so it's all programmatic and it's also very bespoke. What I wanted to do with this video is offer a behind the scenes to show you,  one, what Manim is for those who don't know, and even for those who do know,  to show a little bit about how I use it and what the workflow is. Now the way I'm doing this is I sat down with Ben Sparks when I was in the UK a couple  months ago, many of you may recognize him from his many great Numberphile videos. He wanted to know how Manim worked, I knew a number of other people had that same  question, so I recorded the conversation, it's kind of a scrappy recording but we'll  make do. And after a simple hello world example, we animate the famous Lorenz Attractor,  which is very important in the foundations of chaos,  it's also just a fun visual to get into. One quick thing I should mention before we dive in  is that there are actually two versions of Manim. So the first has a history very intertwined with the history of the channel,  the way I started the project, basically when I was finishing my undergrad,  was that I wanted this coding project that would somehow let me illustrate mathematical  functions better as transformations, made a super scrappy bit of Python code for that,  used it to make the first video on this channel, as I made more videos the tool improved,  as the tool improved I would make more videos, and that's just continued ever since. The most recent video I made, which was about holograms, if I do say so myself,  I was pretty proud of the visuals in that, and that would have been dramatically  harder to do even two or three years ago, but over the last month it was actually  kind of a joy to make just because of a lot of the workflow improvements over the years. I've always posted all of the code that I make for videos, it's openly visible on GitHub,  and I also made the tool itself, the underlying tool Manim open source. But I don't, as a personality type, really have the constitution to manage an open  source project, I also don't really have the capacity for it while I'm making videos,  so I wasn't the most attentive to issues and pull requests and things like that,  but a community of people who wanted it to be a more robust tool for others forked  the repo and created a version that is attentive to issues and pull requests and  has better testing and better documentation, and it's called the Manim community version. So it's generally recommended people start with that,  but in the meantime I often do make a bunch of changes or developments to my own,  over the last couple years I've made it more interactive, more performant,  things like that. The reason I bring this up is that what I'll be demoing with Ben is my own version,  but you should be aware that there is this divide and that if you want the better  documented and tested version, it's recommended to go with the community one for that. Without further ado, let's dive into the Hello World example. It's all in Python. Okay, and on the left is a Python, just a text file essentially with... Yep, so this is, it's Sublime text, I use Sublime, that's a text editor. We're going to be typing some Python here. I guess just as like a basic sense of what it  even looks like to have something up on the screen. Let me get something there and then we can talk through what's going on. Here I've created a scene. So all of the scenes that I edit together take the form of a class in Python. And then inside a certain method of that called construct,  this is where all the code that renders stuff is going to live. There's objects added like a circle, like, you know,  we can add like a square in there too. We're also going to add that square. If I kind of ran all of that, we have the square. How did you just run that? Was there... Oh yeah, okay, okay, okay. So this is what... I think you just waved the magic wand and it happened, right? But you have a shortcut it looked like. Okay, so in principle, if over in this little terminal,  it's a Python terminal such that we can call commands on the scene that are relevant. So I might say square.shift to the right, and then that square will shift to the right. And if I call it again, more things will happen. I could also say, you know, what's one plus two, just normal Python. Okay, it's a Python just entry box, basically. Yeah, but it's talking to this. And so while I'm creating a scene, it's nice to have  a Python terminal that's talking to the scene itself. And then separately, so what might be nice as a workflow is to say,  hey, I've got all this stuff that I'm going to do. Like maybe I want to take square and I'm going to put it to the top edge. And so a common thing that you might do is say, take that,  copy that, go over to this, paste that, press enter. And that immediately tests that line. So then it tests that line. But I don't want to do that every time. I don't want to like do it and copy and paste. So instead I have a shortcut written and this is tied to some Sublime specific things. In my case, it's command R, I think the keyboard shortcut I have. It'll copy it and it'll run whatever the text that was copied in there. So you've got a shortcut which runs this code, outputs the visual, immediate check. I just want to jump in with a quick comment here  because there's slightly more going on under the hood. Like all things, this is best motivated with an example. So if I pull up a scene from the most recent video on holograms, these can get quite long. So here, the final output was a four and a half minute MP4 file describing  diffraction gradings and in particular, this one was about the double slit. It's really nice to have these long scenes because they share a bunch  of context and as you're coding, you can kind of reference that context. But the code for something like that ends up being just a big, big, big pile of Python. Lots and lots of code. And it used to be the case I would break this all down into little subroutines,  but historically it's proven to be nice as just to have it kind of  all in one spot where all your local variables are shared. The thing I want to highlight is that if I'm working on the scene and I'm somewhere  in the middle of it, so lots and lots of code has taken place,  but we're in the middle at this point, while I'm iterating on just one little section,  like here I might want to be able to run the code of this section and see what it does. As you can imagine, you might want to tweak it, you might want to change it a little bit. So in this case, let's see what's going on. We've got some graphs being drawn. This like wave kind of showing the red and blue wave is fading out a little bit. So maybe I could say, what if I don't want it to fade out as much? I want that to only be 0.8. I want the runtime here to be a little different. I want to be able to run that same section, but in order for that to work,  when I'm pasting it in, it can't just literally be pasting the code. It has to revert to the state that the scene had at the start. So it's really running this little thing called checkpoint paste,  which basically says if the thing that was copied starts with a certain comment,  I'm going to see if I've seen that comment before and cached a state  of the scene associated with that so that I can run it. Basically it's making it behave a little bit more like a notebook,  like a Jupyter notebook. Some viewers might be wondering why I don't just have it all in a Jupyter notebook,  but I really like having the scene in a single text file and being able  to interact with it through scripts and things like that. But this is kind of like a hybridization between  just the raw text file and a notebook itself. We could also have some like text on there that maybe literally says, hello world. This is like a good plan for hello world. Yeah, put that to the top. And that's also something, you know, it's not  going to show up on this if we don't have this line. So the adding makes it appear. But it looks like, so this is me naively thinking,  when you make an object, it puts it in the middle and unless  you then do some two edges or some other movements, it moves it around. Most objects default to being in the center. Instead of adding it, a different thing you could do,  anytime you're going to do some kind of animation, there's a method called play. And then instead of throwing in an object, I'll  say there's something I want to do to that object. So in this case, maybe I want to write it to make it look like  it's being written on And there's a function baked in here. Yeah. Nice. And I could have some parameters and like, hey,  maybe I want that to happen a little bit longer, like with a runtime of three. And suddenly anyone who's watched any Manim videos recognizes that effect. Yeah.
They're ready to go. That's really useful. Like I wrote that effect and like nothing else uses that  particular effect of having the like edge come on and fade in. It's pretty. It's pretty. That's the signature look for it. A different philosophy also with Manim was like anything can transform into anything. So what I mean by that is let's say we've got this text. I might say, hey, I want to take the the H of that  text and then I'm going to make it turn into the circle. So that's going to turn into a circle. So you defined the circle already, but you didn't add it anywhere. Exactly. Now you're going to transform the H into it. Yeah.
So if we go to this point, the text gets written. What this line is going to do is say extract the H from that text. And then transform it into the circle. Oh, because the circle was in the middle it has moved it hasn't just put it away. And so these these built in functions like write and transform that we're just seeing. These are the ones that you sort of sculpted to  make the jobs that you wanted to happen happen. Yeah, exactly. Exactly. And so a lot of things derive from transform. So usually like it doesn't really there's no pedagogical  reason to have like an H turn into a circle. I enjoyed it. It looks nice and we can, you know, we can maybe make it a little bit slower. I mean, I have other questions like it didn't just transform. It looked like it had it was eased. There's all sorts of nice smoothing functions going on. Oh, yeah. OK, so let's play with that. So let's let's play with the transform. So here notice like the H is shrinking and the circle is growing. I don't actually want that. So when I extract the H, it creates a group of all of the H's that it found in this text. So if I take the first element of that, it'll have a thing of it. This is uglier than it needs to look. But if I want to use a matrix, it's like there's a hierarchy where you might  have groups of objects like this whole text is a group of characters within. So if I just want the first character, actually a simpler way to do this. It's very dumb. I'm going to take the first character. So the zeroeth element in that Python list, then the actual points data of that H. That's fun. OK, right. So instead of taking the characters, just got the geometrical. Yeah. And so the smoothing there, there's an attribute I call like the rate  function and it defaults to a thing called smooth, which just looks smooth. But if it's not the classic smooth step sort of profile,  basically, yeah, it's a cubic bezier. I think that it'll be like a smooth step. But if it was linear, then just notice it's a little jerky. This will be easier if it's a runtime of one to see. It's like, yes, jerky start, jerky stop. Sometimes you want that. Yeah, sometimes you don't. This will come up for us later, actually, is only  this to be linear when it defaults to smooth. I'm really excited to see that because it's those details that make the  difference from like I've made something move to I've made something look good. Yeah, yeah. I really making that easy to do. It's a big part of what my name is doing, I think. We mentioned let's let's do a classic piece of sort of  recreational interesting maths that a lot of people heard of. Yeah, I was like, I've never plotted a Lorenz attractor. And that was that was why I suggested. For those of you who don't know, the Lorenz attractor is this very  bizarre shape that came up in the early history of chaos theory. Ben and I do talk more about it. But what you need to know is that it comes from a set of differential  equations in three dimensions, which basically means if you have a  point somewhere in 3D space, there's this set of deterministic rules  that tells you how that point should change at a given moment in time. And what happens when you try this for a variety of starting  conditions proves to be very interesting as you'll see. It's really nice fodder for animation. And if you want to learn more about it, I'm pretty  sure there's a great Veritasium video on it. But also one of my favorite books, which I think I actually should have up here. Yes. OK.
So one of my favorite books by one of my favorite authors, James Glick, describes, you know, kind of how this came about and the role that it had in early chaos theory. All of that's by the by. But some of you all want to know. So I figured I'd share. I guess maybe one thing I should mention before we dive into this. This is all in 2D. But the points are actually all in 2D. Whoa, that's a bug. This is a rendering bug, is it? Yes, actually, that's it. OK, there's the thing I was playing around with on the low level rendering recently. I know what's going on and why that's happening. And there's a dumb way to fix it, which is to. Yeah, just don't don't don't worry about that. Fun to see the back end. Don't worry about that. Sometimes I go and I try to make the rendering nicer. And then so that was that was always three dimensional. We just happen to be looking at everything's always through. So for example, if I add 3D axes, then it's like everything exists by default on the X,  Y plane and just like ninety nine scenes out of one hundred. I'm just doing it in 2D because pedagogically you want it to feel like a blackboard. Only go up to 3D if you really need to. Now we really need to. So for the Lorenz Attractor, our setup, I just have some like axes with  some coordinates around what we're around what we're going to want to be in. Actually, I'll be very honest with you. The way I started here, I went to chat GPT. What you want to do for the math underlying this is to basically feed some software,  a differential equation and an initial condition and just say,  how does this initial condition evolve? Obviously, people will have built software packages that do it with something smarter. So I just asked and I'm like, hey, write me a Python function using some  numerical ODE solver to find, you know, find a solution of the Lorenz equations. The famous Lorenz equations. Well, you know, I just wanted to. Not the other ones. You know, sometimes I like it. As you've no doubt found, if you're trying to engage with some new library or something,  it's just, you know, just kind of a nice way to see what it is. It solves a lot of the protocol issues that sometimes you take three hours to get past. So it's mentioning the SciPy integrate. So that's a nice library and it's got this solve initial value problem function. And then it gives some boilerplate for how to how that would look. And it's using Matplotlib to render it. Abundantly reasonable, but we're using Manim. So just adapt it. Yeah. And so essentially I've got a function here to describe the differential equation. It says for a given time and for a given state,  which is going to have XYZ coordinates, just what's the derivative of that state. And you've got three parameters, which you've got Greek words for. And so that, you know, I guess if we go to the if we go to the Wikipedia page for Lorenz,  this is a system that has some parameters on it that I guess we can kind of freely tune. There's some parameters that someone must have found makes for nice diagrams. And so let's just use them. Let's keep this page open. So if we want to render the equations onto our scene to do it,  do it in that manner, maybe we can do it in a moment. So we've got that. I've just got a tiny little wrapper around the SciPy numerical integration  solver for us because what I want to do is be able to say, hey,  for a given initial condition, just give me all the points that are going to  be the solution. So let me just check. And you kind of need to know what it's going to spit back at you. Yeah. It's giving you something called solution, which is going to have time values and X,  Y, and Z values. So the way, yeah, this library is a little weird. It's kind of like it's treating Y as the output, but Y might be like a vector value,  which is a little confusing, which is part of why I wanted a wrapper so that I'm  just thinking in terms of states rather than like its language is involving like a Y. And I also wanted this matrix transposed for how I like it. Oh, gotcha.
That's what that T is. Okay.
Yeah. It's just all like, don't worry about the wrapper too much. Let's just actually see what it looks like. So let's say our initial condition is something like, let's just make it 0, 0, 0. Why not? And then we can take the solutions where I'm passing in a given function,  which we want to be the Lorentz system and passing in that initial state,  which is the initial state we just wrote down. How long do I want that to go? So let's see what, I don't know, 10 seconds of solution looks like. And this right here is just going to be a set of points basically. And so if I run this and I ask, you know, what are points? It gives a bunch of zeros. This is maybe predictable that 0 is going to be a bad initial condition. Initial condition, yes. Yeah.
So let's make that like 10 or something like that. And so now if we look at the points. There's some interesting points rather than all zeros. Yeah. Yeah. Okay.
So in this case, I could render a curve where the, like I said, I call everything a mobject for a mathematical object. Many of them are vectorized mobjects, which just tells you how  it's rendering as opposed to being a surface or like a point cloud. And these are things like curves that have some  sort of stroke thickness fill and all that. So that's interpreting the points and then drawing lines between them essentially. Well, so to do that, I'm basically going to say, hey,  set your points as corners as if it was a polygon. All of those points that were just created. And then let's see what that curve looks like. If I knew how to spell self. So if I do that, we don't see it, but actually it's up there. No, because the thing is I was just adding the points,  but I wasn't using the coordinate system of these axes in any way. And so. Ah, so they're not necessarily going to plot them according to those axes. Right.
So what I actually want to do is take the axes and there's a function called like coordinates to points, which is basically going from whatever  the coordinate system of the axes are to the like manum coordinate system. And there's an abbreviation for that because it's used a lot called chords to points. And I'll just pass that in. And I think actually it thinks of it in terms  of you passing a list of X list of Y list of Z's. So I'm going to do a little transposing and don't worry about it too much. But this should be in the actual coordinate system. Can I check what that star is doing in that penultimate line on the code? OK, so yeah, if you have let's say I have a tuple, this like one, two, three. Right. And then if I have I define a function that takes in like X,  Y, Z and it returns let's say like X plus Y plus two times. We'll do a non trivial. If I call function on that tuple, it'll be like type error. Ah, because it wanted them separated. That's a different kind of error. It wants them separated. So I could do it like oh, pass in like the zeroth element. But Python has a little little syntactical snazziness where if  you put an asterisk in front of an iterable thing, it'll unpack it. OK, this is I mean, this is the most useful thing I've learned all day. I mean, manum is pretty good. But thank you. And joking aside, that's helpful. If you don't know what that was, it's always mysterious  to see things you don't understand what they're doing. So in this case, points is an array where I like  to think of each each row is one of the points. But the syntax for this coordinates to points is going  to take in lists of the X coordinates, Y coordinates. It's maybe a dumb design as I'm thinking about it right now. Like maybe the way it should play. It makes sense. The reason it makes sense is usually when you're calling this, you have axi.c2p. You're just passing an actual individual ones like, hey,  I want to know what point does this correspond to in the manum coordinate system. And it's like, here's that point. So if I wanted to add a dot there, you know, this we could see where it shows up for. Why can't I type cell? Because you're on camera. Because I'm on camera. Yeah. And so it's putting it at that. And you say it's a dumb system. If it works, it's not a dumb system. Yeah. It can always be improved. Right.
But it's working as a whole lot better than many systems we try and make. Great. So let's have some fun with this. We could see how it evolves rather than just adding the curve. We could show the creation of the curve, which is basically showing the system evolve. So that's going to take all those points, but just kind of run through them slowly. Yeah.
Or make them appear slowly. Well, here's what it'll do. Right. It'll draw it. But that was very fast. So maybe I want the runtime to match the actual time of the dynamic system. So it should draw it over the course of 10 seconds. But here it's trying to be too smart. When it draws things by default, it does that smoothing function. I see. And that's actually changing the behavior. So actually we want the rate function in this case. Almost always it's nice for it to be smooth. This is one of those cases where the math that it's representing is relevant. It needs to be kept rather than masked. So instead, linearly, this is the actual evolution of it. Nice. And so we can style it too. Maybe we want to set the stroke to make it look blue,  make it look a little bit thinner, something like that. We could actually give it a range if we wanted to have a kind of gradient between things. Which I don't know if that looks nice or not. But you can imagine. That's starting blue and ending up red. Yeah. Starting at zero stroke with ending up at 10 or starting at 10 ending up at zero. Knock yourself out. Yeah, those look pretty ugly to me. And also I think we'll want to use colors for a different reason now. Because the reason the system is interesting is because it's chaotic. If you have initial conditions that are really close to each other. But not quite the same. But not quite the same. They start evolving the same for a while, but then they stop. So I think here's the way that I want to illustrate this. We're going to create multiple curves. I'm going to have curves which I'm going to create a group. And I call it a vgroup just to say, hey, these are going to be vectorized objects. That makes the rendering a little faster if it knows that. If it doesn't know that, it'll render them, but  it doesn't use a certain trick to make it faster. Then I'm going to go through a bunch of states, which I need to define now. So states I'm going to maybe make into... And these are your initial conditions. These are going to be the initial conditions. So let's just change that z coordinate by a little bit. So we'll take like an epsilon to be like 1, 1000. Maybe I'll make it more explicit for n in range. How many initial conditions do you want? Should we start with just two? Sure, sure. I mean, I know you're doing a whole list for it,  and that's slightly redundant, but we can crank that up to lots. Yeah, this will be good. So that'll be our state. So these are not going to be dependent on the state 0,  but whatever state is part of our for loop here. I'm going to take everything we just did and basically say... Put it in the loop. Okay, points were just created. Great. Okay, it says blue. I don't want them all to be blue. So let me make some colors, which at the moment, because there's just two right now,  we're going to have to change this in a moment, but I'm going to make it blue and red. But like... You eventually will need some numerical way of changing it. Generalized, yeah. But this will make it kind of easy to see now. Good commenting, Graham. Oh, it's a rarity when I'm animating. Someone's watching now, eh? Yeah. I'm not the worst in the world, but there's a lot of room for improvement. So I'm just going to include that in the loop. So I'm zipping together the states and the colors. And so the curves are going to be colored differently. And now this showing creation, I want to actually happen... Oh, here we'll use our star again. I love list constructors and all that. So here's a little fanciness for what we're doing. So we've got this group of curves that actually... In this for loop, I'm going to need to add each one. So curves.add curve. So creates an empty group. This list adds new threads to it. In this case, there's just two. In a moment, we can make it 10 if we want. And then this is going to create basically a list. It's a generator, but it'll create a list of animations. Those animations are this show creation thing. And then the stars, so that as you pass it into the play argument,  it's passing them as if they were multiple different animations. So there's a little bit baked into that. But essentially what we want is that we're going  to have an evolution of two curves at once. And right now you only see the red one because the red one's being rendered on top of it. But now they've diverged. Now they've diverged. I want to see that divergence a little bit more clearly. We need to run it for longer. Okay, so first let's run it for longer. So let's actually name this. Let's call it, I don't know, evolution time. We could just call it time. And that will be an overused name again, isn't it? Let's make that 30. The other thing I want to do is have little dots indicating the end point. Oh yes, so you can eyeball it easily. Yeah, so the way I'm going to do that is I'm going to make a  group that'll have a thing called a glow dot color for colors. And again, glow dot is a baked in function that you've got because you want  often to have a point that moves and has a nice bit of coloring into it. And so this one's not a vectorized thing. So rather than it's just like its data is described by a point  in space and like how much I want it to like ambiently glow. And it's got a little color. And I'm going to create an updater function for it where I'm going to update the dots. This is going to be a function that takes those dots in. And I'm just going to write this function kind of in place. I often like to do that where it's like everything relevant  to this animation we're doing just sits in that commenting bit. I'm going to say for dot curve and zipping together the dots with the curves. I want each dot to move to the end point of the curve. So move to curve dot get end. So curve dot get end will tell you its last point. The dots going to move to that point. And this is something I want to happen on every iteration. So I'm going to say add as an updater this. This is a thing I want to be called on these dots at every iteration from here on forward. Python question? Yeah, yeah, yeah. The zip command is sort of stacking two lists sort of in  parallel so that you can iterate through them in parallel. Yeah, yeah. So let's say we have list one looks like one, two, three. List two looks like, you know, a, b, c. Yeah. Oh, that's going to kill me. You couldn't leave it. So if you say for number letter in zip list one list two print number and letter. Then it pairs them up. Yeah, it pairs them up. So you can keep lists which are referring to similar  things sort of implicitly because of their position. Yeah. I mean, that's what I thought, but it's nice to see that. And so there's a it's unsettling in my mind right now because  we're zipping things together that might not have the same size. So we're going to want to do something that makes sure that colors. In fact, let's just do it now. Would it cope if you did or would it spit out an error? Well, so what it'll do, here's what will happen. Suppose that list one was actually range much longer. So list one looks like this. If we run that little bit we had above it just it goes until one of the lists runs out. So we would just it would cope, but you would be missing many of them. And actually quite hard to find that bug if you hadn't spotted it. Yeah, no, it is. It is.
It's why it's unsettling unless you're like sort of fluent with Python. So I have a thing called color gradient that will basically go between  two colors and you you tell it how many steps to how many steps exactly. And so the number of steps should be the length of the states in this case. So we should just feel like, OK, no matter what,  the number of colors matches the length of the states. And now I feel more comfortable. I wonder how much it is insightful to watch someone  doing a workflow and to note when discomfort kicks in. That's a really insightful thing to realize what matters from bitter experience, right? Isn't it? This isn't that bitter. It's maybe just like aesthetically. Experience tells you when to worry about something when not to worry about it. And it's just nice to see that that's how you know  I should deal with that before I forget about it. So how do we want to do this? Oh, yeah. So we've got our dots. We've got the updater. That means if we add the dots to the scene, then as these  evolve and their endpoint changes based on what's been drawn. It should track it around. It should. I'm going to put in a small line that anyone who knows Python is going to vomit at. And if you want, I can explain the line and why I  would never do it in any sort of like serious code. But it is an annoying necessity. Let's see it first and then I'll ask you. We can edit if we need to. Must be a string or real number. What line is this coming up for? So when I set the points. Color and colors. The color gradient is producing. Oh, so the initial argument for glow dot is the center like where it is in space. So it was telling it you needed that parameter to be there could be  a better certainly a better type error message that's that rather than  this is kicking off to this is where people are like who know Python. The constructor of glow dot should definitely have had better error messaging. I'm not going to hold it against you. Yeah, there's the dot. And again, red on top of blue at first. This is OK. The reason they're running so fast is because the  runtime of this is now different from the evolution time. So we should maybe have the 30 step the 30 length solution is now happening in 10 seconds. Yeah. So let's let's run that again. But where we. So this is in the time it's actually supposed to be. So they start off together. And here's the classic. They'd be like they're so close together to start with. But now they're separated. And then after a little bit, it's as if they're doing completely different things. I want to jump in here real quick to explain that global update locals line,  because it is such a ridiculously cursed line of code. But it has to do with a bug in the sort of IPython embed being used. So let me just show you what's going on here. Taking a super simple example, let's say I have this  snippet of Python where I define some variable X. Let me make this bigger. And then I define this function of Y that's going to use that X. So it's defined outside of the function, but it's making use of that X. And then we're going to test, you know, what is like F of 10. So you expect it to return 13. And it'll do this if I run this as just a Python script. I run it from the terminal Python of that thing. It prints out for us F of 10 is equal to 13. All is well and good. Now inside that sort of IPython embed that's being used for Manim. If I take exactly the same code, exactly the same code,  it behaves differently where it says name error, name X is not defined. Because I think what's happening is that when inside an IPython cell like this,  it defines a new function. It doesn't necessarily share the same scope that it would in a normal Python environment. The catch all hack for how to get around this is to say,  hey, I want X to be a global variable. In fact, to just have a universal catch all, I'm going to take the whole dictionary  of global variables, which Python just gives you access to for some reason. And I'm going to say, hey, look at the dictionary of all local variables. That's going to include that X. I just want everything that's local to become global,  which is obviously a horrifying thing to do if this was like code for a real  library or something. But because we're just scrappily running it in this little interactive  session purely for the purpose of scene development, it's not as dangerous. But if you were wondering or if you were vomiting at the screen,  that's basically what's going on. It's that with this kind of interactive mode. Interestingly, it's not the case that that'll be a  problem in just IPython if you run that from the terminal. Like if I take this code not using the dumb hack, it works just fine. So it has something to do with this notion of embedding such that  we're dropping into the middle of a scene kind of like it's a debugger. If I'm missing someone, if someone knows like a better way to get around that,  I'm all ears. Future future me here. Worth being clear about one thing here, which is that the better way to do this,  if you have some function referencing some variable that it needs to use,  is to just make that very explicit. So in this case, I could say X is an argument of the function, give it a default value,  which is the X kind of defined in the same scope as where the function is defined. And then everything will work dandy and as you want. So in the scene that I was doing with Ben, if we look over at the very cursed line here,  the better way to do that where it wants to reference curves is to basically say,  hey, curves should actually be something explicit in there. Maybe an argument that defaults to the value that's  going to be whatever it was on the outside. That will totally handle it. The reason I was in the habit of doing this, for one thing,  it's maybe a little annoying to do that with lambdas on the fly and things like that. But the same bug would come up with list constructors. So if I was to define something like X plus Y for Y in range,  I don't know, 10, something like that. And I want to see what this looks like. This is something where, you know, in normal Python, this X would be visible outside. And so if we were to actually run this, run this little test, it would do what we want. Whereas inside the manum environment, at least previously,  so if I do all this and then I ran that code, previously that same bug would emerge. But when I was just looking at it now, it seems like actually it's fine. Whatever bug had been there that affected list constructors and things like that,  it's fine. So maybe I should just get out of the habit of typing that  incredibly cursed line and you can ignore the last five minutes. Anyway, back to actually finishing out that scene with Ben. Let's make those dots bigger. Can we give them radius one? I don't like red as the second color. I just think that looks kind of ugly. I often... Okay, that's a very big dot. But I guess I don't know. We see it. Yeah, we see it. That's maybe a little bit a little bit too big. So I might ease off on that. Again, I mean, it's a minor comment, but the aesthetics are handled for you. The glow dot, it's too big, right? But it still looks nice, even though it's big because you've paid  attention to making a glow dot function, which makes a nice looking dot. So this is something I was going to ask about. This is interactive. Yeah, yeah, yeah, yeah. And that wasn't obvious until you moved the axes. No, it's because everything is ultimately rendered  and just like made into a YouTube video. And every now and then I've done something where I'll  like have an animation I want to play with in the moment. But like, it's not that common. So okay, a very common thing I might do, we've got this animation,  it's rendering all these. It would be nice for the camera to slowly pan throughout. Agreed. And so it's amazing how useful it is for 3D rendering is that if you're looking at it on a 2d screen, you need the illusion created by the rotation to keep the depth alive. Yeah. So here's what I might do. I have a little another keyboard shortcut that is not documented  anywhere where I can save to my clipboard, basically a call that  needs to be made to put the camera in the current position. So that's just grabbed where the camera angle is right now. That's helpful. And so if in my animation I take the camera frame, which is like frame. I haven't talked about this dot animate thing yet. But basically I say, I want you to do this thing. I don't want you to just do it to the object. I want you to animate that over time. And there's some little bit of magic that underlies what's going on there. But in this case, the thing I wanted to animate  is reorienting itself to a certain position. So over the course of the animation, it should like slowly pan itself over. So it'll take wherever it is, wherever it thinks it is already and try and get to that. So I'm going to also it's nice if the runtime as an argument of the play method,  then it becomes the runtime for every animation in that method. So this might not be enough movement, actually. I might want to like really have it spin around because it's happening over 30 seconds. So back to the beginning. Do all this. Is it panning? Oh, it's very slow. It looks like it is very smooth. It's not. Yeah, it's smooth, which not necessarily. I think I like that. I think I like it as a smooth thing. Agreed.
It might look kind of a jerky style if it wasn't. Yeah.
And so now it's like as we're going, we can see it from all the different angles. I think the color scheme is still a little jarring to me. So I think what I might do is make it go to teal or something that's nice and close to it. And then maybe we'll make this actually even more aggressive. I'm not your best color audience. My color vision deficiency, definitely. I don't know if my colors are the same. Anyway, yellow and blue I can see apart. Blue and teal. In this case, like either you want them to be starkly different so  you see it or you want it to be aesthetically nice where maybe  you're just using the shade of it rather than the hue to distinguish. So I mean, one thing we could try, it's going to look cleaner,  but maybe be harder to discern. Let's say we go between two different shades of blue and I'm going  to now let's have some fun and let's have there be like 10 points. And so they're just going to change by their epsilon in the third coordinate. Yeah, exactly.
Doesn't really matter. We know actually. I mean, mathematical comment. The other amazing thing about this is that wherever you start,  it goes into this sort of shape. That's kind of like the second surprising thing, isn't it? Yeah, yeah, yeah. The whole point is not just that it does something strange,  but that there is an attractor. So often with differential equations, it might be attracted to a single point. It might blow up to infinity. It might be attracted to a cycle, but then this is what's called a strange  attractor where all the points are attracted to a certain shape,  but that shape isn't so simple as a cycle and it's got a fractal nature to it. I often feel like it's the sort of contradiction inherent in trying to describe  chaos to someone because I want you to say, okay, this is when it's unpredictable. And yet at the same time it is predictable and there's this strange attractor. So it's the fact that both are happening. And this is... You know that it's going to be on this subset of R3. It's going to get really close to that subset. Where on that will it be? Well, we just had 10 starting conditions that were really close to each other. And if we remove the curves and just see the dots. They're all over the place. Oh, actually, let's do this. Let's have some fun. What if the curves... Sort of fade out of... Oh yeah, let's have them fade out of... Sorry, you had an idea that I... No, no, no, no, let's do that. Let's have the curves fade over time. I want to know what your idea was. How do I want to do that? I'm going to... I definitely made the part that follows with Ben  way more complicated than it needed to be. We also got sidetracked chasing down a couple of different bugs. I think what I'll do is post the full relatively  uncut version of that conversation maybe on Patreon. But just give you a much more succinct version of how we wrapped up here. Here I have essentially the same scene that I was doing with Ben. So we've got our axes setting up a 3D coordinate system. We've got our curves. I've got 10 of them. Here, when we animate, the curves are getting drawn. The dots are following. And Ben had just asked if we want to have the curves fade out over time. What I should have said is that you just type fade out curves,  which is another animation type. It'll slowly change them to have zero opacity. In this case, that evolution time, if we make it the parameter... The runtime, rather. If we make that the parameter of the play argument here,  then it becomes a runtime for everything on the inside. So now when we do that, it goes. And over the course of those 10 seconds, the curves should slowly fade. And indeed it looks like they do. And then we're left just with the dots, which is nice. It looks very nice. The other thing that we got into, and I just took  way longer to say this than I properly should have. Because I was trying to remember what the names  of the functions were and things like that. Again, I'll post this all in a more uncut version elsewhere. If we wanted a nice effect where there's this sort of  tail following the dots that sort of fades out nicely. There's this thing I once wrote for some... You don't even remember what video, way in the past, called Tracing Tail. And so the way this will work is if you give it just a single little object of some kind. So let's give it that first dot. And then let's add the tail. Then, rather than fading out the curves in this case,  actually what I'm going to do is just set those curves to be invisible. So set their opacity to be zero. So they'll be drawn that will determine where the dots go as  they're having this kind of update function called on them. But we won't actually see them. What we will see is this one tail for one of the dots. I think. So the way that it looks... Great.
We see that one little tail and it kind of fades out in the back. I like the effect. It sort of goes from full opacity to zero opacity, zero stroke width. You can change some of the parameters on it here. In this case, the amount of time that it follows it. So right here it's showing the last one second. And if we were to wait, it would sort of fade out because one more second has passed. So instead I could say, hey, I want you to follow it for a little bit more time. So let's make that time traced three seconds. Instead of just having one tail, we could have a group of them. So we'll create a group of these tails, not just for the zeroth dot,  but for all of the dots. For dots and dots. And then I could maybe have it match the color  of that dot so that we kind of see them all. So now, when we do this, we should see ten different  tails all following for a little bit more time. Which I think should just give a nice, oh yeah,  yeah, yeah, that gives a nice smooth little effect. And they all start to spread out. You can see that spread really cleanly. And here we can have more fun by basically having it evolve over more time. Instead of ten seconds, we could bring that up to thirty seconds. We could make them closer so this epsilon value,  instead of being one one thousandth, we could make it one one hundred thousandth. So it should take longer for them to all diverge. So now if I go, we see all of those tails. In theory, these ten dots should actually stay closer for much longer. And it should take longer before we see that divergence in the chaos. And indeed, it takes a little while, but eventually they spread out. So, I think that's kind of a nice end effect. Like I said, I'll post the more uncut version,  but now is a pretty good point to just jump ahead towards other topics. Well, goal achieved. You've got a Lorentz Attractor with multiple initial conditions varied very slightly,  animating prettily with a glitchy trail. So before we finish the workflow, you've made a code that does a thing. And let's say you're happy with it. I know there's lots of polishing that you want to do. But you then bake it into an MP4 file. Oh yeah, yeah, yeah. So in this case, once I have the scene that I like,  and so in this case maybe we'll clean it a little bit. I might want to render this out, so I've got a little keyboard shortcut. The way that you might call Manim usually is in the command line,  if you've downloaded the GitHub and you've imported it all, you say Manim,  and then you pass in a file, a Python file that contains the scene. And so in this case, I found the scene to put that. You say which scene do you want to render from that file. And in this case, I have a couple different parameters. If I say pre-run, it'll go through it all without animating to one,  estimate how long it'll take, and also catch any errors rather than halfway through  the animation. This Finder thing just means it's going to pop it up in Finder, the Mac OS file system. And then W means write it to file. And so if I run this, it pre-runs through, thinks about it,  it knows how long it'll take now, and now it's rendering it to an MP4. And because I'll usually render it at 4K, sometimes  the rendering will take a little longer. One of the reasons I wanted to make any kind of behind the scenes,  the way I used to use Manim, and the way I actually suspect a lot of people  who use Manim Community do use it, is you're always running it from the command line. So you've got your scene and then you run Manim, that scene, and then it pops up. It renders an MP4 file, so it has to render the file and then pop it up. And there were a bunch of shortcuts to say, oh, don't render the whole file,  just render it starting at this animation or something. But you can imagine the iteration cycle is a little more annoying  if every single time you're making an update and you want to see it. So it was later in the game, around the same time I was changing the implementation  to run on OpenGL, to then also have the interactive shell version,  such that the process of creating just is like,  highlight the code and see what the code does. And that's a fundamental change to the workflow. It's huge! And my specific workflow, it depends on these Sublime scripts that I wrote that will  send a command to the Terminus, which is the extension of Sublime that makes a terminal. So what I'll do is in the description of this video,  I'll actually document what that process is. And so if anyone's curious and wants to replicate it,  probably whatever text editor they're using you can do something that does the same. So for all the people who are in Visual Studio and whatnot,  you can do something that would look the same. So here it rendered it, and now it's going to look  all glitchy because of those glitches that I mentioned. But this is now playing in a video player, it's a file. This I would drop into Final Cut, do my editing. I guess another thing we never did is we could have the equations. Let's add the equations. So you can have a LaTeX object that's basically going to say hey,  take some LaTeX and then render it, and then we'll add it on. Have you ever used MathPix? MathPix is so good. So it's OCR, but for LaTeX you can take a snapshot of just any equations and then it  gives you all sorts of things, but one of them would be the LaTeX for that expression. Fantastic.
And so it also gives you it as an SVG if you want and all that. It's really good. So from a screen, literally a bitmap is taken to a scalable vector. It's really panicky. It's great. It's so good. I guess it renders it in LaTeX and then SVGs it out. So we can use this here, so we can have our equations and then add those. So that will dump them in the middle of the screen, am I right? You're absolutely right. And also on the XY play. If there's a 3D scene and you want stuff like that,  you say fix in frame, as if it's glued on the camera frame. And then in this case we might want it in a corner. So here's something I wrote which, let's see if this works actually. So you can index into it by a string. So I can say every time you find an X you know, maybe color that red. That's useful. But not working. Tech to color. And by better I mean more it'll actually work. So T to C I guess is what we call it. So T to C Let me get my line spacing in a way that looks a little bit nicer. So here's a nice thing you can do. If we say everything that looks like an X make that red. Everything that's Y, red, green, blue. I think that will... And actually now that it's known to separate those out at some point,  if I do say equations and I try to pull out the Xs and I  shift them a little bit up then it has control on them. It does its best if you don't do anything to say hey these are specific variables  I'm going to want to separate but you have to from the tech expression know how  many symbols there will be such that it can dissect the manum object in that. It's a little tricky to get it to actually work. So if you know you want control over variables  you just put them in an expression like this. There's another one called isolate or something. 9 times out of 10 it will work by default anyway for simpler expressions. Maybe you do something where it's like you've got we're going  to write the equations onto the screen to just beam in a bit. And now that's going to be the scene that renders  if we go and then it does its whole thing. And so those are just up there as it's doing its thing. And are they behind or in front of the camera? That's the sort of thing I'm sure you can control right? So in this case by default things will just be rendered in the  order that you put them on unless you tell them to apply a depth test. So a lot of 3D objects that know they're supposed to  be in three dimensions it's going to be depth tested. In this case its actual position in space is on that xy plane so it's a little bit weird. But if we wanted them to be rendered, wanted to make sure they show up  in front what we could do is just make sure that we add it down here. And then what I could do we could maybe say hey let's take those equations and  I want to set a backstroke so that there's a little bit of space around them. Let's maybe make the font size a little smaller so that they're just  up in the corner so the font size is like 30 something like that. We put that on they're a little bit smaller up there and then now when we render our I  guess they're not really going to overlap with the solutions because I made them smaller. Because they're being updated every frame. Being able to break the text into sort of mathematical parts is  extraordinarily useful if you want to highlight mathematical parts. And it's something that would be a real pain to do in any other context. Yeah you know what I maybe should say. I have some example scenes basically. So this is my intention. Hey if you wanted to get started just look at a couple of these examples. And so if you wanted to see like working with some tech what that might look like. In this case I've got actually a series of expressions that we're  going to play with which is basically rearranging a certain equation. And these are going to be the lines of our equation  and now it's just rendering the first of those lines. I've got a special notion of transform that will try to match the strings underlying it. So that if we play like this the A squared goes to the A  squared the B squared goes to the B squared and things like that. There's example scenes in here to kind of show the kinds of operations available. If you just play around with some strings this like matching  string will automatically give you a nice anagram animator. Where you don't really you don't even have to think. You don't have to worry about it. You don't have to think. It's just like move the letter to the corresponding  letter and like it's sort of a one liner that does that. That was like an emergent thing. I mean slightly not helpful for viewers but we  saw a big anagram discussed a couple of days ago. We should tell Simon. Yeah that's what it would save Simon if he had run it through Manim. I can just like show a little bit more in here if you want where got this equation,  famous equation. If you wanted to say hey I just want to reference the E part of that. There's an animation called flash around and you'd be flashing around just at E. Or you want it. There's another one called indicate and you want to indicate that pie. Things like that. So you're pulling it out bit by bit. And in terms of understanding what functions like that exist. Obviously there's your head which is this vast  trove of experience over the time you wrote it. But the Manim community version is a different version but these still exist. Yeah Manim community definitely has much better documentation. There's not zero documentation on this one. You can see all the animations basically in a folder of the library called animation. If you just look through that folder you'll see the things that exist. All of the code I've ever written for any video is on GitHub. If you go to github. slash 3b1b slash videos this GitHub basically  has all the animation from videos in the past. In this case I guess and videos of the present. I haven't made any animation for holograms yet so that one. We can see some puzzles that I just made for the IMO. You can see it all in there and then that gives you  some sense of what the functionality available is. And maybe this is a workflow thing for people like me who are beginning. If you don't know what functions are out there obviously  you can look at the library and see what's in there. There's no auto complete sort of like if you start typing  one that you think might be it you can't Oh yeah sure there is. There's all sorts of auto complete tools out there. Which will be more to do with the text editor. Yeah so this is the text editor question. So like in Sublime there's a thing called a language server protocol  and so there's some I think it's called like Pi LSP or something. It has some sense of the environment that it's in and might auto complete. So that's one way to find a function. If I was going to write a function I might call it this. You can find out if there is one call. GitHub copilot right? Just like use copilot. I don't like using copilot with Manim just because I know  what I want to do and it doesn't quite know what I want to do. And it's really nice if you're like engaging with a new library of code but I don't  know I just find like dumber auto complete tools to be the thing I actually want. Because often it's like it's not a if I don't know exactly what I want  the way I want to even articulate the request is in code not in English. To each their own but like just try it. Yeah and you have the experience to sort of fall back on your own experience. Yeah yeah yeah yeah just fill it in. No but that is a sort of workflow thing and depending on your  text editor and it's actually something I'm just not used to. Like it's that that lower level sometimes it's  the barrier to getting started on these things. Yeah yeah yeah. But once you've crossed those hurdles. Yeah how do you even know where to start. So the example scenes I think would maybe yeah yeah gives you some sense of it. Nice well thank you for showing me I really enjoyed seeing the back end. It's a very human experience coding and what and the messiness is part of it. So there you go little peek behind the scenes. I will leave a link in the description to that repo where you  can see the code for literally any video I've made in the past. By the time I post this I'll also add something to the readme  of that repo to outline the actual workflow that I'm using here. You know the specific sublime scripts what you would want to  mimic if you're using a different text editor things like that. And I'll also post the full version of that conversation warts and all to Patreon. I might actually do some like manum live streams  or something like that on Patreon periodically. If that's a thing you would be into let me know. If so what kinds of things would you like to see. But in the meantime I'll be busy animating the next video and I will see you then.

================================================================================
VIDEO ID: W3-kpRz-e1Q
TITLE: Hologram preview
URL: https://www.youtube.com/watch?v=W3-kpRz-e1Q
PUBLISHED: 2024-10-11T14:00:27Z
STATUS: SUCCESS
================================================================================
what you're looking at is a hologram in reality all that's there is an empty table and a diverging laser beam shining on the glass inside that glass is a single piece of film that's been exposed in a very special way that records the entire three dimensional scene I want you to take a moment to reflect on just how incredible this is simply from the standpoint of how much information needs to be stored on that film an ordinary photograph records a scene from just a single viewing angle but right here we have available to us an entire Continuum of differing perspectives the key thought to have in your mind when it comes to a hologram is that the goal is to recreate the entire light field around a scene and the specifics of that field are dependent on every Optical property of the objects in your scene and the lights Illuminating it what you see when you're an observer depends on where your eye is in that field in our test scene for example

================================================================================
VIDEO ID: DnjATyPuFFk
TITLE: Holograms are wild (full video linked above)
URL: https://www.youtube.com/watch?v=DnjATyPuFFk
PUBLISHED: 2024-10-05T15:35:00Z
STATUS: SUCCESS
================================================================================
let me show you something I find completely magical behind this piece of glass there appears to be a three-dimensional scene you can move around your head and you see the light play off of the objects in different ways for example that glass Klein bottle in the front warps what's behind it but it's an illusion in reality all that's there is an empty table and a diverging laser beam shining on the glass it's hard to capture in a video how surreal this feels in person because despite there being nothing behind that glass every visual cue available is screaming to your brain that something really is there one of my favorite versions of this is a recording taken of a microscope again it gives this illusion of a three-dimensional object stored on a two-dimensional piece of film and it's a little tricky to get this right but if you put your eye at just the right point in space you can look down the barrel of the microscope and see what it's Imaging in this case a little microchip

================================================================================
VIDEO ID: EmKQsSDlaa4
TITLE: How are holograms possible?
URL: https://www.youtube.com/watch?v=EmKQsSDlaa4
PUBLISHED: 2024-10-05T15:31:58Z
STATUS: SUCCESS
================================================================================
Let me show you something I find completely magical. Behind this piece of glass, there appears to be a three-dimensional scene. You can move around your head and you see the  light play off of the objects in different ways. For example, that glass Klein bottle in the front warps what's behind it. But it's an illusion. In reality, all that's there is an empty table  and a diverging laser beam shining on the glass. Inside that glass is a single piece of film that's been exposed in  a very special way that records the entire three-dimensional scene. It's hard to capture in a video how surreal this feels in person  because despite there being nothing behind that glass,  every visual cue available is screaming to your brain that something really is there. One of my favorite versions of this is a recording taken of a microscope. Again, it gives this illusion of a three-dimensional  object stored on a two-dimensional piece of film. It's a little tricky to get this right, but if you put your eye at just the right  point in space, you can look down the barrel of the microscope and see what it's imaging. In this case, a little microchip. I want you to take a moment to reflect on just how incredible this is simply  from the standpoint of how much information needs to be stored on that film. An ordinary photograph records a scene from just a single viewing angle,  but right here we have available to us an entire continuum of differing perspectives. In the first example, this includes how the light from the pie creature  refracts through the glass in different ways from different angles,  or how sometimes you get this little glint of light off the disco ball. Every optical detail from all these viewing angles  is stored on that two-dimensional piece of film. What you're looking at is a hologram. When most people hear the word hologram, what pops into their mind is something like  what R2D2 projects in Star Wars, but real-world holograms are a special kind of recording  taken on film that gives the illusion of looking through a window into a recorded scene. The principle behind this was discovered by Dennis Gabor in 1947 while  he was working on methods for electron microscopy, and as the story goes,  the fundamental insight came to him while he was watching a tennis match. It wasn't until decades later, with the invention of lasers,  that holography actually became practical, and in 1971 Gabor won the Nobel Prize  for his discovery. The type that I'm showing you here, where the scene is visible only  when you illuminate it with a laser from behind, is the simplest version. It's what's called a transmission hologram. In this video, you and I will roll up our sleeves  and dig into the details to understand how this works. A more advanced variant is what's called a white light reflection hologram,  which as the name suggests can be illuminated using ordinary light that reflects  off of it. This includes that microscope that I was showing you earlier,  which is part of a collection from the Exploratorium in San Francisco,  which they very generously let us record. First I want to show you the process for how you actually record a hologram,  and then you and I will cover some of the fundamental principles of  optics that explain one very simple and very specific hologram,  but in such a way that we can get a deep and visceral understanding for it. Then after that I'll share a slightly more abstract but much more  powerful framing that explains how it works so well in general. Optics can be tricky and sometimes magical, so my goal at each of these steps is  for this to really feel like something that you could have rediscovered for yourself. When my collaborator Paul and I asked around for help to record our own custom hologram,  multiple people pointed us to these two very skilled holographers,  Craig Newswanger and Sally Weber, who generously showed us the ropes when  it comes to the delicate orchestration of lasers involved in doing this. The whole setup risks feeling like a set of arbitrary steps,  but I think maybe the best way to motivate it is to contrast what we're doing with  ordinary photography. In a photograph, a given point is only influenced by a very narrow  region of the scene that you're recording, something like a pixel. The simplest kind of camera would be a pinhole camera,  where you only let light pass through a tiny little hole that exposes your film  meaning each part of the film can only see one narrow little region of the  scene through that hole. The point is that you're limiting things to a single viewing angle to influence the film. All of the other information from all other possible viewing angles is lost. The key thought to have in your mind when it comes to a hologram is  that the goal is to recreate the entire light field around a scene. What I mean by that is when you set up some scene and there's some light shining on it,  there's this incredibly complicated undulating electromagnetic field that  surrounds everything, and the specifics of that field are dependent on every  optical property of the objects in your scene and the lights illuminating it. What you see when you're an observer depends on where your eye is in that field. In our test scene, for example, from some angles you see the pie creature's eye refracted  through the glass of the Klein bottle, from others you see a glint of light off that  disco ball, but in principle everything you can see from various different viewing angles  is entirely a function of whatever this undulating light field is that surrounds the  scene. So if you could come up with a procedure that recreates the full state of that field,  even when the objects are no longer there, it would give the  complete illusion that we're aiming for. Contrast this with the pinhole camera, where a ton of information  is lost about that light field based on filtering through the hole. After all, that hole is there to limit the exposure to just one viewing angle. So the first thing you would do if you wanted to record the whole field is to get  rid of that pinhole altogether, or the lens that simulates it with most cameras. On its own, exposing the film would now create a non-sensically blurred mess,  but the key to making it sensible is to account for another piece of  information about light that normal photography loses, phase. Think about a beam of light shining on a single point of film,  say one that has a pure frequency that you could think of as an oscillating sine wave. The height of this wave is called its amplitude,  and how far you are along in the cycle is called the phase. Only one of those determines how much the film gets exposed, the amplitude of the wave. The exposure takes some time, and it's influenced  by the average intensity of this wave over that time. Actually, more specifically, the exposure is proportional  to the square of the amplitude of this wave. That's going to be important for us much later. If you were to shift this wave back by half of its wavelength,  it makes no difference to the exposure on the film,  in a sense that point of the film completely forgets everything about the  phase of the light that exposed it. You could almost reinvent holography for yourself if you ask,  how might it be possible to record the phase of the light, not just the amplitude? Can you come up with a procedure where one beam of light would expose the  film differently than another beam that is in all respects identical,  except for the fact that its phase is shifted back, say by half of a cycle? If you give yourself a moment, and if you're rather clever,  you might think of something like this. Shine on a second beam of light that has exactly the same frequency. We're going to call this the reference wave. When the first beam is in sync with that reference wave,  the two will constructively interfere, producing a wave that has twice the amplitude,  so the film gets exposed a lot at that point. But if that first beam was shifted back half of a cycle,  the two would now cancel out with each other, interfering destructively,  so the film would be exposed much less at that point. It's not a perfect recording of the phase, but in this case the exposure is highly  sensitive to phase shifts in a way that's not at all true for normal photography. Admittedly, it might not yet be clear why this has anything to do with storing  a three-dimensional scene on a two-dimensional film, but at least in principle,  if you know that the goal is to recreate the full state of a light field around  your scene, perhaps you could believe that having a record of the phase variations  in that light field along the plane of the film might somehow be relevant. This insight of interfering with a reference beam  only works if all the light has the same frequency. So looking at your setup, you cannot illuminate the scene with ordinary white light. What you have to do is use a laser. A clever way to do this is to pass that laser through a beam splitter,  where half of it gets spread out, bounces off the scene, and hits the film. We'll call that the object wave. And then the other half also gets spread out, but it  doesn't interact with anything before hitting the film. This will act as the reference wave. Those two waves interfere at the plane of the film in a  way that depends heavily on the phase of that object wave. The full setup that Craig and Sally made for us  looks only a little bit more complicated than this. One little nuance is that beam splitters change the polarization of light,  so you have to do something to counteract that. The object beam follows this trajectory here, which lets our scene  get right up next to the film and get illuminated from the front. And then on the left we have the reference beam. But at a high level, the essence of any holography setup is to  have these two different sources of light, both of the same single frequency,  interfering with each other at the plane of the film. This means that the exposure pattern on the film is based on the  extremely subtle ways that these two waves interfere with each other. The exposure pattern looks absolutely nothing like the original objects. If you zoomed in with a microscope, you would see a complete mess,  some rapidly oscillating fringes between points of high and low exposure. From a practical standpoint, you should note how this also  means the exposure pattern is incredibly sensitive to even the  tiniest movement of the objects in the scene during the recording. If their position shifts by an amount comparable to the wavelength of the light,  a few hundred nanometers, it can completely change that pattern. So when Craig and Sally were showing us the ropes,  one thing that really surprised me was how part of the process involved all  of us sitting in this meditative stillness throughout the exposure,  which took a couple of minutes. We even had to sit still during the minutes leading up to it,  reducing as much motion as possible in the air of the room. Now at this point, even if you believe that this resulting interference pattern  on the film somehow records information about the light and its phase and all of that,  it's not at all obvious how you could use it to recreate the original field,  making that illusion of the scene behind the glass visible from many angles. But here, my friend, is the magic. If you now remove all the objects from the scene and you block that object beam,  so the only thing shining on this now exposed film is the reference beam,  then what it produces beyond the glass includes a complete recreation of that object  wave, a recreation of light that would be there if the scene were still there and the  object beam were still shining. This is the surprise of holography, the mystery that you  and I are going to dig into for the remainder of the video. Why is it that shining the reference wave through this film,  which was exposed using the combined object and reference waves,  gives you such a bizarrely perfect recreation of the object? How does this delicate and apparently nonsensical interference  pattern on the film somehow record an entire three-dimensional scene? To drive home how magical this feels, we cut out  a very small circle from the film that we recorded. In an ordinary photograph, cutting out a small piece obviously cuts away the  vast majority of the scene, but for a hologram holding up that same small little  circle of film to the reference beam, as you shift your viewing position looking  through that circle, you can see essentially every part of the scene recorded,  from that pie creature to the disco ball and the various shapes behind it. You just can't see all of them at once. Continuing with the goal of rediscovery, universal problem solving tip number one is  to begin analyzing any hard problem by taking the simplest version of that problem. So to puzzle over how holography works, a natural place you might start is to ask,  what happens if you record a hologram of the simplest object you could think of,  maybe a little point floating in three-dimensional space? We'll think of the light that reflects as a wave  propagating radially away from that point. The basic outline for what follows is that we'll figure out what the exposure pattern  on the film is in this very simple case, then deduce why shining the reference through  that known exposure pattern creates the illusion of a single point behind the glass,  even when it's not there, and then we'll generalize to more complicated objects. I should maybe take a moment to be clear on how  I'm representing light waves throughout this video. Light is a wave in the electromagnetic field, where for example  the electric half of that is an association between each point in  space and a little oscillating vector pointing in three dimensions. Where that field is strong in one direction, I'll color a point blue,  and when it's strong in the opposite direction, I'll color it red,  and the dark bands in between represent where it's zero. In principle, the field exists everywhere in three-dimensional space,  but typically it's a lot easier to think about if I only color the points along a  two-dimensional slice of it. Even more narrowly, it's often helpful to think of a little sine  wave over this when we want to think of what the wave-like  variations are just along a single one-dimensional line through space. And for the detail oriented among you, throughout this video we'll be  assuming that the light is linearly polarized,  meaning it just oscillates in one direction, which it typically would be  if we're recording a hologram. Now, when we take a hologram of this single point,  the radial wave coming from that point is our object wave, and for the reference wave,  again in the spirit of simplicity, I want you to think of it as coming from very  very far away, enough so that we can model it as a plane wave coming in  perpendicular to the film. In other words, what I mean by that is that all of the wave  crests from that reference beam are parallel to the film. You should know that in practice for real holography,  you want this reference beam to come in at an angle,  later on you're going to understand why, but for right now, keeping the analysis simple,  making that beam perpendicular gives us a friendly situation to study. I can simulate for you what the combination of both of these waves looks like,  and what the resulting exposure pattern on the film looks like,  but it is helpful to think through for yourself. For example, if the light off of that object hitting the  nearest point of the film happens to be in phase with the reference beam,  it means that center point would be strongly exposed. In that case, for points farther away from the center,  because the distance to the object gets longer,  the phase of the object wave along this strip falls in and out of phase  with the reference wave, meaning that the exposure pattern oscillates  between points of high and low exposure. For example, at a certain point on that film, the distance to the  object will be exactly half of a wavelength longer than the distance  between the object and the closest point on the film, at that center. So if the object and reference beams had been in phase in the middle,  it would mean that they're exactly out of phase here,  so the combined wave has a low amplitude and you get this dark spot at that point. The same would be true for everything along this ring around the center,  of all points the same distance to the object. In general, the exposure pattern here looks like a bunch of concentric rings. If you enjoy exercises, you might like taking a moment to try writing an explicit  formula for the radii of all of those rings, as a function of the distance  between the object point and the film, as well as the wavelength of the light. At a more qualitative level though, just note that the distance between  these fringes gets smaller as you go farther away from the middle. This pattern is important enough in optics that it has its own special name,  it's called a Fresnel zone plate. The wavelength of visible light is really small,  and that means that the fringes of exposed points are spaced very close together. Farther away from the middle point, they approach the wavelength of the light itself. In the simulation, notice how if I bring the object point closer,  the inner rings get smaller, and if I pull that object point farther away,  the inner rings get bigger. So in a manner, this pattern records the three-dimensional coordinates of our point. The center of the rings give you the xy coordinates,  and the ring spacing uniquely determines the z coordinate. So you go ahead and you record this simplest of all holograms,  and you end up with film that has this peculiar zone plate exposure pattern. But how does reconstruction work in this case? What happens when you remove the object and the object beam,  and the only thing shining on the exposed film is the reference wave? Well, if you look at just a small region of the film,  the zone plate pattern looks like a bunch of parallel stripes,  and this is related to a very well-studied phenomenon in optics known  as a diffraction grating. And while I could just plop down something known as the  diffraction equation right now to continue with the explanation,  it is a real joy to see how it arises from first principles. So continuing that theme of letting this feel like something  that you might have rediscovered, let's take a brief sidestep  into a mini-lesson so that I don't have to rob you of that joy. Here's the basic puzzle for this mini-lesson. You've got a light wave shining onto a wall, and imagine this wall is solid and opaque,  except for having a bunch of very thin evenly spaced slits that the light can pass  through. The basic question is, what does the light wave look like on the other side of this wall? And in particular, how does it depend on the distance between those slits? Now, a full answer is extremely complicated, so much so that  it's surprising that we'll be able to say anything useful at all. And before I spoil the general shape of the answer with the simulation here,  let me be clear about how we're going to think about it. For each individual one of those slits, we'll imagine that it's  thin enough that you can model it as a single point emanating light,  matching whatever wavelength and frequency the incoming light has. So if there was some wall or film behind this single slit,  you wouldn't really see anything all that interesting. It would be brightest in the middle, and then taper off very gently to the side,  depending on how the amplitude of that wave diminishes over distance. In particular, nothing here really gives you a hint about the phase of the light,  so the wave nature remains relatively under-spoken. Very famously, this changes when you open up a second slit. In fact, when Thomas Young did this for monochromatic light in 1801,  it was one of the earliest confirmations that light really is a wave. For you and me, thinking about two slits is a nice warm-up before we get to more. As an example, think about the point at the center  of that wall on the opposite side of the slits. In that case, the waves coming from each one would be in phase with each other,  so they interfere constructively, and that's why you get a bright spot. If you move over a little bit to the side, where the distance to one  slit is exactly half a wavelength longer than the distance to the other,  they would add destructively, and that's why you get a dark spot. And in general, you get these oscillations between  bright and dark as you scan left to right. The key point here, which you have to imagine was a bit of a surprise in 1801,  is that the brightness on the wall is not just a sum of what it would be for each  individual slit. The key, when you have light just of one frequency like this,  is to understand where the waves are in and out of phase with each other. Also, I want you to notice how the pattern changes  if we change the wavelength of the light. A shorter wavelength would give more rapid oscillations between bright and dark spots. There's a really nice exhibit at the Exploratorium in  San Francisco showing this double slit interference. You shine a thin laser beam through two even thinner slits, and on a wall very far down,  what you see is an array of light and dark spots, just like what we saw in the simulation. That's just two slits, but remember that our key question is what happens when  you have a whole bunch of slits, say spaced a distance d away from each other. I have to say this was incredibly fun to simulate,  and you can probably guess how the simulation here is working. At every point in space, you consider the n different light waves coming from each  one of those slits, you add up the values of those waves,  which might add or subtract depending on their phase,  and then you color that point depending on the result. Blue for positive values, red for negative values. In the immediate vicinity of the slits, this is a complete chaotic mess,  but the surprise is that when you zoom out, order emerges. You have one beam of light shining down the middle,  but you also get these other beams shining off on either side,  and one of those beams specifically is going to be the key to explaining  our first hologram. In particular, I want you to understand how you'd  compute the angle between that other beam and the center. How would you analyze a point which is along a  line some angle theta away from that perpendicular? Well, the key question is what are the distances from that point  to all of the individual slits where the light is coming from? If this point is far enough away, then when you zoom in close to those slits,  all of those lines look like they're parallel to each other. What you want to know is whether a given one of these lines is longer than  another one of the lines, and more specifically, how much longer it would be. I think one of the nicest ways to think about this is to zoom out again so that  we can see the point we're analyzing, and imagine pivoting one of those lines  around that point so you're looking at everywhere else that's the same distance away. If you were zoomed in next to the slits, that pivoting motion  looks basically like you're translating in a perpendicular direction. So what that means is if you drop a little perpendicular line from one of the slits to  the line adjacent to it, you can conclude that the distance between that first slit and  the point we're analyzing is exactly the same as this section of the adjacent line,  meaning that the difference between those two distances is visible as this little snippet  right here. So the key question, if you want to understand whether those two waves  are in or out of phase with each other, is how big is that snippet? What's the size of that difference? Well if you go in and you draw the appropriate little right triangle,  the hypotenuse of that triangle is the spacing between the slits,  which I'm going to call d, so this key difference we care about looks like one  of the legs of that triangle, d times the sine of a certain little angle that  I'm going to call theta. It's not too hard to convince yourself that that angle theta is actually  the same as the angle between all these lines and the vertical,  so the difference between all of these lengths,  and this is really the key lesson of diffraction gradings,  looks like d times the sine of that angle. In particular, if it was the case that this key expression, d times the sine of theta,  happened to be exactly the wavelength of the light, commonly denoted lambda,  all of the beams emanating from these different slits are going to be in phase  with each other, so they'll constructively interfere at the point we're analyzing. This is why, even in the immediate vicinity, you have this chaotic mess that's very hard  to describe, zoomed out a sufficient distance away,  you have a distinct beam along a certain direction, and moreover,  you now know how to compute the angle of that direction. It's the angle such that d, the spacing between your slits,  times the sine of that angle equals the wavelength of the light. That will be a key equation for us, so do remember it,  but this graphic also helps give a nice qualitative intuition for how changing the  spacing influences the angle. Imagine locking the length of this critical leg of the triangle,  you want it to always equal the wavelength. Then if you want it to narrow the spacing of the grating, making d smaller,  the only way to keep that leg locked is to make the angle theta bigger. On the other hand, if you had a wider spacing and you increased that value d,  the only way to keep that leg locked is to decrease the value of theta. You can also say a little bit more here too. For large enough values of d, it's possible for d times the sine of  theta to not just be a single wavelength, but to equal two whole wavelengths,  so you would still get constructive interference but at a bigger angle,  and the same goes for any whole number multiple of the wavelength. And again, this is something that you can see in practice. Here we're shining a green laser through a diffraction  grating that has 500 lines per millimeter. You can not only see how it splits up into these distinct beams,  but you could actually do the math to figure out the angle between those beams. The centermost one is commonly called the zeroth order beam,  the ones immediately next to it are called the first order beams,  and if they exist, the other ones are called second order, third order, and so on. Another fun thing to notice is how this equation depends on the wavelength of the light. So if you shine white light through a diffraction grating like this,  you get a separation into distinct wavelengths, distinct colors like a rainbow. If you've ever noticed how the reflections off of a DVD or a CD produce  this rainbow pattern, it's essentially the same effect going on there. The angle of reflection depends on the spacing  between the ridges and the wavelength of the light. So that's the packaged lesson about diffraction gratings,  but now let's zoom out and remember why we were doing this. If you record a hologram of a simple point in space,  the exposure pattern on the film is this Fresnel zone plate,  concentric rings that get spaced closer together the farther you go away. In fact, you can be a little bit more quantitative  and write down the exact spacing between those fringes. Let's say you draw a line from a point on this film down to the object,  or maybe I should say down to where the object was during recording. Consider the angle between this line and the one perpendicular to the film,  which I'm going to call theta prime to distinguish it from  the diffraction angles we were just looking at. I won't narrate through all the details here,  but you can work out this fringe spacing exactly. You start with the premise that the distance between adjacent  fringes to the object should differ by one whole wavelength. I know some of you are curious and want to pause and ponder,  so I'll leave up the details, but the upshot is that it all boils down to a delightfully  clean and convenient fact. The spacing between the fringes for our Fresnel zone plate, which I'll label as D,  multiplied by the sine of this angle, theta prime, equals the wavelength of the light. This might give you a little dÃ©jÃ  vu, and if it strikes you as uncannily similar to the  diffraction equation, you are 100% right and it's the key to how our first hologram works. When you just shine the reference wave through this pattern,  near a given point on the film, it acts like a diffraction grating,  splitting the wave into distinct beams, and the angle of those first  order beams satisfies the diffraction equation, D times sine of theta equals lambda. Therefore, the angle of one of these first order beams exactly matches  the angle of the line connecting this point of the film to where the  object was during recording, even though the object isn't there anymore. So, critically, think about why this would imply  there's the illusion of a point behind the screen. For an observer on the other side of that film, as the reference wave is shining onto it,  every point of that film is emitting multiple different beams,  but one of those beams at each point matches what a beam from that  object dot would look like if that object dot were still there. So the observer always sees this bright spot on the glass at a point where  a line from their eye to the past object position intersects the glass. As they move their head around, and their eye moves in 3D space,  that apparent bright spot on the glass moves with them in just such a  way that it gives the illusion of a floating point of light behind that glass. The way things are set up right now, the other  beams would add some distraction for that observer. The zeroth order beam, for example, at all of these points is essentially a rescaled  version of what the reference wave would look like if the film weren't there. To the observer, this looks like a bright glow coming from everywhere behind the film. This would be pretty obnoxious, but it can be  solved by shining the reference beam in at an angle. You might be curious about the other first order beam, and it's actually very interesting. If you draw a line along that other first order beam from every point at the film,  all of those lines converge at a single point on the opposite side of the film. This is our first peek at a funny little artifact  of holography known as the conjugate image. Much earlier I said that the way you want to think about a hologram is that you're  trying to record and reconstruct the state of the light field around a scene. The truth is that a hologram doesn't exactly do this. What it actually recreates can be thought of as a sum of three different light waves. One of them is a scaled copy of the reference wave,  which for our simple point example corresponds to the zeroth order beam. Another corresponds to a copy of the wave emanating from the object. This is exactly the thing we want to reconstruct,  and in our simple example it corresponds to one of these first order beams,  but there's also a third wave in there. In this simple example of a hologram of a single point,  that third component looks like the reference beam being  concentrated in to a single reflection of that point through the film. More generally though, this third component looks like the reference beam being  refocused onto a reflected version of your full object on the opposite side of the film. In the hologram that we recorded with Craig and Sally,  you can actually see this by putting a piece of paper behind the glass,  where at the appropriate distance away, you see the light focused onto the shape of,  for example, the pie creature, which was part of the scene we recorded. This is known as the conjugate image. In the earliest days of holography, Dennis Gabor had a lot of  trouble seeing the holograms that he wanted to,  because this conjugate image kept getting in the way, muddying up the waters. However, again this is something where if you use a reference beam  that shines on the film at an angle, you can get a clean separation  of the reconstructed object wave from this conjugate wave artifact. The astute among you might ask about the higher order beams from a diffraction grating. After all, we saw how the equation doesn't just imply three beams for large enough  values of d, you can have many more angles that satisfy the diffraction equation. This is something I actually didn't know until learning about holography,  but if instead of a binary grating, where light either completely passes through or gets  completely blocked, you instead have a material that only partially allows light through  with an opacity that follows a sine wave pattern,  then you actually don't get higher order beams. The diffraction pattern only includes zeroth and first order beams. The most elegant way to show why, in my opinion,  comes from the more formal explanation of holograms that I want to show you in a few  minutes, but for right now just know that you're safe to only think about three beams  emanating from each point of the film. So, stepping back, you, the problem solver puzzling over holography,  have at least this one example to hold onto. A hologram of a single point gives a zone plate,  and the diffraction effect of shining the reference through the zone plate includes,  among other things, a recreation of the wave from that point. A natural place your mind might go from here is to wonder about two such points in space. Right here is a simulation for what the resulting exposure pattern would look like. It's based on adding the two radial waves from those points together with a reference  wave, and you can clearly tell that it's related to the zone plate associated with each  one, effectively encoding two distinct 3D positions,  but it is more complicated than simply adding the two individual patterns,  in the same way that the double slit interference is more complicated than simply adding  the brightness from each individual slit. The result depends on how the waves and their phases interfere. Even still, you can see how this might lead you to think about building up a scene  as a combination of multiple points, and hypothesizing that the resulting exposure  pattern can be thought of as some kind of combination of the zone plates for each one. The simulation I'm showing you has only 30 points,  and already the result effectively looks like random noise. But nevertheless, I think you would agree that a reasonable hypothesis would  be that the diffraction effect of shining a reference beam through this  pattern might be the sum of what you would get from the zone plates associated  with each individual point, and you know that looking through from the other  side of this film, it would give the illusion of those 30 points being there. If that were true, you could think of a more complicated object or more  complicated scene as a continuous cloud of many little points,  and the resulting pattern would not only encode the 3D position and orientation  of that object, but it would also enable the simple reconstruction that we're looking for. As stated so far, this is all sketchy and non-rigorous,  but it does actually lead you to some very real intuition about how holography  works in practice. Think back to the very start, when I asked you to appreciate  how much information is being stored on this film,  in that it can recreate a scene from a wide continuum of viewing angles. Part of the catch is that for this process to work,  the film has to have extremely high resolution. For comparison, standard Polaroid Instant Film  resolves only around 10 lines per millimeter. Microfilm will get you somewhere a little over 100 lines per millimeter,  but the film that we used to record this hologram can resolve many thousands of lines  per millimeter. And now you know why this is necessary. The spacing between fringes in a zone plate becomes very very narrow,  and faithfully recording those variations is necessary to reconstruct the object beam  at that point. Without the outer fringes, the effect for a viewer would be that they  simply don't see the object if they're viewing from a sharp angle. This is not a complete explanation without justifying how exactly the  exposure pattern that you get from multiple points would have a diffraction  effect that equals the sum of what you would get for the individual points. Even then, there's a deeper issue. Building up a scene from individual points would  not do true justice to the power of holography. The reason we included that glass Klein bottle in our example is to emphasize this power. That glass does not act as a collection of points, merely reflecting light. It affects the surrounding optics of the scene,  like how the light from the objects behind gets bent and distorted as it passes through. The hologram perfectly recreates this effect in a way  that could not be explained by adding up individual points. Anyone who has experience with ray tracing will appreciate the difference here. Also, the sharp-eyed viewers among you might have noticed  a couple gaps in the explanation even for a single point. For example, I mentioned shining in the reference beam at an angle,  but that would also change the exposure pattern,  so it's not entirely clear that the logic still works. Sometimes in math, a complex problem can be solved incrementally by building  up simple cases, but other times the simple cases act more like training exercises,  and the best way to tackle a general situation is to set up a new framework  for thinking about it, such that the general solution simply falls right out. In the case of studying holography, there is an entirely different and  more powerful way to explain holograms that subsumes all of these issues. I'll walk through it at the very end here as a kind of technical  appendix to the whole video, but I think it would be nice to wrap up  the main discussion by stepping back and discussing holograms more broadly. Everything we just described covers a transmission hologram,  the simplest variety, and these have been possible ever since the late 60s. More advanced techniques exist where the film can reproduce the scene not using a laser,  but with ordinary white light reflecting off of it. And it goes beyond that. There are techniques where you can make changes in the scene over time  visible as you view the hologram from different angles,  or where you can take a 3D computer graphics model and produce a hologram of it. You and I covered the bicycle, but people went on to cars and planes thereafter. In our example, we were modeling the film as a two-dimensional surface with no thickness,  and that's perfectly okay for transmission holograms,  but it's worth noting that that changes for white light reflection holograms. Variations in the exposure through the thickness of that film become  relevant for filtering out the appropriate wavelengths during reconstruction. The fact that Dennis Gabor won a Nobel Prize should give you some  hint that the significance here goes beyond its use as an art form. That clip that I showed earlier where we delicately touch the  object with a feather is displaying the original scene,  superimposed with its own hologram that we had just freshly recorded. The dark stripes that you see on the pie creature arise from the extremely  tiny shifts in position and how that affects the interference of the light. And you can actually use that to measure the size of those shifts. This gives a very small glimpse into the relevance that holograms have to interferometry,  which is the technique of using wave interference to measure extremely tiny distances. More broadly, being able to record and reproduce an entire wavefront  is just a useful tool to have in your belt for a variety of experiments. For any of you who want a deeper look at the history and development of  holography and physics, I highly recommend reading Gabor's Nobel Prize lecture. Throughout the lesson, I've repeatedly referenced the goal of making  holograms feel like something you could have invented yourself. But there's an irony here, because in his own reflections,  Gabor describes this not as a deliberate discovery. He called it, quote, an exercise in serendipity,  the art of looking for something and finding something else. But luck favors a prepared mind, and the more that you engage with imagined rediscovery  of the inventions that you find around you, the better moment of similar serendipity. And finally, for the stalwart viewers hungry for the final details,  here's the more formal description of why holography works. For the small price of introducing complex numbers into the discussion,  the result kind of just pops out from a few lines of algebra. So think about recording a hologram where you have both  a reference wave and an object wave shining on the film. We're going to write down the sum of those two waves as R plus O. The exposure pattern depends on the amplitude  of this combined wave at each point on the film. And like I said earlier, more precisely, it's  proportional to the square of that amplitude. Each of these symbols, say the object wave O, is meant to represent  a function that takes in a point in space, as well as a time,  and returns some real number value describing the strength of the point. It's an incredibly complicated function, but at a fixed point in space,  this output value simply oscillates up and down over time,  which we've been visualizing throughout as oscillations between blue and red. Very often, the math that you do with waves has a habit of becoming a  lot more elegant when you treat an oscillating value like this,  not merely as a real number, but as the real component of a rotating complex number. This might feel very strange if it's something you haven't seen before,  but one way to motivate why you might do this is that a complex number very  elegantly encodes both the phase and the amplitude of the wave at a snapshot in  space and time. The wave amplitude is visible as the size of this value, its distance from the origin,  and the phase is visible as the angle this number makes off the horizontal. The physical significance when you model things like this is just that the real  component of that rotating complex value tells you the strength of the wave at that point. But you might think of adding on an imaginary component like  this as sort of extra bookkeeping that lets you more readily  keep track of the phase and amplitude of the wave at that point. For example, the amplitude of that combined wave,  the thing we care about to describe the exposure,  can now be written as the magnitude of this sum, R plus O,  where now we're thinking of that as a sum between two complex values at every point on  the plane of the film. So for example, it places where those two values align,  that corresponds to constructive interference between the waves,  and the film is going to be more opaque. Where they are out of phase, you get a really small result,  and that corresponds to the film being more transparent. Now think about reconstruction when you just shine  the reference wave through this exposure pattern. Let's write the wave immediately on the other side of the  film as R times 1 minus the opacity at that point on the film. So for example, where the film is very transparent, R passes through unchanged,  but where it's more opaque, R is going to get scaled down. We can go ahead and substitute in the expression for opacity that we have,  and then distribute a little, and what I want to do is focus on analyzing this  component right here, which is going to be part of the wave on this other side of  the film. When you expand this expression and interpret its terms,  the truth of holography stares right back at you. To do so, what you need to know about complex numbers is one definition and one fact. The definition is that the complex conjugate of a number,  which you typically denote with a star, is its reflection over the horizontal axis. And the fact that you need is that when you multiply a number by its own  complex conjugate, the result is the square of the magnitude of that number. So in our expression, that exposure term could also be written as  R plus O multiplied by its own complex conjugate, R-star plus O-star. The reason to do this is now you have something you can expand algebraically,  although admittedly when you do this it might first look like a big pile of symbols  that is very far removed from physical intuition about reconstructing a three-dimensional  scene. But give it just a moment here. When you organize the terms the right way, the answer sort of pops out. Whenever you see a value multiplied by its own complex conjugate,  just think of it as some real number, some scaling factor. For example, one part in the final expression looks like  some certain real number all times R, the reference wave. And what this corresponds to is a scaled copy of that  reference wave here on the other side of the film. In our simple point example, that would correspond to the zeroth  order beam from the diffraction grating off the zone plate. The key term is this part right here. It looks like some real number, some scaling factor, multiplied by the object wave itself. So here you are on the other side of the film during reconstruction,  and the expression for the state of the light field includes this scaled copy of  the object wave. It doesn't matter how complicated O is, the scene that it  comes from could have whatever complicated optics that you want. But here on the other side of the film there will always be this scaled copy of o. In our simple point example, this corresponds to one of those first order beams. And finally, you have this funny little term at the end  that involves the complex conjugate of the object wave. This corresponds, as you can probably guess, to the conjugate image,  and maybe now the name makes a little bit more sense. This is a difficult term to make sense of, and I'm not going to say  too much more about it, other than to show that for the hologram we made,  if you flip the film around, you can see this conjugate image as a very bizarre,  warped, and reflected version of the original scene. So that is it. A little piece of complex algebra shows why you have  a copy of the object wave on the other side of the film. And importantly, there were no assumptions about how simple that object wave is. Also, it makes no assumptions about how simple the reference wave is. You just need to be able to reproduce the same wave that you used during recording,  or at least something close to it. Even though this is more powerful, on its own  I would find this explanation very unsatisfying. The breakdown of a single point with the zone plate pattern and diffraction gradings,  for all of its shortcomings, gives a lot more intuition in my opinion. For instance, the algebra tells you nothing about how the film resolution could matter,  but the abstract path and all the power that it brings does offer some reassurance  that the shortcomings in that first explanation are all surmountable. In his Nobel Prize lecture, Gabor wrote, in holography, nature is on the inventor's side. You do actually need to say a little bit more to finish the abstract derivation. Strictly speaking, we've only shown that you have a copy of this  object wave on the plane immediately after the film,  but what you want to show is that it exists in all of 3D space, beyond that film. Rigorously justifying this would go beyond the scope of an already long lesson,  but it's not too hard a fact to believe. What we're basically saying is that if you have some function that you know  satisfies whatever equations light must obey, namely the object wave O,  and you have another function describing a steady state wave where you know  that O shows up as a component along a 2D boundary like this,  then in the free space beyond that boundary, the wave must also include as a  component O in its entirety. This actually has a nice connection to the key mystery from the very beginning of  the lesson of how a three-dimensional scene could possibly be stored on 2D film. Part of what's required for this to be possible is that light  obeys laws regular enough that the state of a light wave in 3D  space is sufficiently constrained by its value on a 2D boundary.

================================================================================
VIDEO ID: 9-Jl0dxWQs8
TITLE: How might LLMs store facts | Deep Learning Chapter 7
URL: https://www.youtube.com/watch?v=9-Jl0dxWQs8
PUBLISHED: 2024-08-31T12:11:19Z
STATUS: SUCCESS
================================================================================
If you feed a large language model the phrase, Michael Jordan plays the sport of blank, and you have it predict what comes next, and it correctly predicts basketball, this would suggest that somewhere, inside its hundreds of billions of parameters, it's baked in knowledge about a specific person and his specific sport. And I think in general, anyone who's played around with one of these models has the clear sense that it's memorized tons and tons of facts. So a reasonable question you could ask is, how exactly does that work? And where do those facts live? Last December, a few researchers from Google DeepMind posted about work on this question, and they were using this specific example of matching athletes to their sports. And although a full mechanistic understanding of how facts are stored remains unsolved, they had some interesting partial results, including the very general high-level conclusion that the facts seem to live inside a specific part of these networks, known fancifully as the multi-layer perceptrons, or MLPs for short. In the last couple of chapters, you and I have been digging into the details behind transformers, the architecture underlying large language models, and also underlying a lot of other modern AI. In the most recent chapter, we were focusing on a piece called Attention. And the next step for you and me is to dig into the details of what happens inside these multi-layer perceptrons, which make up the other big portion of the network. The computation here is actually relatively simple, especially when you compare it to attention. It boils down essentially to a pair of matrix multiplications with a simple something in between. However, interpreting what these computations are doing is exceedingly challenging. Our main goal here is to step through the computations and make them memorable, but I'd like to do it in the context of showing a specific example of how one of these blocks could, at least in principle, store a concrete fact. Specifically, it'll be storing the fact that Michael Jordan plays basketball. I should mention the layout here is inspired by a conversation I had with one of those DeepMind researchers, Neil Nanda. For the most part, I will assume that you've either watched the last two chapters, or otherwise you have a basic sense for what a transformer is, but refreshers never hurt, so here's the quick reminder of the overall flow. You and I have been studying a model that's trained to take in a piece of text and predict what comes next. That input text is first broken into a bunch of tokens, which means little chunks that are typically words or little pieces of words, and each token is associated with a high-dimensional vector, which is to say a long list of numbers. This sequence of vectors then repeatedly passes through two kinds of operation, attention, which allows the vectors to pass information between one another, and then the multilayer perceptrons, the thing that we're gonna dig into today, and also there's a certain normalization step in between. After the sequence of vectors has flowed through many, many different iterations of both of these blocks, by the end, the hope is that each vector has soaked up enough information, both from the context, all of the other words in the input, and also from the general knowledge that was baked into the model weights through training, that it can be used to make a prediction of what token comes next. One of the key ideas that I want you to have in your mind is that all of these vectors live in a very, very high-dimensional space, and when you think about that space, different directions can encode different kinds of meaning. So a very classic example that I like to refer back to is how if you look at the embedding of woman and subtract the embedding of man, and you take that little step and you add it to another masculine noun, something like uncle, you land somewhere very, very close to the corresponding feminine noun. In this sense, this particular direction encodes gender information. The idea is that many other distinct directions in this super high-dimensional space could correspond to other features that the model might want to represent. In a transformer, these vectors don't merely encode the meaning of a single word, though. As they flow through the network, they imbibe a much richer meaning based on all the context around them, and also based on the model's knowledge. Ultimately, each one needs to encode something far, far beyond the meaning of a single word, since it needs to be sufficient to predict what will come next. We've already seen how attention blocks let you incorporate context, but a majority of the model parameters actually live inside the MLP blocks, and one thought for what they might be doing is that they offer extra capacity to store facts. Like I said, the lesson here is gonna center on the concrete toy example of how exactly it could store the fact that Michael Jordan plays basketball. Now, this toy example is gonna require that you and I make a couple of assumptions about that high-dimensional space. First, we'll suppose that one of the directions represents the idea of a first name Michael, and then another nearly perpendicular direction represents the idea of the last name Jordan, and then yet a third direction will represent the idea of basketball. So specifically, what I mean by this is if you look in the network and you pluck out one of the vectors being processed, if its dot product with this first name Michael direction is one, that's what it would mean for the vector to be encoding the idea of a person with that first name. Otherwise, that dot product would be zero or negative, meaning the vector doesn't really align with that direction. And for simplicity, let's completely ignore the very reasonable question of what it might mean if that dot product was bigger than one. Similarly, its dot product with these other directions would tell you whether it represents the last name Jordan or basketball. So let's say a vector is meant to represent the full name, Michael Jordan, then its dot product with both of these directions would have to be one. Since the text Michael Jordan spans two different tokens, this would also mean we have to assume that an earlier attention block has successfully passed information to the second of these two vectors so as to ensure that it can encode both names. With all of those as the assumptions, let's now dive into the meat of the lesson. What happens inside a multilayer perceptron? You might think of this sequence of vectors flowing into the block, and remember, each vector was originally associated with one of the tokens from the input text. What's gonna happen is that each individual vector from that sequence goes through a short series of operations, we'll unpack them in just a moment, and at the end, we'll get another vector with the same dimension. That other vector is gonna get added to the original one that flowed in, and that sum is the result flowing out. This sequence of operations is something you apply to every vector in the sequence, associated with every token in the input, and it all happens in parallel. In particular, the vectors don't talk to each other in this step, they're all kind of doing their own thing. And for you and me, that actually makes it a lot simpler, because it means if we understand what happens to just one of the vectors through this block, we effectively understand what happens to all of them. When I say this block is gonna encode the fact that Michael Jordan plays basketball, what I mean is that if a vector flows in that encodes first name Michael and last name Jordan, then this sequence of computations will produce something that includes that direction basketball, which is what will add on to the vector in that position. The first step of this process looks like multiplying that vector by a very big matrix. No surprises there, this is deep learning. And this matrix, like all of the other ones we've seen, is filled with model parameters that are learned from data, which you might think of as a bunch of knobs and dials that get tweaked and tuned to determine what the model behavior is. Now, one nice way to think about matrix multiplication is to imagine each row of that matrix as being its own vector, and taking a bunch of dot products between those rows and the vector being processed, which I'll label as E for embedding. For example, suppose that very first row happened to equal this first name Michael direction that we're presuming exists. That would mean that the first component in this output, this dot product right here, would be one if that vector encodes the first name Michael, and zero or negative otherwise. Even more fun, take a moment to think about what it would mean if that first row was this first name Michael plus last name Jordan direction. And for simplicity, let me go ahead and write that down as M plus J. Then, taking a dot product with this embedding E, things distribute really nicely, so it looks like M dot E plus J dot E. And notice how that means the ultimate value would be two if the vector encodes the full name Michael Jordan, and otherwise it would be one or something smaller than one. And that's just one row in this matrix. You might think of all of the other rows as in parallel asking some other kinds of questions, probing at some other sorts of features of the vector being processed. Very often this step also involves adding another vector to the output, which is full of model parameters learned from data. This other vector is known as the bias. For our example, I want you to imagine that the value of this bias in that very first component is negative one, meaning our final output looks like that relevant dot product, but minus one. You might very reasonably ask why I would want you to assume that the model has learned this, and in a moment you'll see why it's very clean and nice if we have a value here which is positive if and only if a vector encodes the full name Michael Jordan, and otherwise it's zero or negative. The total number of rows in this matrix, which is something like the number of questions being asked, in the case of GPT-3, whose numbers we've been following, is just under 50,000. In fact, it's exactly four times the number of dimensions in this embedding space. That's a design choice. You could make it more, you could make it less, but having a clean multiple tends to be friendly for hardware. Since this matrix full of weights maps us into a higher dimensional space, I'm gonna give it the shorthand W up. I'll continue labeling the vector we're processing as E, and let's label this bias vector as B up and put that all back down in the diagram. At this point, a problem is that this operation is purely linear, but language is a very non-linear process. If the entry that we're measuring is high for Michael plus Jordan, it would also necessarily be somewhat triggered by Michael plus Phelps and also Alexis plus Jordan, despite those being unrelated conceptually. What you really want is a simple yes or no for the full name. So the next step is to pass this large intermediate vector through a very simple non-linear function. A common choice is one that takes all of the negative values and maps them to zero and leaves all of the positive values unchanged. And continuing with the deep learning tradition of overly fancy names, this very simple function is often called the rectified linear unit, or ReLU for short. Here's what the graph looks like. So taking our imagined example where this first entry of the intermediate vector is one, if and only if the full name is Michael Jordan and zero or negative otherwise, after you pass it through the ReLU, you end up with a very clean value where all of the zero and negative values just get clipped to zero. So this output would be one for the full name Michael Jordan and zero otherwise. In other words, it very directly mimics the behavior of an AND gate. Often models will use a slightly modified function that's called the GELU, which has the same basic shape, it's just a bit smoother. But for our purposes, it's a little bit cleaner if we only think about the ReLU. Also, when you hear people refer to the neurons of a transformer, they're talking about these values right here. Whenever you see that common neural network picture with a layer of dots and a bunch of lines connecting to the previous layer, which we had earlier in this series, that's typically meant to convey this combination of a linear step, a matrix multiplication, followed by some simple term-wise nonlinear function like a ReLU. You would say that this neuron is active whenever this value is positive and that it's inactive if that value is zero. The next step looks very similar to the first one. You multiply by a very large matrix and you add on a certain bias term. In this case, the number of dimensions in the output is back down to the size of that embedding space, so I'm gonna go ahead and call this the down projection matrix. And this time, instead of thinking of things row by row, it's actually nicer to think of it column by column. You see, another way that you can hold matrix multiplication in your head is to imagine taking each column of the matrix and multiplying it by the corresponding term in the vector that it's processing and adding together all of those rescaled columns. The reason it's nicer to think about this way is because here the columns have the same dimension as the embedding space, so we can think of them as directions in that space. For instance, we will imagine that the model has learned to make that first column into this basketball direction that we suppose exists. What that would mean is that when the relevant neuron in that first position is active, we'll be adding this column to the final result. But if that neuron was inactive, if that number was zero, then this would have no effect. And it doesn't just have to be basketball. The model could also bake into this column and many other features that it wants to associate with something that has the full name Michael Jordan. And at the same time, all of the other columns in this matrix are telling you what will be added to the final result if the corresponding neuron is active. And if you have a bias in this case, it's something that you're just adding every single time, regardless of the neuron values. You might wonder what's that doing. As with all parameter-filled objects here, it's kind of hard to say exactly. Maybe there's some bookkeeping that the network needs to do, but you can feel free to ignore it for now. Making our notation a little more compact again, I'll call this big matrix W down and similarly call that bias vector B down and put that back into our diagram. Like I previewed earlier, what you do with this final result is add it to the vector that flowed into the block at that position and that gets you this final result. So for example, if the vector flowing in encoded both first name Michael and last name Jordan, then because this sequence of operations will trigger that AND gate, it will add on the basketball direction, so what pops out will encode all of those together. And remember, this is a process happening to every one of those vectors in parallel. In particular, taking the GPT-3 numbers, it means that this block doesn't just have 50,000 neurons in it, it has 50,000 times the number of tokens in the input. So that is the entire operation, two matrix products, each with a bias added and a simple clipping function in between. Any of you who watched the earlier videos of the series will recognize this structure as the most basic kind of neural network that we studied there. In that example, it was trained to recognize handwritten digits. Over here, in the context of a transformer for a large language model, this is one piece in a larger architecture and any attempt to interpret what exactly it's doing is heavily intertwined with the idea of encoding information into vectors of a high-dimensional embedding space. That is the core lesson, but I do wanna step back and reflect on two different things, the first of which is a kind of bookkeeping, and the second of which involves a very thought-provoking fact about higher dimensions that I actually didn't know until I dug into transformers. In the last two chapters, you and I started counting up the total number of parameters in GPT-3 and seeing exactly where they live, so let's quickly finish up the game here. I already mentioned how this up projection matrix has just under 50,000 rows and that each row matches the size of the embedding space, which for GPT-3 is 12,288. Multiplying those together, it gives us 604 million parameters just for that matrix, and the down projection has the same number of parameters just with a transposed shape. So together, they give about 1.2 billion parameters. The bias vector also accounts for a couple more parameters, but it's a trivial proportion of the total, so I'm not even gonna show it. In GPT-3, this sequence of embedding vectors flows through not one, but 96 distinct MLPs, so the total number of parameters devoted to all of these blocks adds up to about 116 billion. This is around 2 thirds of the total parameters in the network, and when you add it to everything that we had before, for the attention blocks, the embedding, and the unembedding, you do indeed get that grand total of 175 billion as advertised. It's probably worth mentioning there's another set of parameters associated with those normalization steps that this explanation has skipped over, but like the bias vector, they account for a very trivial proportion of the total. As to that second point of reflection, you might be wondering if this central toy example we've been spending so much time on reflects how facts are actually stored in real large language models. It is true that the rows of that first matrix can be thought of as directions in this embedding space, and that means the activation of each neuron tells you how much a given vector aligns with some specific direction. It's also true that the columns of that second matrix tell you what will be added to the result if that neuron is active. Both of those are just mathematical facts. However, the evidence does suggest that individual neurons very rarely represent a single clean feature like Michael Jordan, and there may actually be a very good reason this is the case, related to an idea floating around interpretability researchers these days known as superposition. This is a hypothesis that might help to explain both why the models are especially hard to interpret and also why they scale surprisingly well. The basic idea is that if you have an n-dimensional space and you wanna represent a bunch of different features using directions that are all perpendicular to one another in that space, you know, that way if you add a component in one direction, it doesn't influence any of the other directions, then the maximum number of vectors you can fit is only n, the number of dimensions. To a mathematician, actually, this is the definition of dimension. But where it gets interesting is if you relax that constraint a little bit and you tolerate some noise. Say you allow those features to be represented by vectors that aren't exactly perpendicular, they're just nearly perpendicular, maybe between 89 and 91 degrees apart. If we were in two or three dimensions, this makes no difference. That gives you hardly any extra wiggle room to fit more vectors in, which makes it all the more counterintuitive that for higher dimensions, the answer changes dramatically. I can give you a really quick and dirty illustration of this using some scrappy Python that's going to create a list of 100-dimensional vectors, each one initialized randomly, and this list is going to contain 10,000 distinct vectors, so 100 times as many vectors as there are dimensions. This plot right here shows the distribution of angles between pairs of these vectors. So because they started at random, those angles could be anything from 0 to 180 degrees, but you'll notice that already, even just for random vectors, there's this heavy bias for things to be closer to 90 degrees. Then what I'm going to do is run a certain optimization process that iteratively nudges all of these vectors so that they try to become more perpendicular to one another. After repeating this many different times, here's what the distribution of angles looks like. We have to actually zoom in on it here because all of the possible angles between pairs of vectors sit inside this narrow range between 89 and 91 degrees. In general, a consequence of something known as the Johnson-Lindenstrauss lemma is that the number of vectors you can cram into a space that are nearly perpendicular like this grows exponentially with the number of dimensions. This is very significant for large language models, which might benefit from associating independent ideas with nearly perpendicular directions. It means that it's possible for it to store many, many more ideas than there are dimensions in the space that it's allotted. This might partially explain why model performance seems to scale so well with size. A space that has 10 times as many dimensions can store way, way more than 10 times as many independent ideas. And this is relevant not just to that embedding space where the vectors flowing through the model live, but also to that vector full of neurons in the middle of that multilayer perceptron that we just studied. That is to say, at the sizes of GPT-3, it might not just be probing at 50,000 features, but if it instead leveraged this enormous added capacity by using nearly perpendicular directions of the space, it could be probing at many, many more features of the vector being processed. But if it was doing that, what it means is that individual features aren't gonna be visible as a single neuron lighting up. It would have to look like some specific combination of neurons instead, a superposition. For any of you curious to learn more, a key relevant search term here is sparse autoencoder, which is a tool that some of the interpretability people use to try to extract what the true features are, even if they're very superimposed on all these neurons. I'll link to a couple really great anthropic posts all about this. At this point, we haven't touched every detail of a transformer, but you and I have hit the most important points. The main thing that I wanna cover in a next chapter is the training process. On the one hand, the short answer for how training works is that it's all backpropagation, and we covered backpropagation in a separate context with earlier chapters in the series. But there is more to discuss, like the specific cost function used for language models, the idea of fine-tuning using reinforcement learning with human feedback, and the notion of scaling laws. Quick note for the active followers among you, there are a number of non-machine learning-related videos that I'm excited to sink my teeth into before I make that next chapter, so it might be a while, but I do promise it'll come in due time. Thank you.

================================================================================
VIDEO ID: rjVY7HXN6qA
TITLE: In the vector space of all advice...
URL: https://www.youtube.com/watch?v=rjVY7HXN6qA
PUBLISHED: 2024-05-22T17:56:07Z
STATUS: SUCCESS
================================================================================
and a common cliche is for someone who was lucky enough to land in a dream job to stand confidently in front of a group of fledgling graduates and to compel them to follow their dreams frankly on its own I don't think this is very good advice for one thing not everyone has a pre-baked dream sitting there waiting to be followed that's completely okay and even if you are one of the lucky ones who has a passion that you want to roll into a career I think there are a few pragmatic con conerns that don't always fit very neatly into an inspirational speech that are required to make this actually work now I know I'm talking to a very nerdy audience so I'm tempted to describe my aims here a little bit more mathematically precisely where in the vector space of all possible advice if you consider the follow your dreams Vector I want to explore its orthogonal Subspace maybe though it's better if I just start with a story

================================================================================
VIDEO ID: W3I3kAg2J7w
TITLE: What "Follow Your Dreams" Misses | Harvey Mudd Commencement Speech 2024
URL: https://www.youtube.com/watch?v=W3I3kAg2J7w
PUBLISHED: 2024-05-18T14:50:47Z
STATUS: SUCCESS
================================================================================
Last year, Grant gave the math department's Michael E. Moody lecture on where math and physics collide. He explored unexpected connections between kinematics, optics, and quantum computing. Our students loved his talk, and the senior class voted overwhelmingly to ask him back as commencement speaker. Grant has said that he seeks to educate and inspire the world with the beauty and the power of mathematics. He certainly has inspired many of us here at Harvey Mudd. Please join me in welcoming Grant Sanderson. Thank you President Nempahrd for that very warm introduction and for inviting me. And thank you to the class of 2024 for including me in such a special day. I had the joy of getting to know many of you last year on this visit. And I distinctly remember coming away with the feeling that a future in your hands is a bright future indeed. For those in the audience who don't know who I am, I focus on making videos about mathematics with an emphasis on visualizations. It's a weird job. I do love it though, and it's no exaggeration to describe it as a dream job. And a common clichÃ© is for someone who is lucky enough to land in a dream job, to stand confidently in front of a group of fledgling graduates, and to compel them to follow their dreams. Frankly, on its own, I don't think this is very good advice. To be clear, there is truth behind the clichÃ©. It is true that those who make the biggest ripples are the ones who are fueled by passion. It is true that the life that you live is much more enjoyable if you can find something doing what you love. And it's also true that you shouldn't feel shackled by societal constraints. But for one thing, not everyone has a pre-baked dream sitting there waiting to be followed. That's completely okay. And even if you are one of the lucky ones who has a passion that you want to roll into a career, I think there are a few pragmatic concerns that don't always fit very neatly into an inspirational speech that are required to make this actually work. Now, I know I'm talking to a very nerdy audience, so I'm tempted to describe my aims here a little bit more mathematically precisely, where in the vector space of all possible advice, if you consider the follow your dreams vector, I want to explore its orthogonal subspace. Maybe though, it's better if I just start with a story. Before I entered college, I was one of those who knew what I wanted to major in. There's no surprises here, it was math. This was a topic that I had loved for a long time, as long as I can remember. When I was in college, I was plenty seduced by the adjacent field of computer science and programming, and I would spend my summers interning at software startups. But I distinctly remember coming back at the end of each of those summers and thinking, man, you know what I really want to do with my life, is spend more time doing math. So I had a passion, I had something I would want to follow. But in hindsight, that passion was a lot more arbitrary and maybe a little more self-centered than I would have liked to admit at the time. Why did I love math? You know, if I'm honest, I think it had its roots in the fact that when I was young, the adults emphasized this is an important topic to learn, and they told me I was good at it. This makes me spend more time with it. Spending time with something is how you get better at something, and that kicks off a positive feedback loop, in both senses of the word positive feedback. Now, as time went on, I do believe it became less about perceptions when I was in college. I remember genuinely enjoying the aesthetic delights that beautiful math problem solving has to have. But thinking of it as a career ambition, not just a hobby, this had the fatal flaw that I was viewing the world through a lens of what I personally enjoyed, not giving enough weight to a plan for how exactly it would add value to others. I don't know if you felt it yet, but today marks a day in your life when a fundamental goal changes. When you're a student, the fundamental goal is to grow, to learn, to become better. So many institutions and structures around you are there to support you in growing and learning and getting better and to reward you for doing so. In life after college, the goal changes a little, and success hinges on how effectively you're able to add value to others. Now, these aren't at odds with each other. In fact, they go hand in hand. You're much better positioned to make a difference if you're armed with an expertise and if you spend your life honing that expertise. But there is a big difference between personal growth being the end in and of itself versus being a means to an end. By way of comparison, I also loved the violin when I was growing up. And let's take a moment to imagine two distinct music students. I'm going to name them Paganini and Taylor. Both of them are talented, very talented, but Paganini pushes for technical excellence. He tries to perfect virtuosically challenging pieces. Taylor strives to write music that speaks to people, that resonates with them emotionally. Now, in a music school, Paganini is going to get the better grades every time. He's always going to get the better position. But pursuing music careers, Taylor is at the clear advantage. My first piece of advice, something I would have told myself I could go back in time and be in the seat where you are now, is that if you have a passion that you want to incorporate into a career, take a step back and recognize the fact that this is a passion that grew in a time of your life when the goal was to learn and to grow. But you're transitioning to a period when the primary aim shifts to adding value to others. The clichÃ© to follow your dreams overlooks how critical it is that the dreams you have are about something more than just yourself. Those who excel in their first jobs are the ones who make life easier for everyone around them, even when it involves doing things they don't love. Those who excel in PhD programs are the ones who recognize how their work fits into a broader research community, not just the ones who view it as the next chapter in school. The successful entrepreneurs are the ones who have a relentless focus on making sure that what they have to sell is what people want to buy, not just those who are looking to make something impressive. Now, for some people when you hear the words follow your dreams, it falls flat because you don't have a defining passion. Like I said earlier, that's completely okay. If anything, it might put you at an advantage. I think you'll do just as well if you start by seeking out opportunities where the skills that you've developed here intersect with adding values to others. And from there, I promise the passion will follow. One of the best pieces of advice I remember receiving from a friend many years ago is that action precedes motivation. This is often useful on a much smaller scale. We feel most awake after getting out of bed, not before. A drive to exercise comes from the habit of exercising. It doesn't go the other way around. But I think the idea that action precedes motivation applies to this bigger question of finding a career doing what you love. These days, I do love making videos, and I really do love teaching. But when I was finishing college, I had no penchant or experience with videos at all. And my interest in teaching was honestly only insofar as it scratched this itch to do more math. It was only by stumbling into a wacky career where I was doing both of them that I came to love them. Now, in my own story, what happened after college involves a fair bit of luck, but luck can come in a lot of different forms. And I think with a little bit of foresight, you can actually avoid having to rely on chance in quite the same way. There's a post I like on the webcomic XKCD that shows a man standing on a stage, and he has bags of cash surrounding him. Never stop buying lottery tickets, he says. No matter what people tell you, I failed again and again, but I never gave up, and here I am as proof that if you put in the time, it pays off. The caption notes that every inspirational speech should come with a disclaimer about survivorship bias. The obvious way that Follow Your Dreams is susceptible to survivorship bias is that for all of the high-risk, high-reward paths, things like professional athletics, starting a social media company, making a career in the arts, it's only the few who rise to the top who are in a position to give advice at all. But there's also a more subtle way that survivorship bias applies here. It's not just about the odds of winning a particular game. It has to do with whether the game you choose to play meshes well with the way that the future unfolds. If you were a software enthusiast in the late 1980s, you would be well poised to ride the dot-com boom in the decade that followed. If you were someone with a niche interest and an act for film production, you would find yourself with an unexpected opportunity when YouTube and other film-sharing platforms started to rise in prominence. When I was finishing my undergrad, one of these ways that I scratched that itch to do more math was to hack together a very rudimentary Python library for making math visualizations, and I used it to make a couple videos about neat proofs and problems that I enjoyed and posting them online. I was not planning for this to be a career. I had an appreciation for how valuable personal projects are, but it didn't go much beyond that. This led to conversations with Khan Academy, a group I had great respect for, and it turned into a job there, making more lessons online. In the meantime, I continued my own channel as a side hobby, and it didn't blow up, but there was a very modest growth of others who enjoyed the same kind of visualizations that I did, and I saw it in just a steady take-up in the audience size. Now, my original plan, I think, was to spend a year or two doing this online education stuff, working at Khan Academy, and maybe returning to do a PhD. But as time went on, something between the gratitude that I saw from many students around the planet for the lessons I put out and the slow and steady growth on my own channel led me to doubling down and forming a somewhat unorthodox career in online lessons and math visualization. Now, looking back, it would feel very incomplete if I were to somehow ascribe the success that I found to the extent there was any to the fact that I was following a dream, pursuing a passion. Passion plays into it. You can't have good lessons without a teacher who cares, but we can't ignore the other factors at play. I already brought up the biggest one, success is a function of the value you bring to others, so a pursuit equally fueled by love, but which did nothing to help or to entertain people just wouldn't have had a chance to work. But another factor I want to focus on is how I was very lucky with the timing. If I had been born 10 years earlier, I don't think I could have reached the same number of people posting lessons on a much more infant version of the internet, where there was less infrastructure that could have existed to help form a career doing so. If I had started 10 years later, the space would have been a lot more saturated. So another piece of advice that I'd like to offer, another little ingredient that makes following your dreams a little more likely to work out is to ask yourself what's possible now that wasn't possible 10 years ago and which might get harder 10 years from now. There are more opportunities in a less crowded landscape. There are more chances to grow if you're part of a rising tide, but this requires pushing past the inevitable discomfort that comes from following a path that has little to no precedent. Now next, I want to take a moment to talk about whose dreams you should be thinking about, because it's not just your own. When I was visiting Harvey Mudd last year, I had the pleasure of talking to one of the gems in your math department, Talithia Williams, and I asked her, hey, what made you pursue math in the first place? She had a very clear story. She told me she hadn't thought about it very much until one distinct day in her high school calculus class, her teacher, Mr. Dorman, pulled her aside and said, Talithia, you're really good at this. You should consider majoring in math. Evidently, she had never thought about it before, but that one comment was enough to knock over the first in a series of dominoes that led to a very flourishing career in the topic. Over the years, I've asked a lot of mathematicians the same question, and you would be shocked how often I hear a very similar answer. There was this one particular teacher, and one seemingly simple thing that they did, that was the beginning in a long series of encouragements. Never underestimate just how much influence you can have on others, especially the ones who are younger than you are. Growing older is a process of slowly seeing the proportion of people around you who are younger than you are rise inexorably closer to 100%. As this happens, you stand to have as much influence by shaping the dreams of those behind you as you do by following those of your own. And as a very last point, the biggest risk in the follow your dreams clichÃ© is the implication that there's one static target point at all. In the next 10, 20, 30 years, the world around you is going to change a lot, and those changes are going to be unpredictable. I hardly need to emphasize this point. You are the class who spent your formative transition from high school to college under a pandemic. But it's not just the world around you. Tonight, when you're celebrating your graduation and hopefully remembering to celebrate Mother's Day as well, take a few moments to ask the people who are older than you how they've changed, how their personalities, how their value systems have changed since they were a student. You'll notice that essentially all of them has an answer, which suggests you have every reason to expect that there's going to be something fundamental about you that changes as well in the coming decades, probably unpredictably. Almost everyone I know has undergone some kind of shift since college. Some came to place more value on having a family than they used to. Some shifted from a trajectory that was oriented towards an academic career to going into industry. Some went the other way around and after spending some time in industry returned to grad school. And so, so many of them have jobs that simply didn't exist at the time of their graduation. So rather than having any one particular goal that defines who you are, you'll take better advantage of whatever the future has to offer you if you remain nimble and if you're responsive to the changes in the world and if you anticipate change within yourself. My final piece of advice is to not treat passion as something to follow. Think of it as an initial velocity vector. It gives a clear direction to point yourself and loving what you do can have you move quickly. But you should expect and you should even hope that the specific direction that you're moving changes based on the force vectors around you. Now in these unpredictable decades that come, your generation is the one that holds more sway than any other over how it unfolds. And you, the graduating class of Harvey Mudd, represent some of the most talented and thoughtful minds in that generation. Influence is not distributed uniformly in the population and I for one would feel a lot more comfortable if it was you who were at the helm guiding this crazy ship that we're all riding. If you step into the next chapter of life with an implacable focus on adding values to others, you're more likely to be the ones at the helm. If you recognize that action precedes motivation, you're more likely to be at the helm. And if you ask what's possible now that wasn't 10 years ago, you're more likely to be at the helm. If you appreciate just how much power you have to shape the lives of the generation that follows you, you're more likely to be at the helm. And if you remain adaptable to a changing world, treating passion not as a destination but as a fuel, following not dreams but opportunities, you're more likely to be at the helm. One final time, would everyone please join me in congratulating the class of 2024 on what they've done to get here and make some noise to let them know how excited we are to see where they go from here.

================================================================================
VIDEO ID: XsLK3tPy9SI
TITLE: Temperature in LLMs
URL: https://www.youtube.com/watch?v=XsLK3tPy9SI
PUBLISHED: 2024-04-28T15:22:38Z
STATUS: SUCCESS
================================================================================
when a large language model generates text there's a parameter that can be set called temperature which in a manner of speaking controls how creative it is to understand temperature you first have to understand that large language models are originally trained to take in a passage of text and predict what word or other common character combination comes next this prediction looks like some kind of probability distribution when these models generate new text what's going on is that a full context describing the interaction is input into the model the model predicts what word comes next it takes a random sample from the distribution that it generates it appends that random choice to the full context and then it runs it all again on this extended text and so on and so on over and over the temperature is a way to modify the probability distributions that it generates if you set a high temperature it gives more weight to the less likely Words which essentially gives the model a better chance of selecting unusual phrases and ideas whereas a low temperature makes it more likely to choose the most predictable words

================================================================================
VIDEO ID: FJtFZwbvkI4
TITLE: How word vectors encode meaning
URL: https://www.youtube.com/watch?v=FJtFZwbvkI4
PUBLISHED: 2024-04-11T16:23:26Z
STATUS: SUCCESS
================================================================================
What is Hitler plus Italy minus Germany? This came up in a full video that I did dissecting  what happens inside large language models. You see, when tools like Chachipt process text,  the first thing they do is subdivide it into little pieces,  and they associate each piece with a large vector, some long list of numbers. This is called an embedding of that piece of text,  and it's helpful to imagine these embedding vectors as directions in some very  high dimensional space, even if we struggle to concretely visualize anything  more than three dimensions. Models that learn to embed words as vectors like this often  encode meaning into the directions of this high dimensional space. If you take the difference between the embeddings of man and woman and you add that  to the embedding of uncle, you get a vector very close to the embedding of aunt. If you take the embedding of Italy minus Germany and you add it to the  embedding of Hitler, you get something very close to the embedding of Mussolini. It's as if the model learned to associate some directions in this high  dimensional space with Italian-ness, and others with World War II axis leaders.

================================================================================
VIDEO ID: eMlx5fFNoYc
TITLE: Attention in transformers, step-by-step | Deep Learning Chapter 6
URL: https://www.youtube.com/watch?v=eMlx5fFNoYc
PUBLISHED: 2024-04-07T12:53:54Z
STATUS: SUCCESS
================================================================================
In the last chapter, you and I started to step through the internal workings of a transformer. This is one of the key pieces of technology inside large language models, and a lot of other tools in the modern wave of AI. It first hit the scene in a now-famous 2017 paper called Attention is All You Need, and in this chapter you and I will dig into what this attention mechanism is, visualizing how it processes data. As a quick recap, here's the important context I want you to have in mind. The goal of the model that you and I are studying is to take in a piece of text and predict what word comes next. The input text is broken up into little pieces that we call tokens, and these are very often words or pieces of words, but just to make the examples in this video easier for you and me to think about, let's simplify by pretending that tokens are always just words. The first step in a transformer is to associate each token with a high-dimensional vector, what we call its embedding. The most important idea I want you to have in mind is how directions in this high-dimensional space of all possible embeddings can correspond with semantic meaning. In the last chapter we saw an example for how direction can correspond to gender, in the sense that adding a certain step in this space can take you from the embedding of a masculine noun to the embedding of the corresponding feminine noun. That's just one example you could imagine how many other directions in this high-dimensional space could correspond to numerous other aspects of a word's meaning. The aim of a transformer is to progressively adjust these embeddings so that they don't merely encode an individual word, but instead they bake in some much, much richer contextual meaning. I should say up front that a lot of people find the attention mechanism, this key piece in a transformer, very confusing, so don't worry if it takes some time for things to sink in. I think that before we dive into the computational details and all the matrix multiplications, it's worth thinking about a couple examples for the kind of behavior that we want attention to enable. Consider the phrases American shrew mole, one mole of carbon dioxide, and take a biopsy of the mole. You and I know that the word mole has different meanings in each one of these, based on the context. But after the first step of a transformer, the one that breaks up the text and associates each token with a vector, the vector that's associated with mole would be the same in all of these cases, because this initial token embedding is effectively a lookup table with no reference to the context. It's only in the next step of the transformer that the surrounding embeddings have the chance to pass information into this one. The picture you might have in mind is that there are multiple distinct directions in this embedding space encoding the multiple distinct meanings of the word mole, and that a well-trained attention block calculates what you need to add to the generic embedding to move it to one of these specific directions, as a function of the context. To take another example, consider the embedding of the word tower. This is presumably some very generic, non-specific direction in the space, associated with lots of other large, tall nouns. If this word was immediately preceded by Eiffel, you could imagine wanting the mechanism to update this vector so that it points in a direction that more specifically encodes the Eiffel tower, maybe correlated with vectors associated with Paris and France and things made of steel. If it was also preceded by the word miniature, then the vector should be updated even further, so that it no longer correlates with large, tall things. More generally than just refining the meaning of a word, the attention block allows the model to move information encoded in one embedding to that of another, potentially ones that are quite far away, and potentially with information that's much richer than just a single word. What we saw in the last chapter was how after all of the vectors flow through the network, including many different attention blocks, the computation you perform to produce a prediction of the next token is entirely a function of the last vector in the sequence. Imagine, for example, that the text you input is most of an entire mystery novel, all the way up to a point near the end, which reads, therefore the murderer was. If the model is going to accurately predict the next word, that final vector in the sequence, which began its life simply embedding the word was, will have to have been updated by all of the attention blocks to represent much, much more than any individual word, somehow encoding all of the information from the full context window that's relevant to predicting the next word. To step through the computations, though, let's take a much simpler example. Imagine that the input includes the phrase, a fluffy blue creature roamed the verdant forest. And for the moment, suppose that the only type of update that we care about is having the adjectives adjust the meanings of their corresponding nouns. What I'm about to describe is what we would call a single head of attention, and later we will see how the attention block consists of many different heads run in parallel. Again, the initial embedding for each word is some high dimensional vector that only encodes the meaning of that particular word with no context. Actually, that's not quite true. They also encode the position of the word. There's a lot more to say about the specific way that positions are encoded, but right now, all you need to know is that the entries of this vector are enough to tell you both what the word is and where it exists in the context. Let's go ahead and denote these embeddings with the letter e. The goal is to have a series of computations produce a new refined set of embeddings where, for example, those corresponding to the nouns have ingested the meaning from their corresponding adjectives. And playing the deep learning game, we want most of the computations involved to look like matrix-vector products, where the matrices are full of tuneable weights, things that the model will learn based on data. To be clear, I'm making up this example of adjectives updating nouns just to illustrate the type of behavior that you could imagine an attention head doing. As with so much deep learning, the true behavior is much harder to parse because it's based on tweaking and tuning a huge number of parameters to minimize some cost function. It's just that as we step through all of different matrices filled with parameters that are involved in this process, I think it's really helpful to have an imagined example of something that it could be doing to help keep it all more concrete. For the first step of this process, you might imagine each noun, like creature, asking the question, hey, are there any adjectives sitting in front of me? And for the words fluffy and blue, to each be able to answer, yeah, I'm an adjective and I'm in that position. That question is somehow encoded as yet another vector, another list of numbers, which we call the query for this word. This query vector though has a much smaller dimension than the embedding vector, say 128. Computing this query looks like taking a certain matrix, which I'll label wq, and multiplying it by the embedding. Compressing things a bit, let's write that query vector as q, and then anytime you see me put a matrix next to an arrow like this one, it's meant to represent that multiplying this matrix by the vector at the arrow's start gives you the vector at the arrow's end. In this case, you multiply this matrix by all of the embeddings in the context, producing one query vector for each token. The entries of this matrix are parameters of the model, which means the true behavior is learned from data, and in practice, what this matrix does in a particular attention head is challenging to parse. But for our sake, imagining an example that we might hope that it would learn, we'll suppose that this query matrix maps the embeddings of nouns to certain directions in this smaller query space that somehow encodes the notion of looking for adjectives in preceding positions. As to what it does to other embeddings, who knows? Maybe it simultaneously tries to accomplish some other goal with those. Right now, we're laser focused on the nouns. At the same time, associated with this is a second matrix called the key matrix, which you also multiply by every one of the embeddings. This produces a second sequence of vectors that we call the keys. Conceptually, you want to think of the keys as potentially answering the queries. This key matrix is also full of tuneable parameters, and just like the query matrix, it maps the embedding vectors to that same smaller dimensional space. You think of the keys as matching the queries whenever they closely align with each other. In our example, you would imagine that the key matrix maps the adjectives like fluffy and blue to vectors that are closely aligned with the query produced by the word creature. To measure how well each key matches each query, you compute a dot product between each possible key-query pair. I like to visualize a grid full of a bunch of dots, where the bigger dots correspond to the larger dot products, the places where the keys and queries align. For our adjective noun example, that would look a little more like this, where if the keys produced by fluffy and blue really do align closely with the query produced by creature, then the dot products in these two spots would be some large positive numbers. In the lingo, machine learning people would say that this means the embeddings of fluffy and blue attend to the embedding of creature. By contrast to the dot product between the key for some other word like the and the query for creature would be some small or negative value that reflects that are unrelated to each other. So we have this grid of values that can be any real number from negative infinity to infinity, giving us a score for how relevant each word is to updating the meaning of every other word. The way we're about to use these scores is to take a certain weighted sum along each column, weighted by the relevance. So instead of having values range from negative infinity to infinity, what we want is for the numbers in these columns to be between 0 and 1, and for each column to add up to 1, as if they were a probability distribution. If you're coming in from the last chapter, you know what we need to do then. We compute a softmax along each one of these columns to normalize the values. In our picture, after you apply softmax to all of the columns, we'll fill in the grid with these normalized values. At this point you're safe to think about each column as giving weights according to how relevant the word on the left is to the corresponding value at the top. We call this grid an attention pattern. Now if you look at the original transformer paper, there's a really compact way that they write this all down. Here the variables q and k represent the full arrays of query and key vectors respectively, those little vectors you get by multiplying the embeddings by the query and the key matrices. This expression up in the numerator is a really compact way to represent the grid of all possible dot products between pairs of keys and queries. A small technical detail that I didn't mention is that for numerical stability, it happens to be helpful to divide all of these values by the square root of the dimension in that key query space. Then this softmax that's wrapped around the full expression is meant to be understood to apply column by column. As to that v term, we'll talk about it in just a second. Before that, there's one other technical detail that so far I've skipped. During the training process, when you run this model on a given text example, and all of the weights are slightly adjusted and tuned to either reward or punish it based on how high a probability it assigns to the true next word in the passage, it turns out to make the whole training process a lot more efficient if you simultaneously have it predict every possible next token following each initial subsequence of tokens in this passage. For example, with the phrase that we've been focusing on, it might also be predicting what words follow creature and what words follow the. This is really nice, because it means what would otherwise be a single training example effectively acts as many. For the purposes of our attention pattern, it means that you never want to allow later words to influence earlier words, since otherwise they could kind of give away the answer for what comes next. What this means is that we want all of these spots here, the ones representing later tokens influencing earlier ones, to somehow be forced to be zero. The simplest thing you might think to do is to set them equal to zero, but if you did that the columns wouldn't add up to one anymore, they wouldn't be normalized. So instead, a common way to do this is that before applying softmax, you set all of those entries to be negative infinity. If you do that, then after applying softmax, all of those get turned into zero, but the columns stay normalized. This process is called masking. There are versions of attention where you don't apply it, but in our GPT example, even though this is more relevant during the training phase than it would be, say, running it as a chatbot or something like that, you do always apply this masking to prevent later tokens from influencing earlier ones. Another fact that's worth reflecting on about this attention pattern is how its size is equal to the square of the context size. So this is why context size can be a really huge bottleneck for large language models, and scaling it up is non-trivial. As you imagine, motivated by a desire for bigger and bigger context windows, recent years have seen some variations to the attention mechanism aimed at making context more scalable, but right here, you and I are staying focused on the basics. Okay, great, computing this pattern lets the model deduce which words are relevant to which other words. Now you need to actually update the embeddings, allowing words to pass information to whichever other words they're relevant to. For example, you want the embedding of Fluffy to somehow cause a change to Creature that moves it to a different part of this 12,000-dimensional embedding space that more specifically encodes a Fluffy creature. What I'm going to do here is first show you the most straightforward way that you could do this, though there's a slight way that this gets modified in the context of multi-headed attention. This most straightforward way would be to use a third matrix, what we call the value matrix, which you multiply by the embedding of that first word, for example Fluffy. The result of this is what you would call a value vector, and this is something that you add to the embedding of the second word, in this case something you add to the embedding of Creature. So this value vector lives in the same very high-dimensional space as the embeddings. When you multiply this value matrix by the embedding of a word, you might think of it as saying, if this word is relevant to adjusting the meaning of something else, what exactly should be added to the embedding of that something else in order to reflect this? Looking back in our diagram, let's set aside all of the keys and the queries, since after you compute the attention pattern you're done with those, then you're going to take this value matrix and multiply it by every one of those embeddings to produce a sequence of value vectors. You might think of these value vectors as being kind of associated with the corresponding keys. For each column in this diagram, you multiply each of the value vectors by the corresponding weight in that column. For example here, under the embedding of Creature, you would be adding large proportions of the value vectors for Fluffy and Blue, while all of the other value vectors get zeroed out, or at least nearly zeroed out. And then finally, the way to actually update the embedding associated with this column, previously encoding some context-free meaning of Creature, you add together all of these rescaled values in the column, producing a change that you want to add, that I'll label delta-e, and then you add that to the original embedding. Hopefully what results is a more refined vector encoding the more contextually rich meaning, like that of a fluffy blue creature. And of course you don't just do this to one embedding, you apply the same weighted sum across all of the columns in this picture, producing a sequence of changes, adding all of those changes to the corresponding embeddings, produces a full sequence of more refined embeddings popping out of the attention block. Zooming out, this whole process is what you would describe as a single head of attention. As I've described things so far, this process is parameterized by three distinct matrices, all filled with tunable parameters, the key, the query, and the value. I want to take a moment to continue what we started in the last chapter, with the scorekeeping where we count up the total number of model parameters using the numbers from GPT-3. These key and query matrices each have 12,288 columns, matching the embedding dimension, and 128 rows, matching the dimension of that smaller key query space. This gives us an additional 1.5 million or so parameters for each one. If you look at that value matrix by contrast, the way I've described things so far would suggest that it's a square matrix that has 12,288 columns and 12,288 rows, since both its inputs and outputs live in this very large embedding space. If true, that would mean about 150 million added parameters. And to be clear, you could do that. You could devote orders of magnitude more parameters to the value map than to the key and query. But in practice, it is much more efficient if instead you make it so that the number of parameters devoted to this value map is the same as the number devoted to the key and the query. This is especially relevant in the setting of running multiple attention heads in parallel. The way this looks is that the value map is factored as a product of two smaller matrices. Conceptually, I would still encourage you to think about the overall linear map, one with inputs and outputs, both in this larger embedding space, for example taking the embedding of blue to this blueness direction that you would add to nouns. It's just that it's broken up into two separate steps. What this means is you can think of it as mapping the large embedding vectors down to a much smaller space. This is not the conventional naming, but I'm going to call this the value down matrix. The second matrix maps from this smaller space back up to the embedding space, producing the vectors that you use to make the actual updates. I'm going to call this one the value up matrix, which again is not conventional. The way that you would see this written in most papers looks a little different. I'll talk about it in a minute. In my opinion, it tends to make things a little more conceptually confusing. To throw in linear algebra jargon here, what we're basically doing is constraining the overall value map to be a low rank transformation. Turning back to the parameter count, all four of these matrices have the same size, and adding them all up we get about 6.3 million parameters for one attention head. As a quick side note, to be a little more accurate, everything described so far is what people would call a self-attention head, to distinguish it from a variation that comes up in other models that's called cross-attention. This isn't relevant to our GPT example, but if you're curious, cross-attention involves models that process two distinct types of data, like text in one language and text in another language that's part of an ongoing generation of a translation, or maybe audio input of speech and an ongoing transcription. A cross-attention head looks almost identical. The only difference is that the key and query maps act on different data sets. In a model doing translation, for example, the keys might come from one language, while the queries come from another, and the attention pattern could describe which words from one language correspond to which words in another. And in this setting there would typically be no masking, since there's not really any notion of later tokens affecting earlier ones. Staying focused on self-attention though, if you understood everything so far, and if you were to stop here, you would come away with the essence of what attention really is. All that's really left to us is to lay out the sense in which you do this many many different times. In our central example we focused on adjectives updating nouns, but of course there are lots of different ways that context can influence the meaning of a word. If the words they crashed the preceded the word car, it has implications for the shape and structure of that car. And a lot of associations might be less grammatical. If the word wizard is anywhere in the same passage as Harry, it suggests that this might be referring to Harry Potter, whereas if instead the words Queen, Sussex, and William were in that passage, then perhaps the embedding of Harry should instead be updated to refer to the prince. For every different type of contextual updating that you might imagine, the parameters of these key and query matrices would be different to capture the different attention patterns, and the parameters of our value map would be different based on what should be added to the embeddings. And again, in practice the true behavior of these maps is much more difficult to interpret, where the weights are set to do whatever the model needs them to do to best accomplish its goal of predicting the next token. As I said before, everything we described is a single head of attention, and a full attention block inside a transformer consists of what's called multi-headed attention, where you run a lot of these operations in parallel, each with its own distinct key query and value maps. GPT-3 for example uses 96 attention heads inside each block. Considering that each one is already a bit confusing, it's certainly a lot to hold in your head. Just to spell it all out very explicitly, this means you have 96 distinct key and query matrices producing 96 distinct attention patterns. Then each head has its own distinct value matrices used to produce 96 sequences of value vectors. These are all added together using the corresponding attention patterns as weights. What this means is that for each position in the context, each token, every one of these heads produces a proposed change to be added to the embedding in that position. So what you do is you sum together all of those proposed changes, one for each head, and you add the result to the original embedding of that position. This entire sum here would be one slice of what's outputted from this multi-headed attention block, a single one of those refined embeddings that pops out the other end of it. Again, this is a lot to think about, so don't worry at all if it takes some time to sink in. The overall idea is that by running many distinct heads in parallel, you're giving the model the capacity to learn many distinct ways that context changes meaning. Pulling up our running tally for parameter count with 96 heads, each including its own variation of these four matrices, each block of multi-headed attention ends up with around 600 million parameters. There's one added slightly annoying thing that I should really mention for any of you who go on to read more about transformers. You remember how I said that the value map is factored out into these two distinct matrices, which I labeled as the value down and the value up matrices. The way that I framed things would suggest that you see this pair of matrices inside each attention head, and you could absolutely implement it this way. That would be a valid design. But the way that you see this written in papers and the way that it's implemented in practice looks a little different. All of these value up matrices for each head appear stapled together in one giant matrix that we call the output matrix, associated with the entire multi-headed attention block. And when you see people refer to the value matrix for a given attention head, they're typically only referring to this first step, the one that I was labeling as the value down projection into the smaller space. For the curious among you, I've left an on-screen note about it. It's one of those details that runs the risk of distracting from the main conceptual points, but I do want to call it out just so that you know if you read about this in other sources. Setting aside all the technical nuances, in the preview from the last chapter we saw how data flowing through a transformer doesn't just flow through a single attention block. For one thing, it also goes through these other operations called multi-layer perceptrons. We'll talk more about those in the next chapter. And then it repeatedly goes through many many copies of both of these operations. What this means is that after a given word imbibes some of its context, there are many more chances for this more nuanced embedding to be influenced by its more nuanced surroundings. The further down the network you go, with each embedding taking in more and more meaning from all the other embeddings, which themselves are getting more and more nuanced, the hope is that there's the capacity to encode higher level and more abstract ideas about a given input beyond just descriptors and grammatical structure. Things like sentiment and tone and whether it's a poem and what underlying scientific truths are relevant to the piece and things like that. Turning back one more time to our scorekeeping, GPT-3 includes 96 distinct layers, so the total number of key query and value parameters is multiplied by another 96, which brings the total sum to just under 58 billion distinct parameters devoted to all of the attention heads. That is a lot to be sure, but it's only about a third of the 175 billion that are in the network in total. So even though attention gets all of the attention, the majority of parameters come from the blocks sitting in between these steps. In the next chapter, you and I will talk more about those other blocks and also a lot more about the training process. A big part of the story for the success of the attention mechanism is not so much any specific kind of behaviour that it enables, but the fact that it's extremely parallelizable, meaning that you can run a huge number of computations in a short time using GPUs. Given that one of the big lessons about deep learning in the last decade or two has been that scale alone seems to give huge qualitative improvements in model performance, there's a huge advantage to parallelizable architectures that let you do this. If you want to learn more about this stuff, I've left lots of links in the description. In particular, anything produced by Andrej Karpathy or Chris Ola tend to be pure gold. In this video, I wanted to just jump into attention in its current form, but if you're curious about more of the history for how we got here and how you might reinvent this idea for yourself, my friend Vivek just put up a couple videos giving a lot more of that motivation. Also, Britt Cruz from the channel The Art of the Problem has a really nice video about the history of large language models. Thank you.

================================================================================
VIDEO ID: wjZofJX0v4M
TITLE: Transformers, the tech behind LLMs | Deep Learning Chapter 5
URL: https://www.youtube.com/watch?v=wjZofJX0v4M
PUBLISHED: 2024-04-01T19:13:57Z
STATUS: SUCCESS
================================================================================
The initials GPT stand for Generative Pretrained Transformer. So that first word is straightforward enough, these are bots that generate new text. Pretrained refers to how the model went through a process of learning from a massive amount of data, and the prefix insinuates that there's more room to fine-tune it on specific tasks with additional training. But the last word, that's the real key piece. A transformer is a specific kind of neural network, a machine learning model, and it's the core invention underlying the current boom in AI. What I want to do with this video and the following chapters is go through a visually-driven explanation for what actually happens inside a transformer. We're going to follow the data that flows through it and go step by step. There are many different kinds of models that you can build using transformers. Some models take in audio and produce a transcript. This sentence comes from a model going the other way around, producing synthetic speech just from text. All those tools that took the world by storm in 2022 like DALL-E and Midjourney that take in a text description and produce an image are based on transformers. Even if I can't quite get it to understand what a pi creature is supposed to be, I'm still blown away that this kind of thing is even remotely possible. And the original transformer introduced in 2017 by Google was invented for the specific use case of translating text from one language into another. But the variant that you and I will focus on, which is the type that underlies tools like ChatGPT, will be a model that's trained to take in a piece of text, maybe even with some surrounding images or sound accompanying it, and produce a prediction for what comes next in the passage. That prediction takes the form of a probability distribution over many different chunks of text that might follow. At first glance, you might think that predicting the next word feels like a very different goal from generating new text. But once you have a prediction model like this, a simple thing you could try to make it generate, a longer piece of text, is to give it an initial snippet to work with, have it take a random sample from the distribution it just generated, append that sample to the text, and then run the whole process again to make a new prediction based on all the new text, including what it just added. I don't know about you, but it really doesn't feel like this should actually work. In this animation, for example, I'm running GPT-2 on my laptop and having it repeatedly predict and sample the next chunk of text to generate a story based on the seed text. The story just doesn't actually really make that much sense. But if I swap it out for API calls to GPT-3 instead, which is the same basic model, just much bigger, suddenly almost magically we do get a sensible story, one that even seems to infer that a pi creature would live in a land of math and computation. This process here of repeated prediction and sampling is essentially what's happening when you interact with ChatGPT, or any of these other large language models, and you see them producing one word at a time. In fact, one feature that I would very much enjoy is the ability to see the underlying distribution for each new word that it chooses. Let's kick things off with a very high level preview of how data flows through a transformer. We will spend much more time motivating and interpreting and expanding on the details of each step, but in broad strokes, when one of these chatbots generates a given word, here's what's going on under the hood. First, the input is broken up into a bunch of little pieces. These pieces are called tokens, and in the case of text these tend to be words or little pieces of words or other common character combinations. If images or sound are involved, then tokens could be little patches of that image or little chunks of that sound. Each one of these tokens is then associated with a vector, meaning some list of numbers, which is meant to somehow encode the meaning of that piece. If you think of these vectors as giving coordinates in some very high dimensional space, words with similar meanings tend to land on vectors that are close to each other in that space. This sequence of vectors then passes through an operation that's known as an attention block, and this allows the vectors to talk to each other and pass information back and forth to update their values. For example, the meaning of the word model in the phrase "a machine learning model" is different from its meaning in the phrase "a fashion model". The attention block is what's responsible for figuring out which words in context are relevant to updating the meanings of which other words, and how exactly those meanings should be updated. And again, whenever I use the word meaning, this is somehow entirely encoded in the entries of those vectors. After that, these vectors pass through a different kind of operation, and depending on the source that you're reading this will be referred to as a multi-layer perceptron or maybe a feed-forward layer. And here the vectors don't talk to each other, they all go through the same operation in parallel. And while this block is a little bit harder to interpret, later on we'll talk about how the step is a little bit like asking a long list of questions about each vector, and then updating them based on the answers to those questions. All of the operations in both of these blocks look like a giant pile of matrix multiplications, and our primary job is going to be to understand how to read the underlying matrices. I'm glossing over some details about some normalization steps that happen in between, but this is after all a high-level preview. After that, the process essentially repeats, you go back and forth between attention blocks and multi-layer perceptron blocks, until at the very end the hope is that all of the essential meaning of the passage has somehow been baked into the very last vector in the sequence. We then perform a certain operation on that last vector that produces a probability distribution over all possible tokens, all possible little chunks of text that might come next. And like I said, once you have a tool that predicts what comes next given a snippet of text, you can feed it a little bit of seed text and have it repeatedly play this game of predicting what comes next, sampling from the distribution, appending it, and then repeating over and over. Some of you in the know may remember how long before ChatGPT came into the scene, this is what early demos of GPT-3 looked like, you would have it autocomplete stories and essays based on an initial snippet. To make a tool like this into a chatbot, the easiest starting point is to have a little bit of text that establishes the setting of a user interacting with a helpful AI assistant, what you would call the system prompt, and then you would use the user's initial question or prompt as the first bit of dialogue, and then you have it start predicting what such a helpful AI assistant would say in response. There is more to say about an added step of training that's required to make this work well, but at a high level this is the idea. In this chapter, you and I are going to expand on the details of what happens at the very beginning of the network, at the very end of the network, and I also want to spend a lot of time reviewing some important bits of background knowledge, things that would have been second nature to any machine learning engineer by the time transformers came around. If you're comfortable with that background knowledge and a little impatient, you could probably feel free to skip to the next chapter, which is going to focus on the attention blocks, generally considered the heart of the transformer. After that, I want to talk more about these multi-layer perceptron blocks, how training works, and a number of other details that will have been skipped up to that point. For broader context, these videos are additions to a mini-series about deep learning, and it's okay if you haven't watched the previous ones, I think you can do it out of order, but before diving into transformers specifically, I do think it's worth making sure that we're on the same page about the basic premise and structure of deep learning. At the risk of stating the obvious, this is one approach to machine learning, which describes any model where you're using data to somehow determine how a model behaves. What I mean by that is, let's say you want a function that takes in an image and it produces a label describing it, or our example of predicting the next word given a passage of text, or any other task that seems to require some element of intuition and pattern recognition. We almost take this for granted these days, but the idea with machine learning is that rather than trying to explicitly define a procedure for how to do that task in code, which is what people would have done in the earliest days of AI, instead you set up a very flexible structure with tunable parameters, like a bunch of knobs and dials, and then, somehow, you use many examples of what the output should look like for a given input to tweak and tune the values of those parameters to mimic this behavior. For example, maybe the simplest form of machine learning is linear regression, where your inputs and outputs are each single numbers, something like the square footage of a house and its price, and what you want is to find a line of best fit through this data, you know, to predict future house prices. That line is described by two continuous parameters, say the slope and the y-intercept, and the goal of linear regression is to determine those parameters to closely match the data. Needless to say, deep learning models get much more complicated. GPT-3, for example, has not two, but 175 billion parameters. But here's the thing, it's not a given that you can create some giant model with a huge number of parameters without it either grossly overfitting the training data or being completely intractable to train. Deep learning describes a class of models that in the last couple decades have proven to scale remarkably well. What unifies them is that they all use the same training algorithm, it's called backpropagation, we talked about it in previous chapters, and the context that I want you to have as we go in is that in order for this training algorithm to work well at scale, these models have to follow a certain specific format. And if you know this format going in, it helps to explain many of the choices for how a transformer processes language, which otherwise run the risk of feeling kinda arbitrary. First, whatever kind of model you're making, the input has to be formatted as an array of real numbers. This could simply mean a list of numbers, it could be a two-dimensional array, or very often you deal with higher dimensional arrays, where the general term used is tensor. You often think of that input data as being progressively transformed into many distinct layers, where again, each layer is always structured as some kind of array of real numbers, until you get to a final layer which you consider the output. For example, the final layer in our text processing model is a list of numbers representing the probability distribution for all possible next tokens. In deep learning, these model parameters are almost always referred to as weights, and this is because a key feature of these models is that the only way these parameters interact with the data being processed is through weighted sums. You also sprinkle some non-linear functions throughout, but they won't depend on parameters. Typically, though, instead of seeing the weighted sums all naked and written out explicitly like this, you'll instead find them packaged together as various components in a matrix vector product. It amounts to saying the same thing, if you think back to how matrix vector multiplication works, each component in the output looks like a weighted sum. It's just often conceptually cleaner for you and me to think about matrices that are filled with tunable parameters that transform vectors that are drawn from the data being processed. For example, those 175 billion weights in GPT-3 are organized into just under 28,000 distinct matrices. Those matrices in turn fall into eight different categories, and what you and I are going to do is step through each one of those categories to understand what that type does. As we go through, I think it's kind of fun to reference the specific numbers from GPT-3 to count up exactly where those 175 billion come from. Even if nowadays there are bigger and better models, this one has a certain charm as the first large-language model to really capture the world's attention outside of ML communities. Also, practically speaking, companies tend to keep much tighter lips around the specific numbers for more modern networks. I just want to set the scene going in, that as you peek under the hood to see what happens inside a tool like ChatGPT, almost all of the actual computation looks like matrix vector multiplication. There's a little bit of a risk getting lost in the sea of billions of numbers, but you should draw a very sharp distinction in your mind between the weights of the model, which I'll always color in blue or red, and the data being processed, which I'll always color in gray. The weights are the actual brains, they are the things learned during training, and they determine how it behaves. The data being processed simply encodes whatever specific input is fed into the model for a given run, like an example snippet of text. With all of that as foundation, let's dig into the first step of this text processing example, which is to break up the input into little chunks and turn those chunks into vectors. I mentioned how those chunks are called tokens, which might be pieces of words or punctuation, but every now and then in this chapter and especially in the next one, I'd like to just pretend that it's broken more cleanly into words. Because we humans think in words, this will just make it much easier to reference little examples and clarify each step. The model has a predefined vocabulary, some list of all possible words, say 50,000 of them, and the first matrix that we'll encounter, known as the embedding matrix, has a single column for each one of these words. These columns are what determines what vector each word turns into in that first step. We label it W_E, and like all the matrices we see, its values begin random, but they're going to be learned based on data. Turning words into vectors was common practice in machine learning long before transformers, but it's a little weird if you've never seen it before, and it sets the foundation for everything that follows, so let's take a moment to get familiar with it. We often call this embedding a word, which invites you to think of these vectors very geometrically as points in some high dimensional space. Visualizing a list of three numbers as coordinates for points in 3D space would be no problem, but word embeddings tend to be much much higher dimensional. In GPT-3 they have 12,288 dimensions, and as you'll see, it matters to work in a space that has a lot of distinct directions. In the same way that you could take a two-dimensional slice through a 3D space and project all the points onto that slice, for the sake of animating word embeddings that a simple model is giving me, I'm going to do an analogous thing by choosing a three-dimensional slice through this very high dimensional space, and projecting the word vectors down onto that and displaying the results. The big idea here is that as a model tweaks and tunes its weights to determine how exactly words get embedded as vectors during training, it tends to settle on a set of embeddings where directions in the space have a kind of semantic meaning. For the simple word-to-vector model I'm running here, if I run a search for all the words whose embeddings are closest to that of tower, you'll notice how they all seem to give very similar tower-ish vibes. And if you want to pull up some Python and play along at home, this is the specific model that I'm using to make the animations. It's not a transformer, but it's enough to illustrate the idea that directions in the space can carry semantic meaning. A very classic example of this is how if you take the difference between the vectors for woman and man, something you would visualize as a little vector in the space connecting the tip of one to the tip of the other, it's very similar to the difference between king and queen. So let's say you didn't know the word for a female monarch, you could find it by taking king, adding this woman minus man direction, and searching for the embedding closest to that point. At least, kind of. Despite this being a classic example for the model I'm playing with, the true embedding of queen is actually a little farther off than this would suggest, presumably because the way queen is used in training data is not merely a feminine version of king. When I played around, family relations seemed to illustrate the idea much better. The point is, it looks like during training the model found it advantageous to choose embeddings such that one direction in this space encodes gender information. Another example is that if you take the embedding of Italy, and you subtract the embedding of Germany, and add that to the embedding of Hitler, you get something very close to the embedding of Mussolini. It's as if the model learned to associate some directions with Italian-ness, and others with WWII axis leaders. Maybe my favorite example in this vein is how in some models, if you take the difference between Germany and Japan, and add it to sushi, you end up very close to bratwurst. Also in playing this game of finding nearest neighbors, I was very pleased to see how close cat was to both beast and monster. One bit of mathematical intuition that's helpful to have in mind, especially for the next chapter, is how the dot product of two vectors can be thought of as a way to measure how well they align. Computationally, dot products involve multiplying all the corresponding components and then adding the results, which is good, since so much of our computation has to look like weighted sums. Geometrically, the dot product is positive when vectors point in similar directions, it's zero if they're perpendicular, and it's negative whenever they point in opposite directions. For example, let's say you were playing with this model, and you hypothesize that the embedding of cats minus cat might represent a sort of plurality direction in this space. To test this, I'm going to take this vector and compute its dot product against the embeddings of certain singular nouns, and compare it to the dot products with the corresponding plural nouns. If you play around with this, you'll notice that the plural ones do indeed seem to consistently give higher values than the singular ones, indicating that they align more with this direction. It's also fun how if you take this dot product with the embeddings of the words one, two, three, and so on, they give increasing values, so it's as if we can quantitatively measure how plural the model finds a given word. Again, the specifics for how words get embedded is learned using data. This embedding matrix, whose columns tell us what happens to each word, is the first pile of weights in our model. Using the GPT-3 numbers, the vocabulary size specifically is 50,257, and again, technically this consists not of words per se, but of tokens. The embedding dimension is 12,288, and multiplying those tells us this consists of about 617 million weights. Let's go ahead and add this to a running tally, remembering that by the end we should count up to 175 billion. In the case of transformers, you really want to think of the vectors in this embedding space as not merely representing individual words. For one thing, they also encode information about the position of that word, which we'll talk about later, but more importantly, you should think of them as having the capacity to soak in context. A vector that started its life as the embedding of the word king, for example, might progressively get tugged and pulled by various blocks in this network, so that by the end it points in a much more specific and nuanced direction that somehow encodes that it was a king who lived in Scotland, and who had achieved his post after murdering the previous king, and who's being described in Shakespearean language. Think about your own understanding of a given word. The meaning of that word is clearly informed by the surroundings, and sometimes this includes context from a long distance away, so in putting together a model that has the ability to predict what word comes next, the goal is to somehow empower it to incorporate context efficiently. To be clear, in that very first step, when you create the array of vectors based on the input text, each one of those is simply plucked out of the embedding matrix, so initially each one can only encode the meaning of a single word without any input from its surroundings. But you should think of the primary goal of this network that it flows through as being to enable each one of those vectors to soak up a meaning that's much more rich and specific than what mere individual words could represent. The network can only process a fixed number of vectors at a time, known as its context size. For GPT-3 it was trained with a context size of 2048, so the data flowing through the network always looks like this array of 2048 columns, each of which has 12,000 dimensions. This context size limits how much text the transformer can incorporate when it's making a prediction of the next word. This is why long conversations with certain chatbots, like the early versions of ChatGPT, often gave the feeling of the bot kind of losing the thread of conversation as you continued too long. We'll go into the details of attention in due time, but skipping ahead I want to talk for a minute about what happens at the very end. Remember, the desired output is a probability distribution over all tokens that might come next. For example, if the very last word is Professor, and the context includes words like Harry Potter, and immediately preceding we see least favorite teacher, and also if you give me some leeway by letting me pretend that tokens simply look like full words, then a well-trained network that had built up knowledge of Harry Potter would presumably assign a high number to the word Snape. This involves two different steps. The first one is to use another matrix that maps the very last vector in that context to a list of 50,000 values, one for each token in the vocabulary. Then there's a function that normalizes this into a probability distribution, it's called softmax and we'll talk more about it in just a second, but before that it might seem a little bit weird to only use this last embedding to make a prediction, when after all in that last step there are thousands of other vectors in the layer just sitting there with their own context-rich meanings. This has to do with the fact that in the training process it turns out to be much more efficient if you use each one of those vectors in the final layer to simultaneously make a prediction for what would come immediately after it. There's a lot more to be said about training later on, but I just want to call that out right now. This matrix is called the Unembedding matrix and we give it the label WU. Again, like all the weight matrices we see, its entries begin at random, but they are learned during the training process. Keeping score on our total parameter count, this Unembedding matrix has one row for each word in the vocabulary, and each row has the same number of elements as the embedding dimension. It's very similar to the embedding matrix, just with the order swapped, so it adds another 617 million parameters to the network, meaning our count so far is a little over a billion, a small but not wholly insignificant fraction of the 175 billion we'll end up with in total. As the very last mini-lesson for this chapter, I want to talk more about this softmax function, since it makes another appearance for us once we dive into the attention blocks. The idea is that if you want a sequence of numbers to act as a probability distribution, say a distribution over all possible next words, then each value has to be between 0 and 1, and you also need all of them to add up to 1. However, if you're playing the deep learning game where everything you do looks like matrix-vector multiplication, the outputs you get by default don't abide by this at all. The values are often negative, or much bigger than 1, and they almost certainly don't add up to 1. Softmax is the standard way to turn an arbitrary list of numbers into a valid distribution in such a way that the largest values end up closest to 1, and the smaller values end up very close to 0. That's all you really need to know. But if you're curious, the way it works is to first raise e to the power of each of the numbers, which means you now have a list of positive values, and then you can take the sum of all those positive values and divide each term by that sum, which normalizes it into a list that adds up to 1. You'll notice that if one of the numbers in the input is meaningfully bigger than the rest, then in the output the corresponding term dominates the distribution, so if you were sampling from it you'd almost certainly just be picking the maximizing input. But it's softer than just picking the max in the sense that when other values are similarly large, they also get meaningful weight in the distribution, and everything changes continuously as you continuously vary the inputs. In some situations, like when ChatGPT is using this distribution to create a next word, there's room for a little bit of extra fun by adding a little extra spice into this function, with a constant T thrown into the denominator of those exponents. We call it the temperature, since it vaguely resembles the role of temperature in certain thermodynamics equations, and the effect is that when T is larger, you give more weight to the lower values, meaning the distribution is a little bit more uniform, and if T is smaller, then the bigger values will dominate more aggressively, where in the extreme, setting T equal to zero means all of the weight goes to maximum value. For example, I'll have GPT-3 generate a story with the seed text, "once upon a time there was A", but I'll use different temperatures in each case. Temperature zero means that it always goes with the most predictable word, and what you get ends up being a trite derivative of Goldilocks. A higher temperature gives it a chance to choose less likely words, but it comes with a risk. In this case, the story starts out more originally, about a young web artist from South Korea, but it quickly degenerates into nonsense. Technically speaking, the API doesn't actually let you pick a temperature bigger than 2. There's no mathematical reason for this, it's just an arbitrary constraint imposed to keep their tool from being seen generating things that are too nonsensical. So if you're curious, the way this animation is actually working is I'm taking the 20 most probable next tokens that GPT-3 generates, which seems to be the maximum they'll give me, and then I tweak the probabilities based on an exponent of 1/5. As another bit of jargon, in the same way that you might call the components of the output of this function probabilities, people often refer to the inputs as logits, or some people say logits, some people say logits, I'm gonna say logits. So for instance, when you feed in some text, you have all these word embeddings flow through the network, and you do this final multiplication with the unembedding matrix, machine learning people would refer to the components in that raw, unnormalized output as the logits for the next word prediction. A lot of the goal with this chapter was to lay the foundations for understanding the attention mechanism, Karate Kid wax-on-wax-off style. You see, if you have a strong intuition for word embeddings, for softmax, for how dot products measure similarity, and also the underlying premise that most of the calculations have to look like matrix multiplication with matrices full of tunable parameters, then understanding the attention mechanism, this cornerstone piece in the whole modern boom in AI, should be relatively smooth. For that, come join me in the next chapter. As I'm publishing this, a draft of that next chapter is available for review by Patreon supporters. A final version should be up in public in a week or two, it usually depends on how much I end up changing based on that review. In the meantime, if you want to dive into attention, and if you want to help the channel out a little bit, it's there waiting.

================================================================================
VIDEO ID: 81QNyDnYtg0
TITLE: Simulating the electric field and a moving charge
URL: https://www.youtube.com/watch?v=81QNyDnYtg0
PUBLISHED: 2024-01-26T06:00:04Z
STATUS: SUCCESS
================================================================================
I recently had a lot of fun making simulations for how the electric field responds to a moving charge it was all for a longer video on YouTube that covers the fundamentals of what light is but here I just thought I'd share with you some of the pretty animations that came out of it the full electric field is threedimensional it Associates each point in space with a little Vector telling you what force would be applied to a unit charge if it were sitting at that point in Space the 3D fields are fun to look at but they are a bit busy so often it's easier to just show a slice of that field say on the XY plane in the main video I talk about the underlying law used to make these simulations it's not actually Maxwell's equations which are the fundamental laws underlying electricity and magnetism instead I'm coding in another intermediate law something that you can derive from Maxwell's equations but which is a little easier to wrap your mind around both for the sake of making the animations and also for the sake of the student trying to understand what's going [Music] on

================================================================================
VIDEO ID: -ikRg-OfFHc
TITLE: A challenging puzzle about subset sums
URL: https://www.youtube.com/watch?v=-ikRg-OfFHc
PUBLISHED: 2024-01-22T06:00:00Z
STATUS: SUCCESS
================================================================================
Turning to chapter 2, advanced problems, problem  number 10 asks this seemingly innocent question. Find the number of subsets of the set 1 up to 2000,  the sum of whose elements is divisible by 5. That might take a little moment to parse, but to illustrate let me  show it on a much simpler example, where we have the set 1, 2, 3, 4, 5. This has 2 to the 5th, or 32 distinct subsets, which look like this. If you compute the sum of each of those subsets,  and you organize them by which ones have the same sum,  you'll see that 8 of those subsets have a sum which is divisible by 5. So the answer here would be 8. The case with all the subsets of 1 up to 2000 is obviously way,  way bigger, and you might be able to guess at a rough estimate for the answer,  but the challenge is to compute the exact answer. I really love this problem, and the full video I did on this question  covers a really beautiful and surprising way you can think about it. It uses one of those tools that mathematicians keep in their  belt that legitimately feels like magic the first time you see it.

================================================================================
VIDEO ID: -3jPW_TGATI
TITLE: Ellipses have multiple definitions, how are these the same?
URL: https://www.youtube.com/watch?v=-3jPW_TGATI
PUBLISHED: 2024-01-19T19:00:00Z
STATUS: SUCCESS
================================================================================
there are at least three main ways that you could Define an ellipse geometrically one is to say you take a circle and you just stretch it out in one dimension another is the classic two thumb tacks and a piece of string construction where you Loop a string around two thumb tacks stuck into a piece of paper and Pull It taut with a pencil and then Trace around keeping the string taut the whole time and yet another way to define an ellipse is to slice a cone with a plane at an angle an angle that's smaller than the slope of the cone itself why why on Earth should these three definitions have anything to do with each other I mean sure it kind of makes sense that each should produce some vaguely oval looking stretched out Loop but why should the family of Curves produced by these three totally different methods be precisely the same shapes

================================================================================
VIDEO ID: w-CXIqIjfRI
TITLE: Three levels of understanding Bayes' theorem
URL: https://www.youtube.com/watch?v=w-CXIqIjfRI
PUBLISHED: 2024-01-17T07:00:31Z
STATUS: SUCCESS
================================================================================
Baye theorem this formula it's Central to scientific discovery it's a core tool in machine learning and Ai and it's even been used for treasure hunting when in the 1980s a small team led by Tommy Thompson and I'm not making up that name used basan search tactics to help uncover a ship that had sunk a century and a half earlier and the ship was carrying what in today's terms amounts to $700 Million worth of gold so it's a formula worth understanding but of course there were multiple different levels of possible understanding at the simplest there's just knowing what each one of the parts means so that you can plug in numbers then there's understanding why it's true but maybe the most important level is being able to recognize when you need to use it

================================================================================
VIDEO ID: xIMlJUwB1m8
TITLE: The medical test paradox (well "paradox")
URL: https://www.youtube.com/watch?v=xIMlJUwB1m8
PUBLISHED: 2024-01-15T07:00:30Z
STATUS: SUCCESS
================================================================================
Picture a thousand women and suppose that 1% of them have breast cancer. And let's say they all undergo a certain breast cancer screening, and that 9 of those with cancer correctly get positive results, and there's one false negative. And then suppose that among the remainder without cancer, 89 get false positives, and 901 correctly get negative results. So if all you know about a woman is that she does the screening and she gets a positive result, the probability that she's in the cancer group given the test results is 9 divided by 9 plus 89, which is approximately 1 in 11. So the paradox here is that in one sense, the test is over 90% accurate. It gives correct results to over 90% of the patients who take it. And yet, if you learn that someone gets a positive result without any added information, there's actually only a 1 in 11 chance that that particular result is accurate.

================================================================================
VIDEO ID: IstyL9vnybg
TITLE: Positioned as the hardest question on a Putnam exam  (#6, 1992)
URL: https://www.youtube.com/watch?v=IstyL9vnybg
PUBLISHED: 2024-01-12T07:00:13Z
STATUS: SUCCESS
================================================================================
here's the question if you choose four random points on a sphere and consider the tetrahedron with these points as its vertices what is the probability that the center of the sphere is inside that tetrahedron go ahead take a moment and kind of digest this question and how do you even approach a problem like this right where do you even start well it's usually a good idea to think about simpler cases so let's knock things down to two Dimensions where you'll choose three random points on a circle and it's always helpful to name things so let's call these guys P1 P2 and P3 the question is what's the probability that the triangle formed by these points contains the center of the circle it's way easier to visualize now but it's still a hard question so again you ask is there a way to simplify what's going on get ourselves to some kind of foothold that we can build up from well maybe you imagine fixing P1 and P2 in place and only letting that third Point vary and when you do this

================================================================================
VIDEO ID: DWnb2UUlqd0
TITLE: Why does light slowing imply a bend? (Beyond the tank/car analogy)
URL: https://www.youtube.com/watch?v=DWnb2UUlqd0
PUBLISHED: 2024-01-11T00:00:11Z
STATUS: SUCCESS
================================================================================
why exactly light slowing down would imply that it bends as it enters a medium if you have some light wave shining into a material like glass if it slows down notice how that means that it gets kind of scrunched up if its wavelength in a vacuum was some number Lambda then the wavelength inside this material where it's gotten slowed down is something smaller than that this particular animation is a little bit messy and hard to follow so it might be clearer if instead we simply color every point of the plane such that those points are white near the crests of the wave and then black away from the crests if that glass were positioned at an angle think about what happens to each one of those wave crests as it hits the glass the lower parts slow down before the top Parts causing it to get sort of smeared out and overall the wave Crest ends up at a different angle when you take into account the fact that for a beam of light the beam is always perpendicular to those wave crests this means your light has to turn and moreover you can calculate exact

================================================================================
VIDEO ID: U3O1nzSojnc
TITLE: The cube shadow puzzle
URL: https://www.youtube.com/watch?v=U3O1nzSojnc
PUBLISHED: 2024-01-09T17:15:05Z
STATUS: SUCCESS
================================================================================
Here's a really nice puzzle. Suppose you randomly orient a cube in three-dimensional space,  and you look at the area of its shadow. What's the expected value for that area? Or phrased another way, if you repeat this process over and over,  randomly tossing that cube and tallying up the areas that you find,  what would the empirically measured mean of all those measured areas approach as  you do this more and more? Strictly speaking, in referencing the shadow, that would depend on  where the light source is, but here we're doing the typical mathematician  thing of thinking of the light source as being infinitely far away,  so the shadow is just a flat projection, say, onto the xy-plane. It is definitely a hard problem, and I'm curious actually  to hear how you would approach it in the comments. The longest video I've made to date explores this question. Really, it's a saga about two distinct problem-solving styles,  and why popularizations of math tend to have a bias in what kinds of styles  they represent. The shadow puzzle just turns out to be a very perfect setting for that story.

================================================================================
VIDEO ID: XIW-2ykgVPI
TITLE: What does it mean that light "slows down" in glass?
URL: https://www.youtube.com/watch?v=XIW-2ykgVPI
PUBLISHED: 2024-01-08T07:00:19Z
STATUS: SUCCESS
================================================================================
why passing through a medium would change the speed of a light wave at all I want you to think of your material like glass as being broken up into a bunch of distinct layers all perpendicular to the direction the light is traveling and we'll start by focusing our attention on the effect of just one of those layers on the light wave the true effect would be minuscule but if you'll let me exaggerate it for a moment what it does is kick back the phase of the wave let's say you go and add a bunch of other layers of the glass each one also applying their own Kickback to the phase of the wave notice what happens if I smooth it out by doubling the density of layers but having each one only apply half the phase kick as I continue this over and over approaching a situation where you have a Continuum of glass each layer applying just a tiny infinite tesmo phase kick what you end up with is identical to indistinguishable from a wave that's simply traveling slower

================================================================================
VIDEO ID: vItzPPpNXEs
TITLE: Why do we call them "scalars"?
URL: https://www.youtube.com/watch?v=vItzPPpNXEs
PUBLISHED: 2024-01-06T00:00:33Z
STATUS: SUCCESS
================================================================================
if you take the number two and multiply it by a given Vector it means you stretch out that Vector so that it's two times as long as when you started if you multiply that vector by say 1/3 it means you squish it down so that it's 1/3 the original length when you multiply it by a negative number like 1.8 then the vector first gets flipped around then stretched out by that factor of 1.8 this process of stretching or squishing or sometimes reversing the direction of a vector is called scaling and whenever you catch a number like 2 or 1/3 or 1.8 acting like this scaling some Vector you call it a scalar numerically stretching out a vector by a factor of say two corresponds with multiplying each of its components by that factor two so in the conception of vectors as lists of numbers multiplying a given vector by a scalar means multiplying each one of those components by that scaler

================================================================================
VIDEO ID: teYL0Er4c3g
TITLE: A beautiful international math olympiad problem
URL: https://www.youtube.com/watch?v=teYL0Er4c3g
PUBLISHED: 2024-01-03T07:00:30Z
STATUS: SUCCESS
================================================================================
the international math Olympiad consists of six problems broken up over 2 days the three problems given on each day are supposed to get progressively harder but on the test from 2011 problem number two was much more challenging than the organizers intended for it to be here's what it states let s be a finite set of at least two points in the plane assume that no three points of s are collinear a windmill is a process that starts with a line L going through a single point P and S the line rotates clockwise about the pivot P until the first time that that line meets some other point belonging to S this point Q takes over as the new pivot and the line now rotates clockwise around Q until the next time it meets a point of s this process continues indefinitely show that you can choose a point p in s and a line L going through P such that the resulting windmill uses each point of s as a pivot infinitely many times it's a really beautiful problem and in the full video we cover a very clever way that you can solve it

================================================================================
VIDEO ID: BTryyW7gqg4
TITLE: Definition of a "bit", in information theory
URL: https://www.youtube.com/watch?v=BTryyW7gqg4
PUBLISHED: 2024-01-02T00:00:09Z
STATUS: SUCCESS
================================================================================
the standard unit of information is the bit which has a little bit of a funny formula but it's really intuitive if we just look at examples if you have an observation that cuts your space of possibilities in half we say that it has one bit of information if instead a new fact chops down that space of possibilities by a factor of four we say that it has two bits of information if the observation cuts that space by a factor of eight we say it's three bits of information and so on and so forth so now it's when you might want to take a moment and pause and ask for yourself what is the formula for information for the number of bits in terms of the probability of An Occurrence well what we're saying here is basically that when you take 1/2 to the number of bits that's the same thing as the probability which is the same thing as saying two to the power of the number of bits is one over the probability which rearranges further to saying the information is the log base 2 of 1 / the probability and sometimes you see this with one more rearrangement still where the information is the negative log base 2 of the probability

================================================================================
VIDEO ID: kpG7I2MOcnI
TITLE: The Newton art puzzle
URL: https://www.youtube.com/watch?v=kpG7I2MOcnI
PUBLISHED: 2023-12-29T19:00:32Z
STATUS: SUCCESS
================================================================================
Here's an art puzzle that feels impossible but is secretly related to some deep math. Try creating a picture that has at least three colors,  so that any point that's on the boundary of one color is on the boundary of all of them. So for example in this diagram with red, green, and blue,  the middle point is on the boundary of all three colors, so it's fine,  but this whole line of points here is disallowed,  since they're all on the boundary of red and green, but not blue. Likewise these other two border lines are disallowed. So maybe you try to correct that, you go and add a bunch of blue blobs on the  boundary of the red and green, and do something similar on the other border lines,  but now the smaller boundaries of those blobs would cause a problem,  so maybe you try to correct that even further and keep iterating and iterating. This might feel impossible, and with smooth shapes it is,  but there are actually infinitely many solutions. One example is a family of figures known as Newton fractals. What's very fun is that the diagrams are closely tied to a kind of chaos,  a chaos that emerges from a common algorithm that's used all over  the place in engineering to find numerical solutions to equations.

================================================================================
VIDEO ID: 3KbiJ-z0j44
TITLE: What is a group?
URL: https://www.youtube.com/watch?v=3KbiJ-z0j44
PUBLISHED: 2023-12-27T19:00:01Z
STATUS: SUCCESS
================================================================================
when we say a face is symmetric what we mean is that you can reflect it about a line and it's left looking completely the same it's a statement about an action that you can take something like a snowflake is also symmetric but in more ways you can rotate at 60Â° or 120Â° you can flip it along various different axes and all these actions leave it looking the same a collection of all of the actions like this taken together is called a group take note we always consider the action of doing nothing to be part of the group so if we include that do nothing action the group of symmetries of a snowflake includes 12 distinct actions it even has a fancy name D6 the simple group of symmetries that only has two elements acting on a face also has a fancy name C2 in general there is a whole zoo of groups with no shortage of jargon to their names categorizing the many different ways that something can be symmetric

================================================================================
VIDEO ID: R1e7aHBKLnM
TITLE: How to derive a formula for Ï€
URL: https://www.youtube.com/watch?v=R1e7aHBKLnM
PUBLISHED: 2023-12-25T19:00:15Z
STATUS: SUCCESS
================================================================================
imagine yourself with nothing more than a pencil some paper and a desire to find a formula for computing Pi there are countless ways that you could approach this but as a broad outline for the plot line here you'll start by asking how many lattice points of the plane sit inside a big circle when I say lattice Point what I mean is a point a on the plane where A and B are both integers a spot where the grid lines here cross if you draw a circle centered at the origin let's say with radius 10 how many lattice points would you guess are inside that Circle well there's one lattice point for each unit of area so the answer should be approximately equal to the area of the circle PK R 2 what we're going to try to do is find a second way to answer the same question how many lattice points are inside the circle because that can lead to another way to express the area of a circle and hence another way to express Pi

================================================================================
VIDEO ID: tjIOqIr80ns
TITLE: The limit of limiting arguments
URL: https://www.youtube.com/watch?v=tjIOqIr80ns
PUBLISHED: 2023-12-23T00:00:26Z
STATUS: SUCCESS
================================================================================
I'd like to show you a simple argument for the fact that Pi is equal to 4 we start off with a circle say with radius 1 and we ask how can we figure out its circumference after all Pi is by definition the ratio of this circumference to the diameter of the circle we start off by drawing the square whose side lengths are all tangent to that Circle it's not too hard to see that the perimeter of this square is eight then the argument proceeds by producing a sequence of Curves all of whom also have this perimeter of eight but which more and more closely approximate the circle and there are all sorts of examples throughout calculus when we talk about approximating one thing we want to know as a limit of a bunch of other things that are easier to understand so the question at the heart here is why exactly is it not okay to do that in this example

================================================================================
VIDEO ID: W1gW1dHRsOw
TITLE: For anyone who might not know how links in shorts work
URL: https://www.youtube.com/watch?v=W1gW1dHRsOw
PUBLISHED: 2023-12-21T00:15:02Z
STATUS: SUCCESS
================================================================================
based on comments it looks like at least some viewers don't know that at the bottom of a short video creators can add links to longer videos so if hypothetically you stumbled on a short showing how idealized colliding blocks can compute pi and you have questions the answer might literally be one click away or if a short gives you an overview of the standard prism explanation and you're sitting there wondering why would light slow down as it passes through glass and why that would imply that it bends there might just be an in-depth explainer sitting right there waiting for you or let's say you land on one showing how the sum of many rotating vectors can basically draw any picture you want and you're curious how on Earth the initial sizes and orientations of those arrows could be computed again maybe you're just one click away no pressure If you're happy in the shorts feed you do you it's just that I cannot help but highlight it when 99% of the questions asked are literally answered in a full video where I spent hundreds of hours of my life trying to illustrate a topic as best I know how and obviously 60 seconds is too short to give full

================================================================================
VIDEO ID: p9i3cYMQtBY
TITLE: Infinite Lighthouses and Ï€
URL: https://www.youtube.com/watch?v=p9i3cYMQtBY
PUBLISHED: 2023-12-21T00:00:20Z
STATUS: SUCCESS
================================================================================
imagine standing at the origin of a number line and placing little identical lighthouses on all of the positive integers you know 1 2 3 4 and so on what is the intensity of the light that you see well if you rescale units so that the brightness from that first light is one say measured as the energy your eye is receiving from it per unit time then by the inverse Square law the brightness of that second Lighthouse would be 1/4 the brightness of the third would be 1 nth and so on and so forth which means means the total brightness from all of them together is 1 plus a 4th plus a 9th adding on all of the reciprocals of the square numbers up to Infinity this value turns out to be very special it is precisely pi^ 2 / 6 I know it's amazing why is pi there and why would you square it this game with the lighthouses is more than just a cute way to visualize the sum it's the beginning of a very clever proof by Yan wund that explains why this sum is related to circles

================================================================================
VIDEO ID: X4jpqCu-wlA
TITLE: Can you even imagine 2^256?
URL: https://www.youtube.com/watch?v=X4jpqCu-wlA
PUBLISHED: 2023-12-16T00:00:24Z
STATUS: SUCCESS
================================================================================
how big is 2 to 256 well it's 2 to 32 multiplied by itself 8 * 2 32 is about 4 billion suppose you have a really good computer that runs 4 billion operations per second and imagine 4 billion of those computers this is something like a thousand times the number of computers that Google has Earth has about 8 billion people so imagine giving half of every individual on the planet their own personal killer Google then imagine a Galaxy that has 4 billion copies of this Earth take 4 billion copies of this Galaxy and we'll call it your Giga Galactic supercomputer let that run for 4 billion seconds 126.80 then let it run for 4 billion times that 37 times the age of the universe even still it falls short of 2 to the 256 operations you would have to do all of that again 4 billion times so if someone describes a cryptographic protocol as having 256bit security let's just say that it means a Brute Force attack would take a damn long time

================================================================================
VIDEO ID: GOSezO0CHss
TITLE: Order from chaos
URL: https://www.youtube.com/watch?v=GOSezO0CHss
PUBLISHED: 2023-12-15T00:00:13Z
STATUS: SUCCESS
================================================================================
this is a gton board maybe you've seen one before it's a popular demonstration of how even when a single event is chaotic and random with an effectively unknowable outcome it's still possible to make precise statements about a large number of events namely how the relative proportions for many different outcomes are distributed more specifically the gon board illustrates one of the most prominent distributions in all of probability known as the normal distribution more colloquially known as a bell curve and also called a gaussian [Music] [Music] distribution

================================================================================
VIDEO ID: TaopSi3Ucfc
TITLE: A short on shorts
URL: https://www.youtube.com/watch?v=TaopSi3Ucfc
PUBLISHED: 2023-12-13T00:00:09Z
STATUS: SUCCESS
================================================================================
I have mixed feelings about shorts. On the one hand, lots of individual shorts are  insightful and funny and even awe-inspiring. And let's be real, long-form videos on YouTube can often be  bloated and shorts are necessarily to the point, so I get the appeal. At the same time, no one I know seems to actually feel good  after a long session on shorts, or reels or TikTok or whatever. Something about the rapid barrage of instant gratification  and context switching seems to leave us feeling mentally numb. Recently, I've been posting a pile of shorts that  are all adapted snippets from pre-existing videos. And it's not just that this is the easiest way to get into the shorts feed,  readily outsourceable while I stay focused on new long-form lessons. The second ulterior motive is to offer an escape hatch. A good short is one that's thought-provoking on its own,  but unless there's a way to more deeply engage with whatever that thought is,  it feels hollow. Since we can so nicely link to other videos right at the bottom of a short,  I kind of love the idea that anyone who wants to hop out of the  feed and engage more deeply is just one click away.

================================================================================
VIDEO ID: BIbHGfdjc_g
TITLE: A pretty way to add weighted dice
URL: https://www.youtube.com/watch?v=BIbHGfdjc_g
PUBLISHED: 2023-12-12T00:00:07Z
STATUS: SUCCESS
================================================================================
suppose you're rolling a pair of dice and you want to know the probability of seeing various different sums each of these are going to be weighted dice there's a very pretty way that you can visualize the computation you need to do start by making a 6x6 grid of all the possible outcomes then the probability of seeing each one of the outcomes in this grid looks like multiplying the probability for the first die value times the probability for the second die value to be a little more visual you could represent all of these values as a three-dimensional plot now notice how all of the pairs of dice values with a given sum say a sum of six all happen to sit along a certain diagonal of this diagram likewise all of those pairs of dice values that add up to seven sit on another diagonal and so on so to think about the distribution for all possible sums what you can think about is collapsing this full three-dimensional plot along a diagonal Direction adding up all the heights of These Bars along each one of these diagonals

================================================================================
VIDEO ID: 4xWpQe3G9qI
TITLE: A simple image convolution
URL: https://www.youtube.com/watch?v=4xWpQe3G9qI
PUBLISHED: 2023-12-12T00:00:03Z
STATUS: SUCCESS
================================================================================
what's going on is I've got this little 3x3 grid of values that's marching along our original image and if we zoom in each one of those values is 1 nth and what I'm doing at each iteration is multiplying each of those values by the corresponding pixel that it sits on top of and of course in computer science we think of colors as little vectors of three values representing the red green and blue components when I multiply all these little values by 1 nth and I add them together it gives us an average along each color Channel and the corresponding pixel for the image on the right is defined to be that sum the overall effect as we do this for every single Pixel on the image is that each one kind of bleeds into all of its neighbors which gives us a blurrier version than the original in the lingo we'd say that the image on the right is a convolution of our original image with a little grid of values or more technically maybe I should say that it's the convolution with a 180Â° rotated version of that little grid of values

================================================================================
VIDEO ID: VS9yOhwtVDY
TITLE: These integrals all equal Ï€, until...
URL: https://www.youtube.com/watch?v=VS9yOhwtVDY
PUBLISHED: 2023-12-11T00:00:18Z
STATUS: SUCCESS
================================================================================
sometimes it feels like the universe is just messing with you I have up on screen here a sequence of computations and what I want you to notice is how the sequence follows a very predictable if random seeming pattern and how each computation happens to equal Pi you might think that this was a pattern that would go on forever but it doesn't at some point it stops and instead of equaling Pi you get a value which is just barely barely less than pi and before you go thinking this is the result of some numerical error maybe because we're doing something with floating Point arithmetic if you work this out more precisely here is the exact value of that last integral which is a certain fraction of Pi where the numerator and the denominator are absurd they're both around 400 billion billion billion

================================================================================
VIDEO ID: Cm-zmm0nANo
TITLE: The split necklace puzzle (with a surprise topological solution)
URL: https://www.youtube.com/watch?v=Cm-zmm0nANo
PUBLISHED: 2023-12-11T00:00:07Z
STATUS: SUCCESS
================================================================================
you and your friend steal a necklace full of a whole bunch of jewels maybe it's got some sapphires emeralds diamonds and rubies they're all arranged on the necklace in some random order right here I have eight sapphires 10 emeralds Four Diamonds and six rubies the challenge is for you to make as few cuts to the necklace as possible so that you can divvy up the resulting segments between you and your co-conspirator with each of you getting half of each Jewel type for example for the arrangement that I'm showing here I just did it with four Cuts if I give the top three strands to you and these bottom two strands to your co-conspirator each of you ends up with four sapphires five emeralds two diamonds and three rubies the claim the thing that I want to prove in this video is that if there are n different Jewel types it's always possible to do this Fair division with only n Cuts or fewer

================================================================================
VIDEO ID: yZMw2rOKYwE
TITLE: Error correction is incredible
URL: https://www.youtube.com/watch?v=yZMw2rOKYwE
PUBLISHED: 2023-12-10T00:00:26Z
STATUS: SUCCESS
================================================================================
have you ever wondered how it's possible to scratch a CD or a DVD and still have it play back whatever it's storing the scratch really does affect the ones and zeros on the disk so it reads off different data from what was stored but unless it's really scratched up the bits that it reads off are decoded into precisely the same file that was encoded onto it any file whether it's a video or sound or text uh some code and image whatever is ultimately some sequence of ones and zeros and a simple strategy to correct any bit that gets flipped would be to store three copies of each bit but what that means is using 2/3 of your space for redundancy the much more interesting question is how to make it so that errors can be corrected while giving up as little space as possible for example using the method that you'll learn about this video you could store your data in 256-bit blocks where each block uses nine bits nine to act as a kind of redundancy and the other 240

================================================================================
VIDEO ID: NQFIU5Exjuo
TITLE: The chessboard and coins puzzle
URL: https://www.youtube.com/watch?v=NQFIU5Exjuo
PUBLISHED: 2023-12-10T00:00:10Z
STATUS: SUCCESS
================================================================================
you walk alone into a room and you find a chess board each of the 64 squares has a coin sitting on top of it this is going to be one of those classic prisoner puzzles where a strangely math obsessed Warden offers you and a fellow inmate a chance for freedom but only if the two of you solve some elaborate scheme that they've laid out in this case what they've done is carefully turned over each of the coins to be heads or tails according to whatever pattern they want it to be and then they show you a key they put that key inside one of the chessboard squares each square is a secret compartment or something like that so you know where the key is and the goal is going to be to get prisoner number two to also know where the key is but the only thing that the warden allows you to do before you leave the room is to turn over one and only one of these coins at that point you walk out your fellow prisoner walks in and with no information other than the set of heads and tails that they're looking at which you've only barely tweaked they're supposed to deduce where the key is hidden potentially winning freedom for the both of you

================================================================================
VIDEO ID: h2V3r7oBeMI
TITLE: Prime spirals
URL: https://www.youtube.com/watch?v=h2V3r7oBeMI
PUBLISHED: 2023-12-09T00:00:19Z
STATUS: SUCCESS
================================================================================
I first saw this pattern that I'm about toÂ 
show you in a question on the math stackÂ Â  exchange what the user had been doingÂ 
was playing around with data in polarÂ Â  coordinates the pattern that we'll look atÂ 
centers around plotting points where bothÂ Â  of these coordinates are a given primeÂ 
number it initially looks quite randomÂ Â  after all primes are famous for their chaotic andÂ 
difficult to predict Behavior but when you zoom out what you start to see are theseÂ 
very clear Galactic seaming SpiralsÂ Â  and what's weird as some of theÂ 
arms seem to be missing and zoomingÂ Â  out even further those spiralsÂ 
give way to a different pattern [Music] these many different outward pointing rays

================================================================================
VIDEO ID: 31xm81m0iYs
TITLE: The barber pole effect
URL: https://www.youtube.com/watch?v=31xm81m0iYs
PUBLISHED: 2023-12-09T00:00:02Z
STATUS: SUCCESS
================================================================================
this is a demo that really tests your understanding of how light works what we've got here is a cylinder full of sugar water basically and a powerful lamp shining white light through a polarizing filter and there's also another linearly polarizing filter on the other end when we turn the lamp on you see that the light gets separated out into these diagonal colored bands and if you rotate that first filter those bands seem to walk down the tube like a barber pole also take note of how the light coming out the other end through that second filter is no longer white you might think okay it's whatever color happens to be at the end of this barber pole rainbow but that can't be right because rotating the second filter causes that color shining onto the wall to change and I think what I found most bizarre about the whole thing is why those stripes are diagonal wouldn't you expect the whole setup to be symmetric from the top to the [Music] bottom

================================================================================
VIDEO ID: nXIHYB0Gp70
TITLE: Fourier series
URL: https://www.youtube.com/watch?v=nXIHYB0Gp70
PUBLISHED: 2023-12-08T00:00:22Z
STATUS: SUCCESS
================================================================================
[Music] here we look at the math behind an animation like this one what's known as a complex 4A series each little Vector is rotating at some constant integer frequency and when you add them together tip to tail the final tip draws out some shape over time by tweaking the initial size and angle of each Vector we can make it draw pretty much anything that we want and here you'll see how this particular animation has 300 rotating arrows in total Go full screen for this if you can the intricacy is worth it when you consider the chaotic frenzy that you're looking at and the Clockwork rigidity underlying all the Motions it's bizarre how the Swarm acts with a kind of coordination to trace out some very specific shape and unlike much of the emergent complexity you find elsewhere in nature this is something that we have the math to describe and to control completely just by tuning the starting conditions nothing more we can make this swarm conspire in all of the right ways to draw anything that you want

================================================================================
VIDEO ID: 1tLvj_HSjPk
TITLE: Seeing with sound
URL: https://www.youtube.com/watch?v=1tLvj_HSjPk
PUBLISHED: 2023-12-08T00:00:02Z
STATUS: SUCCESS
================================================================================
let's say that you wanted to write some software that would enable people to see with their ears to make initial experiments easier you might start by treating incoming images with a low resolution maybe 256x 256 pixels and to make my own animation efforts easier let's represent one of these images with a square grid each cell corresponding with a pixel one approach to this sound to sight software would be to find a nice way to associate each one of those pixels with a unique frequency value then when that pixel is brighter the frequency associated with it would be played louder and if the pixel were darker the frequency would be quiet listening to all of the pixels all at once would then sound like a bunch of frequencies overlaid on top of one another with dominant frequencies corresponding to The Brighter regions of the image sounding like some cacophonous mess until your brain learns to make sense out of the information that it contains

================================================================================
VIDEO ID: GSIuXqgPsnY
TITLE: How prisms work (full video linked above)
URL: https://www.youtube.com/watch?v=GSIuXqgPsnY
PUBLISHED: 2023-12-07T01:31:43Z
STATUS: SUCCESS
================================================================================
I realized recently that I didn't really understand how a Prism Works you see the standard explanation what you might hear in a high school physics class for example goes something like this when light enters a medium like glass it slows down if a beam of light enters this glass at an angle then a consequence of this slowdown is that it bends a little bit or using the lingo it refracts what's going on with a prism then is that the specific amount that light slows down depends a little bit on its frequency now most of the light that you see is not a clean pure sine wave in particular the white light coming from the sun is not a clean sine wave it's something much Messier but it can be expressed as a sum of a bunch of clean sine waves each one corresponding to a pure spectral color so when you shine white light into a prism like this all those different components get refracted by slightly different amounts causing this iconic separation of the pure rainbow colors

================================================================================
VIDEO ID: P11ykXwx4-k
TITLE: I'm still astounded this is true
URL: https://www.youtube.com/watch?v=P11ykXwx4-k
PUBLISHED: 2023-12-07T01:11:14Z
STATUS: SUCCESS
================================================================================
this has got to be one of the wildest facts I've ever seen start with a 1 kg block sliding on a frictionless plane if it hits another 1 kg block assuming perfectly elastic collisions it transfers all of its momentum and what we're going to do is put an immovable wall to the left that this second block can bounce off of and for this simple example there are three total collisions it gets interesting when we make that first block bigger say 100 kg in this case it retains much more of its momentum with each Collision so it takes many more bounces before it gets turned around completely and in total the way it works out here we end up with 31 collisions if it's even bigger say 10,000 kg and with all of our idealizing assumptions where no energy is lost and things like that if you work it out exactly the total number is 314 collisions as you keep increasing the mass of that big block by powers of 100 the digits in the number of collisions will always always match the starting digits of pi

================================================================================
VIDEO ID: VFbyGEZLMZw
TITLE: Don't let it fool you!
URL: https://www.youtube.com/watch?v=VFbyGEZLMZw
PUBLISHED: 2023-12-07T01:11:14Z
STATUS: SUCCESS
================================================================================
draw two points on a circle and connect them obviously this divides the circle into two different regions if you put a third point on the circle and then draw lines connecting it to the previous points now the circle's been divided into four separate regions at a fourth Point add lines connecting it to all the previous ones and again count up how many regions the circle's been divided into this time we get eight if you start to see the pattern let's do one more at a fifth Point connect it to all the previous ones count up the regions and this time we get 16 again maybe you can guess what's coming next but would You Bet Your Life on it well let's try I'll add a sixth Point connect it to all of the previous ones and this time if I go through and meticulously count all the regions you can pause and do it yourself I'm not pulling any trickery here you actually get 31 be careful of extrapolating patterns without proof in this case there's a very good reason why it looks like powers of two until suddenly breaking at the sixth iteration it's a little too long for a short form explanation but before watching the full video on YouTube I highly encourage you to try thinking it through yourself

================================================================================
VIDEO ID: Cz4Q4QOuoo8
TITLE: Answering viewer questions about refraction
URL: https://www.youtube.com/watch?v=Cz4Q4QOuoo8
PUBLISHED: 2023-12-03T11:35:57Z
STATUS: SUCCESS
================================================================================
The last video I put out was about the index of refraction. It talked about why light slows down when it passes through a medium, and in particular, why the rate of slowdown would depend on color. It turns out people have a lot of questions about the index of refraction, and in this supplemental video I wanted to take a chance to answer a couple of them. For example, how is it possible for this index to be lower than one, which seems to imply that light would travel faster than the speed of light through some materials. To kick things off though, I want to take a question that does not require too much background, asked by Kevin O'Toole, which is why exactly light slowing down would imply that it bends as it enters a medium. There's a common analogy, which is to think of something like a car or a tank, where it turns a little bit while one side of it slows down before the other, and although it's a very visceral and memorable analogy, it's not like light has wheels, and it also tells you nothing about how to be more quantitative and derive the formula describing exactly how much light bends. Here's a better way to think about it. If you have some light wave shining into a material like glass, if it slows down, notice how that means that it gets kind of scrunched up. If its wavelength in a vacuum was some number lambda, then the wavelength inside this material, where it's gotten slowed down, is something smaller than that. Here I am drawing the wave only on a one-dimensional line, but we need to understand it in at least two dimensions, where every point on this plane, for example, is associated with a little vector in the electric field oscillating up and down. This particular animation is a little bit messy and hard to follow, so it might be clearer if instead we simply color every point of the plane, such that those points are white near the crests of the wave, and then black away from the crests. You can still clearly see the wavelength as the distance between these crests. It's exactly what we were looking at before, just drawn in a different way, and in particular notice how they're scrunched up inside the glass. If that glass were positioned at an angle, think about what happens to each one of those wave crests. As it hits the glass, the lower parts slow down before the top parts, causing it to get sort of smeared out. It reminds me a little of the rolling shutter effect, and overall the wave crest ends up at a different angle. When you take into account the fact that for a beam of light, the beam is always perpendicular to those wave crests, this means your light has to turn, and moreover you can calculate exactly how much it needs to turn. Think about all those waves in the vacuum, with some kind of wavelength lambda-1 sitting between them, and focus on all the points where those crests intersect with the boundary between the vacuum and the glass. But then consider those wave crests inside the glass. If it was the case that no bending happened, then because the wavelength is smaller in there, when you look at all those intersection points, they would have to be closer together. But of course that can't happen, whether you're looking at it from one side, or looking at it from the other, those intersection points are all the same. So the only way this can work is if those wave crests inside the glass were oriented at a different angle. You might mentally imagine turning them with a little knob to find the sweet spot angle where all those intersection points line up. And for those of you into exercises, you could take a moment to try to write down the specific equation telling you how to relate the wavelengths inside and outside the glass with the angles between those wave crests and the boundary itself. If you do this, what you write down is effectively the same thing as Snell's law, you just have a tiny bit of added work to relate the relevant angles here, and then to note how the speed and the wavelength all depend on each other. To answer the other questions I want to get to, we're going to lean pretty heavily on the explanation from the main video. I'm mostly assuming that people here will have watched that, but here's a quick recap of the key points. When we talk about a light wave slowing down in a material, what's really going on is that its interaction with each layer of that material slightly kicks back the phase of the wave. Now a continuous sequence of infinitesimal phase kicks like this produces something that's mathematically identical to a wave that's just traveling slower. The actual mechanism for that phase kick is that the incoming light wave causes the charges in the material to oscillate a little bit. Those oscillations produce their own propagation in the electromagnetic field, and when you add together this newly induced wave with the original one, then in the region of space past that layer, the sum looks just like a copy of that original wave, but shifted back a little. The last key point is that if you want to know the size of that phase shift, which is what determines the index of refraction, we model the charges in the material as simple harmonic oscillators, bound to some equilibrium position with a linear restoring force. What we found is that the amplitude of oscillation, when you shine a light on a charge like this, will depend on how close the frequency of that light is to the resonant frequency associated with this spring-like restoring force. Or to put it shortly, the index of refraction depends on how much the light resonates with charges in the material. As an example of one phenomenon that this explanation helps us to understand, let's take a question asked by Dan Stock, which is what causes birefringence? So this is a phenomenon where a material has two distinct indices of refraction, which has the effect of making you see double when you look through it. Imagine you have some kind of crystal structure such that the ions in that structure will have some restoring force when you pull them in one direction, which is distinct from the restoring force when you pull them in another direction. That is, the resonant frequency for oscillations in one direction is distinct from the resonant frequency from oscillations in another. What that means is if you shine some light through this material, then because the index of refraction depends on resonance, the value of that index of refraction will be different for light that's oscillating up and down than it will for light that's oscillating side to side. That is, it depends on the polarization of the light. And this really happens. The example you're looking at right now is calcite, and when you're seeing double, it's because light with one polarization is getting bent at a different rate than light with the other polarization. For those of you who watched the videos about the barber pole effect, a very similar phenomenon answers the final question that we left there. If you didn't watch those, feel free to jump ahead, but if you did, you might recall that where we left off was with a claim that sugar causes right-handed circularly polarized light to travel at a slightly different speed from left-handed circularly polarized light. The reason that mattered is that it meant linearly polarized light, which can be expressed as a sum of those two, will slowly rotate over time as one of those two components lags behind the other. Once you understand that an index of refraction depends on resonance, you can start to see why something like this might happen. If the molecular structure of sucrose was one such that electrons might get pushed along a path with a clockwise component more freely than they get pushed along paths with counterclockwise components, well that would mean that the resonance with right-handed circularly polarized light would be a little different from what it is for left-handed circularly polarized light, and hence the indices of refraction would be slightly different for each one. When you combine this together with the fact that the resonance depends on the frequency of the light, which is to say it depends on the color, this ultimately explains why the optical rotation in that barber pole effect separated out the colors the way that it did. Now one example of a shape that would resonate differently with left-handed and right-handed circularly polarized light would be a helix, and in fact people will use a helical antenna when they want to pick up on radio waves with just one-handedness. Although sucrose is not so clean and pure an example as a helix, the key property is that it is chiral, meaning it's fundamentally different from its mirror image, in that there's no way to reorient it in 3D space to make it look like its mirror image. I will not pretend to know why this particular structure resonates with one-handedness more than another, but at least in principle it makes sense that chirality would lend itself to this phenomenon. And finally, to wrap things up, let's hit what might be the most intriguing question of them all, which is how the index of refraction can be lower than one, since what that seems to imply is that the speed of light through a medium would be faster than the speed of light. So this really does happen, and it's not as wild as you might think. If you think back to how everything in our discussion arose from how a layer of material can kick back the phase of a wave, there is no reason that the layer of the material can't also kick forward the phase of that wave, and when you have many successive layers, kicking forward the phase like this, it gives the illusion of a wave that's traveling faster than the speed of light, in the sense that those crests genuinely are moving faster than c. In fact, when you unpack the math underlying all of this, whenever the key amplitude expression that we wrote down is smaller than zero, that corresponds to an index of refraction smaller than one. So in particular, if the frequency of the light, omega sub l, is bigger than the resonant frequency for our oscillator, you have this effect. For example, when you shine an x-ray through glass, the index of refraction really is smaller than one. There is no contradiction with causality here, and it's worth taking a moment to reflect on the role played by the speed c in all of this explanation. c is the speed determining how long it takes for an accelerating charge to induce a force on any other charge. Even if there's material in the way, whether that material has an index of refraction bigger than one or less than one, that amount of time that it takes for the influence of one charge to reach another is always the distance between them divided by c. By contrast, the speed that's relevant to an index of refraction is how fast the crest of one of those waves is moving. This is known as the phase velocity. That phase velocity is what determines how much the wave gets scrunched up, which in turn determines how much it refracts or bends, which is part of the reason I think it's very good terminology to call this the index of refraction rather than say the index of slowing. In general, the electric field inside a medium like glass is this incredibly complicated sum of a whole bunch of propagating influences from every one of the wiggling charges in that material, all together with the incoming light wave. But importantly, all of those individual propagations are traveling at c, never slower, never faster. It is miraculous that the way that these combine can be described simply at all, and that it's not some monstrously intractable mess. But we are fortunate, and when you add them all up, the net effect can be described cleanly, and it looks just like a sine wave, one whose phase velocity happens to be different from c. Another thing to keep in mind if it seems very weird for these wave crests to move faster than c is that everything in this explanation depends very heavily on things being in a steady state. That's very different from say, trying to send information through the medium with a little pulse of light. This is what Mithana explores in her videos on the index of refraction over on Looking Glass Universe, which you should definitely look at. Over there she talks about how when you express a pulse of light as a sum of many pure sine waves, even if the phase velocities of those constituent components go faster than c, that doesn't necessarily imply that the center of mass of this pulse will itself go faster than c. And in fact, when you simulate the effect of passing through a medium, when the index of refraction is less than one, what you find is a pulse that goes slower than c, even when the crests within it are going faster. And if that still seems a bit weird, here's an analogy to help see why phase velocity can be way higher than the speed of anything real. Imagine a little machine that has a bunch of rotating arms all extending from a shared shaft. If you view this machine from the side, the tips of all of those arms form what looks like a wave, with crests traveling from right to left. But if I go and reposition the arms to be angled quite close to each other, then you can make it so that the phase velocity of this emergent wave is arbitrarily high, potentially faster than the speed of light or anything else, even when the shaft is rotating at a gentle constant rate, and even when every component of the machine is moving at a reasonably slow pace. Here, it's pretty obvious that such a machine doesn't violate the rules of physics, and that it doesn't let you send messages faster than light, because the wave crest is not a real object. It's not something that could carry information. It's more of an illusion. The phase velocity in a light wave is similar. Sure, if you shine an x-ray through glass, it is true that the wave crests go faster than the speed of light, but the underlying influences between electric charges that determine the field values in the first place are themselves all bound by the speed c.

================================================================================
VIDEO ID: KTzGBJPuJwM
TITLE: But why would light "slow down"? | Visualizing Feynman's lecture on the refractive index
URL: https://www.youtube.com/watch?v=KTzGBJPuJwM
PUBLISHED: 2023-11-30T18:42:33Z
STATUS: SUCCESS
================================================================================
I realized recently that I didn't really understand how a prism works. The standard explanation, what you might hear in a high school physics class for example, goes something like this. When light enters a medium, like glass, it slows down,  in the sense that if you look at the crests of the wave,  in a vacuum those crests are travelling at c, the speed of light,  but inside the glass those crests will be travelling a little bit slower. And the specific ratio between the speed of light in a vacuum and the speed  inside a medium like this is called the index of refraction for that medium. The reason we use the word refraction instead of, say, the index of slowing,  is that if a beam of light enters this glass at an angle,  then a consequence of this slowdown is that it bends a little bit, or using the lingo,  it refracts. And the way my high school physics teacher always explained this was to imagine a  tank going from some region where it can travel relatively quickly, like concrete,  into something slower, like mud, where if it's coming in at an angle,  then as one of its treads hits the slow region first,  that tread will be going slower while the other one is faster,  causing the whole thing to steer a little bit,  until that second tread also enters the mud, then it continues straight,  just travelling a little slower. We'll get back to the actual reason for bending in a bit,  but at this point the high school physics students typically learn  a law known as Snell's law, which specifies exactly how much things bend. If you draw a line perpendicular to the boundary between the glass and water,  and consider the angle between that perpendicular line and the beam of light,  then Snell's law tells us that the sine of this angle divided by the speed of the light  is always a constant. So the slower the light, the lower that angle will be,  and that lets you actually calculate how much things refract. What's going on with a prism, then, is that the specific amount  that light slows down depends a little bit on its frequency. For example, blue light, which has a relatively high frequency,  would get slowed down more aggressively than red light,  which has a relatively low frequency. Now most of the light that you see is not a clean pure sine wave,  in particular the white light coming from the sun is not a clean sine wave,  it's something much messier, but it can be expressed as a sum of a bunch  of clean sine waves, each one corresponding to a pure spectral color. So when you shine white light into a prism like this,  all those different components get refracted by slightly different amounts,  causing this iconic separation of the pure rainbow colors. So that is the standard explanation, and it's not wrong per se,  it's just that all of the key components are handed down from on high. Why would light slow down like this? And what exactly do we mean by slowing down? And even if you understand that, why would the amount that  it slows down have anything to do with the color of the light? Is that just a coincidence, or is it necessary? If you have a sufficiently high standard for explanations,  you want both of these facts to feel discovered,  rather than feeling like they were handed down. The first explanation I saw that started to give this feeling came from  the Feynman lectures on the matter, and a lot of what I'd like to do with  this video is simply animate a lot of the key points that he makes there. It involves really digging in to think about each individual wiggling  charge in the material, and the propagating light waves caused by each  one of those charges, and how all of them superimpose on top of each other. Which feels like it should be a complete mess,  but it actually works out to be not only understandable, but satisfyingly explanatory. For example, it explains why it has to depend on color,  and the key intuition there really comes down to what happens if you're bad at  pushing a child on a swing. Bear with me, I promise that'll make sense later. Also, when I mentioned on Patreon the intention to cover this topic,  a lot of people had a lot of questions about the index of refraction. For example, numerous people asked about how it's possible for this number  to be lower than 1, which really does happen, despite that seeming to imply  the impossibility of something traveling faster than the speed of light. There was also a question about birefringence,  which is where a material can have two different indices of refraction,  causing you to see double when you look through it. And that actually ties in really nicely to putting in the final  puzzle piece from the last two videos about the barber pole phenomenon. And a couple people also asked about why light slowing down would imply a bending  like this, and I agree that deserves a better explanation than the tank analogy. I promise we'll get to all of these questions later,  but it makes sense to first lay down some groundwork by spending the bulk of  our time on the key question of why passing through a medium would change the  speed of a light wave at all. And for this, I want you to think of your material, like glass,  as being broken up into a bunch of distinct layers,  all perpendicular to the direction the light is traveling. And we'll start by focusing our attention on the  effect of just one of those layers on the light wave. The true effect would be miniscule, but if you'll let me exaggerate it for a moment,  what it does is kick back the phase of the wave. And maybe it's worth a brief aside to make sure we're  all on the same page when it comes to wave terminology. If you go and graph the function sine of x, when you put some term in front of it,  affecting how high that wave oscillates up and down, that's what we call the amplitude,  when you put a term in front of x, this will affect how rapidly it oscillates. If this is meant to describe a wave over time,  that term would be called the angular frequency,  whereas if it's meant to describe a wave over space,  that constant would be called the wave number. Then if you were to add some other constant inside that sine function,  and notice how as you change what that constant is,  it sort of slides the wave left and right, that term describes the phase of the wave. So when I say that our light wave hitting a layer of glass causes its phase to  get kicked back, I mean if you take whatever function describes it before it  hits the glass, then the function describing it after that looks almost the same,  just with a little extra something added to the input of that sine function. Like I said, in reality that'll be a very small number,  something proportional to the infinitesimal thickness of that layer,  but I'll keep drawing it as something exaggerated and keep track of the value of  that phase kick over here on the left. Let's say you go and add a bunch of other layers of the glass,  each one also applying their own kickback to the phase of the wave. The question for you is what does that new wave look like? If the value of that phase kick applied by each layer is something really close to zero,  then the wave is hardly affected at all. But the larger that phase kick, the more the wave  kind of gets squished together among all those layers. Admittedly, right here it looks all kaleidoscopic and weird,  but that's really just because I have a discrete set of layers,  each applying an unrealistically large kick. Notice what happens if I smooth it out by doubling the density of layers,  but having each one only apply half the phase kick. And then I do that again, I double the density of the layers,  but have each one only apply half the phase kick. As I continue this over and over, approaching a situation where you have a continuum of  glass, each layer applying just a tiny infinitesimal phase kick,  what you end up with is identical to, indistinguishable from,  a wave that's simply traveling slower, oscillating up and down with the same frequency,  but with a wavelength that's been kind of scrunched up. This right here is the first key idea with the index of refraction. Instead of asking why does light slow down in glass,  what we really need to ask is why does its interaction with  a single layer of that glass cause a kickback to the phase of the wave? And then when we want to get quantitative and understand exactly how much  the light slows down, which is critical for understanding why it depends on color,  instead the real question is how strong is that phase kick? From here it's helpful to turn back to the fundamentals of what light even is. This is something we talked a lot about in the last video,  but a little review never hurts, so let me go over the essentials. As many of you know, light is a wave in the electromagnetic field,  but here we'll just be drawing the electric field. The electric field associates each point in 3D space with a  little 3-dimensional vector telling you what force would be  applied to a hypothetical unit charge sitting at that point in space. The key thing going on with light is that if you have a charged  particle and something causes it to wiggle up and down,  that results in these propagating ripples in the electric field away from the charge,  and that propagation is traveling at the speed c, the speed of light. Whenever those ripples happen to reach another charged particle,  they cause it to wiggle up and down, albeit a little more weakly than the initial wiggle,  and that in turn causes its own propagations. The way we described this in the last video was that if at some point in time  a charge is accelerating, then after a little delay, which depends on this speed c,  the existence of that acceleration induces a force on another charge. We went over the specific force law describing this,  it's something that can be derived downstream of Maxwell's equations,  but for our purposes here, the main thing to tuck away in your mind is that the  amount of time it takes that initial acceleration to cause any kind of influence  elsewhere travels at exactly the speed c. And really, you should think of c not so much as the speed of light per se,  but as the speed of causality. It determines how fast any kind of influence travels,  it's just that one of multiple consequences of that is that it's the speed of light. In particular, when you get a charge oscillating up and down in a  nice clean sinusoidal motion, you can think of these rippling effects  in the electric field as describing the force that would be applied  to another charge sitting there as a result of that past acceleration. I will freely admit that I had a bit too much fun in that video just simulating how the  electric field responds to accelerating charges,  and that I'm kind of doing the same thing here,  but there are two important facts for our pursuit of the index of refraction. The first is that when you have multiple different charges oscillating up and down,  the net effect on the electric field is just the sum of what it would be  for each individual charge, which is kind of what you would expect. The way it shakes out is that if you have a row of charges oscillating  in sync with each other, or for our purposes today,  a plane of charges all wiggling up and down in sync within that plane,  then the effects of each individual charge tend to cancel each other out  in most directions, except perpendicular to that plane,  they actually constructively interfere. This is how you can get a concentrated beam of light. That's the important thing. If you have a layer of charges wiggling up and down in sync with each other,  then even far away from that layer, it produces this nice sinusoidal wave  in the electric field that we're so fond of drawing to represent light. When I draw a light wave like this, it's really only  depicting the electric field on a single one-dimensional line. A more full picture of light in three dimensions would look something more like this. That tends to be a little bit busier, so usually we just draw the sine wave. So thinking back to the question of why interactions with a layer of material  would cause a kick back to the phase of the wave, let's start thinking it through. When a light beam enters a material, like glass,  then it causes all of the charges inside that material, you know,  electrons or maybe the occasional ion, to wiggle up and down in response  to that light wave. You might think that adding together all the propagations from all those  charges is a complete nightmare, but we can think about it one layer at a time. As the light wave causes this layer to wiggle up and down,  that wiggling produces its own second-order light wave at the same frequency,  and it propagates in both directions perpendicular to that layer. The overall electric field, then, looks like the initial  incoming light wave added together with the second-order wave. By far the most distracting part of what's going on here is everything on the left,  and this actually corresponds to the light being reflected back. And from experience, you all know that when you look at water or you look at glass,  light not only goes through it, but some of it gets reflected back. And we could have a whole interesting discussion on quantifying exactly how much,  but in the spirit of staying focused, we will completely ignore that for  today and only focus on what's happening to the right of that layer. You can probably predict what I'm going to say. It turns out that when you add that second-order oscillation,  the overall effect is almost identical to the incoming light,  but just shifted back in phase by a little bit. And then because many successive shifts to the phase like this are the same  thing as light slowing down, this will ultimately explain the index of refraction. But of course the sufficiently curious viewers will now be raising  their hands and asking, why is that the effect when you add them together? And so here it might be worth a little sidebar  on how to think about adding two waves together. If you draw some sine wave with some particular amplitude, some specific frequency,  and some specific phase, and then you draw another sine wave,  also with its own amplitude, frequency, and phase,  in general it's very hard to think about what the sum of those two waves should  look like as you tweak those initial parameters. In the specific case where the frequencies are the same, which is true for our example,  the result will also look like a sine wave with that same frequency. But even then it's a little tricky to think about exactly how to describe that wave. It has some amplitude and some phase, and if I ask you to concretely compute both of  those numbers based on the amplitudes and phases of the initial waves,  it's not immediately clear how you would do that without throwing a bunch of trig  identities at the problem. But here's a really nice way to think about it. Imagine that first wave describes the y-component of some rotating vector. The length of that vector corresponds with the amplitude of our wave,  and then the initial rotation of that vector corresponds with the phase of our wave. And then similarly think of that second wave as describing the y-component of  another rotating vector, where again the amplitude corresponds with the length  of that vector, and the phase of the wave tells us the initial angle of that vector. Now to think about the sum of the two waves, just  think about adding those two vectors tip to tail. And because they both have the same frequency as both of them rotate,  their sum rotates in lockstep with them. So if you want to think about the amplitude of our resulting wave,  it comes down to the length of this vector sum,  and similarly the phase corresponds to the angle of that vector sum. In some cases this tells you things that you probably already knew,  like if the two phases happen to be the same, then you get  constructive interference and you have a bigger wave that results. And if the phases were 180 degrees out of sync,  then you get deconstructive interference with a relatively small resulting wave. What's a little bit less obvious, but what's crucial for our discussion here,  is that if the phase of that second wave happens to be exactly 90 degrees behind  the phase of the first, so kind of a quarter cycle out of sync,  and if that second wave is also very small compared to the first,  then if you look at the little vector sum on the lower left,  you'll notice how this means that the resulting wave is almost identical to the  initial wave, but has just shifted back in its phase by a tiny bit. Moreover, the size of that phase shift depends  on the specific amplitude of that second wave. So looking back at our previous animation, where we have some wiggling charges  in a layer of glass causing these second order propagations that need to be  added together with the incoming light, the way it works out is that the phase  of that second wave is exactly a quarter of a cycle behind the phase of the first. So when you add them together, you get this little phase shift. And then, critically, the size of that phase shift is bigger when that second  order wave is larger, and then smaller when that second order wave is smaller. Again, the very curious viewers will be raising their hands and saying,  why does it work out to be exactly a quarter of a cycle behind? There is a very nice reason, but it's just a little too much detail for us today. If you're curious, I highly encourage you to take  a look at the Feynman lectures on the matter. For our purposes, step back for a second and think about what you need to explain the  key question of prisms, which is why the index of refraction would depend on color at all. As you now know, that index depends on how much each layer of glass kicks back  the phase of the wave, and that phase kick depends on the strength of the  second order wave resulting from charge oscillations in a layer of that glass. So you need to drill in and understand exactly how much  those charges wiggle in response to an incoming light wave. So let's zoom in on that layer and think of each one of those charged particles,  and even though the specific molecular structure is going to be something  very complicated, we're going to model each one of those charges as if it  was bound to some equilibrium position by a spring, or maybe a set of springs. I don't mean this literally, of course, I just mean if we describe the  displacement of this charge from its equilibrium with a little vector x  that's going to depend on time, then in our model, the force applied to the charge,  pulling it back to that equilibrium, is going to be something proportional  to the size of that displacement, with a little proportionality constant k. This is the same law that governs how springs work. You might ask if that's accurate, and the idea is that for very small displacements,  it's actually a really good approximation. This is a very common thing to do throughout physics,  we would call it a linear restoring force. The idea is that maybe the actual force law depends on the position in a much more  complicated way, but we're basically taking a low order approximation near the  equilibrium. If I just run this as a simulation, plugging in this force law,  here's what that displacement looks like as a function of time. What you get looks like a sine wave, this is called simple harmonic motion,  and the frequency of this wave is going to matter a lot for you and me,  and finding that comes down to solving a certain differential equation,  because the force is really the same thing as mass times acceleration,  and the acceleration is the same thing as the second derivative of that displacement. So what we're saying is we want some function whose second  derivative looks like a certain constant times that function itself. Any differential equations students among you  might enjoy thinking about how you solve this. I won't go over the full details, but the answer is reasonably intuitive,  and anyone who knows a little calculus can just check it for themselves. The way it shakes out is that if the initial condition is that our little charge has  a velocity of zero, but it's offset from the equilibrium by a little vector x-naught,  then the way it evolves over time looks like x-naught multiplied by a cosine expression. So the amplitude of this wave is kind of uninteresting,  it just depends on how far we pulled things back originally,  but the meat is this frequency term, square root of k divided by m. And if you think about it, this should hopefully be at least a little intuitive. For example, if you increase k, which is kind of like increasing  the strength of that spring, then it results in a faster oscillation. Whereas if you increase m, the mass of the particle,  there's a lot more inertia and it results in a slower oscillation. This term, square root of k divided by m, has a special name,  it's called the resonant frequency for our simple harmonic oscillator. And being a little more precise, I should call this the resonant angular frequency. This is always a little bit of an awkwardness with physics,  where whenever you have some kind of cyclic process,  when you give an intuitive description, it's natural to phrase things in terms of the  frequency, the number of cycles that this process makes per unit time. But when doing math, it's often more natural to talk about the angular frequency,  which you could think of as describing how much angle this  process covers in radians per unit time. It's just the same as the frequency, but multiplied by 2 pi. So for example, if you have something like a cosine expression,  which you might think of as describing the x component of a cycling vector like this,  then the term sitting right in front of the t in that cosine is the angular frequency. This is why angular frequency makes the math a little cleaner. For example, in our simple harmonic motion, the term sitting in front of t  looks like the square root of k divided by m, which I'm writing as omega sub r. Let's package all of that up and call that our solution in the simple case,  where there's no external force acting on our charged particle. But of course, what we're interested in is what happens when  you shine a beam of light on this material, which intuitively  causes this charge to jiggle, but the question is how much. In our equation, this looks like adding a new force term corresponding to the light wave. That force oscillates up and down, also according to some kind of cosine function,  but this time with a distinct angular frequency, that I'm going to call omega sub l. E naught here describes the strength of the wave,  and then q describes the charge of whatever particle we're modeling. As usual, it's a lot easier to think about when we only draw a subset of that light wave,  and in this case we're going to draw it on the plane of the  layer of material we care about. You might think of gusts of wind blowing our little ball  on the spring up and down in a clean sinusoidal pattern. Or as another analogy, it's similar to pushing a child on a swing. The swing would oscillate on its own due to the force of gravity,  but you as the pusher are applying an external force which itself is oscillating  over time. Although a key difference here is that the frequency of that external force in  general has nothing to do with the resonant frequency of that little oscillator. The better analogy would be if you're pushing the child on the swing with a  cyclic force that has nothing to do with what the swing naturally wants to do. And my favorite part in literally trying to do this with my niece is that  at some point she gently murmurs to herself, this isn't how mom does it. Now, in trying to understand how much our charge is oscillating in response to  the incoming light, let me start by just simulating it and plotting the result. You'll notice that there's a little startup period where it kind of has to get going,  but then after that, mercifully, it looks nice and clean, just like another sine wave. Now you might be thinking, yeah, yeah, everything is sine waves,  but it's important to understand that this one has a very different character from the  sine wave we saw earlier. Earlier, without any external forces, the frequency of that  wave came down to the spring constant and the mass,  which is to say it depends exclusively on material properties of the glass. By contrast, with this external cycling driving force,  the frequency in that steady state is the same as the frequency of the light. And then in our first case, the amplitude of the wave was kind of uninteresting,  it just depends on how far you pulled the spring out to begin with. But in the second case, the amplitude of this wave  is actually where all the interesting stuff happens. Exactly how much will this charge be oscillating in response to the light wave? Again, I won't go over the full details of solving this,  but any eager calculus students among you might enjoy going through the exercise where  if you just guess that a solution looks like a cosine wave with the same frequency as  the light, and you solve for the amplitude, you can get a concrete solution to this  equation that looks like this. This is worth unpacking for a bit, and just to be clear,  this is only describing things in the steady state, after things have gotten up and going. A fully descriptive solution would be notably more complicated. As I said, everything interesting here comes down to the amplitude,  which here looks like a large collection of constants,  most of which should be pretty intuitive if you take a moment to think about it. For example, it is proportional to the strength of that incoming light wave,  so the stronger the light the more the oscillations. It's also proportional to the charge, which again makes sense. And the real heart of the matter comes down to what's sitting in the denominator here,  the difference between the square of the resonant frequency  and the square of the light frequency. And to build a little intuition, take a moment to think about  what would happen if the frequency of the incoming light was  something very close to the resonant frequency of this oscillator. This is analogous to the normal situation pushing a child on a swing,  where the frequency of your force lines up quite closely with what the swing wants to do. In this case, running the simulation, notice how the oscillations of  that particle will grow and grow and grow, becoming quite large over time. Some of you may know the famous example of the Millennium Bridge in London,  where on its opening day it started oscillating way more than the engineers expected  it to. And what was going on is that the frequency of the steps of the crowd lined up  very closely with a resonant frequency, causing this worryingly high amplitude. By contrast, notice what happens in the simulation if the frequency of the light,  Ï‰L, is something much smaller than the resonant frequency. For this particular simulation it takes a little bit of a moment before  things get into their full swing, eventually it finds a nice sinusoidal motion,  but the amplitude of that motion is much more modest in comparison. So what our equation is telling us is that the larger the difference between those  frequencies, then the bigger the denominator, so the smaller the overall wiggle to that  charge. And again, this is something you can see in the footage with my niece. As I'm applying a force with a frequency that's very different from  what the swing wants to do, she ends up oscillating at the same frequency as my force,  but she's going at a relatively low amplitude. Stepping back, what this means is that as you shine light into a material,  like glass, it's not just that it induces wiggles in the charges of that material,  but the specific size of those wiggles depends on the frequency of the light,  as a consequence of this denominator term. And the more those wiggle, the bigger the size of this second order wave caused by  that layer, which in turn causes a bigger shift to the phase of the overall wave. Because a lot of different shifts to the phase are what causes  this apparent slowdown to the light, it means that the amount that  it will slow down ultimately depends on the frequency of the light. So that is the real reason why prisms work. You cannot truly explain the light separation  until you get down to the driven harmonic oscillator. Now, I have left out a number of details, and again,  I encourage the curious viewers to take a look at the Feynman lectures that  a lot of this is based on. One quite important detail that would be a little criminal not to mention is that when  we're modeling our charge as a little harmonic oscillator with this linear restoring  force, there should really also be a term that depends on the velocity of that charge. You might think of this as a kind of drag force. This term accounts for the fact that energy from  the incoming light wave is absorbed by the material. Without it, this whole explanation would seem to imply that light always passes through  every material, not just glass and water, when as you can tell just by looking around,  there's all sorts of materials for which light is mostly reflected and absorbed. As I mentioned at the start, folks on Patreon had numerous questions  about the index of refraction, like how it can be less than one,  and why slowing implies bending, so I made a supplemental video answering  a handful of those questions, which should be published in just a few days. In the meantime, my friend Mithuna from the channel Looking Glass Universe  just put out a pair of videos on the related but definitely distinct question  of whether light slows down in a medium, not in the sense of following the  crests of a clean pure sine wave in a steady state,  but in the sense of trying to send information through that medium,  like with a little wave packet. I definitely owe the existence of this video to many conversations with her about this  topic, and viewers here will definitely enjoy taking a look, especially at the second one. By the way, some collaborators and I made this notebook that I think a lot of viewers  might enjoy, and given that it's the holiday season it seems worth a quick mention. The premise is that every one of the pages has a quote that's related to math,  and I had a lot of fun curating them all, trying to constrain myself  to quotes conveying some genuinely thought-provoking idea. And aside from the content, I basically made the kind of notebook that I most enjoy  taking notes in, something that's readily portable with very faint grid lines helpful  for diagrams but otherwise unobtrusive, all bound in this nice soft faux leather. If that seems up your alley, you can find them in the  3blue1brown store next to a lot of other mathematical merchandise.

================================================================================
VIDEO ID: 6a1fLEToyvU
TITLE: 25 Math explainers you may enjoy | SoME3 results
URL: https://www.youtube.com/watch?v=6a1fLEToyvU
PUBLISHED: 2023-10-07T14:28:37Z
STATUS: SUCCESS
================================================================================
This year we ran the third Summer of Math Exposition, which is a contest aimed at encouraging more people to put up math explainers online, in whatever way they dream of doing that. A lot of them are videos, not all of them are videos. Every year we select some winners, but I say at every time the contest is not actually about the winners, success looks like getting more good explanations online. Now last year in the winner announcement video I talked all about the specific criteria I try to think about. I won't necessarily repeat that here, you can watch that one for all that. Instead I thought I'd just go down 25 different entries and say a couple of words on what I like about each one. Before I dive in, I've got to be honest, I found it especially hard this year to actually make the decisions for what constitutes an honorable mention, what constitutes a winner. And to be clear, I'm not the only one making decisions here, we have a whole bunch of guest judges who helped, I'm really just assembling my own feedback on everyone else's. But nevertheless at some point you have to make a call that says this one is a winner, this one is an honorable mention. And I think I realized one of the reasons that it was so hard is I don't think there's such a thing as a generally good math explainer for a general audience. I think there's such a thing as a pretty good video for a general audience, and I think there's such a thing as great videos for very specific audiences. And in some ways it's that second category that is where the internet really shines, where you have something that maybe isn't perfectly tailored for everyone because it can't be, but for that particular audience that it's great for, it's kind of the best thing you could have asked for. And I'll actually give one example. So one of the entries that I want to showcase for you is called Pixel Art Anti-Aliasing. It's all about the task of taking a piece of two-dimensional really low resolution pixel art, but displaying it in a three-dimensional potentially high resolution environment. I found it fascinating, and I think anyone who's really into computer graphics, and especially anyone who enjoys shader programming, would find this completely fascinating. For that specific audience, I am very confident in saying, watch it, you'll enjoy it, you're going to get something out of it. Now this one does a good job of motivating the mathematical ideas that go into it, even if you aren't necessarily into shader programming. But if I'm expanding the scope of who I might be recommending this to, to any generally math curious internet goer, well, you know, that makes a couple assumptions for things you might know about that maybe not everyone does. And to be fair, omitting certain fundamentals is the correct choice for the target audience. Now the next entry, and by the way, I randomly sorted this list of content that I want to go through ahead of time. I'll talk about which ones were chosen as winners at the very end. This next one is called The Math of Saving the Enola Gay. So this is talking about the plane which dropped the nuclear bombs in World War II. And the author acknowledges that there's some obvious moral questions associated with the mission itself. But the focus is on the surprisingly interesting physics question of the best route that the plane should take after dropping the weapon to avoid paying potentially calamitous consequences of the aftershock of the weapon itself. And what I appreciate is that he really does go into the full detail of the problem itself. And this is the kind of video lecture I could imagine as being a really, really excellent case study that you could use in a high school physics class or something like that. It's a worked example that covers a lot of very fundamental ideas that you would need for a class like that. And whereas often on YouTube it can make sense to kind of skip over some of the heavier details and mention that this is best left as an exercise to the viewer or something like that. I really respect those who actually do step through all of the detail because that most authentically reflects what the feeling of doing math is and the amount of time that it can take. So it's definitely something to watch when you're in the mood for details. But when you are, it's excellent. Next up is Making a Pitch Shifter. And so this is the technology that allows you to auto-tune and things like that. And also it's an equivalent problem to how you speed up or slow down audio without changing the pitch of it. For example, I imagine a lot of you are watching this video at 1.5x or 2x. And if you step back and think about what's required to make that work, it's actually a very interesting question. And this video goes through a lot of the different ways that you might think about it, some of the initial approaches, quirks associated with those. It shows the code that he's using along the way. It's a great practical problem and who doesn't love a little more forte in their lives. Next up we have a non-video entry. This one is Cayley Graphs and Pretty Things. This is another example where for the right audience, this is an excellent piece of content. In this case, I think that audience would be students in group theory. In particular, I think what it does an excellent job describing is the semi-direct product. So it describes a lot of other things, but it builds up to this, which is a very specific and kind of niche thing that a group theory student might come across. Might be a little bit confusing in the book. The way that everything is explained here gives a really satisfying mental image that you can hold in your head for that, which is great. Ah, okay. The next one is the longest increasing subsequence. I talk about one of the things I'm looking for as being memorable pieces of content. This channel definitely satisfies that because for the last three years, I remember the entries that they put in. They have a very particular style, a very distinctively clear way of talking about what would usually be rather technical topics. And here I'm envisioning the target audience as probably being the same kind of people who would attend like a seminar in a math department, curious undergrads or some of the grad students in the department. Because it describes a problem which to be perfectly fair, you might not care about if you're not already super into math. It's talking about if you have a random permutation, what might you expect the longest increasing subsequence in that permutation to be? So a very natural, but very pure question. The tactics brought to studying this are surprising, but really well motivated in the context of the video. And I think just really beautiful to think about. Next up, we've got another non-video entry, the Matrix Arcade. And this one, I think I remember in the peer review, might've gotten marked down a little bit more than some of the others. And I'm guessing it's because one of the things we mentioned looking for in any given content piece is novelty. And in terms of topic matter, this one covers a lot of the same things as the Essence of Linear Algebra series that I made way back when. But I do actually think this one is worth highlighting because even if there's overlap in the subject matter, I think presenting it in this mode in an interactive way where at the end you offer a playground that someone can go through. And along the way, each idea is really well illustrated on the main screen and really well described in the text on the right. That adds something that I've wanted to see added to the space for a long time. And I could absolutely see recommending this to teachers of linear algebra. It's a great link that you can send to someone. Next in my randomly sorted list of featured content is a video called Watching Neural Networks Learn. And on the one hand, it's very beautiful. A lot of the imagery comes from a certain way to visualize the gradient descent process or what the neural network can do during that process. But the thing that really sold this for me was not so much the nice visuals, but there's a really thought provoking discussion in here on the choices that you can make as you set up the network and what different features you can use. And in the context of learning a function that describes a two dimensional image, why Fourier series in particular end up giving dramatically better results. And I had never thought about this particular combination of ideas before and I thought it was just really fascinating. Next up, we've got an article, Functions are Vectors. This is one of those topics that's just very important. There's a time in your life before you think about functions as vectors and there's a time in your life after you think about functions as vectors. And this article was just very thorough and well explained. And I think it's one of the best resources out there to transition someone between those two states. Next up, we've got the Art of Linear Programming. And this addresses a class of problems that come up in computer science and the algorithmic way of thinking about a good way to solve them. And the approach that the author takes, which I always think is a very good one in any kind of education, is to just start with one of the most simple, non-trivial examples that you can have and really just working through what everything looks like in that context as he then goes on to describe the more general or sometimes more constrained situations where those similar ideas can apply. It's well illustrated, the ideas along the way are well motivated, so just a bang up job all around. This next one is actually a little different. It's called The Mosaic Problem, How and Why to Do Math for Fun. So the author is describing a very specific question that they were once contemplating. You know, I think a criticism that you could lay is that there's not a lot of motivation for why you might care about the problem. But that's not actually what the video is about. He's really just using this as an example of what he calls a backburner problem. And this is an idea that I think is very much worth getting into the minds of more math students out there. Essentially it's that if you have some sort of problem that you care about and you think about, even if no one else does, as long as it's brought out your own curiosity, and when you go into new math classes, you have that as a problem that you can kind of turn to every now and then, it offers a fertile ground for adding context to a lot of math out there, which is sometimes so desperately lacking a good context that motivates the students. So for his particular question, this mosaic problem, he talks about how it made relevant certain ideas like generating functions and principles of inclusion and exclusion. And his broader point is not that this particular problem is the most important in the world, but that having a backburner problem of some kind is actually one of the best ways to stay engaged with math. And that I would definitely agree with. And I guess on the topic of problems which probably don't really matter, but are fun to think about and end up being a path to some actually interesting math, the next one, affording a planet with geometry, is I think the only claymation entry that I saw this year used to good effect in describing a certain optimization problem, framed in the context of deciding what shape you want to turn your planet into if you want to experience a certain amount of gravity, but not use too much mass to do it. It's well explained. If you're into that kind of problem, definitely check it out. Next up we've got when can't math be generalized, the limits of analytic continuation. And thinking in terms of target audiences, anyone who's taking a complex analysis class, this is outstanding, perfect for them. Anyone who might have a complex analysis class in their future, I think this does a good job setting up some of the ideas that you run across in that. It's not talking about generalizing math in the sense of applying it to a general set of circumstances, but in a setting where sometimes you can take a function defined on one domain and extend that definition beyond it, there are circumstances where you actually can't do that. And he offers a really clear description of what exactly we mean by extending in this context and then an example where you can't do that that seems like it's sort of dropped in from out of the blue, but it gives a really satisfying reason for why this example would have the properties that it does with some suggestion for how you might have come up with that. And the next step is just a very cute example of an argument in geometry. Some of you might have thought about this before, but if you translate something and then rotate it, or maybe you rotate and then translate, it's always possible to express the composite motion there as some kind of rotation about some point. And of course, there's a slight caveat there where if you just translate it but rotate it zero degrees, that's not the same as a rotation. And this video offers just a really well illustrated proof of why that's the case. And I think what stuck out to me is the way that the second half of the proof was framed in terms of this kind of game that you're playing with a certain demon, which takes what otherwise is maybe a little bit of a confusing set of logical steps that leads to a contradiction, and instead just makes it a little easier to hold on to while you're following all of the reasoning. So I appreciated that. Ah, so the next one, rethinking the real line. I really liked this one, and it stood out from many others, for one thing just because it felt very natural, like the presentation didn't feel like it was scripted or over-edited in any way. But what really shown is the subject matter. And again, I think the sense in which it's great is for a particular target audience. So in this case, if you've ever thought about visualizing rational numbers or rational approximations of irrational numbers, it offers just a really dense set of very nice ideas for how to think about these topics. And they're all connected with each other very nicely. And I, for one, felt like I came out of it armed with a few more mental constructs for how to think about a few of these ideas, which is, of course, just such a nice feeling. All right, next we've got how did the ancient Egyptians find this volume without algebra? So this is a question which is interesting in terms of the history of math or what you can do without certain ideas that we take for granted. So the problem at hand is how you find the volume of essentially a pyramid where you cut off the top of it. The author talks about how the Egyptians had this formula for it, which is, of course, not written algebraically. People didn't think algebraically back then. But he addresses how it's actually very surprising to get to that formula if you don't think algebraically. And so tries to address the problem of how might you find this idea as a algorithm for finding the volume not expressed as a formula without being able to manipulate the formulas that you or I would naturally manipulate to land on that idea. This next one, I think, has one of the best hooks of any of the ones that I've seen before. So he essentially asks if you're swinging a ball on a rope above your head, and then at some point you release the rope, you let go of the rope, what happens to the ball with the three possibilities that it continues on the circular path, that it continues on the straight line path tangent to the circle, or it goes on this straight path away from the circle. And I guess I'll just say it's not the answer that most people say it is. And he does, I think, a really good job laying out the intuition for why that's not the case, and then demonstrating it experimentally. Also on the more physics-oriented side of things, we have the math of bubbles, minimal surfaces and the calculus of variations. So again, there's a great hook here where the problem at hand is to understand the shape of the surface that you get if you take two cylindrical boundaries and then form a bubble in between them, where the relevant physics at play is that bubbles try to have the minimal surface area that they can subject to some kind of boundary conditions. The way to solve this problem is to bring in something known as the calculus of variations. It's very important in other contexts. For example, if any of you have ever heard of Lagrangian mechanics, and the author here describes the general framework used for not just this problem, but a wide category of problems and works through it for this particular case. Again, it's one of those where to get the most out of it, you've got to be in the mood for some details. And in this one, he does leave a lot of room to kind of pause and think through things where if certain steps are something you might have thought about before, you don't have to linger on it too much. But definitely if it's the first time you're going through any calculus of variation example, it is something you kind of need to stop and digest for a bit. And he leaves the room for that, which is nice. Next up is another non-video entry, which I think is a really just perfect example for any calculus 2 class out there. Any teachers looking to pull in something, I think this is a really great resource. The question is very simply, how do computers calculate logarithms? What happens when you're clicking that button? He goes into things like Taylor series, but then perhaps more importantly, why the simple naive Taylor series approach here doesn't necessarily get you something as good as you might want. That last step is really well motivated, really well described. So if you're curious, go take a look. Next on the docket, we have what happens if you add fractions incorrectly? So if you ask elementary schoolers to add fractions together, there's kind of this instinct to just add the numerators and add the denominators. If that's happening, it's probably a sign that the student doesn't appreciate what's actually being represented or that the rules of math actually have a reason for them. And you need to think through those reasons. But the funny thing is that operation, which is not adding fractions, is actually the start of a surprisingly far ranging set of ideas in other parts of math. It has a special name, it's known as the mediant. The author essentially walks through this pretty wide space of different things that this seemingly arbitrary operation can lead you to. It's actually pretty connected with the one we were talking about a couple minutes ago on reimagining the reals, things like rational approximations. It also talks about Dirichlet's theorem. Forward circles are in there, who doesn't love a good forward circle? So if you're curious about the meandering set of ideas that you can be led to here, definitely do take a look. Next we've got, can you guess a shape from its shadows? So maybe you've thought about this kind of problem before. If you take a 3D shape and you look at its shadow from one direction, shadow from another, and then shadow from a third, can you reconstruct what that shape is? And he mentions a seemingly obvious example where all three of those shadows are squares, so you think the answer is a cube, but it's actually dramatically more interesting than a cube. And he talks about the set of shapes that you can get from this. Ah, okay, so the next one, stylistically, is one of the most distinct of all of them, which I always appreciate, especially if I'm going through hundreds of different explainers and trying to make a decision. At first when I was watching this, I was like, wait, what's going on here? Why is he just kind of like walking around in a bunch of different places? But he has this really kind of calming way of incorporating a bunch of different environments and nature into these otherwise sometimes pretty technical descriptions of what he's talking about. And the topic matter, broadly speaking, is fixed point theorems. So this is one where I can imagine the target audience being like a math major or someone who has reason to care about fixed point theorems. And as it goes on, he does get into some real depth of it. We're closing in now towards the end of my randomly sorted list of featured videos. I guess the next one is not actually a video. I keep saying video is a generic stand in for content. But the next one is an article describing how computers represent numbers, in particular floating point numbers. And I've seen other explainers for floating point representations out there before, but I think this is the best one that I've seen. And I really appreciate the approach that he takes, which is to have you imagine that you want to represent them and go through a refined set of ideas where each one is not quite what the final answer ends up being, but motivates the next step in a nice way. This genre of discovery fiction, I think works especially well when you have topics that seem like they have a lot of arbitrary or unexpected choices along the way. It's just really well explained. I liked it a lot. All right, next on the list, we've got mathematical magic mirror ball. Say that five times fast. Essentially describing how if you take a picture of a spherical mirror, you can use that image to reconstruct a 360 degree view of the room all around it. And he described how that works, what it's used for, what the trade offs are all around just a great application of a pretty surprising phenomenon. All right, this penultimate one on my list is just actually kind of amazing. The person built this machine, which will weave a string along a whole bunch of pegs around a circle, such that as those strings intersect very densely at some points to make it dark and very sparsely at others to make it light, you can reconstruct an image. That's just amazing that such a thing is possible. And the author describes the process for how this was made and the various ideas that he tried, the reasons that they didn't work. It both motivates a lot of mathematical ideas, while also acknowledging that sometimes the thing that seems like very clever, pure math that you're bringing in to address a problem just isn't actually very effective. And that what's more important when you're applying math to the world is to find the right framing of the problem in the first place. And this is just a lesson I think is worth emphasizing a little bit more in math, that rather than trying to find a better solution to a particular problem, you want to instead ask whether the problem that you're solving is actually the right problem to be solving. And then last but not least on my list here is another one that I just recognize the author immediately because it's such a distinctive style that I've seen in the last two years, where the topic matter broadly speaking is infinity. What exactly does one mean by that? Like everything on this channel, it is unreasonably beautifully illustrated. And in just 20 minutes, you know, he hits on a lot of the really big important ideas around what exactly infinity means and how those ideas all relate to each other. So that's a wrap for the ones that I wanted to mention right now and highlight to you. There are many more, of course, that were submitted and quite a few that are worth looking at even if I didn't mention them here. Again, I do think what makes the judging here at the end so hard is that what makes something good is usually the sense in which it's good for a very specific audience and trying to come up with any notion of how to rank all of these against each other in an objective way. And for the different target audiences, it's just an apples to oranges comparison. With all of that said, the ones selected as winners, the ones collecting the golden pie creature prizes, are the mathematics of string art, minimal surfaces and the calculus of variations, rethinking the real line, pixel art anti-aliasing, and from the non-video category, how computers use numbers. So evidently, shortly after this point in the recording, my camera battery died, which I guess is almost perfect timing. I do want to close out though by saying a really big thanks to James Schloss for all the organization and helping to make this happen, to Fred Crozetier for the web development and putting together a new peer review system, which made everything this year just much, much smoother, and many, many thanks to the kind folks at Jane Street for providing the funding both for the prizes associated with the winners and honorable mentions, and also with other costs associated with running the event. Also, at the end of August, a ton of you participated in the peer review process, and I really just want to say thank you for donating your time to doing that. And then of course, thank you to everybody who made some kind of math explainer for the event. There are many really good ones that I didn't have the time to talk about in this video. In the description you'll find a link to a playlist for all the video entries, and then on the website we'll include a list of all the non-video entries. So do check them out, I can almost guarantee that if you scroll through and see what you're interested in, you'll find some hidden gems in there.

================================================================================
VIDEO ID: aXRTczANuIs
TITLE: How wiggling charges give rise to light
URL: https://www.youtube.com/watch?v=aXRTczANuIs
PUBLISHED: 2023-09-01T13:39:37Z
STATUS: SUCCESS
================================================================================
In the last video, you and I looked at this demo here,  where we shine linearly polarized light through a tube full of sugar water,  and we saw how it rather mysteriously results in these colored diagonal stripes. There, I walked through the general outline for an explanation,  keeping track of what questions still need to be answered. Namely, why does sugar water twist the polarization direction of light? Why does that twisting rate depend on the color of the light? And why, even if you understand that this twist is happening,  would you see any evidence of it when viewing the tube from the side,  with no additional polarizing filters? Here, I'd like to begin with the very fundamental idea of what light is,  and show how the answer to these questions can emerge from an extremely minimal set of  assumptions. In some sense, the fundamental question of electricity and magnetism is how  the position and motion of one charged particle influences that of another. For example, one of the first things you learn, say in a high school physics class,  is that charges with the same sign tend to repel each other. And the strength of this force depends a lot on the distance between them. If your charges are close, that repulsive force is very strong,  but it decays very rapidly as these particles go away from each other. Specifically, here's how you might see this written down as an equation,  known as Coulomb's law. The force is proportional to the charge of both of the particles,  where it's common to use the letter q. There are some constants in there, which for our purposes  we can just think of as one big proportionality constant. And the important fact is that you've got this 1 divided by r squared term,  where r is the distance between them. So for example, if the distance between them increases by a factor of 3,  the force that they're applying to each other goes down by a factor of 9. Another way you might see a law like this written down is to focus on just one  charged particle, and then say for every point in space,  if there was a second charge there, what force would this first charge be applying  to that second one? And instead of describing a force per se, you might see this  written describing what's known as the electric field,  which is just a way of saying what force would be applied to a unit charge. And in this context, the word field means there's  a value associated with every single point in space. So the way I have it written here, it depends on a little vector r,  which would be the vector from our charge to a given point in space,  and the direction of this field at all points is in the same direction as r. I bring up Coulomb's law to emphasize that it's not the full story. There are other ways that charges influence each other. For example, here's a phenomenon that this law alone could not explain. If you wiggle one charge up and down, then after a little bit of a delay,  a second charge some distance to its right will be induced to wiggle up and down as well. We can write down a second law, which you might think of as a correction  term to be added to Coulomb's law, that describes what's going on here. Suppose at some point in time t0, that first charge is accelerating. Then I'll let time play forward, but leave on the screen a kind of ghost of that  particle indicating where it was and how it was accelerating at this time t0. After a certain delay, this causes a force on the second charge,  and the equation describing this force looks something like this. So again, it's proportional to the charge of both of the particles,  and once more a common way to write it involves this pile of  constants that you don't really need to worry about. The important factor I want you to notice is how the force also  depends on the distance between the particles,  but instead of decaying in proportion to r squared, it only decays in proportion to r. So over long distances, this is the force that dominates, and Coulomb's law is negligible. And then finally, it depends on the acceleration of that first particle,  but it's not the acceleration of that particle at the current time,  it's whatever that acceleration was at some time in the past. How far in the past depends on the distance between the particles and the speed of light,  denoted with c. The way to think about it is that any form of  influence can't propagate any faster than this speed, c. In fact, a more accurate description of Coulomb's  law would also involve a delay term like this. Again, the intuitive way to read this equation is that wiggling a charge in one  location after some delay causes a wiggle to a second charge in another location. And actually, the way I have it written right now is a little bit wrong. Instead of the acceleration vector here, I should really be writing  something like a perp, indicating the component of that acceleration  vector which is perpendicular to the line drawn between the two charges. In other words, when you wiggle that first charge,  the direction that the second charge wiggles is always perpendicular  to the line between them, and the amount that it wiggles gets weaker  and weaker when that line between them is more lined up with the initial acceleration. As before, this is something you might see written down in a way that  describes a component of the electric field caused by just one charge. Again, that means what force would be applied to a  second charge at all possible different points in space. This component of the field is only ever non-zero when our first  charge is moving somehow, when it has an acceleration vector on it. And because of this delay term, the effects on  this field tend to radiate away from the charge. This is why I'm writing it down with the subscript rad. This is the component of the electric field that will radiate away from a given charge. For instance, when the charge is oscillating up and down, you get these propagating waves. And for many of the vector fields I'll be showing,  the intensity of the field is illustrated with the opacity of each little vector. This radiating influence is light, or more generally, electromagnetic radiation,  including things like radio waves and x-rays and all that good stuff. As a side note, you sometimes see this propagation described a very different way  that puts the fields front and center, using what are known as Maxwell's equations. For our purposes, I want to focus just on this one law and show  just how far it can take us when it comes to intuitions for light. For the animations I'm about to show, all I've really done is encoded in this one law,  which tells us what should this component of the electric field be at every point  in space, as determined by the history of accelerations of a particular charge. For example, if I set that charge oscillating up and down in the z direction,  and illustrate this component of the electric field everywhere on the xy plane,  you see these circular propagations of equal strength in all directions. It's a little easier to think about if we focus on just one axis, like the x-axis. And at first when I made this animation, I assumed that there was some kind of bug,  because near the charge it just looks crooked and wrong. But when you think about it, this is actually what you should expect,  because remember, each one of these vectors is supposed to be perpendicular to  the line drawn between that point and where the charge was at some point in the past. At points that are far enough away from the charge,  which is where this component of the field is what dominates anyway,  the wiggling in the field is essentially parallel to the wiggling in the charge,  which is why when we think about light waves, we're safe to think about the wiggling  direction as being perpendicular to the propagation direction. Like I said, this propagation for just one charge is equally strong in all of  the directions perpendicular to its wiggling, and really I should emphasize  that the propagation does happen in all directions of three-dimensional space. It's maybe a little busy to try to illustrate the full three-dimensional vector  field on screen like this, so it's clarifying if we just focus on, say, the xz plane. Notice how the waves here are strongest in the x direction,  but it still does propagate in all other directions,  it's just that that propagation gets weaker in directions that are more  aligned with the original wiggling. At the extreme, the only place where there's no propagation is in the z axis. Because our law has this 1 divided by r in it,  the strength of the wave caused by just one particle does decay as you go farther away,  in proportion to 1 over r. But notice what happens if I take a whole row of charges, say oriented along the y axis,  and I have them all start wiggling up and down in the z direction,  and I illustrate the combined effects that all of them have on this component of the  electric field. The effects of all these charges interfere deconstructively along the y direction,  but they interfere constructively along the x direction. This is what it looks like for a beam of light  to be concentrated along just one dimension. So if you were to focus on the field just along the x axis,  instead of decaying in proportion to 1 over r,  this combined effect decays much more gently. In the extreme, you can get something arbitrarily close to those pure sine  wave propagations we were illustrating earlier,  if at some distance away you have a large number of charges oscillating in  sync with each other like this. One thing that's worth emphasizing when you see light illustrated  with a sine wave like this, is that even though that wave is being  drawn in two or three dimensions, it's only describing the electric  field along a one-dimensional line, namely the base of all those vectors. It's just that to draw the vectors you have to venture off of that line. Great, so one of the last important things to highlight  before we get back to the sugar water is polarization. In everything I've been showing, the driving charge is just oscillating along  a single direction, like the z axis, and this causes linearly polarized light. But it doesn't have to happen like that. For example, if I set the charge rotating in a little circle along the yz plane,  meaning its acceleration vector is also rotating in a little circle,  notice what the field looks like. This is known, aptly enough, as circularly polarized light. Honestly, it's easiest to think about for just one point of the electric field. What it means for light to be circularly polarized is that at that point,  the electric field vector is just rotating in a circle. People often find circular polarization a little confusing,  and I suspect part of the reason for that is that it's hard to illustrate with  a static diagram, but also it's a little confusing when you try to think about  the full electric field. For example, here's what the field looks like on the xy  plane when I set that little charge rotating in a circle. It's certainly very beautiful, I could look at this all day,  but you can understand why it might feel a little confusing. The very last thing I'll mention is that while everything here is a classical  description of light, the important points still hold up in quantum mechanics. You still have propagating waves, there's still  polarization that can be either linear or circular. The main difference with quantum mechanics is that the energy in this wave doesn't  scale up and down continuously, like you might expect, it comes in discrete little steps. I have another video that goes into more detail,  but for our purposes, thinking about it classically is fine. Part of the reason I wanted to go through that is because, frankly,  it's just very fun to animate and I like an excuse for a fundamental lesson. But now let's turn back to our demo and see how we can build up an intuition  for some of our key questions, starting from this very basic premise that  shaking a charge in one location causes a shake to another charge a little bit later. And let's start by actually skipping ahead to question number three,  why do we see the diagonal stripes? To think about this, you need to imagine an observer to the side of the tube,  and then for a particular pure color, say red,  if the observer looks in the tube and sees that color,  it's because light of that color has bounced off something at that point in the tube,  and then propagated towards the eye of the observer. Sometimes when people talk about light bouncing off of things,  the implied mental image is a projectile ricocheting off of some object,  heading off in some random direction. But the better mental image to hold in your mind is that when the propagating  light waves caused by some wiggling charge reach some second charge causing it to wiggle,  that secondary wiggle results in its own propagation. And for the animation on screen, that propagation goes back to the first charge,  which itself causes a propagation towards the second. And this is what it looks like in a very simplified situation  for light to bounce back and forth between two charges. If you have some concentrated beam of polarized light interacting with some charge,  causing it to wiggle up and down, then these resulting second-order propagations  are most strong in the directions perpendicular to the direction of polarization. In some sense, you could think of light as bouncing off of that charge,  but the important point is that it doesn't bounce in all directions equally. It's strongest perpendicular to the wiggle direction,  but gets weaker in all of the other directions. So think about our setup, and for a particular frequency of light,  how likely it is that an observer looking at a particular point in the tube will  see that light. Again, the key phenomenon with sugar water, which we have yet to explain,  is that the polarization direction is slowly getting twisted as it goes down the tube. So suppose the observer was looking at a point like this one,  where the polarization direction happens to be straight up and down. Then the second-order propagations resulting from wiggling charges  at that point are most strong along the plane where the observer is,  so the amount of red that they see at that point would look stronger. By contrast, if they were looking at a different point in the tube like this one,  where the wiggling direction is closer to being parallel to the line of sight,  then the direction where the scattering is strongest is not at all aligned with  the observer, and the amount of red they see is only going to be very weak. And looking at our actual physical setup, if we first pass the light  through a filter showing only the red, we see exactly this effect in action. As you scan your eyes along the tube, the intensity of red that you see goes  from being high to being low, where it's almost black, back to being high again. As an analogy, imagine there was a ribbon going down the tube,  always aligned with the polarization direction for this color,  then putting yourself in the shoes of the observer,  when you look at points where the ribbon appears very thin,  you're going to see very little red light, whereas if you scan your eyes over  to points where the ribbon appears thicker, you're going to see more red light. One thing that's nice about this is that if we try it for various different colors,  you can actually see how the twisting rates are different for each one of the colors. Notice with red light, the distance between where it appears brightest and where it  appears darkest is relatively long, whereas if you look down the colors of the rainbow,  distance between the brightest point and the darkest point gets lower and lower. So what you're seeing in effect is how red light twists slowly,  whereas light waves with higher frequencies get twisted more aggressively. But still, you might wonder why the boundaries  between light and dark points appear diagonal. Why is it that in addition to having variation as you scan your eyes from left to right,  there's also variation as you scan your eyes from the top of the tube to the bottom? This has less to do with what's going on in the tube,  and more to do with a matter of perspective. Take a moment to think about many different parallel beams  of light ranging from the top of the tube to the bottom. At the beginning, all of these light waves are wiggling up and down,  and as you pass through the tube, and the effects of the sugar water  somehow twists these directions, because they're all passing through  the same amount of sugar, they're getting twisted by the same amounts. So at all points, the polarization of these waves are parallel to each other. If you're the observer and you look at the topmost point here,  its wiggling direction is essentially parallel to the line of sight,  so the light scattering from that point is basically not going to reach your eyes at all. It should appear black. But if you scan your eyes down the tube, the angle between the line  of sight and the wiggling direction changes, and so there will be  at least some component of red light scattering towards the eye. So as you scan your eyes from top to bottom, the amount of  a particular color you see might vary, say from dark to light. The full demo that has white light is basically a combination of all  these pure color patterns that go from light to dark to light with  diagonal boundaries between the intense points and the weak points,  hence why you see diagonal boundaries between the colors inside the tube. And now at last let's turn to the heart of the matter and try to explain why  interactions with sugar would make light twist like this in the first place. It's related to the idea that light seems to slow  down as it passes through a given medium. For example, if you look at the crests of a light wave as it goes into water,  the crests through the water are traveling about 1.33 times slower  than the crests of that wave would travel in a vacuum. This number is what's called the index of refraction for water. In a bit, what I'd like to show is how this index of refraction can be explained by  analyzing how the initial light wave shakes all the charges in the material and how  the resulting second order propagations superimpose with that original light wave. For right now, I'll just say that the interactions with each layer  of the material ends up having the effect of slightly shifting back  the phase of the wave, and on the whole, this gives the overall  appearance that that wave moves slower as it passes through the material. Skipping ahead to what's going on with sugar, the relevant  property of sucrose here is that it's what's called a chiral molecule,  meaning it's fundamentally different from its mirror image. You could never reorient it in space to become identical to its mirror image. It's like a left hand or a right hand. Or another much simpler example of a chiral shape is a spiral. If I take this right-handed spiral, then its mirror image is a left-handed spiral,  and no matter how you try to rotate and reorient that first one,  it'll never become identical to the second. What's going on then is that the presence of a chiral molecule  in the water like this introduces an asymmetry when it comes to interactions with light,  specifically circularly polarized light. It turns out that the amount this chiral molecule slows down,  say, left-handed circularly polarized light is different from  the amount that it slows down right-handed circularly polarized light. Effectively, there's not one index of refraction, but two. Now you might say that seems irrelevant to our setup,  since we are very deliberately shining in linearly polarized light,  there is no circularly polarized light. But actually there's a sense in which linearly polarized light is  equal parts left-handed and right-handed circularly polarized light. Here, focus your attention on just one vector in this wave,  wiggling straight up and down, which is to say polarized in the z direction. Notice how it's possible to express this vector as a sum of two rotating vectors,  one of them rotating at a constant rate counterclockwise,  and the other one rotating clockwise. Adding them together tip to tail results in a vector oscillating on a line. In this case, it's a vertical line, but that direction can change  based on the phase of the two vectors we're adding together. Here, let me throw up a couple labels to keep track of how much each one of those  two vectors has rotated in total, and then every now and then I'm going to slow down  that first vector a little bit, and I want you to notice what happens to their sum. Well, every time I slow it down, effectively knocking back its phase a little bit,  it causes the linearly wiggling sum to wiggle in a slightly different direction. So if the circularly polarized light wave represented by that left vector  gets slowed down a little bit every time it runs across a sugar molecule,  or at least slowed down more than its oppositely rotating counterpart would,  the effect on the sum is to slowly rotate the direction of linear polarization. And hence, as you look at slices further and further down the tube,  the polarization direction does indeed get twisted the way we were describing earlier,  representing how the composite effects with many many many different sugar  molecules are slightly different for left-handed light than they are for right-handed  light. As a nice way to test whether you understood everything up to this point,  see if just by looking at the direction of the diagonal slices on our tube,  you can deduce which kind of light the sugar is slowing down more,  left-handed light or right-handed light. I'll call this a partial answer to our question number one,  because it still leaves us wondering why there's an index of refraction in the first  place, and how exactly it might depend on the polarization of the light,  not just the material it's passing through. Also, like I said at the start, a robust enough intuition here should also answer  for us why the strength of this effect would depend on the frequency of the light. At this point I think we've covered quite enough for one video,  so I'll pull out a discussion covering the origins of the index of refraction to  a separate video. Thank you.

================================================================================
VIDEO ID: QCX62YJCmGk
TITLE: This tests your understanding of light | The barber pole effect
URL: https://www.youtube.com/watch?v=QCX62YJCmGk
PUBLISHED: 2023-09-01T13:13:14Z
STATUS: SUCCESS
================================================================================
The setup here starts with a cylinder full of sugar water,  basically, and we're about to shine some white light into it,  but before it gets there, it passes through a linearly polarizing filter. And what that means, basically, is that if you look at all of  the light waves beyond the point of that filter,  those waves are only going to be wiggling in one direction, say up and down. And don't worry, in a few minutes we're going to go into much more detail  about what specifically is wiggling and what the significance of that  wiggling direction is, but skipping to the punchline first,  the demo also includes a second linearly polarizing filter coming out the other end,  and I want you to predict what we're going to see once we turn the light on. Now I suspect some viewers might already have a little bit of a sense for  what's going on, because a few years ago Steve Mould made a really excellent  video about this phenomenon of shining polarized light through sugar water. It was really well done, which is no surprise because everything Steve makes is,  but even if you watched that, this is a rich enough phenomenon  that there's still more to be explained. In fact, even if you made that video, this is a rich  enough phenomenon that there's more to be explained. I'm curious, Steve, when you made that video, did you happen  to get a good view of the side of the glass, probably when the  rest of the lights in the room were off or something like that? No. No, I didn't think about the side view. Great. So given the setup that we're looking at now, once we turn off the room lights  and turn on the lamp, I'm curious if you have a prediction for what you might see. Well, there will be some scattering, I suppose,  but then if we're just looking at the tube, we're not applying any kind of filter  to just looking directly at the tube. So, I mean, my instinct is nothing will happen. That would have been my guess too, but let me just show you what it  looks like when we turn off the room lights and we turn on the lamp. Ooh. And then if you turn the initial polarizer, you can kind of see those. Wow. Stripes, those diagonal stripes seem to walk up the tube. Oh, wow. But why diagonal? Exactly, why diagonal? But why anything? I mean, why anything? Something about the interaction with sugar water separates the light out  into these different bands of color, but it does so in this really intriguing way,  where the colors appear to form these spiral helixes down the tube. And the other thing I want to draw your attention to is the color  that's coming out of the tube after it passes through that second filter. As we rotate the first filter, you rotate through a family of distinct hues. And it doesn't have to be the first filter if you rotate that second filter,  you also rotate through these various different colors. That's Quinn, by the way, who kindly set up this whole demo. And what I love about this setup is that if you want to really understand what you're  looking at with that deep to your bones satisfying sense of what's going on,  it requires having very solid intuitions for a number of different fundamental concepts  about light, like polarization, how scattering works,  and how an index of refraction works. To kick things off, let me show you the overall structure for the explanation of what's  going on here, and along the way record various questions that we still need to answer. A basic premise to the whole thing is to think about polarized  light as a propagating wave which is wiggling in just one direction. And I suppose question number zero is for us to be clear about what exactly is wiggling. Postponing that for the moment, we'll just say if we think about  it as propagating in one direction, say along an x-axis,  the wiggling happens perpendicular to that, say in the z-direction. What's going on when it passes through this tube of  sugar water is that that wiggling direction gets twisted. And so the first key question is why? What is it about interaction with sugar that causes this twist? And just so that it's crystal clear what I mean by twisting,  if you focus your attention on a single slice perpendicular to the axis of the cylinder,  and draw a line indicating how the light is wiggling on that slice,  then if you were to move that slice down the cylinder,  the relevant wiggling direction slowly turns about the axis of the cylinder. Critically, the rate at which it's getting twisted depends on the frequency of the light. Higher frequency light, say violet, actually gets  twisted more quickly than low frequency light, like red. So the second key question we need to answer is  why would that twisting rate depend on the frequency? Whatever explanation we come to for why the twisting happens in the first place,  it should offer some intuition for where the dependence on frequency would come from. Let's take a moment to think about what it means that  different colors of light are getting twisted at different rates. In the demo we're shining in white light, and white light is not a clean pure sine wave,  it's something more complicated. And you typically think about it as a combination of many different pure sine waves,  each one corresponding to one of the colors in the rainbow. For this animation I will schematically represent the  wiggling direction for each pure frequency, just with a line. So the key idea is that as all of those different waves propagate down the tube,  with different pure frequencies twisting at different rates,  purple light twisting the fastest and red light twisting the slowest,  then the polarization directions for each one of those pure colors get separated out. For example, by the time you reach the end of the tube,  they all have their own distinct wiggling directions. But one thing that's important to understand is that this is still white light. If you were to put your eye at the end of the tube and look towards the lamp,  it wouldn't look colored in any way, because even if the wiggling directions are  all different, they're still the same amount of each color as there was at the start. In order to see any evidence of this separation,  one thing you could do is pass it all through a second linear polarizing filter,  say in the vertical direction. The effect that has is that the amount of light of a given frequency passing through  is equal to the component of its polarization direction that lines up with the filter. So colors which happen to align very closely with that filter  pass through almost completely, whereas colors which end up  more perpendicular to the filter pass through only very weakly. So the light coming out the other end of this filter is some imbalanced  combination of all of the pure frequencies, which is why what we see  coming out the other end is no longer white, but some other color. And notice if we rotate the whole setup, say by twisting the initial polarizing filter,  then that changes the components of each pure frequency that happen to be vertical,  resulting in a different balance of all those colors,  which is why rotating the initial filter changes the color you see coming out  the other end. And this is something you can do at home, by the way. You don't need a very fancy setup. Start by creating a pretty dense mixture of sugar water,  and then you'll need to get your hands on some polarizing filters so that you can  pass light first through one of those filters, then through the sugar water,  and then through a second filter. And if you look at this whole setup from the top,  as you rotate one of those filters, you'll see different colors. But even if you understand this, the thing that really had me  scratching my head when Quinn showed me this demo was why you  would see diagonal stripes when you view the cylinder from the side. I mean, take a moment to think about this. At any point down the tube, even though all the colors have been rotated differently,  again, the light at that point is still white. It's still an equal balance of all the different colors. If you were to stick your eye inside the tube and look towards the lamp,  you would see white. So why would viewing it from the side change what you see? The way I've made this animation, I've just left a faint shadow representing  the wiggling direction for each color along the way down the tube. But that's just a cartoon. It's a schematic representation. Why is it that the actual way that light interacts with the molecules  within the tube would discriminate between the colors in any way? And why would the stripes be diagonal? Wouldn't you think the setup should be completely symmetric from top to bottom? So these are the main questions we need to answer. Why would sugar cause the light to twist? Why would the rate at which it twists depend on the frequency of the light? And why, even if you understand both those facts,  would you be seeing different colors appear in these diagonal stripes? You can answer these questions if you have a handful of key intuitions about optics. The first question requires understanding circularly polarized light,  since the key is that sucrose is a chiral molecule,  which is to say there's a handedness to it, it's different from its mirror image,  and the slightly different effects that it has on right-handed versus left-handed  circularly polarized light ends up explaining the twist. The second question requires understanding why light  appears to slow down when it passes through a material. A sufficiently mathematical understanding for where that  slowdown comes from ultimately explains the color separation here. And the third question comes down to the fact that when light scatters off of a material,  it's not like some projectile bouncing in any old direction. The direction of scattering depends on the direction of polarization,  and there's a very good reason for it. My aim is for all of these answers to feel less like facts that I'm  handing down from on high, and more like inevitable discoveries  emerging from a fundamental understanding for what light actually is. For that, we'll begin by returning to that question number zero, what exactly is wiggling? Which is to say, what is light? If you're curious about how the full explanation unfolds, come join me in the next video.

================================================================================
VIDEO ID: d_qvLDhkg00
TITLE: A pretty reason why Gaussian + Gaussian = Gaussian
URL: https://www.youtube.com/watch?v=d_qvLDhkg00
PUBLISHED: 2023-07-11T15:53:09Z
STATUS: SUCCESS
================================================================================
The basic function underlying a normal distribution,  aka a Gaussian, is e to the negative x squared. But you might wonder, why this function? Of all the expressions we could dream up that give you some symmetric smooth  graph with mass concentrated towards the middle,  why is it that the theory of probability seems to have a special place in its  heart for this particular expression? For the last many videos I've been hinting at an answer to this question,  and here we'll finally arrive at something like a satisfying answer. As a quick refresher on where we are, a couple videos ago we talked about  the central limit theorem, which describes how as you add multiple copies  of a random variable, for example rolling a weighted die many different times,  or letting a ball bounce off of a peg repeatedly,  then the distribution describing that sum tends to look approximately like  a normal distribution. What the central limit theorem says is as you make that sum bigger and bigger,  under appropriate conditions, that approximation to a normal becomes better and better. But I never explained why this theorem is actually true. We only talked about what it's claiming. In the last video we started talking about the  math involved in adding two random variables. If you have two random variables, each following some distribution,  then to find the distribution describing the sum of those variables,  you compute something known as a convolution between the two original functions. And we spent a lot of time building up two distinct ways  to visualize what this convolution operation really is. Today our basic job is to work through a particular example,  which is to ask what happens when you add two normally distributed random variables,  which, as you know by now, is the same as asking what do you get if  you compute a convolution between two Gaussian functions. I'd like to share an especially pleasing visual way that you can think  about this calculation, which hopefully offers some sense of what makes  the e to the negative x squared function special in the first place. After we walk through it, we'll talk about how this calculation  is one of the steps involved in proving the central limit theorem. It's the step that answers the question of why a  Gaussian and not something else is the central limit. But first, let's dive in. The full formula for a Gaussian is more complicated than just e to the negative x squared. The exponent is typically written as negative one half times x divided by sigma squared,  where sigma describes the spread of the distribution, specifically the standard deviation. All of this needs to be multiplied by a fraction on the front,  which is there to make sure that the area under the curve is one,  making it a valid probability distribution. And if you want to consider distributions that aren't necessarily centered at zero,  you would also throw another parameter, mu, into the exponent like this. Although for everything we'll be doing here, we just consider centered distributions. Now if you look at our central goal for today,  which is to compute a convolution between two Gaussian functions,  the direct way to do this would be to take the definition of a convolution,  this integral expression we built up last video,  and then to plug in for each one of the functions involved the formula for a Gaussian. It's kind of a lot of symbols when you throw it all together,  but more than anything, working this out is an exercise in completing the square. And there's nothing wrong with that. That will get you the answer that you want. But of course, you know me, I'm a sucker for visual intuition, and in this case,  there's another way to think about it that I haven't seen written about before  that offers a very nice connection to other aspects of this distribution,  like the presence of pi and certain ways to derive where it comes from. And the way I'd like to do this is by first peeling away all of the  constants associated with the actual distribution,  and just showing the computation for the simplified form, e to the negative x squared. The essence of what we want to compute is what the  convolution between two copies of this function looks like. If you'll remember, in the last video we had two different ways to visualize  convolutions, and the one we'll be using here is the second one involving diagonal slices. And as a quick reminder of the way that worked,  if you have two different distributions that are described by two different functions,  f and g, then every possible pair of values that you might get when you  sample from these two distributions can be thought of as individual points  on the xy-plane. And the probability density of landing on one such point,  assuming independence, looks like f of x times g of y. So what we do is we look at a graph of that expression as a two-variable  function of x and y, which is a way of showing the distribution of all  possible outcomes when we sample from the two different variables. To interpret the convolution of f and g evaluated on some input s,  which is a way of saying how likely are you to get a pair of samples that  adds up to this sum s, what you do is you look at a slice of this graph  over the line x plus y equals s, and you consider the area under that slice. This area is almost, but not quite, the value of the convolution at s. For a mildly technical reason, you need to divide by the square root of 2. Still, this area is the key feature to focus on. You can think of it as a way to combine together all the probability  densities for all of the outcomes corresponding to a given sum. In the specific case where these two functions look like e to  the negative x squared and e to the negative y squared,  the resulting 3D graph has a really nice property that you can exploit. It's rotationally symmetric. You can see this by combining the terms and noticing that it's entirely  a function of x squared plus y squared, and this term describes the  square of the distance between any point on the xy plane and the origin. So in other words, the expression is purely a function of the distance from the origin. And by the way, this would not be true for any other distribution. It's a property that uniquely characterizes bell curves. So for most other pairs of functions, these diagonal slices will be some complicated  shape that's hard to think about, and honestly,  calculating the area would just amount to computing the original integral that defines  a convolution in the first place. So in most cases, the visual intuition doesn't really buy you anything. But in the case of bell curves, you can leverage that rotational symmetry. Here, focus on one of these slices over the line x plus y equals s for some value of s. And remember, the convolution that we're trying to compute is a function of s. The thing that you want is an expression of s that tells you the area under this slice. Well, if you look at that line, it intersects the x-axis at s zero and the y-axis  at zero s, and a little bit of Pythagoras will show you that the straight line  distance from the origin to this line is s divided by the square root of two. Now, because of the symmetry, this slice is identical to one  that you get rotating 45 degrees where you'd find something  parallel to the y-axis the same distance away from the origin. The key is that computing this other area of a slice parallel to the y-axis is much,  much easier than slices in other directions because it only  involves taking an integral with respect to y. The value of x on this slice is a constant. Specifically, it would be the constant s divided by the square root of two. So when you're computing the integral, finding this area,  all of this term here behaves like it was just some number, and you can factor it out. This is the important point. All of the stuff that's involving s is now entirely separate from the integrated variable. This remaining integral is a little bit tricky. I did a whole video on it, it's actually quite famous. But you almost don't really care. The point is that it's just some number. That number happens to be the square root of pi,  but what really matters is that it's something with no dependence on s. And essentially this is our answer. We were looking for an expression for the area of these slices as a function of s,  and now we have it. It looks like e to the negative s squared divided by two, scaled by some constant. In other words, it's also a bell curve, another Gaussian,  just stretched out a little bit because of this two in the exponent. As I said earlier, the convolution evaluated at s is not quite this area. Technically it's this area divided by the square root of two. We talked about it in the last video, but it doesn't  really matter because it just gets baked into the constant. What really matters is the conclusion that a convolution  between two Gaussians is itself another Gaussian. If you were to go back and reintroduce all of the constants for a normal distribution  with a mean zero and an arbitrary standard deviation sigma,  essentially identical reasoning will lead to the same square root of two factor that  shows up in the exponent and out front, and it leads to the conclusion that the  convolution between two such normal distributions is another normal distribution with a  standard deviation square root of two times sigma. If you haven't computed a lot of convolutions before,  it's worth emphasizing this is a very special result. Almost always you end up with a completely different kind of function,  but here there's a sort of stability to the process. Also, for those of you who enjoy exercises, I'll leave one up on the screen  for how you would handle the case of two different standard deviations. Still, some of you might be raising your hands and saying, what's the big deal? I mean, when you first heard the question, what do you get when you  add two normally distributed random variables,  you probably even guessed that the answer should be another normally distributed variable. After all, what else is it going to be? Normal distributions are supposedly quite common, so why not? You could even say that this should follow from the central limit theorem. But that would have it all backwards. First of all, the supposed ubiquity of normal distributions is often a little  exaggerated, but to the extent that they do come up,  it is because of the central limit theorem, but it would be cheating to say the central  limit theorem implies this result because this computation we just did is the reason  that the function at the heart of the central limit theorem is a Gaussian in the first  place, and not some other function. We've talked all about the central limit theorem before,  but essentially it says if you repeatedly add copies of a random variable to itself,  which mathematically looks like repeatedly computing convolutions against a given  distribution, then after appropriate shifting and rescaling,  the tendency is always to approach a normal distribution. Technically, there's a small assumption the distribution you start with  can't have infinite variance, but it's a relatively soft assumption. The magic is that for a huge category of initial distributions,  this process of adding a whole bunch of random variables drawn from  that distribution always tends towards this one universal shape, a Gaussian. One common approach to proving this theorem involves two separate steps. The first step is to show that for all the different finite variance  distributions you might start with, there exists a single universal  shape that this process of repeated convolutions tends towards. This step is actually pretty technical, it goes  a little beyond what I want to talk about here. You often use these objects called moment generating functions that gives you  a very abstract argument that there must be some universal shape,  but it doesn't make any claim about what that particular shape is,  just that everything in this big family is tending towards a single point in  the space of distributions. So then step number two is what we just showed in this video,  prove that the convolution of two Gaussians gives another Gaussian. What that means is that as you apply this process of repeated convolutions,  a Gaussian doesn't change, it's a fixed point,  so the only thing it can approach is itself, and since it's one member in this  big family of distributions, all of which must be tending towards a single universal  shape, it must be that universal shape. I mentioned at the start how this calculation, step two,  is something that you can do directly, just symbolically with the definitions,  but one of the reasons I'm so charmed by a geometric argument that leverages the  rotational symmetry of this graph is that it directly connects to a few things that  we've talked about on this channel before, for example,  the Herschel-Maxwell derivation of a Gaussian,  which essentially says that you can view this rotational symmetry as the defining  feature of the distribution, that it locks you into this e to the negative x squared  form, and also as an added bonus, it connects to the classic proof for why pi shows up  in the formula, meaning we now have a direct line between the presence and mystery of  that pi and the central limit theorem. Also, on a recent Patreon post, the channel supporter Daksha Vaid-Quinter  brought my attention to a completely different approach I hadn't seen before,  which leverages the use of entropy, and again, for the theoretically curious among you,  I'll leave some links in the description. By the way, if you want to stay up to date with new videos,  and also any other projects that I put out there, like the Summer of Math Exposition,  there is a mailing list. It's relatively new, and I'm pretty sparing about  only posting what I think people will enjoy. Usually I try not to be too promotional at the end of videos these days,  but if you are interested in following the work that I do,  this is probably one of the most enduring ways to do so.

================================================================================
VIDEO ID: YtkIWDE36qU
TITLE: This pattern breaks, but for a good reason | Moser's circle problem
URL: https://www.youtube.com/watch?v=YtkIWDE36qU
PUBLISHED: 2023-07-02T04:41:01Z
STATUS: SUCCESS
================================================================================
This is a very famous cautionary tale in math, known as Moser's circle problem. Some of you may have seen this before, but what I  want to do here is really explain what's going on. The way this starts is we take a circle and put two points on that  circle and connect them with a line, that is a chord of the circle,  and note that it divides the circle into two different regions. If I add a third point and then connect that to the previous two points with two  more chords, then these lines all divide the circle into four separate regions. Then if you add a fourth point and connect that to the previous three,  and you play the same game, you count up how many regions has this cut the circle into,  you end up with eight. Add a fifth point to the circle, connect it to the previous four,  count up the total number of regions, and if you're careful with your counting,  you'll get a total of sixteen. Naturally, you can guess what might come next, but would you bet your life on it? Add a sixth point, connect it to all the previous ones,  and if you carefully count up all the different regions,  you end up not with the power of two you might have expected, but just one shy of it. Some of you might be raising your hand saying,  doesn't it depend on where we put the points? For example, watch how this middle region disappears if I  place everything nice and symmetrically around the circle. So yes, it does depend, but we're going to consider the cases  where you never have any three lines intersecting with each other. This would be the generic case if you just choose n random points,  almost certainly you'll never have three lines coincide,  but setting aside the technical nuances, the problem is such a tease,  it looks so convincingly like powers of two until it just barely breaks. And I have such a strange soft spot for this particular question. When I was younger I wrote a poem about it and also a song. And on the one hand it's kind of silly, because this is just one example of what  the mathematician Richard Guy called the strong law of small numbers,  summed up in the phrase, there aren't enough small numbers to meet the many demands  made of them. But I think what I really like about this problem is that if you sit down to try  to work out what is the real pattern, what's actually going on here, one,  it's just a really good exercise in problem solving,  so it makes for a nice lesson right here, but also it's not just a coincidence  that it starts off being powers of two. There's a very good reason this happens. And it's also not a coincidence that you seemingly randomly hit  another power of two a little bit later on the tenth iteration. So we've got this pattern, and what you want to find is what function describes it. If you put n points on the boundary of a circle,  and you connect them with all the possible chords,  and you count how many regions the circle has been cut into,  if the answer isn't a power of two, what is it? What function of n should we plug in? As always with math, problem solving rule number one if you're stuck is  to try solving easier questions somehow related to the problem at hand. It helps you get a foothold, and sometimes those  answers are helpful in the final question. In this case, two warm-up questions that come to mind are,  how many total chords are there in this diagram,  and at how many points within the circle do those chords intersect each other? The first question is relatively friendly. Every one of those chords corresponds uniquely with a pair of points on the circle. So effectively what you want to do is count how many distinct pairs of points are there. There's a function that does this, it's called n choose two. By definition, this counts the number of distinct pairs that  you can choose from a set of n items, where order doesn't matter. To calculate it, the way you often think about it is that you have n choices  for what your first item should be, and then you have n minus one options for  what that second item should be, but simply multiplying those would over count,  since for a given pair you would have two distinct ways to arrive at that pair. And remember, we don't care about order. To account for this, you divide by two. So for example, seven choose two would look like seven times six divided by two,  which is seven times three, or twenty-one, and if you count up the number  of distinct pairs of seven items, there are indeed twenty-one of them. Counting the number of intersection points in the diagram is a little bit trickier. One idea might be that it should be the number of pairs of chords,  since every intersection point comes from two different chords. However, that would not quite be right, because the association is not unique. You can find a pair of chords that don't intersect within the circle. As I said, it's a little bit tricky. I'd encourage you to try to pause and think about it for yourself,  and if you do that, you give yourself a moment,  maybe if you're a little bit lucky, here's one thing you might notice. Every intersection point is uniquely associated  with a quadruplet of points on the exterior. For a given quadruplet, you look at the two kind of diagonal chords between them,  and those will intersect within the circle, and it goes the other way around. Every intersection point corresponds with some quadruplet of points. So, what you want now is to count how many distinct  ways can you choose four items given n total choices. This is very similar to the previous question. The function that answers it is called n choose four,  which by definition counts the number of quadruplets from a set of size n,  and the way to calculate it is similar to what we saw before. You would think of having n choices for your first item,  leaving you with n minus one choices for the next item,  leaving you with n minus two choices for the third item,  and n minus three choices for the last item. That, however, would grossly overcount the total number,  since all the different ways you can permute these four items would be counted separately. To account for that, you divide out by the extent to which you've overcounted,  the number of permutations of four items, which looks like four factorial. For example, if you calculate four choose four, everything cancels and you just get one,  and indeed there is a single intersection point in this diagram. If you calculate six choose four, it works out to be 15,  and if you look at this diagram and you count them all up,  you would notice there are indeed 15 different intersection points. And even if you would never want to count it up by hand,  if we had a diagram that has 100 distinct points on the exterior,  and we drew all of the connecting lines, you can conclude that there have  to be 100 choose four, or just about four million intersection points  somewhere in the middle. You've probably guessed this, but these are more than just warm-up questions. They give us the necessary information to answer the question we care about. How many regions has the circle been cut into? The trick is to use a very nice little fact about planar graphs. Here I'm using the word graph in the sense of a diagram that has nodes  and lines connecting them, and what it means to be planar is that you  can draw this diagram without any of the lines intersecting with each other. In graph theory lingo, you typically call those nodes vertices and the lines connecting  them edges, and the wonderful fact that we can leverage is that if you count up the  number of vertices, and then you subtract the total number of edges,  and then you consider the number of regions that this graph has cut the plane into,  including that infinite outer region, then always,  no matter what planar graph you started with, you get two. It's actually very fun. Try this for yourself. Draw any graph, make sure the lines don't intersect,  and then count the number of vertices, subtract the number of edges,  and count the number of regions that it's cut the plane into,  and no matter what diagram you chose, the answer always works out to be two. More commonly you would see this written as v minus e plus f is equal to two,  since originally the equation described the vertices edges and faces of three-dimensional  polyhedra, and if you want to know why this magical fact is true,  you can think about building up your graph from a trivial case,  where you have a single node and no edges. So v would be equal to one, f would also be equal to one because of that  infinite outer region, and e is zero, so the equation is obviously true. Then if you build up your graph one edge at a time,  one thing that could happen is that for each new edge you introduce a new vertex. So e goes up by one, but v also goes up by one, leaving the equation balanced. But if a new edge doesn't correspond to a new vertex,  meaning it's connecting to a pre-existing vertex,  that means that it's enclosed a new region of space, so e goes up by one,  but f also goes up by one, which again leaves the equation balanced. So as you build up some potentially complicated graph,  v minus e plus f always stays fixed at two. This equation has a name, it's called Euler's characteristic formula,  and I remember when I made a video about this a while ago,  I had some dumb joke in there about Euler's being German for beautiful,  and there were a decent number of comments that were like, you know,  Euler is actually a person, I speak German, and it doesn't mean beautiful. Anyway, for our purposes, it gives us a tool for counting  the number of regions that a planar graph has cut space into. Rearranging a little, you would take the number  of edges minus the number of vertices plus two. This is exactly the tool that we want to understand our circle question,  although in that case we don't care about the infinite outer region,  so instead I'll write this as e minus v plus one. And at first you might complain, but we can't use Euler's formula in this case,  because it only applies to planar graphs, and in our case the  lines absolutely intersect with each other. We even counted how many times they intersect with each other. But the key is to treat this as a new graph, where those intersection  points are themselves vertices, so the total number of vertices here would not be n,  but n plus the n choose 4 total intersection points. That in turn chops up all of our chords into a larger number of edges,  it's much more than just n choose 2, and initially it might seem really annoying and  tricky to think about exactly how much it's chopped them up,  but one way you can think about it is that every intersection point takes what started as  two separate lines and then turns it into four lines. So in effect, each intersection point adds two more edges. For example, look at this simple diagram where  we have three lines and two intersection points. The total number of edges after the chopping would look like three plus two times two,  or seven. If you had four lines that intersected at three separate points,  then the total number of little lines after chopping would be 4 plus 2 times 3, or 10. And for the diagram we care about where we started off with n choose two  separate lines and they're getting chopped up at n choose four points in the middle,  you would end up with n choose two plus two times n choose four edges. And actually there are a few more than that, because we're including the circle,  we also need to count the n different arcs that sit on the outside of this diagram. So with all of that you have the information you need to answer the original question.  Pulling up our variant of Euler's formula that counts the number of regions we'll plug  in the expression for the number of vertices which is n plus the n choose four  intersection points, and you also plug in the slightly larger expression for the new  number of edges n choose two plus two times n choose four plus n,  and the expression has a lot of nice cancellation,  for example you are adding an n but also subtracting an n and you're adding two copies  of n choose four but subtracting another copy of n choose four and when all the dust  settles the answer to the question is one plus n choose two plus n choose four. On the one hand, you're done, you answered the question. I give you one of these circle diagrams with n points on the boundary,  and using this formula you can figure out how many regions the circle has been cut into. But of course we're not really done, because that doesn't scratch the itch. Why is it the case that this looks like powers of 2 and then falls short by just 1? It's not just a coincidence, and the key to answering it is to consider Pascal's triangle. You know this triangle, it's the one where each term looks  like a sum of the two different terms above it,  and there are basically two facts we need to bring in about this triangle. The first is that every term inside this triangle  looks like n choose k for some value of n and k. That is, the answer to the question of how many ways can you select a  subset of size k from a set of size n is visible within this triangle. The way to think about it is by indexing the rows and columns starting from 0. For example, if you count up to the 0, 1, 2, 3, 4, 5th row,  you count in to the 0, 1, 2, 3rd element, you see 10. And indeed, 5 choose 3 is equal to 10. If you've never seen this before and you want to know why it's true,  there's a really lovely argument, I'll leave it up as an exercise. But moving on to the second thing that we need to know,  notice what happens when you add up the rows of this triangle. You get 1, and then 1 plus 1 is 2, 1 plus 2 plus 1 is 4,  1 plus 3 plus 3 plus 1 is 8, and as you continue on, you always get powers of 2. Maybe at this point you're a little gun-shy about jumping to conclusions about powers of  2 too quickly, but in this case it's a genuine pattern, there's no trickery being pulled. And there are a few ways that you can think about why there should be powers of 2 here. But one that I like is to think about how as you go from that first row to the next one,  it's like the number 1 is sort of donating two copies of itself into the next row. Likewise, as you go from the second row to the third,  each of those 1s is donating two copies of itself to the next row, and in general,  as you go from one row to the next, each number donates two copies of itself  to the one below. So as you add up the totals for each of these rows,  it stands to reason that those totals double on each iteration. Circling back to our original question, think about what this means. The answer to our question looked like 1 plus n choose 2 plus n choose 4. In the context of Pascal's triangle, you could think about that as adding up the 0th,  2nd, and 4th terms inside some row of that triangle. For instance, when n is equal to 5, it looks like adding up 1 plus 10 plus 5. Now, because each of those numbers is the sum of the two above it,  this is the same thing as adding up the first 5 elements in the previous row,  which in this case is adding up the entire previous row, hence why it's a power of 2. Same deal for all the numbers that are 5 or less. When you situate this formula inside Pascal's triangle,  and you relate it to the previous row, what you're doing is adding up the entirety  of that previous row. The point at which this breaks is for n equals 6, because in that case,  when you relate this to the previous row, adding up the first 5 elements of that row,  it doesn't cover the whole thing. It falls short specifically by just 1, which is why we miss the power of 2,  and why it falls short specifically by just 1. Also, notice what happens when we plug in n equals 10. Looking down at the 10th row, and relating those terms to the previous one,  adding the first 5 elements of the 9th row is exactly half of that row,  and because the triangle is symmetric, this means that when you add them up,  you get exactly half of a power of 2, which itself of course is another power of 2. And as a challenge problem for you, I don't actually know  if this is the last time you'll ever see a power of 2. Maybe one of you out there who's cleverer with diaphantine  equations than I am can come up with some clever proof. Stepping back, to summarize, we started by counting the total number of  chords and the total number of intersection points, which,  by thinking about the right associations, is the same as computing n choose  2 and n choose 4. Bringing in Euler's formula, this let us get an exact closed  form expression for the number of regions inside the circle. Then connecting that with Pascal's triangle gives us a very visceral  connection with the powers of 2 and why they break when they do. So yes, Moser's circle problem is a cautionary tale about being wary of patterns  without proof, but at a deeper level, it also tells us that what's sometimes  chalked up to be coincidence still leaves room for satisfying understandings.

================================================================================
VIDEO ID: NOCsdhzo6Jg
TITLE: How They Fool Ya (live) | Math parody of Hallelujah
URL: https://www.youtube.com/watch?v=NOCsdhzo6Jg
PUBLISHED: 2023-06-28T19:17:11Z
STATUS: SUCCESS
================================================================================
Two, then four, then eight, and then sixteen. It's very nice. Before I go on with this particular pattern, there's a fun story about it. A little known fact. Do you guys know the song Hallelujah, the one popular from Trent? Yeah, okay. We all know the song. Lots of different artists have played it. The original artist was Leonard Cohen. He was the one who wrote the lyrics. Few people know, he actually went through many,  many different iterations of what the song would be. And ultimately it ended up as this biblical devastation of love. But one of the earlier versions was about this particular pattern in math. It's true. 100% true. Leonard Cohen was a low-key math buff. And I thought it might be fun, just because I don't want the original  version to get lost in the annals of history, to share with you guys  what this would have sounded like, if history had turned out that way,  if he didn't make it about love and religion and all of those great things. So welcome to the stage yet again, to accompany on keynote Matt Parker. Wonderful. And I know I know Leonard Cohen, but just imagine if you're watching  Shrek and when they get to that typical moment when you don't think  love is going to hold, you've actually heard the proper original. Well I heard there was a sequence of chords Splits the circle to one, two,  then four And points seem to cut in powers of two Yeah,  it was run like this With fourth and fifth But something's up We go out at six It's  awesome 31 I had a piece for you I'll make it for you I'll make it for you I'll make  it for you I'll make it for you I'll make it for you Yeah When your faith is strong  you still need proof What's your faith? Death can lead to a dew Each integral up on the left is pi over two Yeah I  think that's true For the next, which is terrible like a drum We've shown  that it's off by a hair It's a subtle slip but it's true I had a piece for  you I had a piece for you I'll make it for you I'll make it for you I'll  make it for you Now take a prime and write it in Facebook It's just like  you had before This prime gives a new prime With this rule, yeah Or does it though?

================================================================================
VIDEO ID: IaSGqQa5O-M
TITLE: Convolutions | Why X+Y in probability is a beautiful mess
URL: https://www.youtube.com/watch?v=IaSGqQa5O-M
PUBLISHED: 2023-06-27T15:08:14Z
STATUS: SUCCESS
================================================================================
Let's kick things off with a quiz. Suppose I take a normal distribution with this familiar bell curve shape,  and I have a random variable x that's drawn from that distribution. So what you're looking at right now are repeated samples of that random variable. And as a quick reminder, the way that you interpret this curve,  what the function actually means, is that if you want the probability that your  sample falls within a given range of values, say the probability that it ends up  between negative one and two, well that would equal the area under this curve in  that range of values. That's what the curve actually means. I'll also pull up a second random variable, also following a normal distribution,  but maybe this time a little more spread out, a slightly bigger standard deviation. And here's the quiz for you. If you repeatedly sample both of these variables,  and at each iteration you add up the two results,  well then that sum behaves like its own random variable. And the question is what distribution describes that sum that you're looking at? You think about it for a little moment, maybe you have a guess, maybe you think,  I don't know, it's another normal distribution, or something with a different shape. Needless to say, guessing is not enough. The real quiz is to be able to explain why you get the answer that you do. In this case, if you have that deep to your bones visceral level of understanding  for why the answer is what it is, you'll be a long way towards understanding  why normal distributions serve the special function that they do in probability. Zooming out though, this is actually meant to be a much more general  lesson about how you add two different random variables,  regardless of their distribution, not necessarily just the normally distributed ones. This amounts to a special operation that you apply  to the distributions underlying those variables. The operation has a special name, it's called a convolution,  and the primary thing you and I will do today is motivate and build up two  distinct ways to visualize what a convolution looks like for continuous functions,  and then to talk about how these two different visualizations can each be  helpful in different ways, with a special focus on the central limit theorem. After we do the general lesson, I want to return to the  opening quiz and offer an unusually satisfying way to answer it. As a quick side note, regular viewers among you might know there's already a  video about convolutions on this channel, but that one had a pretty different focus. We were only doing the discrete case, and I wanted to show not just probability,  but the ways that it comes up in a wide variety of contexts. I'm in a slightly awkward spot because it doesn't really make sense for that to be  a prerequisite to this video, but I think the best way to warm up today is to cover  essentially one of the same examples used in that video,  so if you are coming straight from that one, you can probably skip safely ahead,  otherwise, let's dive right in. For this opening quiz question, each of the random variables can take on  a value in a continuous infinite range of values, all possible real numbers. It'll be a lot easier if we warm up in a setting that's more discrete and finite,  like maybe rolling a pair of weighted dice. Here, the animation you're looking at is simulating two weighted dice,  and you can probably tell what's going on, but just to spell it out explicitly,  the blue die is following a distribution that seems to be biased towards lower values,  the red die has a distinct distribution, and I'm repeatedly sampling from  each one and recording the sum of the two values at each iteration. Repeating samples like this many many different times can give you a heuristic sense of  the final distribution, but our real task today is to compute that distribution precisely. What is the precise probability of rolling a 2,  or a 3, or a 4, or a 5, on and on for all possibilities? It's not too hard a question, I'd actually encourage  you to pause and try working it out for yourself. The main goal in this warm-up section will be to walk through two  distinct ways that you could visualize the underlying computation. For example, one way you could start to think about it is that there are 36 distinct  possible outcomes, and we could organize those outcomes in a little 6x6 grid. Now if I was to ask you, what is the probability of seeing any one of these specific  outcomes, say the probability of seeing a blue 4 and a red 2, what would you say? We might say it should be the probability of that blue 4  multiplied by the probability of the red 2, and that would be  correct assuming that the die rolls are independent from each other. You might say that's kind of pedantic, of course the die rolls should be independent  from each other, but it's a point worth emphasizing because everything that we're  going to do from here moving forward, from this simple example all the way up to  the central limit theorem, assumes that the random variables are independent. In the real world, you want to keep a sharp eye out for if this assumption actually holds. Now what I'm going to do is take this grid of all possible outcomes,  but start filling it in with some numbers. Maybe we'll put the numbers for all the probabilities of the blue die down on the bottom,  all the probabilities for the red die over here on the left,  and then we will fill in the grid where the probability for every outcome inside the grid  looks like some product between one number from the blue distribution and one number from  the red distribution. Another way to think about it is we're basically constructing a multiplication table. To be a little more visual about all of this, we could plot each one of these  probabilities as the height of a bar above the square in this sort of three-dimensional  plot. In some sense, this three-dimensional plot carries all the  data that we would need to know about rolling a pair of dice. And so the question is how do we extract the thing that we want to know,  the probabilities for various different sums? Well, if you highlight all of the outcomes with a certain sum,  say a sum of six, notice how all of those end up on a certain diagonal. Same deal if I highlight all the pairs where the sum is seven,  they sit along a different diagonal. So to compute the probability of each possible sum,  what you do is you add together all of the entries that sit on one of these diagonals. Pulling up the 3D plot, we can better foreshadow where we'll go with this  later by saying that the distribution of possible sums looks like combining  all of the heights of this plot along one of these diagonal slices. It's as if we've taken this full distribution for all possible  outcomes and we've kind of collapsed it along one of the directions. And admittedly, I'm just having a bit of fun with the animations at this point. It's not like if you were working this out with pencil  and paper you would be drawing some three-dimensional plot. But it's fun when you collapse it on this direction,  you actually do get the same distribution, which I knew you should,  but it's still fun to see. Also, even though all of this might just seem a little bit playful or  even unnecessarily complicated, I can promise you this intuition about  diagonal slices will come back to us later for a genuinely satisfying proof. But staying focused on the simple dice case a little bit longer,  here's the second way that we could think about it. Take that bottom distribution and flip it around horizontally  so that the die values increase as you go from right to left. Why do this, you might ask? Well, notice now which of the pairs of dice values line up with each other. As it's positioned right now, we have 1 and 6, 2 and 5, 3 and 4, and so on. It is all of the pairs of values that add up to 7. So if you want to think about the probability of rolling a 7,  a way to hold that computation in your mind is to take all of the pairs of  probabilities that line up with each other, multiply together those pairs,  and then add up all of the results. Some of you might like to think of this as a kind of dot product. But the operation as a whole is not just one dot product, but many. If we were to slide that bottom distribution a little more to the left,  so in this case it looks like the die values which line up are 1 and 4, 2 and 3,  3 and 2, 4 and 1, in other words all the ones that add up to a 5, well,  now if we take the dot product, we multiply the pairs of probabilities that  line up and add them together, that would give us the total probability of rolling a 5. In general, from this point of view, computing the full distribution  for the sum looks like sliding that bottom distribution into various  different positions and computing this dot product along the way. It is precisely the same operation as the diagonal slices we were looking at earlier. They're just two different ways to visualize the same underlying operation. And however you choose to visualize it, this operation that takes in two different  distributions and spits out a new one describing the sum of the relevant random  variables is called a convolution, and we often denote it with this asterisk. Really the way you want to think about it, especially as we set up for the continuous  case, is to think of it as combining two different functions and spitting out a new  function. For example, in this case, maybe I give the function  for the first distribution the name p sub x. This would be a function that takes in a possible value for the die,  like a 3, and it spits out the corresponding probability. Similarly, let's let p sub y be the function for our second distribution,  and p sub x plus y be the function describing the distribution for the sum. In the lingo, what you would say is that p sub x plus  y is equal to a convolution between p sub x and p sub y. And what I want you to think about now is what  the formula for this operation should look like. You've seen two different ways to visualize it,  but how do we actually write it down in symbols? To get your bearings, maybe it's helpful to write down a specific example,  like the case of plugging in a 4, where you add up over all the different  pairwise products corresponding to pairs of inputs that add up to a 4. And more generally, here's how it might look. This new function takes as an input a possible sum for your random variables,  which I'll call s, and what it outputs looks like a sum over a bunch of pairs of values  for x and y. Except the usual way it's written is not to write with x and y,  but instead we just focus on one of those variables, in this case x,  letting it range over all of its possible values,  which here just means going from 1 all the way up to 6. And instead of writing y, you write s minus x,  essentially whatever the number has to be to make sure the sum is s. Now the astute among you might notice a slightly  weird quirk with the formula as it's written. For example, if you plug in a given value like s equals 4, and you unpack this sum,  letting x range over all the possible values going from 1 up to 6,  then sometimes that corresponding y value drops below the domain of what we've  explicitly defined. For example, you plug in 0 and negative 1 and negative 2. It's not actually that big a deal. Essentially, you would just say all of these values are 0,  so all these later terms don't get counted. And that should kind of make sense. What is the probability that the red die rolls to become a negative 1? Well, it's 0. That is an impossible outcome. As a next step, let's turn our attention towards continuous distributions,  where your random variable can take on values anywhere in an infinite continuum,  like all possible real numbers. Maybe you're doing weather modeling and trying to predict the  temperature tomorrow at noon, or you're doing some financial projections,  or maybe you're modeling the typical wait times before a bus arrives. There are all sorts of things where you need to handle continuity. In all the graphs that we draw, the x value still represents a possible number  that the random variable can take on, but the interpretation of the y-axis is  a little bit different, because no longer does this represent probability. Instead, the thing that we're graphing is what's called probability density. This is something we've talked about before, so you know the deal. Essentially, the probability that a sample of your variable falls  within a given range looks like the area under the curve in that range. The function describing this curve is commonly called a probability density function,  a common enough phrase that it's frequently just given the abbreviation PDF,  and so the proper way to write all of this down would be to say that the  probability that your sample falls within a given range looks like the  integral of your PDF, the probability density function, in that range. As a general rule of thumb, anytime that you see a sum in the discrete case,  you would use an integral in the continuous case. So let's think about what that means for our main example. Let's say we have two different random variables,  but this time each one will follow a continuous distribution,  and we want to understand their sum and the new distribution that describes that sum. You can probably already guess what the formula will be just by analogy. Remember, in the formula that we just wrote down,  where p sub x is the function for the first variable,  and p sub y is the function for the second variable, the convolution between them,  the thing describing a sum of those variables,  itself looks like a sum where we combine a bunch of pairwise products. The expression in the continuous case really does look 100% analogous. It's just that we swap out that sum for an integral. Sometimes when students see this definition of a convolution out of context,  it can seem a little intimidating. Hopefully the analogy is enough to make it clear,  but the continuous nature really does give it a different flavor,  and it's worth taking a couple minutes to think through what it means on its own terms. And so I put together a little interactive demo that helps  unpack each part of the expression and what it's really saying. For example, the first term in this integral is f of x,  which represents the density function for the first of the two random variables. And in this case, I'm choosing this sort of wedge-shaped function for that distribution,  but it could be anything. Similarly, g represents the density function for the second random variable,  for which I'm choosing this sort of double lump-shaped distribution. And in the same way that earlier we went over all possible pairs of dice values with a  given sum, the way you want to think about this integral is that what it wants to do is  iterate over all possible pairs of values x and y that are constrained to a given sum, s. We don't really have great notation for doing that symmetrically,  so instead the way we commonly write it down gives this artificial emphasis to one  of the variables, in this case x, where we let that value x range over all possible  real numbers, negative infinity up to infinity,  and the thing we plug into the function g is s minus x,  essentially whatever it has to be to make sure that this sum is constrained to be s. So for the demo, instead of graphing g directly, I want to graph g of s minus x. You might ask yourself, what does that look like? Well, if you plug in negative x as the input, that has  the effect of flipping around the graph horizontally. And then if we throw in this parameter s, treat it as some kind of constant,  that has the effect of shifting the graph either left or right,  depending on if s is positive or negative. In the demo, s is a parameter that I'll just grab and shift around a little bit. The real fun comes from graphing the entire contents of the integral,  the product between these two graphs. This is analogous to the list of pairwise products that we saw earlier,  but in this case instead of adding up all of those pairwise products,  we want to integrate them together, which you would interpret as the area underneath  this product graph. As I shift around this value of s, the shape of that  product graph changes and so does the corresponding area. Keep in mind for all three graphs on the left,  the input is x and the number s is just a parameter. But for the final graph on the right, for the resulting convolution itself,  this number s is the input to that function, and the corresponding  output is whatever the area of the lower left graph is,  whatever the integral between this combination of f and g turns out to be. Here, it might be helpful if we do a simple example,  say where each of our two random variables follows a uniform  distribution between the values negative one half and positive one half. So what that looks like is that our density functions each have this kind  of top hat shape, where the graph equals one for all inputs between  negative one half and positive one half, and it equals zero everywhere else. The question, as always, is what should the distribution for the sum look like? Well, let me show you how it looks inside our demo. In this case, the product between the two graphs has a really easy interpretation. It is one wherever the graphs overlap with each other, but zero everywhere else. So if I slide this parameter s far enough to the left that our top  graphs don't overlap at all, then the product graph is zero everywhere,  and that's a way of saying this is an impossible sum to achieve. That should make sense. Each of the two variables can only get as low as negative one half,  so the sum could never get below negative one. As I start to slide s to the right and the graphs overlap with each other,  the area increases linearly until the graphs overlap entirely and it reaches a maximum. And then after that point it starts to decrease linearly again,  which means that the distribution for the sum takes on this kind of wedge shape. And I imagine this actually feels somewhat familiar for anyone  who's thought about a pair of dice, that is unweighted dice. There, if you add up two different uniformly distributed variables,  then the distribution for the sum has a certain wedge shape. Probabilities increase until they max out at a  seven and then they decrease back down again. Where this gets a lot more fun is if instead of asking for a sum  of two uniformly distributed variables, I ask you what it looks  like if we add up three different uniformly distributed variables. At first you might say, I don't know, we need some new  way to visualize combining three things instead of two. But really what you can do here is think about the sum of the first two as  their own variable, which we just figured out follows this wedge shape distribution,  and then take a convolution between that and the top hat function. Pulling up the demo, here's what that would look like. Once again, what makes the top hat function really nice is that multiplying  by it sort of has the effect of filtering out values from the top graph. The product on the bottom looks just like a copy of the top graph,  but limited to a certain window. Again, as I slide this around left and right and the area gets bigger and smaller,  the result maxes out in the middle, but tapers out to either side,  except this time it does so more smoothly. It's kind of like we're taking a moving average of that top left graph. Actually, it's more than just kind of, this literally  is a moving average of the top left graph. One thing you might think to do is take this even further. The way we started was combining two top hat functions and we got this wedge. Then we replaced the first function with that wedge,  and then when we took the convolution, we got this smoother shape describing a sum of  three distinct uniform variables. But we could just repeat. Swap that out for the top function and then convolve  that with the flat rectangular function. And whatever result we see should describe a sum  of four uniformly distributed random variables. Any of you who watched the video about the central  limit theorem should know what to expect. As we repeat this process over and over, the shape looks more and more like a bell curve. Or to be more precise, at each iteration we should rescale the x-axis to make sure that  the standard deviation is one, because the dominant effect of this repeated convolution,  the kind of repeated moving average process, is to flatten out the function over time. So in the limit it just flattens out towards zero. But rescaling is a way of saying yeah, yeah, yeah,  I know that it gets flatter, but what's the actual shape underlying it all? The statement of the central limit theorem, one of the coolest facts from probability,  is that you could have started with essentially any distribution  and this still would have been true. That as you take repeated convolutions like this,  representing bigger and bigger sums of a given random variable,  then the distribution describing that sum, which might start off looking very  different from a normal distribution, over time smooths out more and more until  it gets arbitrarily close to a normal distribution. It's as if a bell curve is, in some loose manner of speaking,  the smoothest possible distribution, an attractive fixed point in the space of  all possible functions, as we apply this process of repeated smoothing through  the convolution. Naturally you might wonder why normal distributions? Why this function and not some other one? That's a very good answer, and I think the most fun way to show the answer  is in the light of the last visualization that we'll show for convolutions. Remember how in the discrete case the first of our two visualizations  involved forming this kind of multiplication table,  showing the probabilities for all possible outcomes and adding up along the diagonals? You've probably guessed it by now, but our last  step is to generalize this to the continuous case. And it is beautiful, but you have to be a little bit careful. Pulling up the same two functions we had before, f of x and g of y,  what in this case would be analogous to the grid of possible pairs that we were  looking at earlier? Well in this case each of the variables can take on any real number,  so we want to think about all possible pairs of real numbers and the xy plane  comes to mind. Every point corresponds to a possible outcome when we sample from both distributions. Now the probability of any one of these outcomes xy,  or rather the probability density around that point,  will look like f of x times g of y, again assuming that the two are independent. So a natural thing to do is to graph this function f of x times g of y as a two variable  function, which would give something that looks like a surface above the xy plane. Notice in this example how if we look at it from one angle where we see the x values  changing, it has the shape of our first graph,  but if we look at it from another angle emphasizing the change in the y direction,  it takes on the shape of our second graph. This three-dimensional graph encodes all of the information we need. It shows all the probability densities for every possible outcome. And if you want to limit your view just to those outcomes where x plus y is  constrained to be a given sum, what that looks like is limiting our view to a  diagonal slice, specifically a slice over the line x plus y equals some constant. All of the possible probability densities for the outcome subject to this constraint  look sort of like a slice under this graph, and as we change around what specific sum  we're constraining to, it shifts around which specific diagonal slice we're looking at. Now what you might predict is that the way to combine all of the probability  densities along one of these slices, the way to integrate them together,  can be interpreted as the area under this curve, which is a slice of the surface. And that is almost correct. There's a subtle detail regarding a factor of the square root  of two that we need to talk about, but up to a constant factor,  the areas of these slices give us the values of the convolution. In fact, all of these slices that we're looking at are precisely  the same as the product graph that we were looking at earlier. Here, to emphasize this point, let me pull up both visualizations side by side,  and I'm going to slowly decrease the value of s,  which on the left means we're looking at different slices,  and on the right means we're shifting around the modified graph of g. Notice how at all points the shape of the graph on the bottom right,  the product between the functions, looks exactly the same as the shape of the  diagonal slice. And this should make sense. They are two distinct ways to visualize the same thing. It sounds like a lot when we put it into words,  but what we're looking at are all the possible products between outputs of the functions,  corresponding to pairs of inputs that have a given sum. Again, it's kind of a mouthful, but I think you see what I'm saying,  and we now have two different ways to see it. The nice thing about the diagonal slice visualization is that  it makes it much more clear that it's a symmetric operation. It's much more obvious that f convolved with g is the same thing as g convolved with f. Technically, the diagonal slices are not exactly the same shape. They've actually been stretched out by a factor of the square root of 2. The basic reason is that if you imagine taking some small step along one  of these lines where x plus y equals a constant, then the change in your x value,  the delta x here, is not the same thing as the length of that step. That step is actually longer by a factor of the square root of 2. I will leave a note up on the screen for the calculus enthusiasts among you  who want to pause and ponder, but the upshot is very simply that the outputs  of our convolution are technically not quite the areas of these diagonal slices. We have to divide those areas by a square root of 2. Stepping back from all of this for a moment, I just think this is so beautiful. We started with such a simple question, or at least such a seemingly simple question. How do you add up two random variables? And what we end up with is this very intricate  operation for combining two different functions. We have at least two very pretty ways to understand it, but still,  some of you might be raising your hands and saying,  pretty pictures are all well and good, but do they actually help you calculate something? For example, I still have not answered the opening quiz  question about adding two normally distributed random variables. Well, the ordinary way that you would approach this kind of question,  if it showed up on a homework or something like that,  is that you would plug in the formula for a normal distribution into  the definition of a convolution, the integral that we've been describing here. And in that case, the visualizations would really just be there to  clarify what the expression is saying, but they sit in the back seat. In this case, the integral is not prohibitively difficult. There are analytical methods. But for this example, I want to show you a more fun method where the visualizations,  specifically the diagonal slices, will play a much more front  and center role in the proof itself. I think many of you may actually enjoy taking a  moment to predict how this will look for yourself. Think about what this 3D graph would look like in the case of two normal distributions,  and what properties that it has that you might be able to take advantage of. And it is for sure easiest if you start with the case  where both distributions have the same standard deviation. Whenever you want the details, and to see how the answer fits  into the central limit theorem, come join me in the next video.

================================================================================
VIDEO ID: cy8r7WSuT1I
TITLE: Why Ï€ is in the normal distribution (beyond integral tricks)
URL: https://www.youtube.com/watch?v=cy8r7WSuT1I
PUBLISHED: 2023-04-02T15:30:13Z
STATUS: SUCCESS
================================================================================
You may have heard the phrase, the unreasonable  effectiveness of mathematics in the natural sciences. This was the title of a paper by the physicist Eugene Wigner,  but even more fun than the title is the way that he chooses to open it. The paper begins, quote, There is a story about two friends  who were classmates in high school, talking about their jobs. One of them became a statistician and was working on population trends. They showed a reprint to their former classmate,  and the reprint started, as usual, with the Gaussian distribution. And the statistician explained to the former classmate the meaning of  the symbols for the actual population, the average population, and so on. The classmate was a bit incredulous and was not quite  sure whether the statistician was pulling their leg. How can you know that? was the query. And what is this symbol over here? Oh, said the statistician, this is pi. What is that? The ratio of the circumference of a circle to its diameter. Well, now you're pushing the joke too far, said the classmate. Surely the population has nothing to do with the circumference of a circle. In the paper, Wigner then goes on to talk about the more general  phenomenon of concepts and pure math, seeming to find applications  that extend strangely beyond what their definitions would suggest. But I would like to stay focused on this particular anecdote  and the question that the statistician's friend is getting at. You see, there is a very beautiful and classic proof that  explains the pi inside the formula for a normal distribution. And despite there being a number of other really great explanations online,  see some links in the description, I cannot help but indulge in the pleasure of  reanimating it here. For one thing, there is a fun side note that I didn't learn until recently about  how you can use this proof to derive the volumes of higher dimensional spheres. But much more importantly than that, what I really  want to do is try to go beyond the classic proof. Consider this hypothetical statistician's friend. What I want to ask is, can we find an explanation that would satisfy their disbelief? You see, they're not just asking for some pure math proof  about a function that was handed down to them on high. The friend's incredulity was that circles should  have anything to do with population statistics. Until we fully draw that connecting line, we should consider the task incomplete. Those of you who watched the last video on the central limit theorem will  have some of the backdrop here, because there we broke down the formula  for a normal distribution, which is also called a Gaussian distribution. And when you strip away all of the different parameters and the constants,  the basic function that describes the bell curve shape is e to the negative x squared. And the reason that pi showed up in the final formula was that the area underneath  this curve works out, as you will see in a couple minutes, to be the square root of pi. So what that meant for us was that at some point we needed to divide out by  that square root of pi to make sure that the area under the curve is one,  which is a requirement before you can interpret it as a probability distribution. In the full formula that you would see, say, in a stats book,  this gets mixed together with some of the other constants,  but in its purest form that pi originates from the area underneath this curve. So step number one for you and me is to explain that area,  but I want to emphasize it's not the last step. To satisfy the question raised by that hypothetical statistician's friend,  we need to go further. We need to also answer why is it that this function e to  the negative x squared is so special in the first place? I mean, there are lots of different formulas you could write down that would give  a shape that, you know, vaguely bulges in the middle and tapers out on either side. So why is it that this specific function holds such a special place in statistics? To phrase our goal another way, can we find a connection between the proof that shows  why pi shows up and the central limit theorem, which,  as we talked about in the last video, is the thing that explains when you can expect a  normal distribution to arise in nature. So with all of that as the goal, first things first,  let's dig into the classic and very beautiful proof. All right, when you want to find the area underneath a curve,  the tool for doing that is an integral. As a quick reminder for how you might read this notation,  you might imagine approximating that area with many different rectangles under the curve,  where the height of each such rectangle is the value of the function above that point,  in this case, e to the negative x squared for a certain input x,  and the width is some little number that we're calling dx. We need to add up the areas of all these rectangles,  for values of x ranging from negative infinity up to infinity,  and the use of that notation dx is kind of meant to imply you shouldn't think of any  specific width, but instead you ask, as the chosen width for your rectangles gets thinner  and thinner, what does this sum of all those areas approach? Of course, all of that is just notation unless you provide a way to answer that question,  and the magic of calculus is that it provides just that, at least usually. You see, usually the procedure here would be to find some function whose  derivative is equal to the stuff we have on the inside, e to the negative x squared. In other words, we want to find an antiderivative of that function. The problem is, for this particular function, it is  provably not possible to find such an antiderivative. It's a little weird and beyond the scope of what I want to talk about here,  but basically, even though there exists an antiderivative, it is a well-defined function,  you cannot express what that antiderivative is using all our usual tools,  like polynomial expressions, trig functions, exponentials,  or any way to mix them together. So finding this area requires a bit of cleverness. There needs to be a new trick that we bring to bear. And the first step to this trick is easily the most absurd. We start by bumping things up one dimension, so that instead of asking for the  area under a bell curve, we ask for the volume underneath this kind of bell surface. You could rightly ask, why would you do that? Who ordered another dimension? And I'll admit, it's not terribly motivated right now,  other than to say, watch what happens when we just try it. In general, with hard problems, it's never a bad idea to try solving cousins of  the problem, since that can help you get a little bit of momentum and insight. To be clear on how this higher dimensional function is defined,  it takes in two different inputs, x and y, which we might think of as a point  on the xy-plane. And the way to think about it is to consider the distance from that point to the origin,  which I'll label as r, and then to plug in that distance to our original bell  curve function, that is, we take e to the negative r squared. You might notice the lines I've drawn on this diagram make a right triangle. So, by the Pythagorean theorem, x squared plus y squared equals r squared. So in the function I have written, where you see x squared plus y squared,  you can think in the back of your mind, that's really the  square of the distance from the point to the origin. The main thing to notice here is how this gives our function a kind of circular symmetry,  in the sense that all of the inputs that sit on a given circle have the same output. And so when we graph this function in three dimensions,  it means it has a rotational symmetry about the z-axis. Math tends to reward you when you respect its symmetries,  so for our question of computing the volume underneath the surface,  what we're going to do is respect that symmetry,  and imagine integrating together a bunch of thin little cylinders underneath that surface. Here, making this a little more quantitative, let's focus on just one of those  cylindrical shells, where its area is going to be the circumference of that shell times  the height. You might imagine it as something like the label  on a soup can that we can unwrap into a rectangle. The circumference of the cylinder, which is the top side of that rectangle,  is going to be 2 pi times the radius. And then the height of our cylinder, the other side of our rectangle,  is the height of the surface at this point, which by definition is the value of our  function associated with that radius, which like I said earlier you can think of as e to  the negative r squared. The real way you want to think about this is to give that cylinder a little  bit of thickness, which we'll call dr, so that the volume that it represents  is approximately that area we just looked at multiplied by this thickness dr. Our task now is to integrate together, or add together,  all of these different cylinders as r ranges between 0 and infinity. Or more precisely, we consider what happens as that thickness gets thinner and thinner,  approaching 0, and we add together the volumes of the many many many  different thin cylinders that sit underneath that curve. You might think this is just a harder version of what we were looking at earlier,  three dimensions should be more complicated than two. But actually something very helpful has happened. First let me clean up a little by factoring the pi outside that integral. Now the stuff inside that integral, having picked up this term 2r,  does have an antiderivative. We can now apply the usual tactics of calculus. Specifically, that whole inside expression is the  derivative of negative e to the negative r squared. And so, those of you comfortable with calculus know what to do from here. We take that antiderivative and plug in the upper bound,  which is negative infinity squared, and that gives us 0,  or speaking a little bit more precisely, if you consider the limit of this  expression as the input approaches infinity, the limiting value is 0,  and we subtract off the value of that antiderivative at the lower bound,  0, which in this case is negative 1. So all in all, the whole integral just works out to be 1,  which means all we're left with is that factor out in front, pi. Evidently, the volume underneath this bell surface is pi. And I'll point out in this case, it's not wild that pi shows up,  because the surface has this intrinsic circular symmetry. Still, you might wonder, how does that help us? As I said, throughout math, if you face a hard problem,  solving an adjacent problem can be unexpectedly helpful as a next step. And in this case, it's helpful not just for building intuition,  but we can directly relate the three-dimensional graph to our  two-dimensional graph by analyzing the volume in a second, different way. You see, the more general way to approach volumes underneath surfaces is to  think of chopping it up into slices that are all parallel to one of the axes. For example, all these slices that are parallel to the x-axis. For example, this right here is a slice that corresponds to the plane y equals 0. You might notice it looks just like a bell curve,  and if we write out the function, this should actually make a lot of sense. You could just plug in y equals 0, but to help see what happens with other slices,  notice how, thanks to the rules of exponentiation,  we could also write our function as e to the negative x squared times e to  the negative y squared. It factors out nicely. On this slice, that e to the negative y squared is just a number,  specifically the number 1. So this is the same graph we've seen before, e to the negative x squared,  meaning that the area of this slice is exactly the thing that we're looking for. It's the mystery constant, which I'm going to give the name c. What's nice is there's nothing really special about this particular slice. If we chose a different slice corresponding to a different y value,  it corresponds to multiplying this curve by a different number. So it's the same basic shape, just scaled down by that number,  meaning its area is the same as our mystery constant, just scaled down by some number. That's pretty cool. Each one of these slices has the same basic shape,  just rescaled in the vertical direction, which, by the way,  is not at all true for most two-variable functions. This is very much dependent on the fact that we were able to factor our function into  one part that's just dependent on the y and another part that's just dependent on the x. Now, to think about the volume underneath this whole surface,  here's another way we could phrase it. We're going to compute another integral that ranges from y  equals negative infinity up to infinity, where the term inside  that integral tells us the area of each one of those slices. And when we multiply it by a little thickness dy,  you might think of it as giving each one of those slices a little bit of volume. And remember, that term c sitting in front represents the thing we want to know,  which itself is an integral, a suspiciously similar-looking integral. See, if we take the expression on the top and we factor out that constant c,  because it's just a number, it doesn't depend on y, the thing we're left with,  the integral we need to compute, is exactly the mystery constant, the thing we don't know. So overall, the volume underneath this bell surface  works out to be this mystery constant squared. Out of context, this might seem very unhelpful,  it's just relating one thing we don't know to another thing we don't know,  except we've already computed the volume under this surface,  we know that it's equal to pi. Therefore, the mystery constant we want to know,  the area underneath this bell curve, must be the square root of pi. It's a very pretty argument, but a few things are not entirely satisfying. For one thing, it feels a little bit like a trick,  something that just happened to work without offering much of a sense for how you  could have rediscovered it yourself. Also, if we think back to our imagined statistician's friend,  it doesn't really answer their question, which was what do circles have to do with  population statistics? Like I said, it's the first step, not the last, and as our next step,  let's see if we can unpack why this proof is not quite as wild and arbitrary  as you might first think, and how it relates to an explanation for where  this function e to the negative x squared is coming from in the first place. John Herschel was this mathematician slash scientist slash inventor  who really did all sorts of things throughout the 19th century. He made contributions in chemistry, astronomy, photography, botany,  he invented the blueprint and named many of the moons in our solar system,  and in the midst of all of this, he also offered a very elegant little derivation for  the Gaussian distribution in 1850. The setup is to imagine that you want to describe some  kind of probability distribution in two-dimensional space. For instance, maybe you want to model the probability density for hits on a dartboard. What Herschel showed is that if you want this distribution to satisfy two pretty  reasonable seeming properties, your hand is unexpectedly forced,  and even if you had never heard of a Gaussian in your life,  you would be inexorably drawn to use a function with the shape e to the negative  x squared plus y squared. You do have one degree of freedom to control the spread of that distribution,  and of course there's going to be some constant sitting in front to make sure it's  normalized, but the point is that we're forced into this very specific kind of bell  curve shape. The first of these two properties is that the probability density around  each point depends only on its distance from the origin, not on its direction. So on a dartboard with everybody aiming for the bullseye,  this would mean that you could rotate the board and it would make no difference  for the distribution. Mathematically, this means that the function describing your probability distribution,  which I'll call f2 since it takes in two inputs x and y,  well it can be expressed as some single variable function of the radius r. And just to spell it out, r is the distance between the point xy and the origin,  the square root of x squared plus y squared. Property number two is that the x and y coordinates of each point are  independent from each other, which is to say if you learn the x coordinate of a point,  it would give you no information about the y coordinate. The way this looks as an equation is that our function,  which describes the probability density around each point on the xy plane,  can be factored into two different parts, one of which can be purely written in terms  of x, this is the distribution of the x coordinate, I'm giving it the name g,  and the other part is purely in terms of y, this would be the distribution for the  y coordinate, which I'm temporarily calling h. But if you combine this with the assumption that things are radially symmetric,  both of these should be the same distribution,  the behavior on each axis should look the same. So we could also write this as g of x times g of y, it's the same function. And more than that, this function is actually going to be proportional  to the one we were looking at, the one that describes our probability  density as a function of the radius, the distance away from the origin. To see this, imagine you were to analyze a point that was on the x-axis,  a distance r away from the origin. Then the two distinct ways to express our function based on the two different  properties tells us that f of r has to equal some constant multiplied by g of r. So these functions f and g are basically the same thing,  just up to some constant multiple. And you know what? It would be really nice if we could just assume that that constant was one,  so that f and g were literally the same function. And what I'm going to do, which might feel a little bit cheeky,  is just assume that that is the case. What this means is that our answer is going to be a little bit wrong. The function that we will deduce describing this  distribution will be off by some constant factor. But that's no big deal, because in the end we can just rescale to make sure the  area under the curve is one, like we always do with probability distributions. Now, if f and g are the same thing, this gives us a very  nice little equation purely in terms of the function f. Remember what this function f is. If you have some point in the xy-plane, a distance r from the origin,  then f of r tells you the relative likelihood of that point showing up in the  random process. More specifically, it gives the probability density of that point. At the outset, this function could have been anything,  but Herschel's two different properties evidently imply something kind of funny about it,  which is that if we take the x and y coordinates of that point on the plane and  evaluate this function on them separately, taking f of x times f of y,  it should give us the same result. Or if you prefer, we could expand out the meaning of that distance r as the square  root of x squared plus y squared, and this is what our key equation looks like. This kind of equation is what's known in the business as a functional equation. We're not solving for an unknown number. Instead, we're saying that the equation is true for all possible numbers x and y,  and the thing we're trying to find is an unknown function. In the back of your mind, you can think we already know one function  that satisfies this property, e to the negative x squared,  and as a sanity check, you might verify for yourself that it does satisfy that. Of course, the point is to pretend that you don't know that,  and to instead deduce what all of the functions are which satisfy this property. In general, functional equations can be quite tricky,  but let me show you how you can solve this one. First, it's nice to introduce a little helper function that I'll call h of x,  which will be defined as our mystery function evaluated at the square root of x. Said another way, h of x squared is the same thing as f of x. For example, in the back of your mind where you know that e  to the negative x squared will happen to be one of the answers,  this little helper function h would be e to the negative x. But again, we're pretending like we don't know that. The reason for doing this is that the key property for f looks a little bit nicer  if we phrase it in terms of this helper function h,  because now what it's saying is if you take two arbitrary positive numbers and you  add them up and evaluate h, it's the same thing as evaluating h on them separately  and then multiplying the results. In a sense, it turns addition into multiplication. Some of you might see where this is going, but let's  take a moment to walk through why this forces our hand. As a next step, you might want to pause and convince yourself that  if this property is true for the sum of two numbers,  this property also must be true if we add up an arbitrary number of inputs. To get a feel for why this is so constraining,  think about plugging in a whole number, something like h of 5. Because you can write 5 as 1 plus 1 plus 1 plus 1 plus 1,  this key property means that it must equal h of 1 multiplied by itself five times. Of course, there's nothing special about 5. I could have chosen any whole number n, and we'd be forced to conclude  that the function looks like some number raised to the power n. And let's go ahead and give that number a name, like b for the base of our exponential. As a little mini exercise here, see if you can pause and take a moment to convince  yourself that the same is true for a rational input,  that if you plug in p over q to this function,  it must look like this base b raised to the power p over q. And as a hint, you might want to think about adding  that input to itself q different times. And then because rational numbers are dense in the real number line,  if we make one more pretty reasonable assumption that we only care about  continuous functions, this is enough to force your hand completely and say  that h has to be an exponential function, b to the power x, for all real number inputs x. I guess to be more precise I should say for all positive real inputs. The way we defined h, it's only taking in positive numbers. Now, as we've gone over before, instead of writing down exponential  functions as some base raised to the power x, mathematicians often  like to write them as e to the power of some constant c times x. Making the choice to always use e as a base while letting that constant c  determine which specific exponential function you're talking about just  makes everything much easier any time calculus comes wandering along your path. And so this means that our target function f has to look  like e to the power of some constant times x squared. The beauty is that that function is no longer  something that was merely handed down to us from on high. Instead we started with these two different premises for how we wanted a distribution  in two dimensions to behave, and we were drawn to the conclusion that the shape of  the expression describing that distribution as a function of the radius away from  the origin has to be e to the power of some constant times that radius squared. You'll remember I said earlier this answer will be off by a factor of a constant. We need to rescale it to make it a valid probability distribution,  and geometrically you might think of that as scaling it so that the volume under the  surface is equal to one. Now you might notice that for positive values of this constant in the exponent c,  our function blows up to infinity in all directions,  so the volume under that surface would be infinite,  meaning it's not possible to renormalize. You can't turn it into a probability distribution. And that leaves us with the last constraint, which is that this  constant in the exponent has to be a negative number,  and the specific value of that number determines the spread of the distribution. Ten years after Herschel wrote this, James Clerk Maxwell,  who's most well known for having written down the fundamental equations  for electricity and magnetism, independently stumbled across the same derivation. In his case he was doing it in three dimensions since he was doing  statistical mechanics and he was deriving a formula for the distribution  for velocities of molecules in a gas, but the logic all works out the same. For you and me, if we view this as the defining property of a Gaussian,  then it's a little bit less surprising that pi might make an appearance. After all, circular symmetry was part of this defining property. More than that, it makes the clever proof that we  saw earlier feel a little bit less out of the blue. I mean, a key problem-solving principle in math is to use the defining features of  your setup, and if you had been primed by this Herschel-Maxwell derivation,  where the defining property for a Gaussian is this coincidence of having a distribution  that's both radially symmetric and also independent along each axis,  then the very first step of our proof, which seemed so strange bumping the problem  up one dimension, was really just a way of opening the door to let that defining  property make itself visible. And if you think back, the essence of the proof came down to using that radial symmetry  on the one hand, and then also using the ability to factor the function on the other. From this standpoint, using both those facts feels less like a  trick that happened to work, and more like an inevitable necessity. Nevertheless, thinking once again of our statistician's friend,  this is still not entirely satisfying. Using the Herschel-Maxwell derivation, saying this property of a multi-dimensional  distribution is what defines a Gaussian, well that presumes that we're  already in some kind of multi-dimensional situation in the first place. Much more commonly, the way that a normal distribution  arises in practice doesn't feel spatial or geometric at all. It stems from the central limit theorem, which is all  about adding together many different independent variables. So to bring it all home here, what we need to do is explain why the function  that's characterized by this Herschel-Maxwell derivation should be the same  thing as the function that sits at the heart of the central limit theorem. And at this point, those of you following along are probably going to make fun of me,  I think it makes sense to pull this last step out as its own video. Oh, and one final footnote here. After making a Patreon post about this particular project, one patron,  who's a mathematician named Kevin Ega, shared something completely delightful that  I had never seen before, which is that if you apply this integration trick in  higher dimensions, it lets you derive the formulas for volumes of higher dimensional  spheres. It's a very fun exercise, I'm leaving the details up on the screen  for any viewers who are comfortable with integration by parts. Thank you very much to Kevin for sharing that one, and thanks to all patrons,  by the way, both for the support of the channel,  and also for all the feedback you offer on the early drafts of videos. Thank you.

================================================================================
VIDEO ID: zeJD6dqJ5lo
TITLE: But what is the Central Limit Theorem?
URL: https://www.youtube.com/watch?v=zeJD6dqJ5lo
PUBLISHED: 2023-03-14T18:36:36Z
STATUS: SUCCESS
================================================================================
This is a Galton board. Maybe you've seen one before, it's a popular demonstration of how,  even when a single event is chaotic and random, with an effectively unknowable outcome,  it's still possible to make precise statements about a large number of events,  namely how the relative proportions for many different outcomes are distributed. More specifically, the Galton board illustrates one of the most prominent  distributions in all probability, known as the normal distribution,  more colloquially known as a bell curve, and also called a Gaussian distribution. There's a very specific function to describe this distribution, it's very pretty,  we'll get into it later, but right now I just want to emphasize how the normal  distribution is, as the name suggests, very common,  it shows up in a lot of seemingly unrelated contexts. If you were to take a large number of people who sit in a similar demographic  and plot their heights, those heights tend to follow a normal distribution. If you look at a large swath of very big natural numbers,  and you ask how many distinct prime factors does each one of those numbers have,  the answers will very closely track with a certain normal distribution. Now our topic for today is one of the crown jewels in all of probability theory,  it's one of the key facts that explains why this distribution is as common as it is,  known as the central limit theorem. This lesson is meant to go back to the basics,  giving you the fundamentals on what the central limit theorem is saying,  what normal distributions are, and I want to assume minimal background. We're going to go decently deep into it, but after this I'd still like to  go deeper and explain why the theorem is true,  why the function underlying the normal distribution has the very specific  form that it does, why that formula has a pi in it, and, most fun,  why those last two facts are actually more related than a lot of traditional  explanations would suggest. That second lesson is also meant to be the follow-on to the convolutions  video that I promised, so there's a lot of interrelated topics here. But right now, back to the fundamentals, I'd like to kick  things off with an overly simplified model of the Galton board. In this model we will assume that each ball falls directly onto a certain central peg,  and that it has a 50-50 probability of bouncing to the left or to the right,  and we'll think of each of those outcomes as either adding one or subtracting one from  its position. Once one of those is chosen, we make the highly unrealistic assumption that it  happens to land dead on in the middle of the peg adjacent below it,  where again it'll be faced with the same 50-50 choice of bouncing to the left or  to the right. For the one I'm showing on screen, there are five different rows of pegs,  so our little hopping ball makes five different random choices between plus one  and minus one, and we can think of its final position as basically being the  sum of all of those different numbers, which in this case happens to be one,  and we might label all of the different buckets with the sum that they represent,  as we repeat this we're looking at different possible sums for those five random numbers. And for those of you who are inclined to complain that this is a highly unrealistic model  for the true Galton board, let me emphasize the goal right now is not to accurately model  physics, the goal is to give a simple example to illustrate the central limit theorem,  and for that, idealized though this might be, it actually gives us a really good example. If we let many different balls fall, making yet another unrealistic  assumption that they don't influence each other, as if they're all ghosts,  then the number of balls that fall into each different bucket gives  us some loose sense for how likely each one of those buckets is. In this example, the numbers are simple enough that it's not too hard to  explicitly calculate what the probability is for falling into each bucket. If you do want to think that through, you'll find it very reminiscent of Pascal's  triangle, but the neat thing about our theorem is how far it goes beyond the simple  examples. So to start off at least, rather than making explicit calculations,  let's just simulate things by running a large number of samples and letting the total  number of results in each different outcome give us some sense for what that distribution  looks like. As I said, the one on screen has five rows, so each  sum that we're considering includes only five numbers. The basic idea of the central limit theorem is that if you increase the size of that sum,  for example here would mean increasing the number of rows of pegs for each  ball to bounce off, then the distribution that describes where that sum  is going to fall looks more and more like a bell curve. Here, it's actually worth taking a moment to write down that general idea. The setup is that we have a random variable, and that's basically shorthand for  a random process where each outcome of that process is associated with some number. We'll call that random number x. For example, each bounce off the peg is a random process modeled with two outcomes. Those outcomes are associated with the numbers negative one and positive one. Another example of a random variable would be rolling a die,  where you have six different outcomes, each one associated with a number. What we're doing is taking multiple different  samples of that variable and adding them all together. On our Galton board, that looks like letting the ball bounce off multiple  different pegs on its way down to the bottom, and in the case of a die,  you might imagine rolling many different dice and adding up the results. The claim of the central limit theorem is that as you let the size of that sum  get bigger and bigger, then the distribution of that sum,  how likely it is to fall into different possible values,  will look more and more like a bell curve. That's it, that is the general idea. Over the course of this lesson, our job is to make that statement more quantitative. We're going to put some numbers to it, put some formulas to it,  show how you can use it to make predictions. For example, here's the kind of question I want  you to be able to answer by the end of this video. Suppose you rolled a die 100 times and you added together the results. Could you find a range of values such that you're  95% sure that the sum will fall within that range? Or maybe I should say find the smallest possible range of values such that this is true. The neat thing is you'll be able to answer this question  whether it's a fair die or if it's a weighted die. Now let me say at the top that this theorem has three different assumptions  that go into it, three things that have to be true before the theorem follows. And I'm actually not going to tell you what they are until the very end of the video. Instead I want you to keep your eye out and see if you can notice  and maybe predict what those three assumptions are going to be. As a next step, to better illustrate just how general this theorem is,  I want to run a couple more simulations for you focused on the dice example. Usually if you think of rolling a die you think of the six outcomes as  being equally probable, but the theorem actually doesn't care about that. We could start with a weighted die, something with a non-trivial  distribution across the outcomes, and the core idea still holds. For the simulation what I'll do is take some distribution  like this one that is skewed towards lower values. I'm going to take 10 distinct samples from that distribution and  then I'll record the sum of that sample on the plot on the bottom. Then I'm going to do this many many different times, always with a sum of size 10,  but keep track of where those sums ended up to give us a sense of the distribution. And in fact let me rescale the y direction to give  us room to run an even larger number of samples. And I'll let it go all the way up to a couple thousand,  and as it does you'll notice that the shape that starts to emerge looks like a bell curve. Maybe if you squint your eyes you can see it skews a tiny bit to the left,  but it's neat that something so symmetric emerged from a starting point that was so  asymmetric. To better illustrate what the central limit theorem is all about,  let me run four of these simulations in parallel,  where on the upper left I'm doing it where we're only adding two dice at a time,  on the upper right we're doing it where we're adding five dice at a time,  the lower left is the one that we just saw adding 10 dice at a time,  and then we'll do another one with a bigger sum, 15 at a time. Notice how on the upper left when we're just adding two dice,  the resulting distribution doesn't really look like a bell curve,  it looks a lot more reminiscent of the one we started with, skewed towards the left. But as we allow for more and more dice in each sum,  the resulting shape that comes up in these distributions looks more and more symmetric. It has the lump in the middle and fade towards the tail's shape of a bell curve. And let me emphasize again, you can start with any different distribution. Here I'll run it again, but where most of the probability is tied up  in the numbers 1 and 6, with very low probability for the mid values. Despite completely changing the distribution for an individual roll of the die,  it's still the case that a bell curve shape will emerge as we consider the different sums. Illustrating things with a simulation like this is very fun,  and it's kind of neat to see order emerge from chaos,  but it also feels a little imprecise. Like in this case, when I cut off the simulation at 3000 samples,  even though it kind of looks like a bell curve,  the different buckets seem pretty spiky, and you might wonder,  is it supposed to look that way, or is that just an artifact of the  randomness in the simulation? And if it is, how many samples do we need before we can be sure that  what we're looking at is representative of the true distribution? Instead moving forward, let's get a little more theoretical and show  the precise shape these distributions will take on in the long run. The easiest case to make this calculation is if we have a uniform distribution,  where each possible face of the die has an equal probability, 1 6th. For example, if you then want to know how likely different sums are for a pair of dice,  it's essentially a counting game, where you count up how many distinct  pairs take on the same sum, which in the diagram I've drawn,  you can conveniently think about by going through all the different diagonals. Since each such pair has an equal chance of showing up,  1 in 36, all you have to do is count the sizes of these buckets. That gives us a definitive shape for the distribution describing a sum of two dice,  and if we were to play the same game with all possible triplets,  the resulting distribution would look like this. Now what's more challenging, but a lot more interesting,  is to ask what happens if we have a non-uniform distribution for that single die. We actually talked all about this in the last video. You do essentially the same thing, you go through all  the distinct pairs of dice which add up to the same value. It's just that instead of counting those pairs,  for each pair you multiply the two probabilities of each particular face coming up,  and then you add all those together. The computation that does this for all possible sums has a fancy name,  it's called a convolution, but it's essentially just the weighted version of  the counting game that anyone who's played with a pair of dice already finds familiar. For our purposes in this lesson, I'll have the computer calculate all that,  simply display the results for you, and invite you to observe certain patterns,  but under the hood, this is what's going on. So just to be crystal clear on what's being represented here,  if you imagine sampling two different values from that top distribution,  the one describing a single die, and adding them together,  then the second distribution I'm drawing represents how likely you are to  see various different sums. Likewise, if you imagine sampling three distinct values from that top distribution,  and adding them together, the next plot represents the probabilities  for various different sums in that case. So if I compute what the distributions for these sums look like for larger and larger  sums, well you know what I'm going to say, it looks more and more like a bell curve. But before we get to that, I want you to make a couple more simple observations. For example, these distributions seem to be wandering to the right,  and also they seem to be getting more spread out, and a little bit more flat. You cannot describe the central limit theorem quantitatively  without taking into account both of those effects,  which in turn requires describing the mean and the standard deviation. Maybe you're already familiar with those, but I want to make minimal assumptions here,  and it never hurts to review, so let's quickly go over both of those. The mean of a distribution, often denoted with the Greek letter mu,  is a way of capturing the center of mass for that distribution. It's calculated as the expected value of our random variable,  which is a way of saying you go through all of the different possible outcomes,  and you multiply the probability of that outcome times the value of the variable. If higher values are more probable, that weighted sum is going to be bigger. If lower values are more probable, that weighted sum is going to be smaller. A little more interesting is if you want to measure how spread out this distribution is,  because there's multiple different ways you might do it. One of them is called the variance. The idea there is to look at the difference between each possible value and the mean,  square that difference, and ask for its expected value. The idea is that whether your value is below or above the mean,  when you square that difference, you get a positive number,  and the larger the difference, the bigger that number. Squaring it like this turns out to make the math much much nicer than if we did  something like an absolute value, but the downside is that it's hard to think about  this as a distance in our diagram because the units are off,  kind of like the units here are square units, whereas a distance in our diagram would  be a kind of linear unit. So another way to measure spread is what's called the standard deviation,  which is the square root of this value. That can be interpreted much more reasonably as a distance on our diagram,  and it's commonly denoted with the Greek letter sigma,  so you know m for mean as for standard deviation, but both in Greek. Looking back at our sequence of distributions,  let's talk about the mean and standard deviation. If we call the mean of the initial distribution mu,  which for the one illustrated happens to be 2.24,  hopefully it won't be too surprising if I tell you that the mean  of the next one is 2 times mu. That is, you roll a pair of dice, you want to know the expected value of the sum,  it's two times the expected value for a single die. Similarly, the expected value for our sum of size 3 is 3 times mu, and so on and so forth. The mean just marches steadily on to the right,  which is why our distributions seem to be drifting off in that direction. A little more challenging, but very important,  is to describe how the standard deviation changes. The key fact here is that if you have two different random variables,  then the variance for the sum of those variables is the same  as just adding together the original two variances. This is one of those facts that you can just compute when you unpack all the definitions. There are a couple nice intuitions for why it's true. My tentative plan is to just actually make a series about probability and  talk about things like intuitions underlying variance and its cousins there. But right now, the main thing I want you to highlight is how it's the variance that adds,  it's not the standard deviation that adds. So, critically, if you were to take n different realizations of the same random  variable and ask what the sum looks like, the variance of sum is n times the  variance of your original variable, meaning the standard deviation,  the square root of all this, is the square root of n times the original standard  deviation. For example, back in our sequence of distributions,  if we label the standard deviation of our initial one with sigma,  then the next standard deviation is going to be the square root of 2 times sigma,  and after that it looks like the square root of 3 times sigma, and so on and so forth.  This, like I said, is very important. It means that even though our distributions are getting spread out,  they're not spreading out all that quickly, they only do so  in proportion to the square root of the size of the sum. As we prepare to make a more quantitative description of the central limit theorem,  the core intuition I want you to keep in your head is that we'll basically realign  all of these distributions so that their means line up together,  and then rescale them so that all of the standard deviations are just going to be  equal to one. And when we do that, the shape that results gets closer and closer to a certain universal  shape, described with an elegant little function that we'll unpack in just a moment. And let me say one more time, the real magic here is how we could have started with  any distribution, describing a single roll of the die, and if we play the same game,  considering what the distributions for the many different sums look like,  and we realign them so that the means line up,  and we rescale them so that the standard deviations are all one,  we still approach that same universal shape, which is kind of mind-boggling. And now, my friends, is probably as good a time as any  to finally get into the formula for a normal distribution. And the way I'd like to do this is to basically peel  back all the layers and build it up one piece at a time. The function e to the x, or anything to the x, describes exponential growth,  and if you make that exponent negative, which flips around the graph horizontally,  you might think of it as describing exponential decay. To make this decay in both directions, you could do something to make sure the  exponent is always negative and growing, like taking the negative absolute value. That would give us this kind of awkward sharp point in the middle,  but if instead you make that exponent the negative square of x,  you get a smoother version of the same thing, which decays in both directions. This gives us the basic bell curve shape. Now if you throw a constant in front of that x,  and you scale that constant up and down, it lets you stretch and  squish the graph horizontally, allowing you to describe narrow and wider bell curves. And a quick thing I'd like to point out here is that based on the  rules of exponentiation, as we tweak around that constant c,  you could also think about it as simply changing the base of the exponentiation. And in that sense, the number e is not really all that special for our formula. We could replace it with any other positive constant,  and you'll get the same family of curves as we tweak that constant. Make it a 2, same family of curves. Make it a 3, same family of curves. The reason we use e is that it gives that constant a very readable meaning. Or rather, if we reconfigure things a little bit so that the exponent looks  like negative 1 half times x divided by a certain constant,  which we'll suggestively call sigma squared, then once we turn this into a  probability distribution, that constant sigma will be the standard deviation  of that distribution. And that's very nice. But before we can interpret this as a probability distribution,  we need the area under the curve to be 1. And the reason for that is how the curve is interpreted. Unlike discrete distributions, when it comes to something continuous,  you don't ask about the probability of a particular point. Instead, you ask for the probability that a value falls between two different values. And what the curve is telling you is that that probability  equals the area under the curve between those two values. There's a whole other video about this, they're called probability density functions. The main point right now is that the area under the entire curve represents  the probability that something happens, that some number comes up. That should be 1, which is why we want the area under this to be 1. As it stands with the basic bell curve shape of e to the negative x squared,  the area is not 1, it's actually the square root of pi. I know, right? What is pi doing here? What does this have to do with circles? Like I said at the start, I'd love to talk all about that in the next video. But if you can spare your excitement, for our purposes right now,  all it means is that we should divide this function by the square root of pi,  and it gives us the area we want. Throwing back in the constants we had earlier, the one half and the sigma,  the effect there is to stretch out the graph by a factor of sigma times the square  root of 2. So we also need to divide out by that in order to make sure it has an area of 1,  and combining those fractions, the factor out front looks like  1 divided by sigma times the square root of 2 pi. This, finally, is a valid probability distribution. As we tweak that value sigma, resulting in narrower and wider curves,  that constant in the front always guarantees that the area equals 1. The special case where sigma equals 1 has a specific name,  we call it the standard normal distribution, which plays an especially important role  for you and me in this lesson. And all possible normal distributions are not only parameterized with this value sigma,  but we also subtract off another constant mu from the variable x,  and this essentially just lets you slide the graph left and right so  that you can prescribe the mean of this distribution. So in short, we have two parameters, one describing the mean,  one describing the standard deviation, and they're all tied together in this big formula  involving an e and a pi. Now that all of that is on the table, let's look back again at the idea of starting with  some random variable and asking what the distributions for sums of that variable look  like. As we've already gone over, when you increase the size of that sum,  the resulting distribution will shift according to a growing mean,  and it slowly spreads out according to a growing standard deviation. And putting some actual formulas to it, if we know the mean of our underlying  random variable, we call it mu, and we also know its standard deviation,  and we call it sigma, then the mean for the sum on the bottom will be mu times  the size of the sum, and the standard deviation will be sigma times the square  root of that size. So now, if we want to claim that this looks more and more like a bell curve,  and a bell curve is only described by two different parameters,  the mean and the standard deviation, you know what to do. You could plug those two values into the formula, and it gives you a highly explicit,  albeit kind of complicated, formula for a curve that should closely fit our distribution. But there's another way we can describe it that's a little more  elegant and lends itself to a very fun visual that we can build up to. Instead of focusing on the sum of all of these random variables,  let's modify this expression a little bit, where what we'll do is we'll look  at the mean that we expect that sum to take, and we subtract it off so that  our new expression has a mean of zero, and then we're going to look at the  standard deviation we expect of our sum, and divide out by that,  which basically just rescales the units so that the standard deviation of our  expression will equal one. This might seem like a more complicated expression,  but it actually has a highly readable meaning. It's essentially saying how many standard deviations away from the mean is this sum? For example, this bar here corresponds to a certain value that you might find when you  roll 10 dice and you add them all up, and its position a little above negative one is  telling you that that value is a little bit less than one standard deviation lower than  the mean. Also, by the way, in anticipation for the animation I'm trying to build to here,  the way I'm representing things on that lower plot is that the area of each one of  these bars is telling us the probability of the corresponding value rather than the  height. You might think of the y-axis as representing  not probability but a kind of probability density. The reason for this is to set the stage so that it aligns with the way we  interpret continuous distributions, where the probability of falling between  a range of values is equal to an area under a curve between those values. In particular, the area of all the bars together is going to be one. Now, with all of that in place, let's have a little fun. Let me start by rolling things back so that the distribution on the bottom represents  a relatively small sum, like adding together only three such random variables. Notice what happens as I change the distribution we start with. As it changes, the distribution on the bottom completely changes its shape. It's very dependent on what we started with. If we let the size of our sum get a little bit bigger, say going up to 10,  and as I change the distribution for x, it largely stays looking like a bell curve,  but I can find some distributions that get it to change shape. For example, the really lopsided one where almost all the probability  is in the numbers 1 or 6 results in this kind of spiky bell curve. And if you'll recall, earlier on I actually showed this in the form of a simulation. Though if you were wondering whether that spikiness was an artifact of the randomness  or reflected the true distribution, turns out it reflects the true distribution. In this case, 10 is not a large enough sum for the central limit theorem to kick in. But if instead I let that sum grow and I consider adding 50 different values,  which is actually not that big, then no matter how I change the distribution for our  underlying random variable, it has essentially no effect on the shape of the plot on  the bottom. No matter where we start, all of the information and nuance for the  distribution of x gets washed away, and we tend towards this single  universal shape described by a very elegant function for the standard  normal distribution, 1 over square root of 2 pi times e to the negative x squared over 2. This, this right here is what the central limit theorem is all about. Almost nothing you can do to this initial distribution changes the shape we tend towards. Now, the more theoretically minded among you might still be  wondering what is the actual theorem, like what's the mathematical  statement that could be proved or disproved that we're claiming here. If you want a nice formal statement, here's how it might go. Consider this value where we're summing up n different instantiations of our variable,  but tweaked and tuned so that its mean and standard deviation are 1,  again meaning you can read it as asking how many standard deviations away from the  mean is the sum. Then the actual rigorous no-jokes-this-time statement of the central limit theorem  is that if you consider the probability that this value falls between two given real  numbers, a and b, and you consider the limit of that probability as the size of your  sum goes to infinity, then that limit is equal to a certain integral,  which basically describes the area under a standard normal distribution between those  two values. Again, there are three underlying assumptions that I have yet to tell you,  but other than those, in all of its gory detail,  this right here is the central limit theorem. All of that is a bit theoretical, so it might be helpful to bring things  back down to earth and turn back to the concrete example that I mentioned at the start,  where you imagine rolling a die 100 times, and let's assume it's a fair  die for this example, and you add together the results. The challenge for you is to find a range of values such that  you're 95% sure that the sum will fall within this range. For questions like this, there's a handy rule of thumb about normal distributions,  which is that about 68% of your values are going to fall within one standard  deviation of the mean, 95% of your values, the thing we care about,  fall within two standard deviations of the mean,  and a whopping 99.7% of your values will fall within three standard  deviations of the mean. It's a rule of thumb that's commonly memorized  by people who do a lot of probability and stats. Naturally, this gives us what we need for our example,  and let me go ahead and draw out what this would look like,  where I'll show the distribution for a fair die up at the top,  and the distribution for a sum of 100 such dice on the bottom,  which by now as you know looks like a certain normal distribution. Step 1 with a problem like this is to find the mean of your initial distribution,  which in this case will look like 1 6th times 1 plus 1 6th times 2 on and on and on,  and works out to be 3.5. We also need the standard deviation, which requires calculating the variance,  which as you know involves adding all the squares of the differences between the  values and the means, and it works out to be 2.92,  square root of that comes out to be 1.71. Those are the only two numbers we need, and I will invite you  again to reflect on how magical it is that those are the only  two numbers you need to completely understand the bottom distribution. Its mean will be 100 times mu, which is 350, and its standard deviation  will be the square root of 100 times sigma, so 10 times sigma, 17.1. Remembering our handy rule of thumb, we're looking for values two standard  deviations away from the mean, and when you subtract 2 sigma from mean,  you end up with about 316, and when you add 2 sigma you end up with 384. There you go, that gives us the answer. Okay, I promised to wrap things up shortly, but while we're on this example,  there's one more question that's worth your time to ponder. Instead of just asking about the sum of 100 die rolls,  let's say I had you divide that number by 100,  which basically means all the numbers in our diagram in the bottom get divided by 100. Take a moment to interpret what this all would be saying then. The expression essentially tells you the empirical average for 100 different die rolls,  and that interval we found is now telling you what range you are  expecting to see for that empirical average. In other words, you might expect it to be around 3.5,  that's the expected value for a die roll, but what's much less obvious and what  the central limit theorem lets you compute is how close to that expected value  you'll reasonably find yourself. In particular, it's worth your time to take a moment mulling over  what the standard deviation for this empirical average is,  and what happens to it as you look at a bigger and bigger sample of die rolls. Lastly, but probably most importantly, let's talk  about the assumptions that go into this theorem. The first one is that all of these variables that  we're adding up are independent from each other. The outcome of one process doesn't influence the outcome of any other process. The second is that all of these variables are drawn from the same distribution. Both of these have been implicitly assumed with our dice example. We've been treating the outcome of each die roll as independent from the outcome  of all the others, and we're assuming that each die follows the same distribution. Sometimes in the literature you'll see these two assumptions lumped  together under the initials IID for independent and identically distributed. One situation where these assumptions are decidedly not true would be the Galton board. I mean, think about it. Is it the case that the way a ball bounces off of one of the pegs  is independent from how it's going to bounce off the next peg? Absolutely not. Depending on the last bounce, it's coming in with a completely different trajectory. And is it the case that the distribution of possible outcomes  off of each peg are the same for each peg that it hits? Again, almost certainly not. Maybe it hits one peg glancing to the left, meaning the outcomes are hugely  skewed in that direction, and then hits the next one glancing to the right. When I made all those simplifying assumptions in the opening example,  it wasn't just to make this easier to think about. It's also that those assumptions were necessary for this  to actually be an example of the central limit theorem. Nevertheless, it seems to be true that for the real Galton board,  despite violating both of these, a normal distribution does kind of come about? Part of the reason might be that there are generalizations of the theorem beyond  the scope of this video that relax these assumptions, especially the second one. But I do want to caution you against the fact that many times people seem to assume that  a variable is normally distributed, even when there's no actual justification to do so. The third assumption is actually fairly subtle. It's that the variance we've been computing for these variables is finite. This was never an issue for the dice example because  there were only six possible outcomes. But in certain situations where you have an infinite set of outcomes,  when you go to compute the variance, the sum ends up diverging off to infinity. These can be perfectly valid probability distributions, and they do come up in practice. But in those situations, as you consider adding many different  instantiations of that variable and letting that sum approach infinity,  even if the first two assumptions hold, it is very much a possibility  that the thing you tend towards is not actually a normal distribution. If you've understood everything up to this point,  you now have a very strong foundation in what the central limit theorem is all about. And next up, I'd like to explain why it is that this particular function is the  thing that we tend towards, and why it has a pi in it, what it has to do with circles. Thank you.

================================================================================
VIDEO ID: KuXjwB4LzSA
TITLE: But what is a convolution?
URL: https://www.youtube.com/watch?v=KuXjwB4LzSA
PUBLISHED: 2022-11-18T16:00:39Z
STATUS: SUCCESS
================================================================================
Suppose I give you two different lists of numbers, or maybe two different functions,  and I ask you to think of all the ways you might combine those two lists to get  a new list of numbers, or combine the two functions to get a new function. Maybe one simple way that comes to mind is to simply add them together term by term. Likewise with the functions, you can add all the corresponding outputs. In a similar vein, you could also multiply the two lists  term by term and do the same thing with the functions. But there's another kind of combination just as fundamental as both of those,  but a lot less commonly discussed, known as a convolution. But unlike the previous two cases, it's not something that's  merely inherited from an operation you can do to numbers. It's something genuinely new for the context of lists of numbers or combining functions. They show up all over the place, they are ubiquitous in image processing,  it's a core construct in the theory of probability,  they're used a lot in solving differential equations,  and one context where you've almost certainly seen it, if not by this name,  is multiplying two polynomials together. As someone in the business of visual explanations, this is an especially great topic,  because the formulaic definition in isolation and without context can look kind of  intimidating, but if we take the time to really unpack what it's saying,  and before that actually motivate why you would want something like this,  it's an incredibly beautiful operation. And I have to admit, I actually learned a little something  while putting together the visuals for this project. In the case of convolving two different functions,  I was trying to think of different ways you might picture what that could mean,  and with one of them I had a little bit of an aha moment for why it is that  normal distributions play the role that they do in probability,  why it's such a natural shape for a function. But I'm getting ahead of myself, there's a lot of setup for that one. In this video, our primary focus is just going to be on the discrete case,  and in particular building up to a very unexpected but very clever algorithm for  computing these. And I'll pull out the discussion for the continuous case into a second part. It's very tempting to open up with the image processing examples,  since they're visually the most intriguing, but there are a couple bits of finickiness  that make the image processing case less representative of convolutions overall,  so instead let's kick things off with probability,  and in particular one of the simplest examples that I'm sure everyone here has  thought about at some point in their life, which is rolling a pair of dice and  figuring out the chances of seeing various different sums. And you might say, not a problem, not a problem. Each of your two dice has six different possible outcomes,  which gives us a total of 36 distinct possible pairs of outcomes,  and if we just look through them all we can count up how many pairs have a given sum. And arranging all the pairs in a grid like this,  one pretty nice thing is that all of the pairs that have a constant sum are visible  along one of these different diagonals. So simply counting how many exist on each of those diagonals  will tell you how likely you are to see a particular sum. And I'd say, very good, very good, but can you think of  any other ways that you might visualize the same question? Other images that can come to mind to think of  all the distinct pairs that have a given sum? And maybe one of you raises your hand and says, yeah, I've got one. Let's say you picture these two different sets of possibilities each in a row,  but you flip around that second row. That way all of the different pairs which add up to seven line up vertically like this. And if we slide that bottom row all the way to the right,  then the unique pair that adds up to two, the snake eyes, are the only ones that align,  and if I schlunk that over one unit to the right,  the pairs which align are the two different pairs that add up to three. And in general, different offset values of this lower array,  which remember I had to flip around first, reveal all the distinct pairs that  have a given sum. As far as probability questions go, this still isn't especially interesting because  all we're doing is counting how many outcomes there are in each of these categories. But that is with the implicit assumption that there's  an equal chance for each of these faces to come up. But what if I told you I have a special set of dice that's not uniform? Maybe the blue die has its own set of numbers describing the probabilities for  each face coming up, and the red die has its own unique distinct set of numbers. In that case, if you wanted to figure out, say,  the probability of seeing a 2, you would multiply the probability  that the blue die is a 1 times the probability that the red die is a 1. And for the chances of seeing a 3, you look at the two distinct  pairs where that's possible, and again multiply the corresponding  probabilities and then add those two products together. Similarly, the chances of seeing a 4 involves multiplying together  three different pairs of possibilities and adding them all together. And in the spirit of setting up some formulas, let's name these top probabilities a 1,  a 2, a 3, and so on, and name the bottom ones b 1, b 2, b 3, and so on. And in general, this process where we're taking two different arrays of numbers,  flipping the second one around, and then lining them up at various different  offset values, taking a bunch of pairwise products and adding them up,  that's one of the fundamental ways to think about what a convolution is. So just to spell it out a little more exactly, through this process,  we just generated probabilities for seeing 2, 3, 4, on and on up to 12,  and we got them by mixing together one list of values, a, and another list of values, b. In the lingo, we'd say the convolution of those two sequences gives us this new sequence,  the new sequence of 11 values, each of which looks like some sum of pairwise products. If you prefer, another way you could think about the same operation is to first  create a table of all the pairwise products, and then add up along all these diagonals. Again, that's a way of mixing together these two  sequences of numbers to get us a new sequence of 11 numbers. It's the same operation as the sliding windows thought, just another perspective. Putting a little notation to it, here's how you might see it written down. The convolution of a and b, denoted with this little asterisk, is a new list,  and the nth element of that list looks like a sum,  and that sum goes over all different pairs of indices, i and j,  so that the sum of those indices is equal to n. It's kind of a mouthful, but for example, if n was 6,  the pairs we're going over are 1 and 5, 2 and 4, 3 and 3, 4 and 2, 5 and 1,  all the different pairs that add up to 6. But honestly, however you write it down, the notation is secondary in  importance to the visual you might hold in your head for the process. Here, maybe it helps to do a super simple example,  where I might ask you what's the convolution of the list 1, 2, 3 with the list 4, 5, 6. You might picture taking both of these lists, flipping around that second one,  and then starting with its lid all the way over to the left. Then the pair of values which align are 1 and 4,  multiply them together, and that gives us our first term of our output. Slide that bottom array one unit to the right,  the pairs which align are 1, 5 and 2 and 4, multiply those pairs,  add them together, and that gives us 13, the next entry in our output. Slide things over once more, and we'll take 1 times 6 plus 2 times 5 plus 3 times 4,  which happens to be 28. One more slide and we get 2 times 6 plus 3 times 5, and that gives us 27. And finally the last term will look like 3 times 6. If you'd like, you can pull up whatever your favorite programming  language is and your favorite library that includes various numerical operations,  and you can confirm I'm not lying to you. If you take the convolution of 1, 2, 3 against 4,  5, 6, this is indeed the result that you'll get. We've seen one case where this is a natural and desirable operation,  adding up to probability distributions, and another common example would be a  moving average. Imagine you have some long list of numbers, and you take  another smaller list of numbers that all add up to 1. In this case, I just have a little list of 5 values and they're all equal to 1 5th. Then if we do this sliding window convolution process,  and kind of close our eyes and sweep under the rug what happens at  the very beginning of it, once our smaller list of values entirely  overlaps with the bigger one, think about what each term in this convolution really means. At each iteration, what you're doing is multiplying each of the values  from your data by 1 5th and adding them all together,  which is to say you're taking an average of your data inside this little window. Overall, the process gives you a smoothed out version of the original data,  and you could modify this starting with a different little list of numbers,  and as long as that little list all adds up to 1,  you can still interpret it as a moving average. In the example shown here, that moving average  would be giving more weight towards the central value. This also results in a smoothed out version of the data. If you do kind of a two-dimensional analog of this,  it gives you a fun algorithm for blurring a given image. And I should say the animations I'm about to show are modified from something  I originally made for part of a set of lectures I did with the Julia lab at  MIT for a certain open courseware class that included an image processing unit. There we did a little bit more to dive into the code behind all of this,  so if you're curious, I'll leave you some links. But focusing back on this blurring example, what's going on is I've got this  little 3x3 grid of values that's marching along our original image, and if we zoom in,  each one of those values is 1 9th, and what I'm doing at each iteration is  multiplying each of those values by the corresponding pixel that it sits on top of. And of course in computer science, we think of colors as little vectors of three values,  representing the red, green, and blue components. When I multiply all these little values by 1 9th and I add them together,  it gives us an average along each color channel,  and the corresponding pixel for the image on the right is defined to be that sum. The overall effect, as we do this for every single pixel on the image,  is that each one kind of bleeds into all of its neighbors,  which gives us a blurrier version than the original. In the lingo, we'd say that the image on the right is a  convolution of our original image with a little grid of values. Or more technically, maybe I should say that it's the convolution  with a 180 degree rotated version of that little grid of values. Not that it matters when the grid is symmetric,  but it's just worth keeping in mind that the definition of a convolution,  as inherited from the pure math context, should always invite you to think about  flipping around that second array. If we modify this slightly, we can get a much more elegant  blurring effect by choosing a different grid of values. In this case, I have a little 5x5 grid, but the distinction is not so much its size. If we zoom in, we notice that the value in the middle  is a lot bigger than the value towards the edges. And where this is coming from is they're all sampled from a bell curve,  known as a Gaussian distribution. That way, when we multiply all of these values by the corresponding  pixel that they're sitting on top of, we're giving a lot more weight  to that central pixel, and much less towards the ones out at the edge. And just as before, the corresponding pixel on the right is defined to be this sum. As we do this process for every single pixel, it gives a blurring effect,  which much more authentically simulates the notion of putting your lens out of focus,  or something like that. But blurring is far from the only thing that you can do with this idea. For instance, take a look at this little grid of values,  which involves some positive numbers on the left,  and some negative numbers on the right, which I'll color with blue and red respectively. Take a moment to see if you can predict and understand  what effect this will have on the final image. So in this case, I'll just be thinking of the image as grayscale instead of colored,  so each of the pixels is just represented by one number instead of three. And one thing worth noticing is that as we do this convolution,  it's possible to get negative values. For example, at this point here, if we zoom in,  the left half of our little grid sits entirely on top of black pixels,  which would have a value of zero, but the right half of negative values all sit on  top of white pixels, which would have a value of one. So when we multiply corresponding terms and add them together,  the results will be very negative. And the way I'm displaying this with the image on the right  is to color negative values red and positive values blue. Another thing to notice is that when you're on a patch that's all the same color,  everything goes to zero, since the sum of the values in our little grid is zero. This is very different from the previous two examples where the sum of our little  grid was one, which let us interpret it as a moving average and hence a blur. All in all, this little process basically detects wherever there's  variation in the pixel value as you move from left to right,  and so it gives you a kind of way to pick up on all the vertical edges from your image. And similarly, if we rotated that grid around so that it varies as you move from  the top to the bottom, this will be picking up on all the horizontal edges,  which in the case of our little pie creature image does result in some pretty  demonic eyes. This smaller grid, by the way, is often called a kernel,  and the beauty here is how just by choosing a different kernel,  you can get different image processing effects, not just blurring your edge detection,  but also things like sharpening. For those of you who have heard of a convolutional neural network,  the idea there is to use data to figure out what the kernels should be in  the first place, as determined by whatever the neural network wants to detect. Another thing I should maybe bring up is the length of the output. For something like the moving average example,  you might only want to think about the terms when both of the windows  fully align with each other. Or in the image processing example, maybe you want  the final output to have the same size as the original. Now, convolutions as a pure math operation always produce an  array that's bigger than the two arrays that you started with,  at least assuming one of them doesn't have a length of one. Just know that in certain computer science contexts,  you often want to deliberately truncate that output. Another thing worth highlighting is that in the computer science context,  this notion of flipping around that kernel before you let it march across  the original often feels really weird and just uncalled for, but again,  note that that's what's inherited from the pure math context,  where like we saw with the probabilities, it's an incredibly natural thing to do. And actually, I can show you one more pure math example where  even the programmers should care about this one,  because it opens the doors for a much faster algorithm to compute all of these. To set up what I mean by faster here, let me go back and pull up some Python again,  and I'm going to create two different relatively big arrays. Each one will have a hundred thousand random elements in it,  and I'm going to assess the runtime, of the convolve function from the NumPy library. And in this case, it runs it for multiple different iterations, tries to find an average,  and it looks like, on this computer at least, it averages at 4.87 seconds. By contrast, if I use a different function from the SciPy library called fftConvolve,  which is the same thing just implemented differently,  that only takes 4.3 milliseconds on average, so three orders of magnitude improvement. And again, even though it flies under a different name,  it's giving the same output that the other convolve function does,  it's just doing something to go about it in a cleverer way. Remember how with the probability example, I said another way you could  think about the convolution was to create this table of all the pairwise products,  and then add up those pairwise products along the diagonals. There's of course nothing specific to probability. Any time you're convolving two different lists of numbers,  you can think about it this way. Create this kind of multiplication table with all pairwise products,  and then each sum along the diagonal corresponds to one of your final outputs. One context where this view is especially natural  is when you multiply together two polynomials. For example, let me take the little grid we already have and replace the top terms  with 1, 2x, and 3x squared, and replace the other terms with 4, 5x, and 6x squared. Now, think about what it means when we're creating all of  these different pairwise products between the two lists. What you're doing is essentially expanding out the full product of  the two polynomials I have written down, and then when you add up along the diagonal,  that corresponds to collecting all like terms. Which is pretty neat. Expanding a polynomial and collecting like terms  is exactly the same process as a convolution. But this allows us to do something that's pretty cool,  because think about what we're saying here. We're saying if you take two different functions and you multiply them together,  which is a simple pointwise operation, that's the same thing as if you had  first extracted the coefficients from each one of those, assuming they're polynomials,  and then taken a convolution of those two lists of coefficients. What makes that so interesting is that convolutions feel,  in principle, a lot more complicated than simple multiplication. And I don't just mean conceptually they're harder to think about. I mean, computationally, it requires more steps to perform a convolution  than it does to perform a pointwise product of two different lists. For example, let's say I gave you two really big polynomials,  say each one with a hundred different coefficients. Then if the way you multiply them was to expand out this product,  you know, filling in this entire 100 by 100 grid of pairwise products,  that would require you to perform 10,000 different products. And then, when you're collecting all the like terms along the diagonals,  that's another set of around 10,000 operations. More generally, in the lingo, we'd say the algorithm is O of n squared,  meaning for two lists of size n, the way that the number of  operations scales is in proportion to the square of n. On the other hand, if I think of two polynomials in terms of their outputs, for example,  sampling their values at some handful of inputs,  then multiplying them only requires as many operations as the number of samples,  since again, it's a pointwise operation. And with polynomials, you only need finitely many  samples to be able to recover the coefficients. For example, two outputs are enough to uniquely specify a linear polynomial,  three outputs would be enough to uniquely specify a quadratic polynomial,  and in general, if you know n distinct outputs,  that's enough to uniquely specify a polynomial that has n different coefficients. Or, if you prefer, we could phrase this in the language of systems of equations. Imagine I tell you I have some polynomial, but I don't tell you what the coefficients are. Those are a mystery to you. In our example, you might think of this as the product that we're trying to figure out. And then, suppose I say, I'll just tell you what the outputs of this polynomial  would be if you inputted various different inputs, like 0, 1, 2, 3, on and on,  and I give you enough so that you have as many equations as you have unknowns. It even happens to be a linear system of equations, so that's nice,  and in principle, at least, this should be enough to recover the coefficients. So the rough algorithm outline then would be, whenever you want to convolve two lists  of numbers, you treat them like they're coefficients of two polynomials,  you sample those polynomials at enough outputs, multiply those samples point-wise,  and then solve this system to recover the coefficients as a sneaky backdoor way to find  the convolution. And, as I've stated it so far, at least, some of you could rightfully complain, grant,  that is an idiotic plan, because, for one thing,  just calculating all these samples for one of the polynomials we know already takes  on the order of n-squared operations. Not to mention, solving that system is certainly going to be  computationally as difficult as just doing the convolution in the first place. So, like, sure, we have this connection between multiplication and convolutions,  but all of the complexity happens in translating from one viewpoint to the other. But there is a trick, and those of you who know about Fourier  transforms and the FFT algorithm might see where this is going. If you're unfamiliar with those topics, what I'm  about to say might seem completely out of the blue. Just know that there are certain paths you could have  walked in math that make this more of an expected step. Basically, the idea is that we have a freedom of choice here. If instead of evaluating at some arbitrary set of inputs, like 0, 1, 2, 3,  on and on, you choose to evaluate on a very specially selected set of complex numbers,  specifically the ones that sit evenly spaced on the unit circle,  what are known as the roots of unity, this gives us a friendlier system. The basic idea is that by finding a number where taking its powers falls into  this cycling pattern, it means that the system we generate is going to have a  lot of redundancy in the different terms that you're calculating,  and by being clever about how you leverage that redundancy,  you can save yourself a lot of work. This set of outputs that I've written has a special name. It's called the discrete Fourier transform of the coefficients,  and if you want to learn more, I actually did another lecture for that same Julia MIT  class all about discrete Fourier transforms, and there's also a really excellent video on  the channel Reducible talking about the fast Fourier transform,  which is an algorithm for computing these more quickly. Also Veritasium recently did a really good video on FFTs, so you've got lots of options. And that fast algorithm really is the point for us. Again, because of all this redundancy, there exists a method to go from  the coefficients to all of these outputs, where instead of doing on  the order of n squared operations, you do on the order of n times the  log of n operations, which is much much better as you scale to big lists. And, importantly, this FFT algorithm goes both ways. It also lets you go from the outputs to the coefficients. So, bringing it all together, let's look back at our algorithm outline. Now we can say, whenever you're given two long lists of numbers,  and you want to take their convolution, first compute the fast Fourier transform of  each one of them, which, in the back of your mind,  you can just think of as treating them like they're the coefficients of a polynomial,  and evaluating it at a very specially selected set of points. Then, multiply together the two results that you just got, point-wise,  which is nice and fast, and then do an inverse fast Fourier transform,  and what that gives you is the sneaky backdoor way to compute the convolution that  we were looking for. But this time, it only involves O of n log n operations. That's really cool to me. This very specific context where convolutions show up,  multiplying two polynomials, opens the doors for an algorithm  that's relevant everywhere else where convolutions might come up. If you want to add probability distributions, do some large image processing,  whatever it might be, and I just think that's such a good example of why you should be  excited when you see some operation or concept in math show up in a lot of seemingly  unrelated areas. If you want a little homework, here's something that's fun to think about. Explain why when you multiply two different numbers,  just ordinary multiplication the way we all learn in elementary school,  what you're doing is basically a convolution between the digits of those numbers. There's some added steps with carries and the like, but the core step is a convolution. In light of the existence of a fast algorithm,  what that means is if you have two very large integers,  then there exists a way to find their product that's faster than the method we learn  in elementary school, that instead of requiring O of n squared operations,  only requires O of n log n, which doesn't even feel like it should be possible. The catch is that before this is actually useful in practice,  your numbers would have to be absolutely monstrous. But still, it's cool that such an algorithm exists. And next up, we'll turn our attention to the continuous  case with a special focus on probability distributions.

================================================================================
VIDEO ID: 851U557j6HE
TITLE: Researchers thought this was a bug (Borwein integrals)
URL: https://www.youtube.com/watch?v=851U557j6HE
PUBLISHED: 2022-11-04T15:54:19Z
STATUS: SUCCESS
================================================================================
Sometimes it feels like the universe is just messing with you. I have up on screen here a sequence of computations, and don't worry,  in a moment we're gonna unpack and visualize what each one is really saying. What I want you to notice is how the sequence follows a very predictable,  if random, seeming pattern, and how each computation happens to equal pi. And if you were just messing around evaluating these on a computer for some reason,  you might think that this was a pattern that would go on forever. But it doesn't. At some point it stops, and instead of equaling pi,  you get a value which is just barely, barely less than pi. All right, let's dig into what's going on here. The main character in the story today is the function sine of x divided by x. This actually comes up commonly enough in math and engineering that it gets its own name,  sinc, and the way you might think about it is by starting with a normal  oscillating sine curve, and then sort of squishing it down as you get  far away from zero by multiplying it by 1 over x. And the astute among you might ask about what happens at x equals 0,  since when you plug that in it looks like dividing 0 by 0. And then the even more astute among you, maybe fresh out of a calculus class,  could point out that for values closer and closer to 0,  the function gets closer and closer to 1. So if we simply redefine the sinc function at 0 to equal 1,  you get a nice continuous curve. All of that is a little by the by because the thing we actually care about is the  integral of this curve from negative infinity to infinity,  which you'd think of as meaning the area between the curve and the x-axis,  or more precisely the signed area, meaning you add all the area bound by the positive  parts of the graph in the x-axis, and you subtract all of the parts bound by the  negative parts of the graph and the x-axis. Like we saw at the start, it happens to be the case that this evaluates to be exactly pi,  which is nice and also a little weird, and it's not entirely clear how  you would approach this with the usual tools of calculus. Towards the end of the video, I'll share the trick for how you would do this. Progressing on with the sequence I opened with,  the next step is to take a copy of the sinc function, where you plug in x divided by 3,  which will basically look like the same graph,  but stretched out horizontally by a factor of 3. When we multiply these two functions together,  we get a much more complicated wave whose mass seems to be more concentrated  towards the middle, and with any usual functions you would expect this  completely changes the area. You can't just randomly modify an integral like this and expect nothing to change. So already it's a little bit weird that this result also equals pi,  that nothing has changed. That's another mystery you should add to your list. And the next step in the sequence was to take an even more stretched out version  of the sinc function by a factor of 5, multiply that by what we already have,  and again look at the signed area underneath the whole curve, which again equals pi. And it continues on like this. With each iteration, we stretch out by a new odd  number and multiply that into what we have. One thing you might notice is how except at the input x equals 0,  every single part of this function is progressively getting multiplied by something  that's smaller than 1. So you would expect, as the sequence progresses,  for things to get squished down more and more,  and if anything you would expect the area to be getting smaller. Eventually that is exactly what happens, but what's bizarre is that it  stays so stable for so long, and of course more pertinently,  that when it does break at the value 15, it does so by the tiniest tiny amount. And before you go thinking this is the result of some numerical error,  maybe because we're doing something with floating-point arithmetic,  if you work this out more precisely, here is the exact value of that last integral,  which is a certain fraction of pi where the numerator and the denominator are absurd. They're both around 400 billion billion billion. So this pattern was described in a paper by a father-son pair,  Jonathan and David Borwein, which is very fun,  and they mentioned how when a fellow researcher was computing these integrals using a  computer algebra system, he assumed that this had to be some kind of bug. But it's not a bug, it is a real phenomenon. And it gets weirder than that actually. If we take all these integrals and include yet another factor, 2 cosine of x,  which again you would think changes their values entirely,  you can't just randomly multiply new things into an integral like this,  it continues to equal pi for much much longer,  and it's not until you get to the number 113 that it breaks. And when it breaks, it's by the most puny, absolutely  subtle amount that you could imagine. So the natural question is what on earth is going on here? And luckily there actually is a really satisfying explanation for all this. The way I think I'll go about this is to show you a phenomenon that  first looks completely unrelated, but it shows a similar pattern,  where you have a value that stays really stable until you get to the number 113.  You get to the number 15, and then it falters by just a tiny amount. And then after that I'll show why this seemingly unrelated phenomenon  is secretly the same as all our integral expressions, but in disguise. So, turning our attention to what seems completely different,  consider a function that I'm going to be calling rect of x,  which is defined to equal 1 if the input is between negative 1 half and 1 half,  and otherwise it's equal to 0. So the function is this boring step, basically. This will be the first in a sequence of functions that we define,  so I'll call it f1 of x, and each new function in our sequence  is going to be a kind of moving average of the previous function. So for example, the way the second iteration will be defined is to take this  sliding window whose width is 1 third, and for a particular input x,  when the window is centered at that input x, the value in my new function drawn  below is defined to be equal to the average value of the first function above  inside that window. So for example, when the window is far enough to the left,  every value inside it is 0, so the graph on the bottom is showing 0. As soon as that window starts to go over the plateau a little bit,  the average value is a little more than 0, and you see that in the graph below. And notice that when exactly half the window is over that plateau at 1 and half of it  is at 0, the corresponding value in the bottom graph is 1 half, and you get the point. The important thing I want you to focus on is how when that window is  entirely in the plateau above, where all the values are 1,  then the average value is also 1, so we get this plateau on our function at the bottom. Let's call this bottom function f2 of x, and what I want you to  think about is the length of the plateau for that second function. How wide should it be? If you think about it for a moment, the distance between the left  edge of the top plateau and the left edge of the bottom plateau  will be exactly half of the width of the window, so half of 1 third. And similarly on the right side, the distance between  the edges of the plateaus is half of the window width. So overall it's 1 minus that window width, which is 1 minus 1 third. The value we're going to be computing, the thing that will look stable for  a while before it breaks, is the value of this function at the input 0,  which in both of these iterations is equal to 1 because it's inside that plateau. For the next iteration, we're going to take a moving average of that last function,  but this time with the window whose width is 1 fifth. It's kind of fun to think about why as you slide around this window you get a  smoothed out version of the previous function, and again,  the significant thing I want you to focus on is how when that window is entirely  inside the plateau of the previous function, then by definition the bottom function  is going to equal 1. This time the length of that plateau on the bottom will be the length  of the previous one, 1 minus 1 third, minus the window width, 1 fifth. The reasoning is the same as before in order to go from the point where the middle of  the window is on that top plateau to where the entirety of the window is inside that  plateau is half the window width and likewise on the right side,  and once more the value to record is the output of this function when the input is 0,  which again is exactly 1. The next iteration is a moving average with a window width of 1 seventh. The plateau gets smaller by that 1 over 7. Doing one more iteration with 1 over 9, the plateau gets smaller by that amount. And as we keep going the plateau gets thinner and thinner. And also notice how just outside of the plateau the function is really really  close to 1 because it's always been the result of an average between the  plateau at 1 and the neighbors, which themselves are really really close to 1. The point at which all of this breaks is once we get to the iteration  where we're sliding a window with width 1 15th across the whole thing. At that point the previous plateau is actually thinner than the window itself. So even at the input x equals 0, this moving average  will have to be ever so slightly smaller than 1. And the only thing that's special about the number 15 here is that as we keep adding  the reciprocals of these odd fractions, one third plus one fifth plus one seventh,  on and on, it's once we get to one fifteenth that that sum grows to be bigger than 1. And in the context of our shrinking plateaus, having started with a plateau of width 1,  it's now shrunk down so much that it'll disappear entirely. The point is with this as a sequence of functions that we've defined by a  seemingly random procedure, if I ask you to compute the values of all of  these functions at the input 0, you get a pattern which initially looks stable. It's 1 1 1 1 1 1 1, but by the time we get to the eighth  iteration it falls short ever so slightly, just barely. This is analogous, and I claim more than just analogous, to the integrals we saw earlier,  where we have a stable value at pi pi pi pi pi until it falls short just barely. And as it happens, this constant from our moving average process that's ever so slightly  smaller than 1 is exactly the factor that sits in front of pi in our series of integrals. So the two situations aren't just qualitatively similar,  they're quantitatively the same as well. And when it comes to the case where we add the 2 cosine of x term inside the integral,  which caused the pattern to last a lot longer before it broke down,  in the analogy what that will correspond to is the same setup,  but where the function we start with has an even longer plateau,  stretching from x equals negative 1 up to 1, meaning its length is 2. So as you do this repeated moving average process,  eating into it with these smaller and smaller windows,  it takes a lot longer for them to eat into the whole plateau. More specifically, the relevant computation is to ask how long do you have  to add these reciprocals of odd numbers until that sum becomes bigger than 2? And it turns out that you have to go until you hit the number 113,  which will correspond to the fact that the integral pattern there continues until  you hit 113. And by the way, I should emphasize that there is nothing special  about these reciprocals of odd numbers, 1 3rd, 1 5th, 1 7th. That just happens to be the sequence of values highlighted by the Borweins  in their paper that made the sequence mildly famous in nerd circles. More generally, we could be inserting any sequence of positive  numbers into those sinc functions, and as long as the sum of  those numbers is less than 1, our expression will equal pi. But as soon as they become bigger than 1, our expression drops a little below pi. And if you believe me that there's an analogy with these moving averages,  you can hopefully see why. But of course, the burning question is why on earth should  these two situations have anything to do with each other? From here, the argument does bring in two mildly heavy bits of machinery,  namely Fourier transforms and convolutions. And the way I'd like to go about this is to spend the remainder of this video  giving you a high-level sense of how the argument will go,  without necessarily assuming you're familiar with either of those two topics,  and then to explain why the details are true in a video that's dedicated to convolutions,  in particular something called the convolution theorem,  since it's incredibly beautiful and it's useful well beyond this specific,  very esoteric question. To start, instead of focusing on this function sine of x divided by x,  where we want to show why the signed area underneath its curve is equal to pi,  we'll make a simple substitution where we replace the input x with pi times x,  which has the effect of squishing the graph horizontally by a factor of pi,  and so the area gets scaled down by a factor of pi,  meaning our new goal is to show why this integral on the right is equal to exactly 1. By the way, in some engineering contexts, people use the name sinc to  refer to this function with the pi on the inside,  since it's often very nice to have a normalized function,  meaning the area under it is equal to 1. The point is, showing this integral on the right is exactly the same  thing as showing the integral on the left, it's just a change of variables. And likewise for all of the other ones in our sequence, go through each of them,  replace the x with a pi times x, and from here the claim is that all these  integrals are not just analogous to the moving average examples,  but that both of these are two distinct ways of computing exactly the same thing. And the connection comes down to the fact that this sinc function,  or the engineer sinc function with the pi on the inside,  is related to the rect function using what's known as a Fourier transform. Now, if you've never heard of a Fourier transform,  there are a few other videos on this channel all about it. The way it's often described is that if you want to break down a function as  the sum of a bunch of pure frequencies, or in the case of an infinite function,  a continuous integral of a bunch of pure frequencies,  the Fourier transform will tell you all the strength and phases for all those  constituent parts. But all you really need to know here is that it is something which  takes in one function and spits out a new function,  and you often think of it as kind of rephrasing the information of your  original function in a different language, like you're looking at it  from a new perspective. For example, like I said, this sinc function written in this new language  where you take a Fourier transform looks like our top hat rect function. And vice versa, by the way. This is a nice thing about Fourier transforms for functions that are symmetric  about the y-axis, it is its own inverse, and actually the slightly more general  fact that we'll need to show is how when you transform the stretched out  version of our sinc function, where you stretch it horizontally by a factor of k,  what you get is a stretched and squished version of this rect function. But of course, all of these are just meaningless words and terminology,  unless you can actually do something upon making this translation. And the real idea behind why Fourier transforms are such a useful thing for math  is that when you take statements and questions about a particular function,  and then you look at what they correspond to with respect to the transformed  version of that function, those statements and questions often look very very  different in this new language, and sometimes it makes the questions a lot easier  to answer. For example, one very nice little fact, another thing on our list of things to show,  is that if you want to compute the integral of some function from negative infinity  to infinity, this signed area under the entirety of its curve,  it's the same thing as simply evaluating the Fourier transformed version of that  function at the input zero. This is a fact that will actually just pop right out of the definition,  and it's representative of a more general vibe that every individual  output of the Fourier transform function on the right corresponds to  some kind of global information about the original function on the left. In our specific case, it means if you believe me that this sync function and the  rect function are related with a Fourier transform like this, it explains the integral,  which is otherwise a very tricky thing to compute,  because it's saying all that signed area is the same thing as evaluating rect at zero,  which is just one. Now, you could complain, surely this just moves the bump under the rug. Surely computing this Fourier transform, whatever that looks like,  would be as hard as computing the original integral. But the idea is that there's lots of tips and tricks for  computing these Fourier transforms, and moreover, that when you do,  it tells you a lot more information than just that integral. You get a lot of bang for your buck out of doing the computation. Now, the other key fact that will explain the connection we're hunting for is that if  you have two different functions and you take their product,  and then you take the sum of the Fourier transform of that product,  it will be the same thing as if you individually took the Fourier transforms of your  original function and then combined them using a new kind of operation that we'll talk  all about in the next video, known as a convolution. Now, even though there's a lot to be explained with convolutions,  the upshot will be that in our specific case with these rectangular functions,  taking a convolution looks just like one of the moving averages that we've been  talking about this whole time, combined with our previous fact that integrating in  one context looks like evaluating at zero in another context,  if you believe me that multiplying in one context corresponds to this new operation,  convolutions, which for our example you should just think of as moving averages,  that will explain why multiplying more and more of these sinc functions together  can be thought about in terms of these progressive moving averages and always  evaluating at zero, which in turn gives a really lovely intuition for why you would  expect such a stable value before eventually something breaks down as the edges of  the plateau inch closer and closer to the center. This last key fact, by the way, has a special name. It's called the convolution theorem, and again,  it's something that we'll go into much more deeply. I recognize that it's maybe a little unsatisfying to end things here  by laying down three magical facts and saying everything follows from those,  but hopefully this gives you a little glimpse of why powerful tools  like Fourier transforms can be so useful for tricky problems. It's a systematic way to provide a shift in perspective  where hard problems can sometimes look easier. If nothing else, it hopefully provides some motivation to  learn about these beautiful things like the convolution theorem. As one more tiny teaser, another fun consequence of this convolution theorem will  be that it opens the doors for an algorithm that lets you compute the product of  two large numbers very quickly, like way faster than you think should be even possible. So with that, I'll see you in the next video.

================================================================================
VIDEO ID: cDofhN-RJqg
TITLE: What makes a great math explanation? | SoME2 results
URL: https://www.youtube.com/watch?v=cDofhN-RJqg
PUBLISHED: 2022-10-01T19:23:52Z
STATUS: SUCCESS
================================================================================
In the last month or two, there's been a measurable increase in  the attention to a wide variety of smaller math channels on YouTube. My friend James and I ran a second iteration of a contest that we did last year,  the Summer of Math Exposition, which invites people to put up lessons about math online. It could be a video, it could be an article, any medium you dream up,  whatever topic you dream up, and we have some prizes available for the ones that we deem,  in some sense, best, whatever that could mean. The deadline for submissions was a little over a month ago,  and if we just focus on the video entries, they've collectively accumulated over 7  million views since that time. Considering that the vast majority of these are uploaded to very young channels,  where the video is often just the first or second upload,  this was really exciting for me to see. I suspect a big part of the reason for this rising tide is that after the  submission deadline, we ran a peer-review process where an algorithm would  feed participants two different videos to compare,  and they'd be asked to vote which one of these is, quote, better,  according to a few criteria. That process generated over 10,000 comparisons, which on the one hand,  helps to provide an initial rough rank ordering of all the videos,  but more important than that, any judgements or rankings,  it gave an excuse for many hundreds of people to upload around a similar time,  and then collectively view each other's work, helping to jumpstart a cluster  of videos with a shared viewer base. And that 7 million number doesn't account for other videos on these channels,  for instance the many submissions people made to last year's contest, which,  since this year's deadline, collectively jumped up by about 2 million views. One group who told me that last year's contest was what inspired them to put up  their first video, mentioned to me that a video they had made in between the two  contests managed to suddenly jump from 1,000 to 600,000 views during the peer-review  process for this year's contest, despite not being among those videos reviewed. This is all to say, there can be a surprising value in the  seemingly simple presence of a shared goal and a shared deadline. And again, these are just the video entries, where it's easy  for us to run these analytics to quickly get a sense of the reach. Many of my favorite entries were the written ones. The spirit of the contest, as you can no doubt tell,  is getting more people to put out math lessons, and on that front, mission accomplished. But I did promise to select five winners, lessons that stood out as especially  valuable for one reason or another, and that brings us to this video here. To choose winners, James and I both spent a couple weeks giving a pretty thorough  look at over 100 of the top entries, as determined by the peer-review process. We also recruited a few guest judges from the community to help look at a subset of  these and make sure that our own biases and blind spots aren't playing too heavy a role. Many many thanks to them and the time they offered. I won't tell you the final decision until the end of the video. What I thought might be more fun is to lead up to it by talking through the criteria  that I had in mind when making this selection,  highlighting as many exemplary submissions as I can along the way,  hopefully giving any of you who are looking to put out your own math lessons online  at some point a few concrete things to focus on. At a high level, the four criteria I told people I'd look out for were motivation,  clarity, novelty, and memorability. The first two are probably the most important, and let's start with motivation. This actually has two meanings I can think of,  one on the macro scale and one on the micro scale. By macro scale motivation, I mean how well do you hook someone into the lesson as a whole? This video by Alexander Berdnikov opens by asking why it is that when  you hear a plane approaching the pitch of its sound seems to slowly fall. He points out how a lot of people assume that this is the Doppler effect,  but that this doesn't actually hold up to scrutiny,  since for example that pitch actually rises as the plane is going away from you. It's a good point, and an interesting question, you have my attention. One of my favorite articles in the batch by Adi Mittal prompts you to wonder about  an algorithm behind the panorama feature on your phone, and proceeds to explain 1. why that's not trivial, and 2. the linear algebra and projective geometry involved in a DIY-style  project to stitch together two overlapping images taken at different angles. Application and tangible problems can make for great motivation,  but that's not the only source of motivation. Depending on the target audience, a good nerd sniping question can also do the trick. This video on the channel Going Null opens with a seemingly impossible puzzle. 10 prisoners are each given a hat, chosen arbitrarily from 10 total hat types available. It is possible for some of the prisoners to have the same hat type as others,  and everyone can see all of the other hats, but not their own. After given a little time to look at everyone else's hat and think about it all,  the prisoners are to simultaneously shout out a guess for their own hat type. The question is, can you find a method that guarantees  at least one of the prisoners will make a correct guess? This video by Eric Rowland motivates the idea of p-adic numbers and the p-adic metric  by showing how if you take 2 to the 10th, and 2 to the 100th, 2 to the 1000th,  so on and so on, and you assign distinct colors to each digit,  lining them all up on the right, you can see that their final digits line up more  and more with larger powers. Then he asks the question of whether it's reasonable to interpret  this as a kind of convergence, despite the fact that these  numbers are clearly diverging to infinity in the usual sense. A completely different form of motivation can come from showing  the historical significance of a problem or a field,  in a sense giving the viewer a feeling that they're part of something bigger. One excellent video on a channel A Well-Rested Dog provides an overview  of the history of calculus and the progression of how some of the world's  smartest minds grappled with the nuances of infinity and infinitesimals. It's the right mixture of entertaining and detailed,  and he goes on to talk about how learning all of this made his own questions  and confusions in a calculus class feel validated,  which I think a lot of students can resonate with. This example is less about the intro of a video motivating the lesson it teaches,  and more about the entire video motivating an entire field. Another one like that would be this lecture, by the channel Thisery,  laying out how Cantor's diagonalization argument and the halting  problem and a number of other paradoxes people might have heard of in math,  computer science, and logic all follow the same basic pattern. And moreover, if you try to formalize the exact sense in which they follow the same  pattern, that ends up serving as a pretty nice motivation for the subject of category  theory. And the last flavor of motivation I'll mention is if you can somehow  make the learner feel like they're playing an active role in the lesson. This is very hard to do with a video, maybe even impossible,  and it's best suited for in-person lessons. But one written entry that I thought did this especially well was an inverse Turing test,  where you as the reader are challenged to come up with a sequence of ones and zeros that  appears random, and the article goes on to explain various statistical tests that you  could apply to prove that the sequence was actually human-generated,  and not really random. The content of the article is centered around the particular sequence that you,  the reader, created, and you're invited to change it along  the way to try to get it to pass more tests. It's a nice touch, and I could easily see this  working really well as a classroom activity. Whatever approach you take, whatever flavor of motivation is your favorite,  it's hard to overstate just how important it is that you do actually give viewers a  reason to care. This is true for any piece of content, but I think it's especially  true for educational content and even more so for math,  given the amount of focus and thought that these topics sometimes require. I think this was articulated best by the author of one of my favorite podcasts,  An Opinionated History of Mathematics, who has a manifesto on his website  that lays out what he calls the axioms of learning, beginning with the first axiom,  quote, In a perfect world, students pursue learning not because it is prescribed to them,  but rather out of a genuine desire to figure things out. It follows that we must not introduce any topic for which we cannot  first convince the students that they should want to pursue it. That said, one mistake that I think I've made in past  videos is to over-philosophize in the video's introduction. Motivation is critical, but it doesn't have to take long,  and often what actually keeps the viewer engaged is to get right to  the point and leave any commentary about broader themes and connections to the end. If you can, motivate using clear examples, not  sweeping statements or promises of what is to come. By microscale motivation, what I mean is whether each new idea that's introduced  in the lesson itself feels to the learner like it has a good reason to be there. For instance, this video by Joshua Maros gives a fairly detailed overview of ray tracing,  and what I love about it is that before he introduces any new technical topic,  like the rendering equation, importance sampling, or the ReSTER algorithm,  he's already outlined the main idea and intuition for that topic with really  well-visualized examples. It makes it so that once the equation comes on the screen, or the algorithm is described,  it doesn't feel like an expression handed down with nothing to hold onto. Instead, it arrives only once it's articulating something that already  exists at least loosely in the viewer's mind, making it much easier to parse. This video by Michael DeFranco about extending the factorial offers  another great example of a lesson with good motivation along the way. You may have heard that there's a function generalizing the  factorial to real and even complex inputs, the gamma function. The usual definition is written down as a certain integral expression  sort of handed down from on high, and the justification for why this  generalizes factorials is certain properties that you can prove about it. But a lot of students find this unsatisfying. Where does it come from? By contrast, in Michael's explanation, he starts by observing the properties  that are true of the normal factorial function that you would want to be true  of a general version, and uses those desired properties to motivate various  different alternate expressions massaged here and there to be more amenable  to non-whole-number inputs, ultimately leading to a pretty satisfying answer. Another good template for this microscale motivation when  introducing a pretty complicated solution to a problem is to  start with a naive but flawed solution, and then progressively refine it. This article by Max Slater on differential programming does this particularly well. The basic question is how you get computers to evaluate derivatives,  a ubiquitous task for machine learning. He starts by describing the most obvious approach,  and then what flaws it has, and uses that as motivation for another approach. But that one has its own flaws, and fixing those motivates yet another approach,  and so on. The ideas he builds up to, dual numbers and backward-mode automatic differentiation,  both could feel a bit confusing if presented out of the blue,  but in context, having motivated each new idea by pointing out flaws  with the previous ones, it all ends up feeling utterly reasonable. Turning back to that same prisoner hat puzzle I referenced earlier,  one of the other things I liked about it is how the author doesn't just  present the solution, there are plenty of puzzle videos out there which do that. Instead, he gives a pretty authentic look at the wrong turns and tangents that  are involved in the problem-solving process, not even eating up too much time to do so,  and justifies each new step with a general problem-solving principle. All of this microscale motivation could just as  well be categorized as a subset of clarity. If motivating a lesson determines how much attention and focus the viewer is  willing to give you, clarity determines how quickly you burn through that focus. The best hook in the world is wasted if the lesson which follows is confusing. This presentation by Xplanaria talks about how to describe various crystal structures  using group theory, which, considering the complex 3D forms involved and the fact  that most people don't know group theory, has the potential to be very confusing. But they do a really effective job at keeping concrete examples front and center,  guiding the reader to focus on one relevant pattern at a time,  and distilling down to a simple version of an idea before seeing how that fits into a  broader, more general setting. In general, entries that struck me as especially clear would often keep one or two  examples front and center, and they'd often give a feeling of playing with those  examples, maybe running simulations or tweaking them to run up against edge cases,  and all around giving the viewer a chance to build their own intuitions before general  rules are presented. The example doesn't even have to be explicit. In a visually driven lesson, the choice of what to show on screen when  making general points is often a great opportunity to offer the viewer  a concrete example to hold onto, but without wasting too much time  explicitly talking about that example or overemphasizing its importance. This I think is part of what gives visually driven lessons the opportunity to be clearer. As a brief side comment by the way loosely related to clarity,  for any of you who want to use music in the videos,  while music can enrich the storytelling aspect of a lesson,  setting the desired tone and momentum, once you're getting into the meat of a  technical explanation it's very easy for the music to do more harm than good. If it's there at all you'll want it to be decidedly  in the background and not calling attention to itself. I recognize some hypocrisy here, it's definitely something I know I've messed up with  past videos, and it's just worth thinking about whatever benefit you see from the  music you don't want to incur a needless cost on clarity that outweighs that benefit. Moving on to novelty, this is another category that has two distinct interpretations. One would be stylistic originality. Back when I created this channel, part of the reason I wrote my own  animation tool behind it was to ensure a kind of stylistic originality. Well, the main reason was it was a fun side project,  and having my hands deep into the guts of some tool helped me to feel  less constrained in trying to visualize whatever came to mind,  but being a forcing function for originality was at least a small part of my reasoning. This means there's at least a little hint of irony in the fact  that if we fast forward to today, so many of the entries in this contest use that tool,  Manum, to illustrate their lessons. I have nothing wrong with that, it actually delights me,  it's why I made it open source, and I'm very grateful to the Manum  community for everything they've done to make the tool more accessible. But I would still encourage people to find their own unique voice and aesthetic,  whatever tools they use, and whoever they take inspiration from. I don't want to overemphasize that point because it's the much less important  half of novelty, the much more important kind of novelty is when the thing  you present would have been very hard to find elsewhere on the internet,  either because it's a highly unique topic or because it's a very unique perspective. For example, this video on percolation showed a completely fascinating toy model for  studying phase changes, a model where it's easier to make exact proofs,  and considering the level of depth and the level of clarity the authors provided,  I think it's fair to say you wouldn't find something like this on YouTube if this  group hadn't made it. As to memorability, I'll keep this one quick. Lessons tick off this box when they ask a question that's just so fun to think about,  or provide such a satisfying aha moment that it stays with you  long after watching it or reading it. Admittedly, this one is highly personal and subjective. To my taste, for example, this video by Daria Ivanova discusses the question of when it's  possible for a single track to have been left by a bicycle, that is,  the back wheel goes through the same path that the front wheel does,  which is just so fun to think about. This video by Gurgly Bensik about how involute gears work had  a really satisfying way of explaining why a certain gear design  pattern worked so well that, for me at least, just stuck. So with all of that, who are the chosen winners? In the announcement I promised that one winner slot would go to an entry  that was made as a collaboration, and that one goes to the percolation video. The other four winners are, perhaps unsurprisingly, also ones that I've already mentioned. They include the post about describing crystal structures with group theory,  the video covering the history of calculus, the one about ray tracing and the algorithms  to make it faster, and the problem solving lesson centered around a tricky hat riddle. These entries really do speak for themselves, so rather than  telling you too much more here, I encourage you to check them out. To be honest, after I got it down to about 25 entries that I wanted to at  least be honorable mentions, it was exceedingly hard to actually choose  winners from that, since for each of these I could easily envision a target  audience for whom that entry would actually be the best recommendation. It was a game of comparing apples to oranges, but times 25. Below the video I've left links to the other 20 that I chose as honorable mentions,  and to a playlist that contains all the video submissions,  and also to a blog post containing links to all of the non-video submissions. Thanks to a sponsorship from Brilliant, each winner will get $1000 as a cash prize,  and also, and much more importantly I think, a rare edition golden pie creature.

================================================================================
VIDEO ID: VYQVlVoWoPY
TITLE: How to lie using visual proofs
URL: https://www.youtube.com/watch?v=VYQVlVoWoPY
PUBLISHED: 2022-07-03T15:03:56Z
STATUS: SUCCESS
================================================================================
Today I'd like to share with you three fake proofs in increasing order of subtlety, and then discuss what each one of them has to tell us about math. The first proof is for a formula for the surface area of a sphere, and the way that it starts is to subdivide that sphere into vertical slices, the way you might chop up an orange or paint a beach ball. We then unravel all of those wedge slices from the northern hemisphere, so that they poke up like this, and then symmetrically unravel all of those from the southern hemisphere below, and now interlace those pieces to get a shape whose area we want to figure out. The base of this shape came from the circumference of the sphere, it's an unraveled equator, so its length is 2 pi times the radius of the sphere, and then the other side of this shape came from the height of one of these wedges, which is a quarter of a walk around the sphere, and so it has a length of pi halves times R. The idea is that this is only an approximation, the edges might not be perfectly straight, but if we think of the limit as we do finer and finer slices of the sphere, this shape whose area we want to know gets closer to being a perfect rectangle, one whose area will be pi halves R times 2 pi R, or in other words pi squared times R squared. The proof is elegant, it translates a hard problem into a situation that's easier to understand, it has that element of surprise while still being intuitive, its only fault, really, is that it's completely wrong, the true surface area of a sphere is 4 pi R squared. I originally saw this example thanks to Henry Reich, and to be fair, it's not necessarily inconsistent with the 4 pi R squared formula, just so long as pi is equal to 4. For the next proof I'd like to show you a simple argument for the fact that pi is equal to 4. We start off with a circle, say with radius 1, and we ask how can we figure out its circumference, after all, pi is by definition the ratio of this circumference to the diameter of the circle. We start off by drawing the square whose side lengths are all tangent to that circle. It's not too hard to see that the perimeter of this square is 8. Then, and some of you may have seen this before, it's a kind of classic argument, the argument proceeds by producing a sequence of curves, all of whom also have this perimeter of 8, but which more and more closely approximate the circle. But the full nuance of this example is not always emphasized. First of all, just to make things crystal clear, the way each of these iterations works is to fold in each of the corners of the previous shape so that they just barely kiss the circle, and you can take a moment to convince yourself that in each region where a fold happened, the perimeter doesn't change. For example, in the upper right here, instead of walking up and then left, the new curve goes left and then up. And something similar is true at all of the folds of all of the different iterations. Wherever the previous iteration went direction A then direction B, the new iteration goes direction B then direction A, but no length is lost or gained. Some of you might say, well obviously this isn't going to give the true perimeter of the circle, because no matter how many iterations you do, when you zoom in, it remains jagged, it's not a smooth curve, you're taking these very inefficient steps along the circle. While that is true, and ultimately the reason things are wrong, if you want to appreciate the lesson this example is teaching us, the claim of the example is not that any one of these approximations equals the curve, it's that the limit of all of the approximations equals our circle. And to appreciate the lesson that this example teaches us, it's worth taking a moment to be a little more mathematically precise about what I mean by the limit of a sequence of curves. Let's say we describe the very first shape, this square, as a parametric function, something that has an input t and it outputs a point in 2d space, so that as t ranges from 0 to 1, it traces that square. I'll call that function c0, and likewise we can parameterize the next iteration with a function I'll call c1, as the parameter t ranges from 0 up to 1, the output of this function traces along that curve. This is just so that we can think of these shapes as instead being functions. Now I want you to consider a particular value of t, maybe 0.2, and then consider the sequence of points that you get by evaluating the sequence of functions we have at this particular point. Now I want you to consider the limit as n approaches infinity of c sub n of 0.2. This limit is a well-defined point in 2d space, in fact that point sits on the circle. And there's nothing specific about 0.2, we could do this limiting process for any input t, and so I can define a new function that I'll call c infinity, which by definition at any input t is whatever this limiting value for all the curves is. So here's the point, that limiting function c infinity is the circle, it's not an approximation of the circle, it's not some jagged version of the circle, it is the genuine smooth circular curve whose perimeter we want to know. And what's also true is that the limit of the lengths of all of our curves really is 8, because each individual curve really does have a perimeter of 8. And there are all sorts of examples throughout calculus when we talk about approximating one thing we want to know as a limit of a bunch of other things that are easier to understand. So the question at the heart here is why exactly is it not okay to do that in this example? And maybe at this point you step back and say, you know, it's just not enough for things to look the same, this is why we need rigor, it's why we need proofs, it's why since the days of Euclid mathematicians have followed in his footsteps and deduced truths step by step from axioms forward. But for this last example I would like to do something that doesn't lean as hard on visual intuition and instead give a Euclid style proof for the claim that all triangles are isosceles. The way this will work is we'll take any particular triangle and make no assumptions about it, I'll label its vertices A, B, and C, and what I would like to prove for you is that the side length AB is necessarily equal to the side length AC Now, to be clear, the result is obviously false, just in the diagram I've drawn you can visually see that these lengths are not equal to each other. But I challenge you to see if you can identify what's wrong about the proof I'm about to show you. Honestly, it's very subtle and three gold stars for anyone who can identify it. The first thing I'll do is draw the perpendicular bisector, the line BC, so that means this angle here is 90 degrees and this length is by definition the same as this length, and we'll label that intersection point D. And then next I will draw the angle bisector at A, which means by definition this little angle here is the same as this little angle here, I'll label both of them alpha, and we'll say that the point where these two intersect is P. And now, like a lot of Euclid style proofs, we're just going to draw some new lines, figure out what things must be equal, and get some conclusions. For instance, let's draw the line from P which is perpendicular to the side length AC, and we'll label that intersection point E. And likewise, we'll draw the line from P down to the other side length AB, again it's perpendicular, and we'll label that intersection point F. My first claim is that this triangle here, which is AFP, is the same, or at least congruent, to this triangle over here, AEP. Essentially this follows from symmetry across that angle bisector. More specifically we can say they share a side length, and then they both have an angle alpha, and both have an angle 90 degrees. So it follows by the side angle angle congruence relation. Maybe my drawing is a little bit sloppy, but the logic helps us see that they do have to be the same. Next I'll draw a line from P down to B, and then from P down to C, and I claim that this triangle here is congruent to its reflection across that perpendicular bisector. Again the symmetry maybe helps make this clear, but more rigorously they both have the same base, they both have a 90 degree angle, and they both have the same height, so it follows by the side angle side relation. So based on that first pair of triangles I'm going to mark this side length here as being the same as this side length here, marking them with double tick marks. And based on the second triangle relation I'll mark this side length here as the same as this line over here, marking them with triple tick marks. And so from that we have two more triangles that need to be the same, namely this one over here, and the one with corresponding two side lengths over here. And the reasoning here is they both have that triple ticked side, a double ticked side, and they're both 90 degree triangles. So this follows by the side side angle congruence relation. And all of those are valid congruence relations, I'm not pulling the wool over your eyes with one of those, and all of this will basically be enough to show us why AB has to be the same as BC. That first pair of triangles implies that the length AF is the same as the length AE, those are corresponding sides to each other, I'll just color them in red here, and then that last triangle relation guarantees for us that the side FB is going to be the same as the side EC. I'll kind of color both of those in blue. And finally the result we want basically comes from adding up these two equations. The length AF plus FB is clearly the same as the total length AB, and likewise the length AE plus EC is the same as the total length AC. So all in all the side length AB has to be the same as the side length AC, and because we made no assumptions about the triangle this implies that any triangle is isosceles. Actually for that matter since we made no assumptions about the specific two sides we chose, it implies that any triangle is equilateral. So this leaves us somewhat disturbingly with three different possibilities. All triangles really are equilateral, that's just the truth of the universe, or you can use Euclid style reasoning to derive false results, or there's something wrong in the proof. But if there is, where exactly is it? So what exactly is going on with these three examples? Now the thing that's a little bit troubling about that first example with the sphere is that it is very similar in spirit to a lot of other famous and supposedly true visual proofs from geometry. For example there's a very famous proof about the area of a circle that starts off by dividing it into a bunch of little pizza wedges, and you take all those wedges and you straighten them out, essentially lining up the crust of that pizza, and then we take half the wedges and inter-slice them with the other half. And the idea is that this might not be a perfect rectangle, it's got some bumps and curves, but as you take thinner and thinner slices you get something that's closer and closer to a true rectangle, and the width of that rectangle comes from half the circumference of the circle, which is by definition pi times R, and then the height of that rectangle comes from the radius of the circle, R, meaning that the whole area is pi R squared. This time the result is valid, but why is it not okay to do what we did with the spheres, but somehow it is okay to do this with the pizza slices? The main problem with the sphere argument is that when we flatten out all of those orange wedges, if we were to do it accurately in a way that preserves their area, they don't look like triangles, they should bulge outward. And if you want to see this, let's think really critically about just one particular one of those wedges on the sphere, and ask yourself how does the width across that wedge, this little portion of a line of latitude, vary as you go up and down the wedge? In particular, if you consider the angle phi from the z-axis down to a point on this wedge as we walk down it, what's the length of that width as a function of phi? For those of you curious about the details of these sorts of things, you'd start off by drawing this line up here from the z-axis to a point on the wedge, its length will be the radius of the sphere R times the sine of this angle. That lets us deduce how long the total line of latitude is where we're sitting, it'll basically be 2 pi times that radial line, 2 pi R sine of phi, and then the width of the wedge that we care about is just some constant proportion of that full line of latitude. Now the details don't matter too much, the one thing I want you to notice is that this is not a linear relationship. As you walk from the top of that wedge down to the bottom, letting phi range from 0 up to pi halves, the width of the wedge doesn't grow linearly, instead it grows according to a sine curve. And so when we're unwrapping all of these wedges, if we want those widths to be preserved, they should end up a little bit chubbier around the base, their side lengths are not linear. What this means is when we tried to interlace all of the wedges from the northern hemisphere with those from the southern, there's a meaningful amount of overlap between those non-linear edges, and we can't wave our hands about a limiting argument, this is an overlap that persists as you take finer and finer subdivisions. And ultimately it's that overlap that accounts for the difference between our false answer with a pi squared from the true answer that has 4 pi. It reminds me of one of those rearrangement puzzles where you have a number of pieces and just by moving them around you can seemingly create area out of nowhere. For example, right now I've arranged all these pieces to form a triangle, except it's missing two units of area in the middle. Now I want you to focus on the vertices of that triangle, these white dots, those don't move, I'm not pulling any trickery with that, but I can rearrange all of the pieces back to how they originally were so that those two units of area in the middle seem to disappear, while the constituent parts remain the same, the triangle that they form remains the same, and yet two units of area seem to appear out of nowhere. If you've never seen this one before, by the way, I highly encourage you to pause and try to think it through, it's a very fun little puzzle. The answer starts to reveal itself if we carefully draw the edges of this triangle and zoom in close enough to see that our pieces don't actually fit inside the triangle, they bulge out ever so slightly, or at least arranged like this they bulge out ever so slightly. When we rearrange them and we zoom back in we can see that they dent inward ever so slightly, and that very subtle difference between the bulge out and the dent inward accounts for all of the difference in area. The slope of the edge of this blue triangle works out to be 5 divided by 2, whereas the slope of the edge of this red triangle works out to be 7 divided by 3. Those numbers are close enough to look similar as slope, but they allow for this denting inward and the bulging outward. You have to be wary of lines that are made to look straight when you haven't had explicit confirmation that they actually are straight. One quick added comment on the sphere, the fundamental issue here is that the geometry of a curved surface is fundamentally different from the geometry of flat space. The relevant search term here would be Gaussian curvature. You can't flatten things out from a sphere without losing geometric information. When you see limiting arguments that relate to little pieces on a sphere that somehow get flattened out and are reasoned through there, those only can work if the limiting pieces that you're talking about get smaller in both directions. It's only when you zoom in close to curved surface that it appears locally flat. The issue with our orange wedge argument is that our pieces never got exposed to that local flatness because they only got thin in one direction. They maintain the curvature in that other direction. Now on the topic of the subtlety of limiting arguments, let's turn back to our limit of jagged curves that approaches the smooth circular curve. As I said, the limiting curve really is a circle and the limiting value for the length of your approximations really is 8. Here, the basic issue is that there is no reason to expect that the limit of the lengths of the curves is the same as the length of the limits of the curves, and in fact this is a nice counter example to show why that's not the case. The real point of this example is not the fear that anyone is ever going to believe that it shows that pi is equal to 4, instead it shows why care is required in other cases where people apply limiting arguments. For example, this happens all throughout calculus. It is the heart of calculus, where say you want to know the area under a given curve. The way we typically think about it is to approximate that with a set of rectangles, because those are the things we know how to compute the areas of. You just take the base times height in each case. Now this is a very jagged approximation, but the thought, or I guess the hope, is that as you take a finer and finer subdivision into thinner and thinner rectangles, the sums of those areas approaches the thing we actually care about. If you want to make it rigorous, you have to be explicit about the error between these approximations and the true thing we care about, the area under this curve. For example, you might start your argument by saying that that error has to be strictly less than the area of these red rectangles. Essentially, the deviation between the curve and our approximating rectangles sits strictly inside that red region. And then what you would want to argue is that in this limiting process, the cumulative area of all of those red rectangles has to approach zero. Now as to the final example, our proof that all triangles are isosceles, let me show you what it looks like if I'm a little bit more careful about actually constructing the angle bisector rather than just eyeballing it. When I do that, the relevant intersection point actually sits outside of the triangle. And then from there, if I go through everything that we did in the original argument, drawing the relevant perpendicular lines, all of that, every triangle that I claimed was congruent really is congruent. All of those were genuinely true, and the corresponding lengths of those triangles that I claimed were the same really are the same. The one place where the proof breaks down is at the very end, when I said that the full side length AC was equal to AE plus EC. That was only true under the hidden assumption that that point E sat in between them. But in reality, for many triangles, that point would sit outside of those two. It's pretty subtle, isn't it? The point in all of this is that while visual intuition is great, and visual proofs often give you a nice way of elucidating what's going on with otherwise opaque rigor, visual arguments and snazzy diagrams will never obviate the need for critical thinking. In math, you cannot escape the need to look out for hidden assumptions and edge cases. Thank you.

================================================================================
VIDEO ID: bOXCLR3Wric
TITLE: Olympiad level counting  (Generating functions)
URL: https://www.youtube.com/watch?v=bOXCLR3Wric
PUBLISHED: 2022-05-23T15:55:10Z
STATUS: SUCCESS
================================================================================
In a moment, I will ask you a puzzle, and it's a pretty hard puzzle, actually, but before I do, I want to lead with a spoiler, which is the fact that the way we're going to solve this involves the use of complex numbers. And once you hear it, you will agree that that seems absurd, given that the puzzle is going to be purely a discrete question. It only asks about whole numbers and their sums. There's not a whiff of the imaginary or even continuity anywhere on the horizon. It's certainly not the only time that complex numbers are unreasonably useful for discrete math, to borrow a phrase. The more famous example that I could bring up would be how the modern way that mathematicians understand prime numbers, you know, questions about how they're distributed, their density at certain regions, things like that, well, it involves studying specially designed functions whose inputs and outputs are complex numbers. Some of you may know that this is what the famous Riemann hypothesis is all about. Basically, there's a specially designed function, and on the face of it, it looks unrelated to the discrete world of primes. It's smooth, it's complex valued. But under the hood, it encodes all of the information that you could ever want about those discrete prime numbers. And most importantly, certain questions about primes are easier to answer by analyzing this function than they would be by directly analyzing the primes themselves. Of course, our puzzle, which I promise I'll share in just a moment, is a lot more innocent than the Riemann hypothesis. It's a toy problem. But at the end of the video, I'll share how the techniques that we use to solve it, the real reason that we're here, are actually pretty similar in spirit to the setup that leads to the Riemann hypothesis. And the prime number theorem and that whole circle of thoughts around it. Our puzzle for today comes from this book here by Titu Andreescu and Zuming Feng. It's basically a collection of problems used in training the USA team for the International Math Olympiad. And if we turn to chapter 2, Advanced Problems, problem number 10 asks this seemingly innocent question. Find the number of subsets of the set 1 up to 2000, the sum of whose elements is divisible by 5. Okay, so that might take a little bit of a moment to parse. For example, something like the set 3, 1, 4, that would be a subset. All of its elements are also elements in the big set. And its sum, 3 plus 1 plus 4 is 8, so that wouldn't be considered. That's not in our count. Whereas something like the set 2, 3, 5, also a subset, has a sum of 10. That is divisible by 5, so it's one that we want to count. The preview animation that I had at the start is essentially a brute force program trying to answer this question. It will iterate through all of the different possible subsets, finding the sum of each one along the way, and it increments a counter each time that it finds a multiple of 5. And you know what, a nice warm-up question here would be to pause and think about how many total subsets are there overall? Forget this multiple of 5 stuff. How long will it take for this program to terminate? Many of you may know, the answer is 2 to the power 2,000. The basic idea there is that when you're constructing a subset, you have 2,000 different binary choices you can make. Do you include an element or do you not? And all of those choices are independent of each other, so the total number of choices you have in constructing a subset is 2 times 2 times 2 times 2 on and on 2,000 times. And thinking about our program, that is a monstrously huge number. So even if we gave this brute forcing approach all the time in the universe, with all the physical resources the universe could conceivably provide, it wouldn't even come close, it wouldn't scratch the surface. Obviously we have to be a lot cleverer than that. And if you were to just guess what the answer should be, make a rough approximation, you'd probably guess, you know, it should be around a fifth of all the total subsets. There's probably a roughly even distribution of all these sums mod 5. And yes, that is true, that's a decent approximation. But the heart of the question, the real challenge here, is to get a precise answer. This can't be the actual answer since it's not an integer, but is the true answer a little bit more or a little bit less? Or maybe it's a lot more or a lot less. What tactics could you possibly use to figure out that error? To be clear, this lesson is definitely much more about the journey than the destination. Will you ever need to filter and count subsets in this way? Almost certainly not, I wouldn't expect so. But toy problem or not, it is a legitimately challenging question, and navigating that challenge develops skills that are relevant to other sorts of challenging questions. For you and me, there are at least two very surprising and very beautiful twists and turns that the solution I'd like to share with you takes. I've already tipped my hand that complex numbers will make a surprise appearance, but before we even get to that, there is another strange turn, which is arguably even weirder and even more unexpected. To set the stage though, let's just get our bearings with the puzzle, and do what all good problem solvers should do, and start with a simpler example, maybe just trying it with the set 1, 2, 3, 4, 5. If you were solving this problem with pencil and paper, you know, you're one of these kids training for the IMO, it's not a bad idea to simply list out all 2 to the 5 subsets. It's only 32, it's not that many. There's different ways that you might want to organize all of these in your mind, but since the thing that we care about is their sum, the natural thing to do would be to go through all of them one by one and compute those sums. Over here, just doing it on YouTube, I've got a computer, so I'll cheat a little and show what all their sums are. I'll also cheat a little bit and rearrange all of these, organizing them suggestively into collections that all have the same sum. For instance, there are 3 distinct subsets that add up to 6, and they'll all sit in this little box, and the 3 subsets adding up to 10 will all live in this little box. And all in all, the ones that we care about, the subsets with a sum divisible by 5, have been put over here on the left, and it looks like there's a total of 8 of them. Oh, and by the way, I should say we are counting the empty set, we consider its sum to be 0, and we consider that to be a multiple of 5. By the end, I hope you'll agree all of those are abundantly natural choices to make. Take a moment to compare this answer to what you might expect heuristically. Out of all 32 total subsets, a fifth of that would have been 6.4, so at least in this small example, the true answer is a little bit bigger than that. That's maybe something you want to talk in the back of your mind. Okay, and this is the part of the video where, I'll be honest with you, I have no idea how to motivate it. Personally, I like it when math feels like something you could have discovered yourself, and if you and I were sitting down together solving this problem, I think there's all sorts of natural steps that you might take. Maybe you try to understand if there's some sort of structure to the subsets, or you play around with how these sums are distributed mod 5 at many different iterations for other small examples, and from that maybe you try to eke out some kind of proof by induction. When I shared an early version of this lesson with some patrons, people brought up some nice linear algebra approaches. All those are well and good, nothing wrong with those. But instead, my goal here is to teach you about something called a generating function. And it's one of those tactics where after the fact you can think, okay, yeah, I get that this works, but how on earth would you have thought of that? Honestly, I don't know. There's a time in your life before you understand generating functions, and a time after, and I can't think of anything that connects them other than a leap of faith. I'm going to ask you to consider the polynomial 1 plus x times 1 plus x squared times 1 plus x cubed times 1 plus x to the fourth times 1 plus x to the fifth. Now, I know you could rightfully ask, where does this come from? What do polynomials have to do with things? What is the variable x even supposed to represent right now? And essentially x is purely a symbol. The only reason that we've written a polynomial here is that the act of algebraically expanding it is going to completely mirror the act of constructing subsets. And, importantly, this grouping that we want, where subsets with the same sum are all bunched together, kind of happens automatically when you do this. And let me show you what I mean. When you expand out this expression, it basically comes down to making five binary choices. Which term from each parenthetical do you choose? If you choose the 1 from each of those parentheticals, that will correspond to the empty set where we don't choose any of the elements. Whereas if I choose the x to the 1 term and then ones from everything else, that will correspond to the singleton set that just contains the number 1. Similarly, if I choose the x squared term but ones from everything else, that corresponds to the set just containing 2. Just choosing the x cubed term corresponds to the set just containing the number 3. But, interestingly, notice what happens if I choose the x to the 1 term and the x squared term and then ones from everything else. This corresponds to the choice of the subset that has 1 and 2 and nothing from everything else. But in the polynomial, the way it expands looks like x cubed. So we have two different x cubed terms, each of which came from a subset whose sum was 3. And honestly, the pattern that I'm going for here is one that's probably easiest if you just take the time to pause and think through for yourself what happens when you expand everything here. Essentially, every possible subset corresponds to one of the terms in this expansion. And then the critical point is that the exponent in the term that you get from that expansion equals the sum of that corresponding subset. Kind of confusing when you say it out loud, but again if you just kind of think it through yourself I think you can see what I mean. For example, when all of the dust settles and we collect all 32 terms here, three of those terms are x to the 10th, and each of those came from a choice of elements whose sum was equal to 10. Now normally when we write a polynomial, we collect together all like terms. Instead of having three copies of x to the 10th, we would just see the coefficient 3 in front of x to the 10th. So each of these coefficients is a way of encoding the number of subsets with a particular sum. So this, like I said at the start, is an example of something called a generating function, where the idea is if you have some question with an answer associated with each positive integer, so in our case how many subsets add up to a particular value. When you construct a polynomial whose coefficients correspond to the answers to that question, you can get a surprising amount of insight from your original question by mathematically manipulating and analyzing the properties of this polynomial. There are tons and tons of examples of generating functions, but just to bring up one other one which is especially fun, you can use the same idea to study Fibonacci numbers. So all the coefficients of this polynomial will be Fibonacci numbers, and in this case it's an infinite polynomial, so I should really be calling it a power series. I won't fully explain the details here, but I will leave them up on the screen for anyone who's curious. Basic idea is that the rule that's used to define Fibonacci numbers, each one being the sum of the previous two, can be expressed as an equation in terms of this function. That equation in turn lets you write that function in an alternate form. And then, and here's most of the details I'm skipping over, if you manipulate that, you know, throw in a little partial fraction decomposition here, a little bit of geometric series power expansion there, you can get yourself an exact closed form expression for each individual Fibonacci number, which is really cool. I mentioned this really just to show the tip of the iceberg of the fact that this idea of a generating function goes way, way beyond our particular example. Now, in our particular problem, if we extend from the simple example with just 12345 to the big example with all the numbers up to 2000, our corresponding generating function involves these 2000 different binomial terms, you know, 1 plus x, 1 plus x squared, on and on, up to 1 plus x to the 2000. And the idea is that if you were to expand this, the coefficients tell us all the information we want. Now, it would be insane to actually expand it, but it is helpful to keep in the back of your mind, in principle, what that would look like. For example, in principle, if you expanded it, you would find that the coefficient in front of the x to the 25th term happens to be 142. And this corresponds to the fact that there are 142 distinct subsets that have a sum of 25. So the art of analyzing a generating function here will be to deduce facts about these coefficients without actually expanding the expression. So moving forward, I'm just going to write this expansion more abstractly, just a sum from n equals 0 up to capital N, where c sub n tells us the coefficients that we don't know. All of that starts off as a black box to us. And moving forward, we're going to start treating this as an actual function, something where we plug in x, we see what the output is, and then we ask, what does that tell us about the coefficients? For example, a very easy input would be to plug in something like x equals 0. In that case, importantly, we know how to evaluate it using the factored form above. If you plug in x equals 0 for everything, all of the terms look like 1, so the answer is 1. And in the expanded form, all of those terms involving an x will get killed, they go to 0, leaving us just with the first term, c sub 0. Now, in this case, that doesn't really tell us anything all that exciting. It essentially translates to saying there is a single empty set, but we're just getting our feet wet. As the next example, take a moment to think about evaluating f at 1. This is something we can do with the expression we know, when you plug in 1 for all of these x's, every term looks like a 2, so in total, we get 2 multiplied by itself 2,000 times. On the other hand, in the expanded expression, if you plug in x equals 1, all of these powers of x go to 1, so we're essentially adding up all of the coefficients, which is pretty cool when you think about it. Just by evaluating the function at a single number, we can deduce what the sum of all of the coefficients are. Now, again, in our particular example, it's not all that exciting, because we already know what the sum of these coefficients are. Remember, each coefficient counts how many subsets have a certain sum, and so when you add them up, we're just counting all of the subsets, which we know to be 2 to the 2,000. However, I can give you a genuinely new fact if I ask you to evaluate this function at negative 1. Take a moment to think about what that means. If you plug in negative 1, again, we start with the thing we know, the factored expression up top, and here, all you need is to look at the first term. When you plug in x, the first parenthetical goes to 0, so the whole expression has to be 0. But what does that tell you when we apply it to the expanded expression, using all of the coefficients? And in the spirit of being as suggestive as possible of the strange turns that this solution takes, I want you to really visualize the various powers of negative 1 in this expression in terms of rotations. The first term, negative 1 to the 0, is just 1, which we'll picture as a vector from 0 to 1. Then negative 1 to the first power is just negative 1 itself, which I want you to be thinking about as a 180-degree rotation away from that last term. Then when we take negative 1 squared, that's positive 1. Again, a 180-degree rotation. And in general, each successive term here looks like another rotation by 180 degrees. Algebraically, what this translates to is that we have an oscillating sum between the even coefficients and the odd coefficients, but keep the visual in the back of your mind. This expression is true for any generating function, but again, for our special generating function, we know that this value, this alternating sum, should equal 0. And a way you can interpret that is that it's telling you there's an equal balance between the even coefficients and the odd coefficients. And remember, maybe in the context of our smaller example, these coefficients are encoding for us facts about subsets. So if there's an equal balance between all those even coefficients and the odd coefficients, it's telling you that half of all the subsets have an even sum, and half of them have an odd sum. That's probably what you would expect, but it's not obvious at first how you would show that, and with the generating function, it just kind of pops right out. And again, to be suggestive of where we're going, let me rewrite this a little bit by taking the last two things we evaluated, add up those two, and then divide by one half. If you think about it, this is a way of filtering out all of the even coefficients and killing all of the odd coefficients. So it becomes an especially clean way to write the fact that the sum of all of the even coefficients, which again in the back of your mind means the total number of subsets with an even sum, will look like half of the total. This is, needless to say, tantalizingly close to the actual question we want to answer. What we would like to do is find some clever thing that we can do to the function f, some well-chosen numbers to evaluate it on, so that we get all the coefficients corresponding to multiples of 5. Again, thinking back to what these coefficients encode for us, that will be answering our final question. That will be counting the total number of subsets whose sum is divisible by 5. The trick to doing this is to generalize what we just did, where the successive powers of the input were rotating back and forth. But this time we don't want them to rotate every other time, we'd like them to somehow rotate with a period of 5. And to do that, we extend into the complex plane. You see, up there we can find a value so that as we take successive powers of it, it will rotate by a fifth of a turn, giving us a process with a frequency of 5. And if you step back, I know that it's kind of absurd that I'm asking you to think about complex numbers. I mean, we started with a counting question, it's discrete math, but hopefully it's not all that wild. And again, the reason that I'm drawing things out to tee up the various strange turns in the solution is that they're actually not all that strange in the broader scheme of math. The trick we're about to apply has a heavy resemblance to many other instances of using complex numbers to better understand discrete questions of integers. So the more it feels like something that you could have discovered yourself, the more it might actually be the case that when you're working on some future problem in this circle of thoughts, you will discover it yourself. To be specific, the complex number that I care about is one that I'm going to label zeta, and it sits a fifth of a turn around the unit circle. So its angle is 2 pi fifths radians, and its magnitude is one. This means with the standard Euler's formula notation, we would write that number explicitly as e to the power 2 pi i divided by 5. If you're not as comfortable with that notation, you could think of it as something whose real part is the cosine of 72 degrees, 72 being a fifth of a full turn, and the imaginary part is the sine of 72 degrees. But to be honest, you don't actually need to think about the explicit value. Instead, the important thing to focus on is the property that powers of this number have. For example, when you square it, because its magnitude was one, the magnitude of its square is also one, but it rotates a fifth of a turn around the unit circle, so it now sits two fifths of a turn around. Similarly, when you raise it to the third power, you end up three fifths of a turn around, raise it to the fourth power, you end up four fifths of a turn, and raise it to the fifth power, and you've gotten all the way back around to one. It's the same thing as if you had raised it to the zeroth power. We get this cycling every five terms. That's the thing that we care about. These numbers have a special name, they're called the fifth roots of unity, essentially because they solve the equation z to the fifth equals one. They are fifth roots of the number one. If you just presented someone with this equation, they would probably say the answer is clearly z equals one. But the idea is that there are four other answers in the complex plane. Four other numbers where when you raise them to the fifth, you get one, and considering them as a collective is often quite useful. Remember that equation, it'll come back for us a little bit later. So in analogy with what we did earlier, where we added together f of one and f of negative one to get this cancellation among the odd terms, what we're going to do is evaluate f at all five of these numbers, and then add them together, and hopefully we get some cancellation. That might seem kind of complicated, but let's just take a super simple example, like the case where f of x is simply equal to x. In that case, when we add up these five terms, we're just adding up the roots of unity themselves. Zeta to the zero plus zeta to the one, on and on, up to zeta to the fourth. When you add complex numbers, you can think of it like vector addition with the tip to the tail. So zeta to the zero plus zeta will look like this, and then if I add on zeta squared, bringing the tail of that vector to the tip of the last one, we get this. Then similarly, if I bring the tail of zeta cubed over to the tip of that one, and then do likewise for zeta to the fourth, you'll see how the overall sum actually loops back to be zero. Another way to think about this is that all five of these terms are evenly balanced around the number zero. Their center of mass is at the origin. Now it's helpful to think about a slightly less trivial example, if f of x was x squared. So when you square zeta to the zero, it stays zeta to the zero. This is just a fancy way of saying the number one. When you square zeta, you get zeta squared itself. So you might imagine this dot up here moving over to the zeta squared dot when we do it. Zeta squared moves to zeta to the fourth. You might imagine this dot moving over to zeta to the fourth. Zeta cubed moves to zeta to the sixth, which, because we loop around every five times, is the same thing as zeta to the one. So this dot will move up here. And finally, zeta to the fourth squares to give us zeta to the eighth, which reduces to be the same as zeta cubed, which I might draw like this. That might seem a little confusing to think about, especially with all the arrows I have drawn here, but it's worth thinking through at least once in your life, because the idea here is that when we square this, like go to all of these different terms, and I program them to double the angle that they have, the overall effect is to just shuffle those terms. We get the same numbers but written in a different order, so their sum is still going to be zero. Similarly, if you go through this exercise with x cubed, which I encourage you to do, and you follow around where are each one of these dots going to end up, you'll be able to see that when we cube these terms, when we take each one and we multiply the angle that it has by three, again we just shuffle them around. Same terms listed in a different order, unsurprisingly the same thing happens if our function was x to the fourth, but, critically, where things change is if we consider the function x to the fifth. In that case, when you raise zeta to the fifth power, by definition it goes to one. Similarly, zeta squared raised to the fifth power goes to one. All of these go to one, they are the roots of unity, this is after all their whole purpose in life. So in this case, when we apply the function and add them all up, instead of going to zero and getting cancellation, we get a kind of constructive interference. All of them equal one, so their sum is equal to five. So if you step back and think about what all those examples mean, essentially this expression is something that will go to zero for powers of x which are not divisible by five, but it goes to something non-zero for powers of x which are divisible by five. And that's exactly the kind of filter that we're looking for. If you're worried that our actual function is much more complicated than a simple power of x, essentially things play really nicely here because everything is linear. If f is some massive polynomial and we want to evaluate this big sum, you could sort of think of going column by column, where each time you really are just adding up powers of zeta, and in most cases all those powers cancel out with each other and you get zero, but when all of those powers are multiples of five, they constructively interfere and instead you get five times whatever the corresponding coefficient is. Deep in the weeds it's easy to forget why we're here in the first place, but remember each one of those coefficients tells us how many subsets add up to a certain value, and so what we want is to add up all of the coefficients that are multiples of five, and what we have right now is a way to explicitly do that. If we evaluate this function on these five different roots of unity, which I know seems kind of weird, then all we have to do is divide by five and it gives us the sum that we want. That's really cool if you ask me. We have a question that's just about subsets, it's a discrete math problem, and yet the way that we can answer it is to evaluate a crazy polynomial on some judiciously chosen complex numbers. The more math you do, the less crazy that seems, because complex numbers have this bizarre relationship with discrete math, but it really is wonderful, there's no two ways about it. However, some of you might complain, the only way that this is useful is if we can actually evaluate this wild expression on our polynomial. Remember, the form of the polynomial we know, the one we're comfortable with, is the factored form, where you have this one plus x, one plus x squared, on and on, all the way up to one plus x to the two thousand. Everything up to this point is just meaningless symbolic play, pushing around one hard problem into another, unless we can actually roll up our sleeves and do some honest calculation here. This is the final thrust in our argument, so step back, take a deep breath. It's actually not as bad as you might think, but let's start just by thinking about how you might evaluate just one of the roots of unity that we need, maybe zeta itself. So what that looks like is one plus zeta, times one plus zeta squared, times one plus zeta cubed, on and on. Except, importantly, after those first five terms, everything starts repeating, because powers of zeta repeat. The entire expression up to two thousand is basically just going to be a copy of this expression four hundred times. It still might seem hard to evaluate this expression, but it's way easier than multiplying out two thousand different terms. A way you might visualize this is that we're taking each one of those roots of unity, but basically adding one, we're shifting them all to the right. This picture actually lends itself to a really nice geometric intuition for the numerical answer that we might expect. The thing that we want is the product of these five different complex numbers, these five yellow dots. And if you know a thing or two about complex numbers, since these come in conjugate pairs, all we really need is to multiply the lengths of these five yellow lines. For example, that dot furthest to the right corresponds to one plus zeta to the fifth, which in the diagram I'm labeling as zeta to the zero plus one. But it doesn't matter, in either case, they're both just fancy ways of writing the number two. Next to that, we have the values one plus zeta and one plus zeta to the fourth, both of which have the same magnitude, the lengths of these lines are the same. And let's just give that a name, L1. So we need to multiply two different copies of that length, L1 squared. Similarly, the remaining two values, zeta squared plus one and zeta cubed plus one, they also have the same length, and they're a conjugate pair. So let's just call that length L2. So our product needs to include two copies of that L2. If we were just making a loose heuristic guess, you might notice that L1 is a length that's something a little bit longer than one, and L2 is something a little bit shorter than one. So the final answer here probably comes to something around two-ish, we're not positive, but something in that ballpark. To turn this into an exact answer, we could just expand out the full expression. It's honestly not that bad, there's only 32 different terms. Okay, you've hung with me for a long time now, and I know that it's getting to be a lot. But there's one final trick in this whole argument that makes our last step much simpler than you might think it should be. And let's just recap to remind ourselves of where we are. So we started with this question asking us, count the number of subsets of 1 up to 2000 whose sum is divisible by 5. We then constructed this polynomial whose coefficients tell us how many subsets have a particular sum for each value n. So what we want is to add up every fifth coefficient of that polynomial. Then we saw how evaluating this polynomial as a function on all of the fifth roots of unity, then adding them up, ends up giving us exactly this filter that we want. And here we're evaluating just one of those terms, f of zeta, which essentially comes down to a product of five complex numbers. As a super slick way to actually evaluate that product, here's the final trick. Remember, I described these numbers as roots of unity. They solve the equation z to the fifth equals one. Another way to think about that is that they are roots of the polynomial z to the fifth minus one. Now what that means is we can factor the polynomial z to the fifth minus one to look like this, where there's one factor corresponding to each one of the roots. You take z minus each one of the roots. This expression is kind of magical when you think about all of the crazy cancellation that has to happen when you expand it all out, but it is true and it's super useful for us right now, because the expression on the right hand side looks almost identical to the thing we need to evaluate up at the top here. It basically just has minus signs where we wish there were plus signs. The trick is to plug in z equals negative one. If you do that, you essentially have the negative of what we want. If you multiply it by negative one, notice how the left hand side here, which started out as negative one minus one or negative two, that just becomes two. And then the right hand side turns into the thing that we want to evaluate. So just as our geometric intuition earlier might have suggested, not only is the answer around two, the answer quite magically turns out to be precisely two. That is actually super nice and very lovely, because it means this bigger expression that we want to evaluate, where we're adding up f on all of the different roots of unity, we know its value on the first root of unity. It will be two to the power four hundred. Essentially identical reasoning shows that its value on the next three roots of unity is also two to the power four hundred, because remember when you take powers of zeta squared or zeta cubed, you get the same list of numbers that are just shuffled in a different order. The only one that's different is when we evaluate it as zeta to the zero. But zeta to the zero is a fancy way of saying the number one, and we know how to evaluate this at one. That's one of the easy things. We did this earlier. All of these parentheticals turn into two, so it looks like taking two multiplied by itself two thousand times. And so finally with that, we have a highly explicit honest answer to our counting question. To add up all of these coefficients which are divisible by five, which, remember, is a way of counting how many total subsets have a sum divisible by five, the answer is one fifth of this weird complex expression, which we just computed to be two to the two thousand plus four different copies of two to the four hundred. And here you might want to do just a quick sanity check on does this answer make any sense. For example, if you do it in the smaller case with the set one two three four five, and you walk through all the same reasoning that we just did, it tells you that the answer is one fifth of two to the fifth, the total number of subsets, plus four times two to the one in this case, which is a fifth of 32 plus eight, which is eight. And if you'll remember when we explicitly looked at them all, that was in fact the answer. Look, this is a hard puzzle, and when it's worth putting in the time to solve a hard problem, it's also worth taking some time to reflect on it. What do you get out of this? What's the takeaway? Now you could reflect on the answer itself, how the dominant part is indeed one fifth of all the total subsets like we might have guessed, and how this error term came about from the not quite destructive interference in a massive combination of roots of unity. But again, what makes this question interesting is not the answer, it's the way that we solved it, namely taking a discrete sequence that we want to understand and treating it as the coefficients on a polynomial, then evaluating that polynomial on complex values. Both of those steps are probably highly unexpected at the outset, but both of those steps relate to some very general and powerful techniques that you'll find elsewhere in math. For example, at the top of the lesson, I promised that the technique that we would use would be similar in spirit to the way that primes are studied, and the set of ideas that leads up to the Riemann hypothesis and things like that. Now this is a very beautiful topic, enough so that I think it seems a little criminal to cram some kind of rushed version into the end here. The right thing to do, I think, is to just make that video I promised a while back about the zeta function, take the time, do it right. But if you're curious, and if you'll allow me to throw some things up on the screen without explaining them, here's the two or three sentence version of how the two are parallel. Just like our subsets puzzle, the way that Riemann studied primes involved a discrete sequence we want to understand, something carrying information about prime numbers, and then considering a function whose coefficients are the terms in that sequence. In that case, it's not quite a polynomial, instead it's a related structure known as a Dirichlet series, or Dirichlet series depending on who you ask, but it's the same essential idea. Then the way to suss out information about those coefficients comes from studying how this function behaves with, you guessed it, complex valued inputs. The techniques in his case get a lot more sophisticated, after all Riemann was a pioneer in complex analysis, but the fact remains extending your domain beyond real numbers like this offers you, the mathematician, a lot more power in making deductions about the coefficients. For some viewers this all might leave the lingering question of why exactly complex numbers are so unreasonably useful in this way. It's a hard question to answer exactly, but if you think about our puzzle, everything we just did, as soon as we were in this situation where plugging in different inputs revealed hidden information about the coefficients, it's sort of like the more inputs you can work with the better, so you might as well open yourself up to a richer space of numbers like the complex plane. But there is a more specific intuition that I want you to come away with here. In our puzzle the relevant fact that we wanted, the sum of every fifth coefficient, was a kind of frequency question, and the real reason the complex numbers as opposed to some other structure proved to be useful for us is that we could find a value so that successive products have this cycling behavior. This use of values on the unit circle and roots of unity in particular to suss out frequency information is extremely fruitful. It is almost impossible to overstate how helpful that idea is. Just to give one out of thousands of examples, in the 1990s Peter Shor found a way for quantum computers to factor large numbers way way faster than classical computers can. And if you go in and you look at the details of how what we now call Shor's algorithm works, the idea is essentially this, the use of roots of unity to detect a kind of frequency information. More generally this is the core idea that underlies Fourier transforms and Fourier series and the infinite swell of topics that follow from those. As to the topic of generating functions themselves, we've really only just scratched the surface here, and if you want to learn more I highly recommend this kind of hilariously named book GeneratingFunctionology by Herbert Wilf. And I'll also leave up a few fun puzzles on the screen here for anyone who wants to flex their muscles a bit with the idea.

================================================================================
VIDEO ID: fRed0Xmc2Wg
TITLE: Oh, wait, actually the best Wordle opener is not â€œcraneâ€â€¦
URL: https://www.youtube.com/watch?v=fRed0Xmc2Wg
PUBLISHED: 2022-02-13T18:33:24Z
STATUS: SUCCESS
================================================================================
Last week I put up this video about solving the game Wordle,  or at least trying to solve it, using information theory. And I wanted to add a quick, what should we call this, an addendum,  a confession, basically I just want to explain a place where I made a mistake. It turns out there was a very slight bug in the code that I was running to recreate  Wordle and then run all of the algorithms to solve it and test their performance. And it's one of those bugs that affects a very small percentage of cases,  so it was easy to miss, and it has only a slight effect that for the most part doesn't  really matter. Basically it had to do with how you assign a color  to a guess that has multiple different letters in it. For example if you guess speed and the true answer is abide,  how should you color those two e's from the guess? Well the way that it works with the Wordle conventions is that the  first e would be colored yellow, and the second one would be colored gray. You might think of that first one as matching up with something from the true answer,  and the grayness is telling you there is no second e. By contrast, if the answer was something like erase,  both of those e's would be colored yellow, telling you that there is  a first e in a different location, and there's a second e also in a different location. Similarly if one of the e's hits and it's green,  then that second one would be gray in the case where the true answer has no second e,  but it would be yellow in the case where there is a second e and it's just in  a different location. Long story short, somewhere along the convention slightly. Honestly it was really dumb. Basically at some point in the middle of the project I wanted to speed up  some of the computations, and I was trying a little trick for how it computed  the value for this pattern between any given pair of words,  and you know I just didn't really think it through, and it introduced this slight change. The ironic part is that in the end the actual way to make things  fastest is to pre-compute all those patterns so that everything is just a lookup,  and so it wouldn't matter how long it takes to do each one,  especially if you're writing hard to read buggy code to make it happen. You know, you live and you learn. As far as how this affects the actual video, I  mean very little of substance really changes. Of course the main lessons about what is information,  what is entropy, all that stays the same. Every now and then if I'm showing on screen some distribution associated with a given  word, that distribution might actually be a little bit off because some of the buckets  associated with various patterns should include either more or fewer true answers. Even then it doesn't really come up because it was very rare that I would  be showing a word that had multiple letters that also hit this edge case. But one of the very few things of substance that does change,  and that arguably does matter a fair bit, was the final conclusion around how if we  want to find the optimal possible score for the wordle answer list,  what opening guess does such an algorithm use? In the video I said the best performance that I could find came  from opening with the word crane, which was true only in the sense  that the algorithms were playing a very slightly different game. After fixing it and rerunning it all, there is a different answer for  what the theoretically optimal first guess is for this particular list. And look, I know that you know that the point of the video is not  to find some technically optimal answer to some random online game. The point of the video is to shamelessly hop on the bandwagon of an  internet trend to sneak attack people with an information theory lesson. And that's all good, I stand by that part. But I know how the internet works, and for a lot of people the  one main takeaway was what is the best opener for the game wordle. And I get it, I walked into that because I put it in the thumbnail,  but presumably you can forgive me if I want to add a little correction here. And a more meaningful reason to circle back to all this actually is that  I never really talked about what went into that final analysis,  and it's interesting as a sublesson in its own right, so that's worth doing here. Now if you'll recall, most of our time last video was spent  on the challenge of trying to write an algorithm to solve  wordle that did not use the official list of all possible answers. To my taste that feels a bit like overfitting to a test set,  and what's more fun is building something that's resilient. This is why we went through the whole process of looking at relative  word frequencies in the English language to come up with some notion  of how likely each one would be to be included as a final answer. However, for what we're doing here, where we're just trying to find an absolute  best performance period, I am incorporating that official list and just shamelessly  overfitting to the test set, which is to say we know with certainty whether a  word is included or not, and we can assign a uniform probability to each one. If you'll remember, the first step in all of this was to say for a  particular opening guess, maybe something like my old favorite, crane,  how likely is it that you would see each of the possible patterns? And in this context, where we are shamelessly overfitting to the wordle answer list,  all that involves is counting how many of the possible answers give each one of these  patterns. And then of course most of our time was spent on this kind of funny looking formula  to quantify the amount of information that you would get from this guess that basically  involves going through each one of those buckets and saying how much information would  you gain, that has this log expression that is a fanciful way of saying how many times  would you cut your space of possibilities in half if you observed a given pattern. We take a weighted average of all of those and it gives us a  measure of how much we expect to learn from this first guess. In a moment we'll go deeper than this, but if you simply search through all 13,000  different words that you could start with and you ask which one has the highest  expected information, it turns out the best possible answer is soar,  which doesn't really look like a real word, but I guess it's an obsolete term for  a baby hawk. The top 15 openers by this metric happen to look like this,  but these are not necessarily the best opening guesses because they're only looking  one step in with the heuristic of expected information to try to estimate what the  true score will be. But there's few enough patterns that we can do an exhaustive search two steps in. For example let's say you opened with soar and the pattern you happen to see was  the most likely one, all grays, then you can run identical analysis from that point. For a given proposed second guess, something like kitty,  what's the distribution across all patterns in that restricted case where  we're restricted only to the words that would produce all grays for soar,  and then we measure the flatness of that distribution using this expected  information formula, and we do that for all 13,000 possible words that we  could use as a second guess. Doing this we can find the optimal second guess in that scenario  and the amount of information we were expected to get from it. And if we wash rinse and repeat and do this for all of the different  possible patterns that you might see, we get a full map of all the best  possible second guesses together with the expected information of each. From there, if you take a weighted average of all those second step values,  weighted according to how likely you are to fall into that bucket,  it gives you a measure of how much information you're likely to gain from the guess  soar after the second step. When we use this two-step metric as our new means of ranking,  the list gets shaken up a bit. Soar is no longer first place, it falls back to 14th,  and instead what rises to the top is slain. Again, doesn't feel very real, and it looks like it is  a British term for a spade that's used for cutting turf. All right, but as you can see, it is a really tight race among all of these  top contenders for who gains the most information after those two steps. And even still, these are not necessarily the best opening guesses,  because information is just the heuristic, it's not telling us the actual score if you  actually play the game. What I did is I ran the simulation of playing all 2315 possible  Wurtle games with all possible answers on the top 250 from this list. And by doing this, seeing how they actually perform,  the one that ends up very marginally with the best possible score turns out to be SalÃ©,  which is, let's see, SalÃ©, an alternate spelling for SalÃ©,  which is a light medieval helmet. All right, if that feels a little too fake for you, which it does for me,  you'll be happy to know that trace and crate give almost identical performance,  and each of them has the benefit of obviously being a real word,  so there is one day when you get it right on the first guess,  since both are actual Wurtle answers. This move from sorting based on the best two-step entropies to sorting based  on the lowest average score also shakes up the list, but not nearly as much. For example, SalÃ© was previously third place before it bubbles to the top,  and crate and trace were both fourth and fifth. If you're curious, you can get slightly better  performance from here by doing a little brute forcing. There's a very nice blog post by Jonathan Olson, if you're curious about this,  where he also lets you explore what the optimal following guesses are  for a few of the starting words based on these optimal algorithms. Stepping back from all this though, I'm told by some people that it quote ruins  the game to overanalyze it like this and try to find an optimal opening guess. It feels kinda dirty if you use that opening guess after learning it,  and it feels inefficient if you don't, but the thing is,  I don't actually think this is the best opener for a human playing the game. For one thing, you would need to know what the optimal  second guess is for each one of the patterns you see. And more importantly, all of this is in a setting where  we are absurdly overfit to the official Wurtle answer list. The moment that, say, the New York Times chooses to change what  that list is under the hood, all of this would go out the window. The way that we humans play the game is just very  different from what any of these algorithms are doing. We don't have the word list memorized, we're not doing exhaustive searches. We get intuition from things like what are the vowels, and how are they placed. I would actually be most happy if those of you watching this video promptly  forgot what happens to be the technically best opening guess,  and instead came out remembering things like how do you quantify information,  or the fact that you should look out for when a greedy algorithm falls  short of the globally best performance that you would get from a deeper search. For my taste at least, the joy of writing algorithms to try to play games  actually has very little bearing on how I like to play those games as a human. The point of writing algorithms for all this is not to affect  the way that we play the game, it's still just a fun word game. It's to hone in our muscles for writing algorithms in more meaningful contexts elsewhere.

================================================================================
VIDEO ID: v68zYyaEmEA
TITLE: Solving Wordle using information theory
URL: https://www.youtube.com/watch?v=v68zYyaEmEA
PUBLISHED: 2022-02-06T13:28:52Z
STATUS: SUCCESS
================================================================================
The game Wordle has gone pretty viral in the last month or two, and never one to overlook an opportunity for a math lesson, it occurs to me that this game makes for a very good central example in a lesson about information theory, and in particular a topic known as entropy. You see, like a lot of people I got kind of sucked into the puzzle, and like a lot of programmers I also got sucked into trying to write an algorithm that would play the game as optimally as it could. And what I thought I'd do here is just talk through with you some of my process in that, and explain some of the math that went into it, since the whole algorithm centers on this idea of entropy. First things first, in case you haven't heard of it, what is Wordle? And to kill two birds with one stone here while we go through the rules of the game, let me also preview where we're going with this, which is to develop a little algorithm that will basically play the game for us. Though I haven't done today's Wordle, this is February 4th, and we'll see how the bot does. The goal of Wordle is to guess a mystery five letter word, and you're given six different chances to guess. For example, my Wordle bot suggests that I start with the guess "crane". Each time that you make a guess, you get some information about how close your guess is to the true answer. Here the grey box is telling me there's no C in the actual answer. The yellow box is telling me there is an R, but it's not in that position. The green box is telling me that the secret word does have an A, and it's in the third position. And then there's no N and there's no E. So let me just go in and tell the Wurdle bot that information. We started with crane, we got grey, yellow, green, grey, grey. Don't worry about all the data that it's showing right now, I'll explain that in due time. But its top suggestion for our second pick is "shtik". And your guess does have to be an actual five letter word, but as you'll see, it's pretty liberal with what it will actually let you guess. In this case, we try "shtik". And alright, things are looking pretty good. We hit the S and the H, so we know the first three letters, we know that there's an R. And so it's going to be like S-H-A something R, or S-H-A R something. And it looks like the Wordle bot knows that it's down to just two possibilities, either shard or sharp. That's kind of a tossup between them at this point, so I guess probably just because it's alphabetical it goes with shard. Which hooray, is the actual answer, so we got it in three. If you're wondering if that's any good, the way I heard one person phrase it is that with Wordle, four is par and three is birdie. Which I think is a pretty apt analogy. You have to be consistently on your game to be getting four, but it's certainly not crazy. But when you get it in three, it just feels great. So if you're down for it, what I'd like to do here is just talk through my thought process from the beginning for how I approach the Wordle bot. And like I said, really it's an excuse for an information theory lesson. The main goal is to explain what is information and what is entropy. My first thought in approaching this was to take a look at the relative frequencies of different letters in the English language. So I thought, okay, is there an opening guess or an opening pair of guesses that hits a lot of these most frequent letters? And one that I was pretty fond of was doing other followed by nails. The thought is that if you hit a letter, you know, you get a green or a yellow, that always feels good, it feels like you're getting information. But in these cases, even if you don't hit and you always get grays, that's still giving you a lot of information, since it's pretty rare to find a word that doesn't have any of these letters. But even still, that doesn't feel super systematic, because for example, it does nothing to consider the order of the letters. Why type nails when I could type snail? Is it better to have that S at the end? I'm not really sure. Now, a friend of mine said that he liked to open with the word weary, which kind of surprised me because it has some uncommon letters in there like the W and the Y. But who knows, maybe that is a better opener. Is there some kind of quantitative score that we can give to judge the quality of a potential guess? Now to set up for the way that we're going to rank possible guesses, let's go back and add a little clarity to how exactly the game is set up. So there's a list of words that it will allow you to enter that are considered valid guesses that's just about 13,000 words long. But when you look at it, there's a lot of really uncommon things, things like "aahed" or "aalii" and "aargh", the kind of words that bring about family arguments in a game of Scrabble. But the vibe of the game is that the answer is always going to be a decently common word. And in fact, there's another list of around 2300 words that are the possible answers. And this is a human curated list, I think specifically by the game creator's girlfriend, which is kind of fun. But what I would like to do, our challenge for this project is to see if we can write a program solving wordle that doesn't incorporate previous knowledge about this list. For one thing, there's plenty of pretty common five letter words that you won't find in that list. So it would be better to write a program that's a little more resilient and would play wordle against anyone, not just what happens to be the official website. And also, the reason that we know what this list of possible answers is, is because it's visible in the source code. But the way that it's visible in the source code is in the specific order in which answers come up from day to day, that you could always just look up what tomorrow's answer will be. So clearly, there's some sense in which using the list is cheating. And what makes for a more interesting puzzle and a richer information theory lesson is to instead use some more universal data like relative word frequencies in general to capture this intuition of having a preference for more common words. So of these 13,000 possibilities, how should we choose the opening guess? For example, if my friend proposes weary, how should we analyze its quality? Well, the reason he said he likes that unlikely W is that he likes the long shot nature of just how good it feels if you do hit that W. For example, if the first pattern revealed was something like this, then it turns out there are only 58 words in this giant lexicon that match that pattern. So that's a huge reduction from 13,000. But the flip side of that, of course, is that it's very uncommon to get a pattern like this. Specifically, if each word was equally likely to be the answer, the probability of hitting this pattern would be 58 divided by around 13,000. Of course, they're not equally likely to be answers. Most of these are very obscure and even questionable words. But at least for our first pass at all of this, let's assume that they're all equally likely and then refine that a bit later. The point is, the pattern with a lot of information is, by its very nature, unlikely to occur. In fact, what it means to be informative is that it's unlikely. A much more probable pattern to see with this opening would be something like this, where, of course, there's not a W in it. Maybe there's an E, and maybe there's no A, there's no R, there's no Y. In this case, there are 1400 possible matches. If all were equally likely, it works out to be a probability of about 11% that this is the pattern you would see. So the most likely outcomes are also the least informative. To get a more global view here, let me show you the full distribution of probabilities across all of the different patterns that you might see. So each bar that you're looking at corresponds to a possible pattern of colors that could be revealed, of which there are 3 to the 5th possibilities, and they're organized from left to right, most common to least common. So the most common possibility here is that you get all grays. That happens about 14% of the time. And what you're hoping for when you make a guess is that you end up somewhere out in this long tail, like over here, where there's only 18 possibilities for what matches this pattern, that evidently look like this. Or if we venture a little farther to the left, you know, maybe we go all the way over here. Okay, here's a good puzzle for you. What are the three words in the English language that start with a W, end with a Y, and have an R somewhere in them? Turns out, the answers are, let's see, wordy, wormy, and wryly. So to judge how good this word is overall, we want some kind of measure of the expected amount of information that you're going to get from this distribution. If we go through each pattern and we multiply its probability of occurring times something that measures how informative it is, that can maybe give us an objective score. Now your first instinct for what that something should be might be the number of matches. You want a lower average number of matches. But instead I'd like to use a more universal measurement that we often ascribe to information, and one that will be more flexible once we have a different probability assigned to each of these 13,000 words for whether or not they're actually the answer. The standard unit of information is the bit, which has a little bit of a funny formula, but is really intuitive if we just look at examples. If you have an observation that cuts your space of possibilities in half, we say that it has one bit of information. In our example, the space of possibilities is all possible words, and it turns out about half of the five letter words have an S, a little less than that, but about half. So that observation would give you one bit of information. If instead a new fact chops down that space of possibilities by a factor of four, we say that it has two bits of information. For example, it turns out about a quarter of these words have a T. If the observation cuts that space by a factor of eight, we say it's three bits of information, and so on and so forth. Four bits cuts it into a sixteenth, five bits cuts it into a thirty second. So now's when you might want to take a moment and pause and ask for yourself, what is the formula for information for the number of bits in terms of the probability of an occurrence? Well, what we're saying here is basically that when you take one half to the number of bits, that's the same thing as the probability, which is the same thing as saying two to the power of the number of bits is one over the probability, which rearranges further to saying the information is the log base two of one divided by the probability. And sometimes you see this with one more rearrangement still where the information is the negative log base two of the probability. Expressed like this, it can look a little bit weird to the uninitiated, but it really is just the very intuitive idea of asking how many times you've cut down your possibilities in half. Now if you're wondering, you know, I thought we were just playing a fun word game, why are logarithms entering the picture? One reason this is a nicer unit is it's just a lot easier to talk about very unlikely events, much easier to say that an observation has 20 bits of information than it is to say that the probability of such and such occurring is 0.0000095. But a more substantive reason that this logarithmic expression turned out to be a very useful addition to the theory of probability is the way that information adds together. For example, if one observation gives you two bits of information, cutting your space down by four, and then a second observation like your second guess in Wordle gives you another three bits of information, chopping you down further by another factor of eight, the two together give you five bits of information. In the same way that probabilities like to multiply, information likes to add. So as soon as we're in the realm of something like an expected value, where we're adding a bunch of numbers up, the logs make it a lot nicer to deal with. Let's go back to our distribution for weary and add another little tracker on here, showing us how much information there is for each pattern. The main thing I want you to notice is that the higher the probability as we get to those more likely patterns, the lower the information, the fewer bits you gain. The way we measure the quality of this guess will be to take the expected value of this information. When we go through each pattern, we say how probable is it and then we multiply that by how many bits of information do we get. And in the example of weary, that turns out to be 4.9 bits. So on average, the information you get from this opening guess is as good as chopping your space of possibilities in half about five times. By contrast, an example of a guess with a higher expected information value would be something like slate. In this case, you'll notice the distribution looks a lot flatter. In particular, the most probable occurrence of all grays only has about a 6% chance of occurring, so at minimum you're getting evidently 3.9 bits of information. But that's a minimum, more typically you'd get something better than that. And it turns out when you crunch the numbers on this one and add up all the relevant terms, the average information is about 5.8. So in contrast with weary, your space of possibilities will be about half as big after this first guess, on average. There's actually a fun story about the name for this expected value of information quantity. You see, information theory was developed by Claude Shannon, who was working at Bell Labs in the 1940s, but he was talking about some of his yet-to-be-published ideas with John von Neumann, who was this intellectual giant of the time, very prominent in math and physics and the beginnings of what was becoming computer science. And when he mentioned that he didn't really have a good name for this expected value of information quantity, von Neumann supposedly said, so the story goes, well, you should call it entropy, and for two reasons. In the first place, your uncertainty function has been used in statistical mechanics under that name, so it already has a name, and in the second place, and more important, nobody knows what entropy really is, so in a debate you'll always have the advantage. So if the name seems a little bit mysterious, and if this story is to be believed, that's kind of by design. Also if you're wondering about its relation to all of that second law of thermodynamics stuff from physics, there definitely is a connection, but in its origins Shannon was just dealing with pure probability theory, and for our purposes here, when I use the word entropy, I just want you to think the expected information value of a particular guess. You can think of entropy as measuring two things simultaneously. The first one is how flat is the distribution? The closer a distribution is to uniform, the higher that entropy will be. In our case, where there are 3 to the 5th total patterns, for a uniform distribution, observing any one of them would have information log base 2 of 3 to the 5th, which happens to be 7.92, so that is the absolute maximum that you could possibly have for this entropy. But entropy is also kind of a measure of how many possibilities there are in the first place. For example, if you happen to have some word where there's only 16 possible patterns, and each one is equally likely, this entropy, this expected information, would be 4 bits. But if you have another word where there's 64 possible patterns that could come up, and they're all equally likely, then the entropy would work out to be 6 bits. So if you see some distribution out in the wild that has an entropy of 6 bits, it's sort of like it's saying there's as much variation and uncertainty in what's about to happen as if there were 64 equally likely outcomes. For my first pass at the Wurtelebot, I basically had it just do this. It goes through all of the different possible guesses that you could have, all 13,000 words, it computes the entropy for each one, or more specifically, the entropy of the distribution across all patterns that you might see for each one, and then it picks the highest, since that's the one that's likely to chop down your space of possibilities as much as possible. And even though I've only been talking about the first guess here, it does the same thing for the next few guesses. For example, after you see some pattern on that first guess, which would restrict you to a smaller number of possible words based on what matches with that, you just play the same game with respect to that smaller set of words. For a proposed second guess, you look at the distribution of all patterns that could occur from that more restricted set of words, you search through all 13,000 possibilities, and you find the one that maximizes that entropy. To show you how this works in action, let me just pull up a little variant of Wurtele that I wrote that shows the highlights of this analysis in the margins. So after doing all its entropy calculations, on the right here it's showing us which ones have the highest expected information. Turns out the top answer, at least at the moment, we'll refine this later, is Tares, which means, um, of course, a vetch, the most common vetch. Each time we make a guess here, where maybe I kind of ignore its recommendations and go with slate, because I like slate, we can see how much expected information it had, but then on the right of the word here it's showing us how much actual information we got given this particular pattern. So here it looks like we were a little unlucky, we were expected to get 5.8, but we happened to get something with less than that. And then on the left side here it's showing us all of the different possible words given where we are now. The blue bars are telling us how likely it thinks each word is, so at the moment it's assuming each word is equally likely to occur, but we'll refine that in a moment. And then this uncertainty measurement is telling us the entropy of this distribution across the possible words, which right now, because it's a uniform distribution, is just a needlessly complicated way to count the number of possibilities. For example, if we were to take 2 to the power of 13.66, that should be around the 13,000 possibilities. Um, a little bit off here, but only because I'm not showing all the decimal places. At the moment that might feel redundant and like it's overly complicating things, but you'll see why it's useful to have both numbers in a minute. So here it looks like it's suggesting the highest entropy for our second guess is Raman, which again just really doesn't feel like a word. So to take the moral high ground here I'm going to go ahead and type in Rains. And again it looks like we were a little unlucky. We were expecting 4.3 bits and we only got 3.39 bits of information. So that takes us down to 55 possibilities. And here maybe I'll just actually go with what it's suggesting, which is combo, whatever that means. And, okay, this is actually a good chance for a puzzle. It's telling us this pattern gives us 4.7 bits of information. But over on the left, before we see that pattern, there were 5.78 bits of uncertainty. So as a quiz for you, what does that mean about the number of remaining possibilities? Well it means that we're reduced down to 1 bit of uncertainty, which is the same thing as saying that there's 2 possible answers. It's a 50-50 choice. And from here, because you and I know which words are more common, we know that the answer should be abyss. But as it's written right now, the program doesn't know that. So it just keeps going, trying to gain as much information as it can, until it's only one possibility left, and then it guesses it. So obviously we need a better endgame strategy, but let's say we call this version 1 of our wordle solver, and then we go and run some simulations to see how it does. So the way this is working is it's playing every possible wordle game. It's going through all of those 2315 words that are the actual wordle answers. It's basically using that as a testing set. And with this naive method of not considering how common a word is, and just trying to maximize the information at each step along the way, until it gets down to one and only one choice. By the end of the simulation, the average score works out to be about 4.124. Which is not bad, to be honest, I kind of expect it to do worse. But the people who play wordle will tell you that they can usually get it in 4. The real challenge is to get as many in 3 as you can. It's a pretty big jump between the score of 4 and the score of 3. The obvious low-hanging fruit here is to somehow incorporate whether or not a word is common, and how exactly do we do that. The way I approached it is to get a list of the relative frequencies for all of the words in the English language, and I just used Mathematica's word frequency data function, which itself pulls from the Google Books English Ngram public dataset. And it's kind of fun to look at, for example if we sort it from the most common words to the least common words. Evidently these are the most common, 5-letter words in the English language. Or rather, these is the 8th most common. First is which, after which there's there and there. First itself is not first, but 9th, and it makes sense that these other words could come about more often, where those after first are after, where, and those being just a little bit less common. Now, in using this data to model how likely each of these words is to be the final answer, it shouldn't just be proportional to the frequency, because for example which is given a score of 0.002 in this dataset, whereas the word braid is in some sense about 1000 times less likely. But both of these are common enough words that they're almost certainly worth considering, so we want more of a binary cutoff. The way I went about it is to imagine taking this whole sorted list of words, and then arranging it on an x-axis, and then applying the sigmoid function, which is the standard way to have a function whose output is basically binary, it's either 0 or it's 1, but there's a smoothing in between for that region of uncertainty. So essentially, the probability that I'm assigning to each word for being in the final list will be the value of the sigmoid function above wherever it sits on the x-axis. Now obviously this depends on a few parameters, for example how wide a space on the x-axis those words fill determines how gradually or steeply we drop off from 1 to 0, and where we situate them left to right determines the cutoff. And to be honest the way I did this was kind of just licking my finger and sticking it into the wind. I looked through the sorted list and tried to find a window where when I looked at it I figured about half of these words are more likely than not to be the final answer, and used that as the cutoff. Now once we have a distribution like this across the words, it gives us another situation where entropy becomes this really useful measurement. For example, let's say we were playing a game and we start with my old openers, which were other and nails, and we end up with a situation where there's four possible words that match it. And let's say we consider them all equally likely, let me ask you, what is the entropy of this distribution? Well, the information associated with each one of these possibilities is going to be the log base 2 of 4, since each one is 1 and 4, and that's 2. 2 bits of information, 4 possibilities. All very well and good. But what if I told you that actually there's more than 4 matches? In reality, when we look through the full word list, there are 16 words that match it. But suppose our model puts a really low probability on those other 12 words of actually being the final answer, something like 1 in 1000 because they're really obscure. Now let me ask you, what is the entropy of this distribution? If entropy was purely measuring the number of matches here, then you might expect it to be something like the log base 2 of 16, which would be 4, two more bits of uncertainty than we had before. But of course the actual uncertainty is not really that different from what we had before. Just because there's these 12 really obscure words doesn't mean that it would be all that more surprising to learn that the final answer is charm, for example. So when you actually do the calculation here and you add up the probability of each occurrence times the corresponding information, what you get is 2.11 bits. Just saying, it's basically two bits, basically those four possibilities, but there's a little more uncertainty because of all of those highly unlikely events, though if you did learn them you'd get a ton of information from it. So zooming out, this is part of what makes Wordle such a nice example for an information theory lesson. We have these two distinct feeling applications for entropy. The first one telling us what's the expected information we'll get from a given guess, and the second one saying can we measure the remaining uncertainty among all of the words we have possible. And I should emphasize, in that first case where we're looking at the expected information of a guess, once we have an unequal weighting to the words, that affects the entropy calculation. For example, let me pull up that same case we were looking at earlier of the distribution associated with Weary, but this time using a non-uniform distribution across all possible words. So let me see if I can find a part here that illustrates it pretty well. Okay, here, this is pretty good. Here we have two adjacent patterns that are about equally likely, but one of them we're told has 32 possible words that match it. And if we check what they are, these are those 32, which are all just very unlikely words as you scan your eyes over them. It's hard to find any that feel like plausible answers, maybe yells, but if we look at the neighboring pattern in the distribution, which is considered just about as likely, we're told that it only has 8 possible matches. So a quarter as many matches, but it's about as likely. And when we pull up those matches, we can see why. Some of these are actual plausible answers like ring or wrath or raps. To illustrate how we incorporate all that, let me pull up version two of the Wordlebot here. And there are two or three main differences from the first one that we saw. First off, like I just said, the way that we're computing these entropies, these expected values of information, is now using the more refined distributions across the patterns that incorporates the probability that a given word would actually be the answer. As it happens, tears is still number one, though the ones following are a bit different. Second, when it ranks its top picks, it's now going to keep a model of the probability that each word is the actual answer, and it'll incorporate that into its decision, which is easier to see once we have a few guesses on the table. Again, ignoring its recommendation because we can't let machines rule our lives. And I suppose I should mention another thing different here is over on the left, that uncertainty value, that number of bits, is no longer just redundant with the number of possible matches. Now if we pull it up and calculate 2 to the 8.02, which would be a little above 256, I guess 259, what it's saying is even though there are 526 total words that actually match this pattern, the amount of uncertainty it has is more akin to what it would be if there were 259 equally likely outcomes. You can think of it like this. It knows borks is not the answer, same with yorts and zorl and zorus. So it's a little less uncertain than it was in the previous case. This number of bits will be smaller. And if I keep playing the game, I'm refining this down with a couple guesses that are apropos of what I would like to explain here. By the fourth guess, if you look over at its top picks, you can see it's no longer just maximizing the entropy. So at this point, there's technically seven possibilities, but the only ones with a meaningful chance are dorms and words. And you can see it ranks choosing both of those above all of these other values that strictly speaking would give more information. The very first time I did this, I just added up these two numbers to measure the quality of each guess, which actually worked better than you might suspect. But it really didn't feel systematic. And I'm sure there's other approaches people could take. But here's the one I landed on. If we're considering the prospect of a next guess, like in this case words, what we really care about is the expected score of our game if we do that. And to calculate that expected score, we say what's the probability that words is the actual answer, which at the moment it describes 58% to. We say with a 58% chance, our score in this game would be four. And then with the probability of one minus that 58%, our score will be more than that four. How much more we don't know, but we can estimate it based on how much uncertainty there's likely to be once we get to that point. Specifically, at the moment, there's 1.44 bits of uncertainty. If we guess words, it's telling us the expected information we'll get is 1.27 bits. So if we guess words, this difference represents how much uncertainty we're likely to be left with after that happens. What we need is some kind of function, which I'm calling f here, that associates this uncertainty with an expected score. And the way it went about this was to just plot a bunch of the data from previous games based on version one of the bot to say, hey, what was the actual score after various points with certain very measurable amounts of uncertainty? For example, these data points here that are sitting above a value that's around like 8.7 or so are saying for some games, after a point at which there were 8.7 bits of uncertainty, it took two guesses to get the final answer. For other games, it took three guesses. For other games, it took four guesses. If we shift over to the left here, all the points over zero are saying whenever there's zero bits of uncertainty, which is to say there's only one possibility, then the number of guesses required is always just one, which is reassuring. Whenever there was one bit of uncertainty, meaning it was essentially just down to two possibilities, then sometimes it required one more guess, sometimes it required two more guesses, and so on and so forth here. Maybe a slightly easier way to visualize this data is to bucket it together and take averages. For example, this bar here is saying among all the points where we had one bit of uncertainty, on average the number of new guesses required was about 1.5. And the bar over here is saying among all of the different games where at some point the uncertainty was a little above four bits, which is like narrowing it down to 16 different possibilities, then on average it requires a little more than two guesses from that point forward. And from here I just did a regression to fit a function that seemed reasonable to this. And remember, the whole point of doing any of that is so that we can quantify this intuition that the more information we gain from a word, the lower the expected score will be. So, with this as version 2.0, if we go back and run the same set of simulations, having it play against all 2315 possible wordle answers, how does it do? Well in contrast to our first version, it's definitely better, which is reassuring. All said and done, the average is around 3.6. Although unlike the first version, there are a couple times that it loses, and requires more than six in this circumstance. Presumably because there's times when it's making that tradeoff to actually go for the goal rather than maximizing information. So can we do better than 3.6? We definitely can. Now, I said at the start that it's most fun to try not incorporating the true list of wordle answers into the way that it builds its model. But if we do incorporate it, the best performance I could get was around 3.43. So if we try to get more sophisticated than just using word frequency data to choose this prior distribution, this 3.43 probably gives a max at how good we could get with that, or at least how good I could get with that. That best performance essentially just uses the ideas that I've been talking about here, but it goes a little farther, like it does a search for the expected information two steps forward rather than just one. Originally I was planning on talking more about that, but I realize we've actually gone quite long as it is. The one thing I'll say is after doing this two-step search and then running a couple sample simulations in the top candidates, so far for me at least, it's looking like Crane is the best opener. Who would have guessed? Also if you use the true wordle list to determine your space of possibilities, then the uncertainty you start with is a little over 11 bits. And it turns out just from a brute force search, the maximum possible expected information after the first two guesses is around 10 bits. Which suggests that best case scenario, after your first two guesses, with perfectly optimal play, you'll be left with around one bit of uncertainty. Which is the same as being down to two possible guesses. But I think it's fair and probably pretty conservative to say that you could never possibly write an algorithm that gets this average as low as three, because with the words available to you, there's simply not room to get enough information after only two steps to be able to guarantee the answer in the third slot every single time without fail.

================================================================================
VIDEO ID: ltLUadnCyi0
TITLE: A tale of two problem solvers | Average cube shadow area
URL: https://www.youtube.com/watch?v=ltLUadnCyi0
PUBLISHED: 2021-12-20T15:02:30Z
STATUS: SUCCESS
================================================================================
In a moment I'm going to tell you about a certain  really nice puzzle involving the shadow of a cube. But before we get to that, I should say that the point of this video is  not exactly the puzzle per se, it's about two distinct problem-solving  styles that are reflected in two different ways that we can tackle this problem. In fact, let's anthropomorphize those two different styles by imagining two students,  Alice and Bob, that embody each one of the approaches. So Bob will be the kind of student who really loves calculation. As soon as there's a moment when he can dig into the details and get a very concrete  view of the concrete situation in front of him, that's where he's the most pleased. Alice on the other hand is more inclined to procrastinate the computations,  not because she doesn't know how to do them or doesn't want to per se,  but she prefers to get a nice high-level general overview of the kind of problem  she's dealing with, the general shape that it has before she digs into the  computations themselves. She's most pleased if she understands not just the specific question sitting  in front of her, but also the broadest possible way that you could generalize it,  and especially if the more general view can lend itself to more swift and  elegant computations, once she does actually sit down to carry them out. Now the puzzle that both of them are going to be faced  with is to find the average area for the shadow of a cube. So if I have a cube kind of sitting here hovering in space,  there are a few things that influence the area of its shadow. One obvious one would be the size of the cube, smaller cube, smaller shadow. But also if it's sitting at different orientations,  those orientations correspond to different particular shadows with different areas. And when I say find the average here, what I mean is average  over all possible orientations for a particular size of the cube. The astute among you might point out that it also matters a lot where the light source is. If the light source were very low, close to the cube itself,  then the shadow ends up larger. And if the light source were kind of positioned laterally off to the side,  this can distort the shadow and give it a very different shape. Accounting for that light position stands to be highly interesting in its own right,  but the puzzle is hard enough as it is, so at least initially,  let's do the easiest thing we can and say that the light is directly above the cube and  really far away, effectively infinitely far, so that all we're considering is a flat  projection, in the sense that if you look at any coordinates, x, y, z, in space,  the flat projection would be x, y, 0. So, just to get our bearings, the easiest situation to think about would  be if the cube is straight up, with two of its faces parallel to the ground. In that case, this flat projection shadow is simply a square,  and if we say the side lengths of the cube are s, then the area of that shadow is sÂ². And by the way, any time that I have a label up on these animations,  like the one down here, I'll be assuming that the relevant cube has a side length of 1. Now, another special case among all the orientations that's fun to think  about is if the long diagonal is parallel to the direction of the light. In that case, the shadow actually looks like a regular hexagon,  and if you use some of the methods that we will develop in a few minutes,  you can compute that the area of that shadow is exactly the square root of 3 times  the area of one of the square faces. But of course, more often, the actual shadow will  be not so regular as a square or a hexagon. It's some harder to think about shape, based on  some harder to think about orientation for this cube. Earlier, I casually threw out this phrase of averaging over all possible orientations,  but you could rightly ask, what exactly is that supposed to mean? I think a lot of us have an intuitive feel for what we want it to mean,  at least in the sense of what experiment would you do to verify it. You might imagine tossing this cube in the air, like a die,  freezing it at some arbitrary point, recording the area of the shadow from that position,  and then repeating. If you do this many many times, over and over, you can take the mean of your sample. The number that we want to get at, the true average here,  should be whatever that experimental mean approaches as you do more and more tosses,  approaching infinitely many. Even still, the sticklers among you could complain that doesn't really answer  the question, because it leaves open the issue of how we're defining a random toss. The proper way to answer this, if we want it to be more formal,  would be to first describe the space of all possible orientations,  which mathematicians have actually given a fancy name. They call it SO3, typically defined in terms of a certain family of 3x3 matrices. And the question we want to answer is, what probability  distribution are we putting to this entire space? It's only when such a probability distribution is well-defined,  that we can answer a question involving an average. If you are a stickler for that kind of thing, I want you  to hold off on that question until the end of the video. You'll be surprised at how far we can get with the more heuristic,  experimental idea of just repeating a bunch of random tosses without really defining  the distribution. Once we see Alice and Bob's solutions, it's actually very interesting to  ask how exactly each one of them defined this distribution along their way. And remember, this is not meant to be a lesson about cube shadows per se,  but a lesson about problem solving, told through the lens of two  different mindsets that we might bring to the puzzle. And as with any lesson on problem solving, the goal here is not to get to the answer  as quickly as we can, but hopefully for you to feel like you found the answer yourself. So if ever there's a point when you feel like you might have an idea,  give yourself the freedom to pause and try to think it through. As a first step, and this is really independent of any particular problem solving style,  just any time you find a hard question, a good thing that you can do is ask,  what's the simplest possible, non-trivial variant of the problem that you can try to  solve? So in our case, what you might say is, okay, let's  forget about averaging over all the orientations. That's a tricky thing to think about. And let's even forget about all the different faces of the cube,  because they overlap, and that's also tricky to think about. Just for one particular face, and one particular orientation,  can we compute the area of this shadow? Once more, if you want to get your bearings with some special cases,  the easiest is when that face is parallel to the ground,  in which case the area of the shadow is the same as the area of the face. And on the other hand, if we were to tilt that face 90 degrees,  then its shadow will be a straight line, and it has an area of zero. So Bob looks at this, and he wants an actual formula for that shadow. And the way he might think about it is to consider  the normal vector perpendicular off of that face. And what seems relevant is the angle that that normal vector makes with the vertical,  with the direction where the light is coming from, which we might call theta. Now, from the two special cases we just looked at,  we know that when theta is equal to zero, the area of that shadow is  the same as the area of the shape itself, which is s squared if the  square has side lengths s. And if theta is equal to 90 degrees, then the area of that shadow is zero. And it's probably not too hard to guess that trigonometry will be somehow relevant,  so anyone comfortable with their trig functions could probably  hazard a guess as to what the right formula is. But Bob is more detail-oriented than that. He wants to properly prove what that area should be,  rather than just making a guess based on the endpoints. And the way you might think about it could be something like this. If we consider the plane that passes through the vertical as well as our normal vector,  and then we consider all the different slices of our shape that are in that plane,  or parallel to that plane, then we can focus our attention on a  two-dimensional variant of the problem. If we just look at one of those slices, who has a normal vector,  an angle theta away from the vertical, its shadow might look something like this. And if we draw a vertical line up to the left here, we have ourselves a right triangle. And from here we can do a little bit of angle chasing,  where we follow around what that angle theta implies about the rest of the diagram. And this means the lower right angle in this triangle is precisely theta. So, when we want to understand the size of this shadow in comparison  to the original size of the piece, we can think about the cosine of that angle,  theta, which remembers the adjacent over the hypotenuse. It's literally the ratio between the size of the shadow and the size of the slice. So, the factor by which the slice gets squished  down in this direction is exactly cosine of theta. And if we broaden our view to the entire square,  all the slices in that direction get scaled by the same factor. But in the other direction, in the one perpendicular to that slice,  there is no stretching or squishing, because the face is not at all tilted in  that direction. So overall, the two-dimensional shadow of our two-dimensional face  should also be scaled down by this factor of a cosine of theta. It lines up with what you might intuitively guess,  given the case where the angle is 0Â° and the case where it's 90Â°,  but it's reassuring to see why it's true. And actually, as stated so far, this is not quite correct. There is a small problem with the formula that we've written. In the case where theta is bigger than 90Â°, the  cosine would actually come out to be negative. But of course, we don't want to consider the shadow to have negative area,  at least not in a problem like this. So there's two different ways you could solve this. You could say we only ever want to consider the normal vector that is pointing up,  that has a positive z component. Or, more simply, we could say, just take the absolute value of that cosine,  and that gives us a valid formula. So Bob's happy because he has a precise formula describing the area of the shadow. But Alice starts to think about it a little bit differently. She says, okay, we've got some shape, and then we apply a rotation  that sort of situates it into 3D space in some way,  and then we apply a flat projection that shoves that back into two-dimensional space. And what stands out to her is that both of these are linear transformations. That means that in principle you could describe each one of them with a matrix,  and that the overall transformation would look like the product of those two matrices. What Alice knows from one of her favorite subjects, linear algebra,  is that if you take some shape and you consider its area,  then you apply some linear transformation, then the area of that output looks like some  constant times the original area of the shape. More specifically, we have a name for that constant. It's called the determinant of the transformation. If you're not so comfortable with linear algebra,  we could give a much more intuitive description and say,  if you uniformly stretch the original shape in some direction,  the output will also uniformly get stretched in some direction. So the area of each of them should scale in proportion to each other. Now, in principle, Alice could compute this determinant,  but it's not really her style to do that, at least not to do so immediately. Instead, the thing that she writes down is how this proportionality constant  between our original shape and its shadow does not depend on the original shape. We could be talking about the shadow of this cat outline,  or anything else, and the size of it doesn't really matter. The only thing affecting that proportionality constant is what transformation  we're applying, which in this context means we could write it down as  some factor that depends on the rotation being applied to the shape. In the back of our mind, because of Bob's calculation,  we know what that factor looks like. You know, it's the absolute value of the cosine of  the angle between the normal vector and the vertical. But Alice right now is just saying, yeah, yeah,  yeah, I can think about that eventually when I want to. But she knows we're about to average over all the different orientations anyway,  though she holds out some hope that any specific formula about a  specific orientation might get washed away in that average. Now it's easy to look at this and say, okay, well, Alice isn't really doing anything then. Of course the area of the shadow is proportional to the area of the original shape. They're both two-dimensional quantities. They should both scale like two-dimensional things. But keep in mind, this would not at all be true if we were  dealing with the harder case that has a closer light source. In that case, the projection is not linear. For example, if I rotate this cat so that its tail ends up quite close to the light  source, then if I stretch the original shape uniformly in the x-direction,  say by a factor of 1.5, it might have a very disproportionate effect on the ultimate  shadow because the tail gets very disproportionately blown up as it gets really close  to the light. Again, Alice is keeping an eye out for what properties of the problem are  actually relevant because that helps her know how much she can generalize things. Does the fact that we're thinking about a square face and not some other shape matter? No, not really. Does the fact that the transformation is linear matter? Yes, absolutely. Alice can also apply a similar way of thinking  about the average shadow for any shape like this. Say we have some sequence of rotations that we apply to our square face. And let's call them R1, R2, R3, and so on. Then the area of the shadow in each one of those cases  looks like some factor times the area of the square. And that factor depends on the rotation. So if we take an empirical average for that shadow across the sample of  rotations we're looking at right now, the way it looks is to add up all  of those shadow areas and then divide by the total number that we have. Now, because of the linearity, this area of the original square  can cleanly factor out of all of that, and it ends up on the left. This isn't the exact average that we're looking for,  it's just an empirical mean of a sample of rotations. But in principle what we're looking for is what this  approaches as the size of our sample approaches infinity. And all the parts that depend on the size of the  sample sit cleanly away from the area itself. So whatever this approaches in the limit, it's just going to be some number. It might be a royal pain to compute, we're not sure about that yet,  but the thing that Alice notes is that it's independent of the size  and the shape of the particular 2D thing that we're looking at. It's a universal proportionality constant. And her hope is that that universality somehow lends  itself to a more elegant way to deduce what it must be. Now Bob would be eager to compute this constant here and now,  and in a few minutes I'll show you how he does it. But before that I do want to stay in Alice's world for a little bit more,  because this is where things start to really get fun. In her desire to understand the overall structure of the question  before diving into the details, she's curious now about how the area  of the shadow of the cube relates to the area of its individual faces. Now if we can say something about the average area of a particular face,  does that tell us anything about the average area of the cube as a whole? For example, a simple thing we could say is that that area is  definitely less than the sum of the areas across all the faces,  because there's a meaningful amount of overlap between those shadows. But it's not entirely clear how to think about that overlap,  because if we focus our attention just on two particular faces,  in some orientations they don't overlap at all. But in other orientations they do have some overlap,  and the specific shape and area of that overlap seems a little bit tricky to think about,  much less how on Earth we would average that across all of the different orientations. But Alice has about three clever insights through this whole problem,  and this is the first one of them. She says, actually, if we think about the whole cube, not just a pair of faces,  we can conclude that the area of the shadow for a given orientation  is exactly one half the sum of the areas of all of the faces. Intuitively you can maybe guess that half of them are bathed in the  light and half of them are not, but here's the way that she justifies it. She says for a particular ray of light that would go from the sky and eventually  hit a point in the shadow, that ray passes through the cube at exactly two points. There's one moment when it enters and one moment when it exits. So every point in that shadow corresponds to exactly two faces above it. Well, okay, that's not exactly true if that beam of light  happened to go through the edge of one of the squares. There's a little bit of ambiguity on how many faces it's passing. But those account for zero area inside the shadow,  so we're safe to ignore them if the thing we're trying to do is compute the area. If Alice is pressed and she needs to justify why exactly this is true,  which is important for understanding how the problem might generalize,  she can appeal to the idea of convexity. Convexity is one of those properties where a lot of us have an intuitive sense for  what it should mean, you know, it's shapes that just bulge out, they never dent inward. But mathematicians have a pretty clever way of  formalizing it that's helpful for actual proofs. They say that a set is convex if the line that connects any two  points inside that set is entirely contained within the set itself. So, a square is convex because no matter where you put two points inside that square,  the line connecting them is entirely contained inside the square. But something like the symbol pi is not convex,  I can easily find two different points so that the line connecting them has to  peak outside of the set itself. None of the letters in the word convex are themselves convex. You can find two points so that the line connecting them has to pass outside of the set. It's a really clever way to formalize this idea of a shape that only bulges out. Because anytime that it dents inward, you can find these counterexample lines. Or, our cube, because it's convex, between the first point of entry and the last  point of exit, it has to stay entirely inside the cube by definition of convexity. But if we were dealing with some other non-convex shape, like a donut,  you could find a ray of light that enters, then exits, then enters,  then exits again, so you wouldn't have a clean two-to-one cover from the shadows. The shadows of all of its different parts, if you were to cover this in a bunch of faces,  would not be precisely two times the area of the shadow itself. So, that's the first key insight, the face shadows double cover the cube shadow. And the next one is a little bit more symbolic,  so let's start things off by abbreviating our notation a little to  make room on the screen. Instead of writing the area of the shadow of the cube,  I'm just going to write s of the cube. And similarly, instead of the area of the shadow of a particular face,  I'm just going to write s of f, where that subscript j indicates which face I'm  talking about. But of course, we should really be talking about the  shadow of a particular rotation applied to the cube. So I might write this as s of some rotation applied to the cube,  and likewise on the right, it's the area of the shadow of that same rotation applied to  a given one of the faces. With the more compact notation at hand, let's think about the average of this  shadow area across many different rotations, some sample of r1, r2, r3, and so on. Again, that average just involves adding up all  of those shadow areas and then dividing them by n. And in principle, if we were to look at this for larger and larger samples,  let n approach infinity, that would give us the average area of the shadow of the cube. Some of you might be thinking, yes, we know this, you've said this already,  but it's beneficial to write it out so that we can understand why it is that  expressing the shadow area for a particular rotation of the cube as a sum across  all of its faces, or one half times that sum at least, why is that beneficial? What is it going to do for us? Well, let's just write it out, where for each one of these rotations of the cube,  we could break down that shadow as a sum across that same  rotation applied across all of the faces. And when it's written as a grid like this, we can get to Alice's second insight,  which is to shift the way that we're thinking about the sum from  going row by row to instead going column by column. For example, if we focused our attention just on the first column,  what it's telling us is to add up the area of the shadow of the first face across many  different orientations. So if we were to take that sum and divide it by the size of our sample,  that gives us an empirical average for the area of the shadow of this face. So if we take larger and larger samples, letting that size go to infinity,  this will approach the average shadow area for a square. Likewise, the second column can be thought of as telling us the average area  for the second face of the cube, which should of course be the same number. And same deal for any other column, it's telling  us the average area for a particular face. So that gives us a very different way of thinking about our whole expression. Instead of saying add up the areas of the cubes at all the different orientations,  we could say just add up the average shadows for the six different  faces and divide the total by one half. The term on the left here is thinking about adding up rows first,  and the term on the right is thinking about adding up columns first. In short, the average of the sum of the face shadows is  the same as the sum of the average of the face shadows. Maybe that swap seems simple, maybe it doesn't,  but I can tell you that there is actually a little bit more  than meets the eye to the step that we just took, but we'll get to that later. And remember, we know that the average area for a particular face looks  like some universal proportionality constant times the area of that face. So if we're adding this up across all the faces of the cube,  we could think of this as equaling some constant times the surface area of the cube. And that's pretty interesting. The average area for the shadow of this cube is  going to be proportional to its surface area. But at the same time, you might complain, well Alice is just  pushing around a bunch of symbols here, because none of this  matters if we don't know what that proportionality constant is. I mean, it almost seems obvious. Like, of course the average shadow area should be proportional to the surface area. They're both two-dimensional quantities, so they should scale in lockstep with each other. I mean, it's not obvious. After all, for a closer light source, it simply wouldn't be true. And also, this business where we added up the grid column by column  versus row by row is a little more nuanced than it might look at first. There's a subtle, hidden assumption underlying all of this,  which carries a special significance when we choose to revisit the question  of what probability distribution is being taken across the space of all orientations. But more than anything, the reason that it's not obvious is that the significance  of this result right here is not merely that these two values are proportional. It's that an analogous fact will hold true for any convex solids,  and, crucially, the actual content of what Alice has built up so far  is that it'll be the same proportionality constant across all of them. Now if you really mull over that, some of you may be able to  predict the way that Alice is able to finish things off from here. It's really delightful, it's honestly my main reason for covering this topic. But before we get into it, I think it's easy to underappreciate her result  unless we dig into the details of what it is that she manages to avoid. So let's take a moment to turn our attention back into Bob's world,  because while Alice has been doing all of this, he's been busy doing some computations. In fact, what he's been working on is finding exactly what Alice has yet to figure out,  which is how to take the formula that he found for the area of a square's  shadow and taking the natural next step of trying to find the average of  that square's shadow averaged over all possible orientations. So the way Bob starts, if he's thinking about all the different possible  orientations for this square, is to ask, what are all the different  normal vectors that that square can have in all these orientations,  because everything about its shadow comes down to that normal vector. It's not too hard to see that all those possible normal vectors trace out the surface  of a sphere, if we assume it's a unit normal vector, it's a sphere with radius 1. And furthermore, Bob figures that each point of this  sphere should be just as likely to occur as any other. Our probabilities should be uniform in that way,  there's no reason to prefer one direction over another. But in the context of continuous probabilities,  it's not very helpful to talk about the likelihood of a particular individual point,  because in the uncountable infinity of points on the sphere,  that would be zero and unhelpful. So instead, the more precise way to phrase this uniformity would be  to say the probability that our normal vector lands in any given  patch of area on the sphere should be proportional to that area itself. More specifically, it should equal the area of that little  patch divided by the total surface area of the sphere. If that's true, no matter what patch of area we're considering,  that's what we mean by a uniform distribution on the sphere. Now to be clear, points on the sphere are not the same thing as orientations in 3D space,  because even if you know what normal vector this square is going to have,  that leaves us with another degree of freedom,  the square could be rotated about that normal vector. But Bob doesn't actually have to care about that extra degree of freedom,  because in all of those cases, the area of the shadow is the same,  it's only dependent on the cosine of the angle between that normal vector and  the vertical. Which is kind of neat, all those shadows are genuinely different shapes,  they're not the same, but the area of each of them will be the same. What this means is that when Bob wants this average shadow area over  all possible orientations, all he really needs to know is the average  value of this absolute value of cosine of theta for all different  possible normal vectors, all different possible points on the sphere. So, how do you compute an average like this? Well, if we lived in some kind of discrete pixelated world,  where there's only a finite number of possible angles theta that  that normal vector could have, the average would be pretty straightforward. What you do is find the probability of landing on any particular value of theta,  which will tell us something like how much of the sphere do normal vectors  with that angle make up, and then you multiply it by the thing we want  to take the average of, this formula for the area of the shadow. And then you would add that up over all of the different possible values of theta,  ranging from 0 up to 180 degrees, or pi radians. But of course, in reality, there is a continuum of possible values of theta,  this uncountable infinity, and the probability of landing on any  specific particular value of theta will actually be 0. And so a sum like this unfortunately doesn't really make any sense,  or if it does make sense, adding up infinitely many zeros should just give us a 0. The short answer for what we do instead is that we compute an integral. And I'll level with you, the hard part here is I'm not entirely sure  what background I should be assuming from those of you watching right now. Maybe it's the case that you're quite comfortable with  calculus and you don't need me to belabor the point here. Maybe it's the case that you're not familiar with calculus  and I shouldn't just be throwing down integrals like that. Or maybe you, you know, you took a calculus class a while ago,  but you need a little bit of a refresher. I'm going to go with the option of setting this up as if it's a calculus lesson,  because to be honest, even when you are quite comfortable with integrals,  setting them up can be kind of an error-prone process,  and calling back to the underlying definition is a good way to sort of check  yourself in the process. If we lived in a time before calculus existed and integrals weren't a thing,  and we wanted to approximate an answer to this question,  one way we could go about it is to take a sample of values for theta that ranges  from 0 up to 180 degrees. We might think of them as evenly spaced with some sort of difference between each one,  some delta theta. And it's still the case that it would be unhelpful to ask about the probability  of a particular value of theta occurring, even if it's 1 in our sample. That probability would still be 0 and it would be unhelpful. But what is helpful to ask is the probability of falling between two different  values from our sample, in this little band of latitude with a width of delta theta. Based on our assumption that the distribution along this sphere should be uniform,  that probability comes down to knowing the area of this band. More specifically, the chances that a randomly chosen vector lands in that  band should be that area divided by the total surface area of the sphere. To figure out that area, let's first think of the radius of that band, which,  if the radius of our sphere is 1, is definitely going to be smaller than 1. And in fact, if we draw the appropriate little right triangle here,  you can see that that little radius, let's just say at the top of the band,  should be the sine of our angle, the sine of theta. This means that the circumference of the band should be 2 pi times  the sine of that angle, and then the area of the band should be  that circumference times its thickness, that little delta theta. Or rather, the area of our band is approximately this quantity. What's important is that for a finer sample of many more values of theta,  the accuracy of that approximation would get better and better. Now remember, the reason we wanted this area is to know the probability  of falling into that band, which is this area divided by the surface area of the sphere,  which we know to be 4 pi times its radius squared. That's a value that you could also compute with an integral similar to the one that we're  setting up now, but for now we can take it as a given, as a standard well-known formula. And this probability itself is just a stepping stone in the direction of  what we actually want, which is the average area for the shadow of a square. To get that, we'll multiply this probability times the corresponding shadow area,  which is this absolute value of cosine theta expression we've seen many times up to this  point. And our estimate for this average would now come down to adding up this expression  across all of the different bands, all of the different samples of theta that we've taken. This right here, by the way, is when Bob is just totally in his element. We've got a lot of exact formulas describing something very concrete,  actually digging in on our way to a real answer. And again, if it feels like a lot of detail, I want you to appreciate that fact,  so that you can appreciate just how magical it is when Alice manages to somehow avoid all  of this. Anyway, looking back at our expression, let's clean things up a little bit,  like factoring out all of the terms that don't depend on theta itself. And we can simplify that 2 pi divided by 4 pi to simply be 1 half. And to make it a little more analogous to calculus,  with integrals, let me just swap the main terms inside the sum here. What we now have, this sum that's going to approximate the answer to our question,  is almost what an integral is. Instead of writing the sigma for sum, we write the integral symbol,  this kind of elongated Leibnizian s, showing us that we're going from 0 to pi. And instead of describing the step size as delta theta,  a concrete finite amount, we instead describe it as d theta,  which I like to think of as signaling the fact that some kind of limit is being taken. What that integral means, by definition, is whatever the  sum on the bottom approaches for finer and finer subdivisions. More dense samples that we might take for theta itself. And at this point, for those of you who do know calculus,  I'll just write down the details of how you would actually carry this out,  as you might see it written down in Bob's notebook. It's the usual anti-derivative stuff, but the one  key step is to bring in a certain trig identity. In the end, what Bob finds after doing this is the surprisingly clean fact that  the average area for a square's shadow is precisely one half the area of that square. This is the mystery constant, which Alice doesn't yet know. If Bob were to look over her shoulder and see the work that she's done,  he could finish out the problem right now. He plugs in the constant that he just found, and he knows the final answer. And now, finally, with all of this as backdrop,  what is it that Alice does to carry out the final solution? I introduced her as someone who really likes to generalize the results she finds. And usually those generalizations end up as interesting footnotes  that aren't really material for solving particular problems. But this is a case where the generalization itself draws her to a quantitative result. Remember, the substance of what she's found so far is that if you look at any convex  solid, then the average area for its shadow is going to be proportional to its surface  area. And critically, it'll be the same proportionality constant across all of these solids. So all Alice needs to do is find just a single convex solid  out there where she already knows the average area of its shadow. And some of you may see where this is going. The most symmetric solid available to us is a sphere. No matter what the orientation of that sphere, its shadow,  the flat projection shadow, is always a circle with an area of pi r squared. So in particular, that's its average shadow area. And the surface area of a sphere, like I mentioned before, is exactly 4 pi r squared. By the way, I did make a video talking all about that surface  area formula and how Archimedes proved it thousands of years before calculus existed,  so you don't need integrals to find it. The magic of what Alice has done is that she can take this seemingly specific  fact that the shadow of a sphere has an area exactly 1 fourth its surface area  and use it to conclude a much more general fact that for any convex solid out there,  its shadow and surface area are related in the same way, in a certain sense. So with that, she can go and fill in the details of the particular question about a cube  and say that its average shadow area will be 1 fourth times its surface area, 6 s squared. But the much more memorable fact that you'll go to sleep thinking about  is how it didn't really matter that we were talking about a cube at all. Now, that's all very pretty, but some of you might complain that this  isn't really a valid argument because spheres don't have flat faces. When I said Alice's argument generalizes to any convex solid,  if we actually look at the argument itself, it definitely depends on the use of a finite  number of flat faces. For example, if we were mapping it to a dodecahedron,  you would start by saying that the area of a particular shadow of that  dodecahedron looks like exactly 1 half times the sum of the areas of the  shadows of all its faces. Once again, you could use a certain ray of light  mixed with convexity argument to draw that conclusion. And remember, the benefit of expressing that shadow area as a sum is that when we want to  average over a bunch of different rotations, we can describe that sum as a big grid where  we can then go column by column and consider the average area for the shadow of each face. And also, a critical fact was the conclusion from much earlier that  the average shadow for any 2D object, a flat 2D object, which is important,  will equal some universal proportionality constant times its area. The significance was that that constant didn't depend on the shape itself. It could have been a square, or a cat, or the pentagonal faces of our dodecahedron,  whatever. Though, after hastily carrying this over to a sphere that doesn't  have a finite number of flat faces, you would be right to complain. But luckily, it's a pretty easy detail to fill in. What you can do is imagine a sequence of different polyhedra that  successively approximate a sphere, in the sense that their faces  hug tighter and tighter around the genuine surface of the sphere. For each one of those approximations, we can draw the same conclusion,  that its average shadow is going to be proportional to its  surface area with this universal proportionality constant. So then, if we say, okay, let's take the limit of the ratio between  the average shadow area at each step and the surface area at each step,  well, since that ratio is never changing, it's always equal to this constant,  then in the limit, it's also going to equal that constant. But on the other hand, by their definition, in the limit,  their average shadow area should be that of a circle, which is Ï€rÂ²,  and the limit of the surface areas would be the surface area of the sphere, 4Ï€rÂ². So we do genuinely get the conclusion that intuition would suggest,  but, as is so common with Alice's argument here,  we do have to be a little delicate in how we justify that intuition. It's easy for this contrast of Alice and Bob to come across like a value judgment,  as if I'm saying, look how clever Alice has managed to be,  she insightfully avoided all those computations that Bob had to do. But that would be a very, um, misguided conclusion. I think there's an important way that popularizations  of math differ from the feeling of actually doing math. There's this bias towards showing the slick proofs,  the arguments with some clever keen insight that lets you avoid doing calculations. I could just be projecting, since I'm very guilty of this, but what I can tell you,  sitting on the other side of the screen here, is that it feels a lot more  attractive to make a video about Alice's approach than Bob's. For one thing, in Alice's approach, the line of reasoning is fun,  it has these nice aha moments. But also, crucially, the way that you explain it is more or  less the same for a very wide range of mathematical backgrounds. It's much less enticing to do a video about Bob's approach,  not because the computations are all that bad, I mean, they're honestly not,  but the pragmatic reality is that the appropriate pace to explain it looks  very different depending on the different mathematical backgrounds in the audience. So you, watching this right now, clearly consume math videos online,  and I think in doing so it's worth being aware of this bias. If the aim is to have a genuine lesson on problem solving,  too much focus on the slick proofs runs the risk of being disingenuous. For example, let's say we were to step up to challenge  mode here and ask about the case with a closer light source. To my knowledge, there is not a similarly slick solution to Alice's here,  where you can just relate to a single shape like a sphere. The much more productive warmup to have done would  have been the calculus of Bob's approach. And if you look at the history of this problem,  it was proved by Cauchy in 1832, and if we paw through his handwritten notes,  they look a lot more similar to Bob's work than Alice's work. Right here at the top of page 11, you can see what is  essentially the same integral that you and I set up in the middle. On the other hand, the whole framing of the paper is to find a general fact,  not something specific like the case of a cube. So if we were asking the question which of these two mindsets correlates with the act of  discovering new math, the right answer would almost certainly have to be a blend of both. But I would suggest that many people don't sign enough weight to  the part of that blend where you're eager to dive into calculations. And I think there's some risk that the videos I make might contribute to that. In the podcast I did with the mathematician Alex Kontorovich,  he talked about the often underappreciated importance of just drilling on  computations to build intuition, whether you're a student engaging with a new class,  or a practicing research mathematician engaging with a new field of study. A listener actually wrote in to highlight what an impression that particular section made. They're a PhD student and describe themselves as being worried that their mathematical  abilities were starting to fade, which they attributed to becoming older and less sharp. But hearing a practicing mathematician talk about the importance of doing hundreds of  concrete examples in order to learn something new,  evidently that changed their perspective. In their own words, recognizing this completely reshaped their outlook and their results. And if you look at the famous mathematicians through history,  you know, Newton, Euler, Gauss, all of them, they all have  this seemingly infinite patience for doing tedious calculations. The irony of being biased to show insights that let us avoid calculations  is that the way people often train up the intuitions to find those  insights in the first place is by doing piles and piles of calculations. All that said, something would definitely be missing without the Alice mindset here. I mean, think about it, how sad would it be if we solved this problem for a  cube and we never stepped outside of the trees to see the forest and understand  that this is a super general fact, it applies to a huge family of shapes. And if you consider that math is not just about answering the questions that are  posed to you, but about introducing new ideas and constructs,  one fun side note about Alice's approach here is that it suggests a fun way to quantify  the idea of convexity. Rather than just having a yes-no answer, is it convex, is it not,  we could put a number to it by saying, consider the average area of the shadow  of some solid, multiply that by four, divide it by the surface area,  and if that number is one, you've got a convex solid, but if it's less than one,  it's non-convex, and how close it is to one tells you how close it is to being convex. Also, one of the nice things about the Alice solution here is that it  helps explain why it is that mathematicians have what can sometimes  look like a bizarre infatuation with generality and with abstraction. The more examples that you see where generalizing and abstracting actually helps  you to solve a specific case, the more you start to adopt the same infatuation. And as a final thought for the stalwart viewers among you who've stuck through it  this far, there is still one unanswered question about the very premise of our puzzle. What exactly does it mean to choose a random orientation? Now if that feels like a silly question, like of course we know what it should mean,  I would encourage you to watch a video that I just did with Numberphile  on a conundrum from probability known as Bertrand's paradox. After you watch it, and if you appreciate some of the nuance at play here,  homework for you is to reflect on where exactly Alice and Bob implicitly answered this  question. The case with Bob is relatively straightforward,  but the point at which Alice locks down some specific distribution on the space of  all orientations is not at all obvious. It's actually very subtle.
680
00:40:00,420 --> 00:39:41,700
.

================================================================================
VIDEO ID: F3Qixy-r_rQ
TITLE: 2021 Summer of Math Exposition results
URL: https://www.youtube.com/watch?v=F3Qixy-r_rQ
PUBLISHED: 2021-10-23T20:25:56Z
STATUS: SUCCESS
================================================================================
This summer, James Schloss and I ran a contest that's meant to encourage more people  to make online math explainers, and here I want to share with you some of my favorites. I wrote up a much fuller blog post about the event and the process for selecting winners,  but let's open here with some of the key points. First of all, it was extremely open-ended. It's meant for math explainers of any kind, any medium,  any target audience, any topic, pretty much just as long as it's about math. The promise was to select around 4-5 to be winners,  which I would then feature in a video, here we are now,  and after I made the initial announcement, Brilliant came in and kindly  offered cash prizes to those winners. Before anything, let me just emphasize this notion of a  winner should really be taken with a heavy grain of salt. The spirit of the event, and hopefully this is obvious,  is to get more people sharing their knowledge,  and preferably to have them do so in a way that's as engaging and  empathetic and novel as possible. The way I see it, there's some benefits to framing it as a contest,  like we have a clear deadline, and that can be a great cure for perfectionism  and stagnation. Also, having some small stakes involved hopefully means that the lessons are  put together with a little bit more care, and with a little bit more attention  to the kind of principles that I wanted to emphasize with the whole event. The downside, which is not to be taken lightly,  is that it gives the false impression that success looks like winning, but it does not. Success means having more material out there that  explains math and inspires people to engage with it. Ten years from now, no one is going to remember my arbitrary selections,  but every one of the pieces made will still exist and will still potentially help someone  trying to learn. We received over 1200 submissions, and as a first pass for the  judgment we had a peer review process to help filter that down to  a little over 100 that James and I could give a really close look at. We also had around half a dozen guest judges, people in the space of math exposition,  to help us narrow down those final judgments. Many, many thanks to those guests for being willing to volunteer some of their time,  and generally helping to ensure that any of my subjective quirks  weren't leaking too much into the final decision. Also, a million thanks to James. He really was the core organizer behind everything here,  and if you participated in the event and found it helpful,  he is absolutely the one you should be thanking. As I said, there's a blog post with more details for any of you who are curious,  but right now, without further ado, let me tell you about some outstanding  math explainers made this summer that I really think you're going to enjoy. This entry, from a channel called Paralogical,  opens by asking why the light reflected at the bottom of a mug seems to form  this characteristic cardioid shape. The core mathematical idea that this video teaches is that of envelopes,  which in short is a way to describe one curve using a family of other curves,  and what really makes the video special is not just how clearly he explains that subject,  but how tangible and well-chosen the examples are,  all delivered with a tone that's just plain friendly and enjoyable to listen to. The key formula he builds up to is really well motivated,  and one of those things that would not be obvious if you just saw it out of context,  and he gives the tools for any curious viewer to pause and work through for  themselves a more detailed understanding, while still leaving room for someone  watching to get the general idea and the core points without necessarily being  bogged down into that algebra. On the topic of fun ways that light gets redirected,  another one of my picks is an absolutely mind-blowing piece of engineering wizardry. This one is a blog post written by Matt Ferraro,  where he explains how he made this acrylic square. It might look innocent at first, like nothing more than a transparent square,  maybe suspiciously wavy, but when you look at its shadow you can see that it's been  carefully crafted to redirect light in such a way as to form a highly deliberate image. The post walks through all of the math and the algorithms involved in pulling this off,  including certain false starts in the discovery process, which I love,  and the author skillfully draws the reader's attention to which details are  important and deserve more of your focus, and which ones are more side notes and minutiae. I found myself a little surprised about what parts of the process  turned out to be hard and which ones were easy,  and by the end the whole task felt a lot less mysterious while still  commanding no shortage of respect for the fact that someone was actually  able to pull it off. The next pick that I have on my list here, I'll feel a little torn about,  I wouldn't be surprised if many of you have already seen this video,  it's called The Beauty of BÃ©zier Curves by Freya Homare. Given the spirit of the contest, which is to encourage people to share their knowledge  without necessarily getting intimidated by a need for high production quality, you know,  focus on the quality of the lesson more so than the medium used to express it,  this video was so beautifully produced I almost felt like choosing it risked sending the  wrong message. Also, part of the goal here is to shine a light on comparatively unknown creators,  and by the time I was watching this one it had around 400,000 views. But the thing is, Freya's video really is a fantastic piece of exposition,  and it would be a little bit silly of me to fault it for also being beautiful  and evidently also being appreciated by many people in both respects. I do want to be clear, the reason that I'm choosing it is not because of the smooth  graphics, it's that here we have someone who uses a certain mathematical tool regularly  in her work, and she has the ability to clearly motivate why you should care too,  and to go into the details of how it works, the many different facets of how she uses it,  how she thinks about it, and what makes it visually great is not so much the smoothness  of the graphics or the aesthetic appeal, it's that they're clean and to the point,  serving to aid what's the core value in the whole piece,  a series of well-chosen intuitions and applications of a topic in math that deserves  to be known by more people. After that one I really did think that with my other picks I could  help direct the audience of this channel to some excellent lessons  that you might not have seen yet, like with the next one I chose. When I saw it, it had a couple hundred views and I really  loved it and I was excited to share it with you all. But then it looks like the internet kind of beat me to it,  this thing is quickly going on a million views, well deserved by the way. If you haven't seen it, it really is delightful. It's not a traditional math lesson in the sense of explaining some topic that  you might need to learn for a course, or even one that exists in a clear field  for that matter, but it absolutely captures the spirit of mathematical discovery. The question posed in the video seems a little bit silly at first,  which is what's the most complicated passcode for those sorts  of swipey swipey pattern passcodes that some phones have. The video opens by making that question rigorous, giving it a solid definition,  and then proceeds with a really engaging story of problem solving that involves very  real math lessons along the way, things about number theory, about induction,  about generalizing a result even after you've solved a sub problem,  definitely take a look. The final pick I have on my list here, which again is in no particular order,  is one that multiple different guest judges singled out as being especially good,  and also easily underappreciated. The video describes a really clever and memorable proof  of this cute fact from geometry known as Pick's theorem. And more than that, the author has some really nice thoughts about the role  of different kinds of proofs in math, thoughts which more students,  and for that matter more teachers, would really benefit from hearing and thinking about. It's no fancier than it needs to be, but the core idea is just so good that,  to me at least, the video has a lot more staying power than many of the professionally  produced educational videos that I've seen from established channels out there. So there you go, those are my five picks for this summer of Math Exposition. But the thing is, if you had seen the submissions that I have seen,  you would agree that choosing just five winners is ridiculous, to the point of absurdity. Again, you know, the point is not the winners,  the event is about encouraging people to follow through with projects,  things about Math Exposition they might have been thinking about doing, all of that. But just reiterating that point feels a little bit hollow, because there are at least,  I don't know, twenty in here where I feel like it is a genuine crime not to have chosen  them. And, well you know, it's my contest, my rules, so if you'll indulge me,  let me quickly tell you about some others that I just loved. One that I think viewers of this channel would especially enjoy is almost an hour. It's about Durock's belt trick by Noah Miller. In a recent event that I was doing with Stephen Strogatz for the MoMath Museum,  we had a call that was ostensibly meant to prepare for that event,  but instead we spent much of it just both gushing over how much we liked this one  particular video. Any of you who have flirted with this topic will probably know how tricky  it can be to understand the link between points on a 4D sphere and rotations in 3D space,  and why any of that has to do with quantum mechanics,  but this animated hour-long lecture does a really good job laying out the full story. Another one which is long but good is about the unsolvability  of the quintic by Carl Turner. For me it was a bit b I'm not seeing it because when I did, I was actively working  on a video that was not just about the same theorem,  but about the same comparatively esoteric proof that it describes there. I thought the video did such a wonderful job, I just kind of set aside the project. I'll still probably cover it at some point, but now I'm motivated to do it in  a different way, but in the meantime, any of you curious about why quintic  polynomials are in a certain sense unsolvable will absolutely love this video. So many entries here were just really solid explainers, plain and simple. This includes the best overview I've seen of the two-envelope problem,  a great explanation for how fonts get turned into pixels,  a wonderful article on spinners, a comic style blog post about E,  a video about an ancient Babylonian algorithm for multiplying numbers,  which has unexpected usefulness for certain programming tasks. There were a number of videos in Chinese on the site Bilibili,  including one I really liked about a fundamental theorem for symmetric polynomials,  perfectly understandable with the English subtitles. And one absolutely fantastic video in here was about lemur factor stencils,  which I had never heard of, and I learned a ton watching this and found it absolutely  fascinating. Many of the entries I saw had excellent aha moments, like this one here,  with a mildly clickbaity title about a graph that will blow your mind,  but the thing is, at least in my experience, that title is 100% accurate. There's a video explaining why pi shows up in the Buffon needle  problem with a really elegant shift in perspective,  and what I especially appreciate is that the author also has an  appendix video going through some of the more technical details not  covered in the main video. A few entries were highly interesting if for no other reason just from a technological  standpoint alone, including a very well-executed interactive video by Rob Schlubb,  which let me tell you is not easy to pull off,  as well as a great interactive article introducing complex numbers and the fundamental  theorem of algebra on the site Trina. And then some of the entries, setting aside all the explanatory value,  were just plain beautiful. Like if I had a category here for greatest style,  I think my pick would be this one about recreating curves from a children's toy. But setting aside style or the core point of all of this,  which is the explanatory quality, there's one feature of online explainers  that can easily be underappreciated, which is the role of narrative and storylines. And a couple entries I think did a great job exemplifying that component. This includes not one but two entries on this game called Hackenbush,  a story about how a lights-out puzzle can lead you to Gaussian elimination,  a nice exploration of the most efficient way to choose a random point in a  circle uniformly, a great puzzle about tiles, which carries with it explanations  of core facts from Fibonacci numbers, and one really nicely done video about  why the Sierpinski triangle shows up in three seemingly completely unrelated contexts. Again, the list goes on for quite a while. As I look at some of these now, I'm really pleased to see that a lot of them have picked  up some traction on YouTube, but there still remain many which are very underappreciated. I highly encourage you to go to the playlist including all the video  submissions and to check out the blog post featuring all other submissions. As you look at that playlist, I would not read into the order of it too much,  it was generated programmatically, but I did try to go through and curate  the first few ones with videos that I think you might especially like. Honestly though, you can happily scroll down that  playlist and find hidden gems all throughout. Like really, go check it out right now. If you do, I can almost guarantee that you have hours of edification  waiting ahead of you, not to mention hours of just pure delight. Thanks again to everyone who participated. Let me just say one more time, I really was blown away by the quality here.

================================================================================
VIDEO ID: LqbZpur38nw
TITLE: Beyond the Mandelbrot set, an intro to holomorphic dynamics
URL: https://www.youtube.com/watch?v=LqbZpur38nw
PUBLISHED: 2021-10-16T12:39:12Z
STATUS: SUCCESS
================================================================================
Today I'd like to tell you about a piece of math known as holomorphic dynamics. This is the field which studies things like the Mandelbrot set,  and in fact one of my main goals today is to show you how this iconic shape,  the poster child of math, pops up in a more general way than the initial definition  might suggest. Now this field is also intimately tied to what we talked about in the last video,  with Newton's fractal, and another goal of ours towards the end of this  video will be to help tie up some of the loose ends that we had there. So first of all, this word holomorphic might seem a little weird. It refers to functions that have complex number inputs and complex number outputs,  and which you can also take a derivative of. Basically what it means to have a derivative in this context is that when you zoom  in to how the function behaves near a given point, to the point and its neighbors,  it looks roughly like scaling and rotating, like multiplying by some complex constant. We'll talk more about that in just a bit, but for now know that  it includes most of the ordinary functions you could write down,  things like polynomials, exponentials, trig functions, all of that. The relevant dynamics in the title here comes from asking what happens when  you repeatedly apply one of these functions over and over,  in the sense of evaluating on some input, then evaluating the same function  on whatever you just got out, and then doing that again, and again and again and again. Sometimes the pattern of points emerging from this gets trapped in a cycle,  other times the sequence will just approach some kind of limiting point. Or maybe the sequence gets bigger and bigger and it flies off to infinity,  which mathematicians also kind of think of as approaching a limit point,  just the point at infinity. And other times still they have no pattern at all, and they behave chaotically. What's surprising is that for all sorts of functions that you might write down,  when you try to do something to visualize when these different possible behaviors arise,  it often results in some insanely intricate fractal pattern. Those of you who watched the last video have already seen one neat example of this. There's this algorithm called Newton's method, which finds the root of some polynomial p,  and the way it works is to basically repeatedly iterate the expression x  minus p of x divided by p prime of x, p prime being the derivative. When your initial seed value is in the loose vicinity of a root to that polynomial,  a value where p of x equals zero, this procedure produces a sequence  of values that really quickly converges to that root. This is what makes it a useful algorithm in practice. But then we tried to do this in the complex plane,  looking at the many possible seed values and asking which  root in the complex plane each one of these seed values might end up on. Then we associated a color with one of the roots,  and then colored each pixel of the plane based on which root a seed value starting at  that pixel would ultimately land on. The results we got were some of these insanely intricate pictures,  with these rough fractal boundaries between the colors. Now in this example, if you look at the function that we're actually iterating,  say for some specific choice of a polynomial, like z cubed minus one,  you can rewrite the whole expression to look like one polynomial divided by another. Mathematicians call these kinds of functions rational functions. And if you forget the fact that this arose from Newton's method,  you could reasonably ask what happens when you iterate any other rational function. And in fact, this is exactly what the mathematicians Pierre Fatou  and Gaston Julia did in the years immediately following World War I. And they built up a surprisingly rich theory of what happens when you  iterate these rational functions, which is particularly impressive given  that they had no computers to visualize any of this the way you and I can. Remember those two names, they'll come up a bit later. By far the most popularized example of a rational function that you  might study like this, and the fractals that can ensue,  is one of the simplest functions, z squared plus c, where c is some constant. I'm going to guess that this is at least somewhat familiar to many of you,  but it certainly doesn't hurt to quickly summarize the story here,  since it can help set the stage for what comes later. For this game, we're going to think of c as a value that can be changed. It'll be visible as this movable yellow dot. For the actual iterative process, we will always  start with an initial value of z equals zero. So after iterating this function once, doing z squared plus c, you get c. If you iterate a second time, plugging in that value to the function,  you get c squared plus c. And as I change around the value c here, you can kind of see how the second value  moves in lockstep. Then we can plug in that second value to get z3,  and that third value to get z4, and continue on like this,  visualizing our chain of values. So if I keep doing this many different times for the first many values,  for some choices of c, this process remains bounded. You can still see it all on the screen. And other times, it looks like it blows up, and you can actually  show that if it gets as big as 2, it'll blow up to infinity. If you color the points of the plane where it stays bounded black,  and you assign some other gradient of colors to the divergent values based on how quickly  the process rushes off to infinity, you get one of the most iconic images in all of math,  the Mandelbrot set. Now this interactive dots and stick visualization of the trajectory,  by the way, is heavily inspired by Ben Sparks' illustration and the  Numberphile video he did about the Mandelbrot set, which is great, you should watch it. I honestly thought it was just too fun not to re-implement here.  I would also highly recommend the interactive article on ako.net about  all of this stuff for any of you who haven't had the pleasure of reading that yet. What's nice about the Ben Sparks illustration is how it illuminates  what each different part of the Mandelbrot set actually represents. This largest cardioid section includes the values of c  so that the process eventually converges to some limit. The big circle on the left represents the values where  the process gets trapped in a cycle between two values. And then the top and bottom circles show values where the process  gets trapped in a cycle of three values, and so on like this. Each one of these little islands kind of has its own meaning. Also notice there's an important difference between how this  Mandelbrot set and the Newton fractals we were looking at before are each constructed,  beyond just a different underlying function. For the Mandelbrot set we have a consistent seed value, z equals zero,  but the thing we're tweaking is the parameter c, changing the function itself. So what you're looking at is what we might call a parameter space. But with Newton's fractal, we have a single unchanging function,  but what we associate with each pixel is a different seed value for the process. Of course, we could play the same game with the map z squared plus c. We could fix c at some constant, and then let the pixels  represent the different possible initial values, z naught. So whereas each pixel of the Mandelbrot set corresponds to a unique function,  the images on the right each just correspond to a single function. As we change the parameter c, it changes the entire image on the right. And again, just to be clear, the rule being applied is that we color pixels  black if the process remains bounded, and then apply some kind of gradient to  the ones that diverge away to infinity based on how quickly they diverge to infinity. In principle, and it's kind of mind-warping to think about,  there is some four-dimensional space of all combinations of c and z naught,  and what we're doing here is kind of looking through individual two-dimensional slices  of that unimaginable pattern. You'll often hear or read the images on the right being referred to as  Julia sets or Julia fractals, and when I first learned about all this stuff,  I'll admit that I kind of was left with the misconception that this is  what the term Julia set refers to, specifically the z squared plus c case,  and moreover that it's referring to the black region on the inside. However, the term Julia set has a much more general definition,  and it would refer just to the boundaries of these regions, not the interior. To set the stage for a more specific definition,  and to also make some headway towards the first goal that I mentioned at the start,  it's worth stepping back and really just picturing yourself as a mathematician right now,  discovering all of this. What would you actually do to construct a theory around this? It's one thing to look at some pretty pictures,  but what sorts of questions would you ask if you actually want to understand it all? In general, if you want to understand something complicated,  a good place to start is to ask if there are any parts of the system  that have some simple behavior, preferably the simplest possible behavior. In our example, that might mean asking when does the process just stay fixed in place,  meaning f of z is equal to z. That's a pretty boring set of dynamics, I think you'd agree. We call a value with this property a fixed point of the function. In the case of the functions arising from Newton's method,  by design they have a fixed point at the roots of the relevant polynomial. You can verify for yourself, if p of z is equal to zero,  then the entire expression is simply equal to z. That's what it means to be a fixed point. If you're into exercises, you may enjoy pausing for a moment and computing the  fixed points of this Mandelbrot set function, z squared plus c. More generally,  any rational function will always have fixed points,  since asking when this expression equals z can always be rearranged as finding the  roots of some polynomial expression, From the fundamental theorem of algebra, this must have solutions,  typically as many solutions as the highest degree in this expression. Incidentally, this means you could also find those fixed points using Newton's method,  but maybe that's a little too meta for us. ight now. Now just asking about fixed points is maybe easy,  but a key idea for understanding the full dynamics,  and hence the diagrams we're looking at, is to understand stability. We say that a fixed point is attracting if nearby points tend to get drawn in towards it,  and repelling if they're pushed away. And this is something that you can actually compute  explicitly using the derivative of the function. Symbolically, when you take derivatives of complex functions,  it looks exactly the same as it would for real functions,  though something like z squared has a derivative of 2 times z. But geometrically, there's a really lovely way to interpret what this means. For example, at the input 1, the derivative of this particular function evaluates to be  2, and what that's telling us is that if you look at a very small neighborhood around  that input, and you follow what happens to all the points in that little neighborhood as  you apply the function, in this case z squared,  then it looks just like you're multiplying by 2. This is what a derivative of 2 means. To take another example, let's look at the input i. We know that this function moves that input to the value negative 1, that's i squared. But the added information that its derivative at this value is 2 times i gives us the  added picture that when you zoom in around that point,  and you look at the action of the function on this tiny neighborhood,  it looks like multiplication by 2i, which in this case is saying it looks like a 90  degree rotation combined with an expansion by a factor of 2. For the purposes of analyzing stability, the only thing  we care about here is the growing and shrinking factor. The rotational part doesn't matter. So if you compute the derivative of a function at its fixed point,  and the absolute value of this result is less than 1,  it tells you that the fixed point is attracting,  that nearby points tend to come in towards it. If that derivative has an absolute value bigger than 1,  it tells you the fixed point is repelling, it pushes away its neighbors. For example, if you work out the derivative of our Newton's map expression,  and you simplify a couple things a little bit, here's what you would get out. So if z is a fixed point, which in this context means that it's one of the roots  of the polynomial p, this derivative is not only smaller than 1, it's equal to 0. These are sometimes called super-attracting fixed points,  since it means that a neighborhood around these points doesn't merely shrink,  it shrinks a lot. And again, this is kind of by design, since the intent of Newton's method  is to produce iterations that fall towards a root as quickly as they can. Pulling up our z squared plus c example, if you did the first  exercise to find its fixed points, the next step would be to ask,  when is at least one of those fixed points attracting? For what values of c is this going to be true? And then, if that's not enough of a challenge,  try using the result that you find to show that this condition corresponds to the main  cardioid shape of the Mandelbrot set. This is something you can compute explicitly, it's pretty cool. A natural next step would be to ask about cycles,  and this is where things really start to get interesting. If f of z is not z but some other value, and then that value comes back to z,  it means that you've fallen into a two cycle. You could explicitly find these kinds of two cycles by  evaluating f of f of z and then setting it equal to z. For example, with the z squared plus c map, f of f of z expands out to look like this. A little messy, but you know, it's not too terrible. The main thing to highlight is that it boils down to solving some degree four equation. You should note though that the fixed points will also be solutions to this equation,  so technically the two cycles are the solutions to this minus the  solutions to the original fixed point equation. And likewise you can use the same idea to look for  n cycles by composing f with itself n different times. The explicit expressions that you would get quickly become insanely messy,  but it's still elucidating to ask how many cycles would you expect based on this  hypothetical process. If we stick with our simple z squared plus c example, as you compose it with itself,  you'd get a polynomial with degree four and then one with degree eight and then  degree sixteen and so on and so on, exponentially growing the order of the polynomial. So in principle, if I asked you how many cycles are there with a period of one million,  you can know that it's equivalent to solving some just absolutely insane  polynomial expression with a degree of two to the one million. So again, fundamental theorem of algebra, you would expect to find something on the order  of two to the one million points in the complex plane which cycle in exactly this way. And more generally, for any rational map you'll always be able  to find values whose behavior falls into a cycle with period n. It ultimately boils down to solving some probably insane polynomial expression. And just like with this example, the number of  such periodic points will grow exponentially with n. I didn't really talk about this in the last video about Newton's fractal,  but it's sort of strange to think that there are infinitely many points  that fall into some kind of cycle even for a process like this. In almost all cases though, these points are somewhere on the boundary  between those colored regions and they don't really come up in  practice because the probability of landing on one of them is zero. What matters for actually falling into one of these is if one of the  cycles is attracting in the sense that a neighborhood of points around  a value from that cycle would tend to get pulled in towards that cycle. A highly relevant question for someone interested in numerical methods  is whether or not this Newton's map process ever has an attracting cycle,  because if there is it means there's a non-zero chance that your  initial guess gets trapped in that cycle and it never finds a root. The answer here is actually yes. More explicitly, if you try to find the roots of z cubed minus 2z plus  2 and you're using Newton's method, watch what happens to a cluster  that starts around the value zero and sort of bounces back and forth. And well okay, in this case the cluster we started with was a  little bit too big so some of the outer points get sprayed away,  but here's what it looks like if we start with a smaller cluster. Notice how all of the points genuinely do shrink  in towards the cycle between zero and one. It's not likely that you hit this with a random seed, but it definitely is possible. The exercise that you could do to verify that a cycle like this is attracting,  by the way, would be to compute the derivative of f of f of z,  and you check that at the input zero this derivative has a magnitude less than one. The thing that blew my mind a little is what happens when you try  to visualize which cubic polynomials have attracting cycles at all. Hopefully if Newton's method is going to be at all decent at finding roots,  those attracting cycles should be rare. First of all, to better visualize the one example we're looking at,  we could draw the same fractal that we had before,  coloring each point based on what root the seed value starting at that point  will tend to, but this time we'll have an added condition of coloring points  that says that if the seed value never gets close enough to a root at all,  we will color the pixel black. Notice if I tweak the roots, meaning that we're trying out different cubic polynomials,  it's actually really hard to find any place to put them so  that we see any black pixels at all. I can find this one little sweet spot here, but it's definitely rare. Now what I want is some kind of way to visualize every possible cubic polynomial  at once with a single image in a way that shows which ones have attracting cycles. Luckily it turns out that there is a really simple way to test  whether or not one of these polynomials has an attracting cycle. All you have to do is look at the seed value which sits at average of the three roots,  this center of mass here. Turns out, this is not at all obvious, if there's an attracting cycle,  you can guarantee that this seed value will fall into that attracting cycle. In other words, if there are any black points, this will be one of them. If you want to know where this magical fact comes from,  it stems from a theorem of our good friend Fatou. He showed that if one of these rational maps has an attracting cycle,  you can look at the values where the derivative of your iterated function equals zero,  and at least one of those values has to fall into the cycle. That might seem like a little bit of a weird fact,  but the loose intuition is that if a cycle is going to be attracting,  at least one of its values should have a very small derivative,  that's where the shrinking will come from. And this in turn means that that value in the cycle sits near some  point where the derivative is not merely small but equal to zero,  and that point ends up being close enough to get sucked into the cycle. This fact also justifies why with the Mandelbrot set,  where we're only using one seed value z equals zero,  it's still enough to get us a very full and interesting picture. If there's a stable cycle to be found, that one seed value is definitely going to find it. I feel like maybe I'm assigning a little too much homework and exercises today,  but if you're into that, yet another pleasing one would be to look back at  derivative expression that we found with our function that arises from Newton's method,  and use this wonderful theorem of Vateau's to show our magical fact about cubic  polynomials, that it suffices to just check this midpoint over the roots. Honestly though, all of those are details that you don't really have to worry about. The upshot is that we can perform a test for whether or not one of these polynomials  has an attracting cycle by looking at just a single point, not all of them. And because of this, we can actually generate a really cool diagram. The way this will work is to fix two roots in place,  let's say putting them at z equals negative one and z equals positive one,  and then we'll move around that third root, which I'll call lambda. Remember, the key feature that we're looking for  is when the point at the center of mass is black. So what I'll do is draw a second diagram on the right,  where each pixel corresponds to one possible choice of lambda. What we're going to do is color that pixel based  on the color of this midpoint of the three roots. If this feels a little bit confusing, that's totally okay. There are kind of a lot of layers at play here. Just remember, each pixel on the right corresponds to a unique polynomial,  as determined by this parameter lambda. In fact, you might call this a parameter space. Sound familiar? Points in this parameter space are colored black if, and only if,  the Newton's method process for the corresponding polynomial produces an attracting cycle. Again, don't worry if that takes a little moment to digest. Now, at first glance, it might not look like there  are any black points at all on this diagram. And this is good news. It means that in most cases Newton's method will not get sucked into cycles like this. But, and I think I've previewed this enough that you know exactly where this is going,  if we zoom in we can find a black region, and that black region  looks exactly like a Mandelbrot set. Yet again, asking a question where we tweak a parameter for one  of these functions yields this iconic cardioid and bubbles shape. The upshot is that this shape is not as specific  to the z squared plus c example as you might think. It seems to relate to something more general and  universal about parameter spaces with processes like this. Still, one pressing question is why we get fractals at all. In the last video, I talked about how the diagrams for Newton's method have this  very peculiar property, where if you draw a small circle around the boundary of a  colored region, that circle must actually include all available colors from the picture. And this is true more generally for any rational map. If you were to assign colors to regions based on which limiting behavior  points fall into, like which limit point or which limit cycle or does it  tend to infinity, then tiny circles that you draw either contain points with  just one of those limiting behaviors, or they contain points with all of them. It's never anything in between. So in the case where there's at least three colors,  this property implies that our boundary could never be smooth,  since along a smooth segment, you can draw a small enough circle that touches  just two colors, not all of them. And empirically, this is what we see. No matter how far you zoom in, these boundaries are always rough. And furthermore, you might notice that as we zoom in,  you can always see all available colors within the frame. This doesn't explain rough boundaries in the context where there's only two limiting  behaviors, but still, it's a loose end that I left in that video worth tying up,  and it's a nice excuse to bring in two important bits of terminology,  Julia sets and Fatou sets. If a point eventually falls into some stable, predictable pattern,  we say that it's part of the Fatou set of our iterated function. And for all the maps that we've seen, this includes almost everything. The Julia set is everything else, which in the pictures we've  seen would be the rough boundaries between the colored regions. What happens as you transition from one stable attractor to another? For example, the Julia set will include all of  the repelling cycles and the repelling fixed points. A typical point from the Julia set though, will not be a cycle. It'll bounce around forever with no clear pattern. Now, if you look at a point in the Fatou set, and you draw a small enough disc around it,  as you follow the process, that small disc will eventually shrink as  you fall into whatever the relevant stable behavior is. Unless you're going to infinity, but you could kind of think of that as  the disc shrinking around infinity, but maybe that just confuses matters. By contrast, if you draw a small disc around a point on the Julia set,  it tends to expand over time as the points from within that circle go off and kind of do  their own things. In other words, points of the Julia set tend to behave chaotically. Their nearby neighbors, even very nearby, will  eventually fall into qualitatively different behaviors. But it's not merely that this disc expands. A pretty surprising result, key to the multicolor property mentioned before,  is that if you let this process play out, that little disc eventually expands so  much that it hits every single point on the complex plane, with at most two exceptions. This is known as the stuff-goes-everywhere principle of Julia sets. Okay, it's not actually called that. In the source I was reading from, it's mentioned as  a corollary to something known as Montel's theorem. But it should be called that. In some sense, what this is telling us is that the points of the Julia set  are not merely chaotic, they're kind of as chaotic as they possibly can be. Here, let me show you a little simulation using the Newton's map,  with a cluster of a few thousand points, all starting from within a tiny distance,  one one-millionth, from a point on the Julia set. Of course, the stuff-goes-everywhere principle is about the uncountably  infinitely many points that would lie within that distance,  and that they eventually expand out to hit everything on the plane,  except possibly two points. But this little cluster should still give the general idea. A small, finite sample from that tiny disk gets  sprayed all over the place in seemingly all directions. What this means for our purposes is that if there's some attractive behavior of our map,  something like an attracting fixed point or an attracting cycle,  you can be guaranteed that the values from that tiny disk around the point on the  Julia set, no matter how tiny it was, will eventually fall into that attracting behavior. If we have a case with three or more attracting behaviors,  this gives us some explanation for why the Julia set is not smooth,  why it has to be complicated. Even still, this might not be entirely satisfying because it kicks  the can one more step down the road, raising the question of why  this stuff-goes-everywhere principle is true in the first place. Like I mentioned, it comes from something called Montel's theorem,  and I'm choosing not to go into the details there, because honestly, it's a lot to cover. The proof I could find ends up leaning on something known as the J function,  which is a whole intricate story in its own right. I will of course leave links and resources in the  description for any of you who are hungry to learn more. And if you know of a simpler way to see why this principle is true,  I'm definitely all ears. I should also say as a brief side note that even though the pictures we've seen  so far have a Julia set which has an area of zero,  it's kind of the boundary between these regions,  there are examples where the Julia set is the entire plane. Everything behaves chaotically, which is kind of wild. The main takeaway for this particular section  is the link between the chaos and the fractal. At first it seems like these are merely analogous to each other, you know, Newton's method turns out to be a kind of messy process for some seed values,  and this messiness is visible one way by following the trajectory of a particular point,  and another way by the complexity of our diagrams,  but those feel like qualitatively different kinds of messiness. Maybe it makes for a nice metaphor, but nothing more. However, what's neat here is that when you quantify just how chaotic  some of the points are, well, that quantification leads us to an actual  explanation for the rough fractal shape via this boundary property. Quite often you see chaos and fractals sort of married together in math,  and to me at least it's satisfying whenever that marriage comes with a  logical link to it, rather than as two phenomena that just happen to coincide.

================================================================================
VIDEO ID: -RdOwhmqP5s
TITLE: Newtonâ€™s fractal (which Newton knew nothing about)
URL: https://www.youtube.com/watch?v=-RdOwhmqP5s
PUBLISHED: 2021-10-12T18:57:07Z
STATUS: SUCCESS
================================================================================
You've seen the title, so you know this is leading to a certain fractal. And actually it's an infinite family of fractals. And yeah, it'll be one of those mind-bogglingly intricate  shapes that has infinite detail no matter how far you zoom in. But this is not really a video about generating some pretty picture for us to gawk at. Well, okay, maybe that's part of it, but the real story here has a much  more pragmatic starting point than the story behind a lot of other fractals. And more than that, the final images that we get to will become a lot more  meaningful if we make an effort to understand why, given what they represent,  they kind of have to look as complicated as they do,  and what this complexity reflects about an algorithm that is used all over  the place in engineering. The starting point here will be to assume that you have some kind of polynomial,  and that you want to know when it equals zero. For the one graphed here, you can visually see there's three different places  where it crosses the x-axis, and you can kind of eyeball what those values might be. We'd call those the roots of the polynomial. But how do you actually compute them exactly? Now this is the kind of question where if you're already bought into math,  maybe it's interesting enough in its own right to move forward. But if you just pull someone on the street aside and ask them this,  I mean, they're already falling asleep, because who cares? But the thing is, this kind of question comes up all the time in engineering,  where I'm personally most familiar with equations like this popping up is in the  setting of computer graphics, where polynomials are just littered all over the place. So it's not uncommon that when you're figuring out how a given pixel should be colored,  that somehow involves solving an equation that uses these polynomials. Here let me give you one fun example. When a computer renders text on the screen, those  fonts are typically not defined using pixel values. They're defined as a bunch of polynomial curves,  what are known in the business as Bezier curves. And any of you who've messed around with vector graphics,  maybe in some design software, would be well familiar with these kinds of curves. But to actually display one of them on the screen,  you need a way to tell each one of the pixels of your screen whether it  should be colored in or not. These curves can be displayed either with some kind of stroke width,  or if they enclose a region, some kind of fill for that region. But if you step back and you really think about it,  it's an interesting puzzle to figure out how each one of the pixels  knows whether it should be colored in or not, just based on the pure mathematical curve. I mean, take the case of stroke width. This comes down to understanding how far away a given pixel is from this pure  mathematical curve, which itself is some platonic ideal, it has zero width. You would think of it as a parametric curve that has some parameter t. Now one thing that you could do to figure out this distance  is to compute the distance between your pixel and a bunch of sample points on that curve,  and then figure out the smallest. But that's both inefficient and imprecise. Better is to get a little mathematical and acknowledge that this distance to the  curve at all the possible points is itself some smooth function of the parameter. And as it happens, the square of that distance will itself be a polynomial,  which makes it pretty nice to deal with. And if this were meant to be a full lesson on rendering vector graphics,  we could expand all that out and embrace the mess. But right now, the only salient point that I want to highlight is that in principle,  this function whose minimum you want to know is some polynomial. Finding this minimum, and hence determining how close the pixel is to the curve  and whether it should get filled in, is now just a classic calculus problem. What you do is figure out the slope of this function graph,  which is to say its derivative, again some polynomial, and you ask,  when does that equal zero? So, to actually carry out this seemingly simple task of just displaying a curve,  wouldn't it be nice if you had a systematic and general way to  figure out when a given polynomial equals zero? Of course, we could draw 100 other examples from 100 other disciplines,  I just want you to keep in mind that as we seek the roots of polynomials,  even though we always display it in a way that's cleanly abstracted away from  the messiness of any real-world problem, the task is hardly just an academic one. But again, ask yourself, how do you actually compute one of those roots? If whatever problem you're working on leads you to a quadratic function,  then happy days, you can use the quadratic formula that we all know and love. And as a fun side note, by the way, again relevant to root finding in computer graphics,  I once had a Pixar engineer give me the estimate that considering how many lights were  used in some of the scenes for the movie Coco,  and given the nature of some of these per-pixel calculations when polynomially defined  things like spheres are involved, the quadratic formula was easily used multiple  trillions of times in the production of that film. Now, when your problem leads you to a higher order polynomial,  things start to get trickier. For cubic polynomials, there is also a formula,  which Mathologer has done a wonderful video on, and there's even a quartic formula,  something that solves degree 4 polynomials, although honestly that one is  such a god-awful nightmare of a formula that essentially no one actually  uses it in practice. But after that, and I find this one of the most fascinating results in all of math,  you cannot have an analogous formula to solve polynomials that have a degree 5 or more. More specifically, for a pretty extensive set of standard functions,  you can prove that there is no possible way that you can combine those functions  together that allows you to plug in the coefficients of a quintic polynomial and  always get out a root. This is known as the unsolvability of the quintic, which is a whole other can of worms,  we can hopefully get into it some other time, but in practice it kind of doesn't matter,  because we have algorithms to approximate solutions to these kinds of  equations with whatever level of precision you want. A common one, and the main topic for you and me today, is Newton's method. And yes, this is what will lead us to the fractals,  but I want you to pay attention to just how innocent and benign the whole  procedure seems at first. The algorithm begins with a random guess, let's call it x0. Almost certainly, the output of your polynomial at x0 is not 0,  so you haven't found a solution, it's some other value visible as the height of this  graph at that point. So to improve the guess, the idea is to ask, when does a  linear approximation to the function around that value equal 0? In other words, if you were to draw a tangent line to the graph at this point,  when does that tangent line cross the x-axis? Now, assuming this tangent line is a decent approximation of the  function in the loose vicinity of some true root,  the place where this approximation equals 0 should take you closer to that true root. As long as you're able to take a derivative of this function,  and with polynomials you'll always be able to do that,  you can concretely compute the slope of this line. So here's where the active viewers among you might want to pause and ask,  how do you figure out the difference between the current guess and the improved guess? What is the size of this step? One way to think of it is to consider the fact that the slope of this tangent line,  its rise over run, looks like the height of this graph divided by the length of that step. But on the other hand, of course, the slope of the tangent  line is the derivative of the polynomial at that point. If we kind of rearrange this equation here, this gives you  a super concrete way that you can compute that step size. So the next guess, which we might call x1, is the previous guess,  adjusted by this step size. And after that, you can just repeat the process. You compute the value of this function, and the slope, at this new guess,  which gives you a new linear approximation, and then you make the next guess,  x2, wherever that tangent line crosses the x-axis. And then apply the same calculation to x2, and this gives you x3,  and before too long you find yourself extremely close to a true root,  pretty much as close as you could ever want to be. It's always worth gut checking that a formula actually makes sense,  and in this case, hopefully it does. If p of x is large, meaning the graph is really high,  you need to take a bigger step to get down to a root. But if p' of x is also large, meaning the graph is quite steep,  you should maybe ease off on just how big you make that step. Now as the name suggests, this was a method that Newton used to solve polynomial  expressions, but he sort of made it look a lot more complicated than it needed to be,  and a fellow named Joseph Rafson published a much simpler version,  more like what you and I are looking at now, so you also often hear this algorithm called  the Newton-Rafson method. These days it's a common topic in calculus classes. One nice little exercise to try to get a feel for it, by the way,  is to try using this method to approximate square roots by hand. But what most calculus students don't see, which is unfortunate,  is just how deep things can get when you let yourself play around with  this seemingly simple procedure and start kind of picking at some of its scabs. You see, while Newton's method works great if you start near a root,  where it converges really quickly, if your initial guess is far from a root,  it can have a couple foibles. For example, let's take the function we were just looking at,  but shift it upward, and play the same game with the same initial guess. Notice, how the sequence of new guesses we're getting kind of bounces  around the local minimum of this function sitting above the x-axis. This should kind of make sense, I mean, a linear approximation of the function  around these values all the way to the right is pretty much entirely unrelated  to the nature of the function around the one true root that it has off to the left,  so they're sort of giving you no useful information about that true root. It's only when this process just happens to throw the new guess  off far enough to the left, by chance, that the sequence of new  guesses does anything productive and actually approaches that true root. Where things get especially interesting is if  we ask about finding roots in the complex plane. Even if a polynomial like the one shown here has only a single real number root,  you'll always be able to factor this polynomial into five terms like  this if you allow these roots to potentially be complex numbers. This is the famous fundamental theorem of algebra. Now in the happy-go-lucky land of functions with real number inputs and real number  outputs, where you can picture the association between inputs and outputs as a graph,  Newton's method has this really nice visual meaning with tangent lines and intersecting  the x-axis. But if you want to allow these inputs to be any complex number,  which means our corresponding outputs might also be any complex number,  you can't think about tangent lines and graphs anymore. But the formula doesn't really care how you visualize it. You can still play the same game, starting with a random guess,  and evaluating the polynomial at this point, as well as its derivative,  then using this update rule to generate a new guess,  and hopefully that new guess is closer to the true root. But I do want to be clear, even if we can't visualize these steps with a tangent line,  it really is the same logic. We're figuring out where a linear approximation of the function around your guess would  equal zero, and then you use that zero of the linear approximation as your next guess. It's not like we're blindly applying the rule to  a new context with no reason to expect it to work. And indeed, with at least the one I'm showing here after a few iterations,  you can see that we land on a value whose corresponding output is essentially zero. Now here's the fun part. Let's apply this idea to many different possible initial guesses. For reference, I'll put up the five true roots of  this particular polynomial in the complex plane. With each iteration, each one of our little dots takes some step based on Newton's method. Most of the dots will quickly converge to one of the five true roots,  but there are some noticeable stragglers which seem to spend a while bouncing around. In particular, notice how the ones that are trapped on the positive real number line,  well, they look a little bit lost. And this is exactly what we already saw before for this same  polynomial when we were looking at the real number case with its graph. Now what I'm going to do is color each one of these dots based on  which of those five roots it ended up closest to,  and then we'll kind of roll back the clock so that every dot goes back  to where it started. Now as I've done it here, this isn't quite enough resolution to get the full story,  so let me show you what it would look like if we started with an even finer grid  of initial guesses and played the same game, applying Newton's method a whole  bunch of times, letting each root march forward,  coloring each dot based on what root it lands on,  then rolling back the clock to see where it originally came from. But even this isn't really a high enough resolution to appreciate the pattern. If we did this process for every single pixel on the plane, here's what you would get. And at this level of detail the color scheme is a little jarring to my eye at least,  so let me calm it down a little. Really whatever resolution I try to use to show this to you here could never possibly  be enough, because the finer details of the shape we get go on with endless complexity. But take a moment to think about what this is actually saying. It means that there are regions in the complex plane where if you slightly adjust that  seed value, you know, you just kind of bump it to the side by 1,1 millionth or 1,1  trillionth, it can completely change which of the five true roots it ends up landing on. We saw some foreshadowing of this kind of chaos with the real graph and the problematic  guess shown earlier, but picturing all of this in the complex plane really shines a  light on just how unpredictable this kind of root finding algorithm can be,  and how there are whole swaths of initial values where this sort of unpredictability  will take place. Now if I grab one of these roots and change it around,  meaning that we're using a different polynomial for the process,  you can see how the resulting fractal pattern changes. And notice for example how the regions around a given root always have the same color,  since those are the points that are close enough to the root where this linear  approximation scheme works as a way of finding that root with no problem. All of the chaos seems to be happening at the boundaries between the regions. Remember that. And it seems like no matter where I place these roots,  those fractal boundaries are always there. It clearly wasn't just some one-off for the polynomial we happened to start with,  this seems to be a general fact for any given polynomial. Another facet we can tweak here just to better illustrate  what's going on is how many steps of Newton's method we're using. For example, if I had the computer just take zero steps,  meaning it just colors each point of the plane based on whatever root it's already  closest to, this is what we'd get. And this kind of diagram actually has a special name, it's called a Voronoi Diagram. And if we let each point of the plane take a single step of Newton's method,  and then color it based on what root that single step result is closest to,  here's what we would get. Similarly, if we allow for two steps, we get a slightly more intricate pattern,  and so on and so on, where the more steps you allow,  the more intricate an image you get, bringing us closer to the original fractal. And this is important, keep in mind that the true shape we're studying here is not any  one of these, it's the limit as we allow for an arbitrarily large number of iterations. At this point, there are so many questions we might ask. Maybe you want to try this out with some other polynomials, see how general it is,  or maybe you want to dig deeper into what dynamics are exactly possible with these  iterated points, or see if there's connections with some other pieces of math that have a  similar theme. But I think the most pertinent question should be something like,  what the **** is going on here? I mean, all we're doing here is repeatedly solving linear approximations. Why would that produce something that's so endlessly complicated? It almost feels like the underlying rule here just shouldn't  carry enough information to actually produce an image like this. And before seeing this, don't you think a reasonable initial guess might have  been that each seed value simply tends towards whichever root it's closest to? And in that case, you know, if you colored each point based on the root  it lands on and move it back to the original position,  the final image would look like one of these Voronoi diagrams with  straight-line boundaries. And since I referenced earlier the unsolvability of the quintic,  maybe you would wonder if the complexity here has anything to do with that. That would be cool, but they're essentially unrelated ideas. In fact, using only degree-5 polynomials so far might have been a little misleading. Watch what happens if we play the same game, but with a cubic polynomial,  with three roots somewhere in the complex plane. Notice how, again, while most points nestle into a root,  some of them are kind of flying all over the place more chaotically. In fact, those ones are the most noticeable ones in an animation like this,  with the ones going towards the roots just quietly nestled in in their ending points. And again, if we stopped this at some number of iterations and we colored all the  points based on what root they're closest to and roll back the clock,  the relevant picture for all possible starting points forms this fractal pattern with  infinite detail. However, quadratic polynomials with only two roots are different. In that case, each seed value does simply tend towards whichever root it's closest to,  the way you might expect. There is a little bit of meandering behavior from all the points that are an  equal distance from each root, it's kind of like they're not able to decide  which one to go to, but that's just a single line of points,  and when we play the game of coloring, the diagram we end up with is decidedly  more boring. So something new seems to happen when you jump from 2 to 3,  and the question is what, exactly? And if you had asked me a month ago, I probably would have shrugged and just said,  you know, math is what it is, sometimes the answers look simple, sometimes not,  it's not always clear what it would mean to ask why in a setting like this,  but I would have been wrong, there actually is a reason that we can give  for why this image has to look as complicated as it does. You see, there's a very peculiar property that we can prove this diagram must have. Focus your attention on just one of the colored regions,  say this blue one, in other words, the set of all points that  eventually tend towards just one particular root of the polynomial. Now consider the boundary of that region, which for the  example shown on screen has this kind of nice threefold symmetry. What's surprising is that if you look at any other color and consider its boundary,  you get precisely the same set. Now when I say the word boundary, you probably have an intuitive sense of what it means,  but mathematicians have a pretty clever way to formalize it,  and this makes it easier to reason about in the context of more wild sets like  our fractal. We say that a point is on the boundary of a set if when you draw  a small circle centered at that point, no matter how small,  it will always contain points that are both inside that set and outside. So if you have a point that's on the interior,  a small enough circle would eventually only contain points inside the set,  and for a point on the exterior, a small enough circle contains no points  of the set at all. But when it's on the boundary, what it means to be on the  boundary is that your tiny tiny circles will always contain both. So looking back at our property, one way to read it is to say that if you draw a circle,  no matter how small that circle, it either contains all of the colors,  which happens when this shared boundary of the colors is inside that circle,  or it contains just one color, and this happens when it's in the interior of one of  the regions. In particular, what this implies is you should never be able to find a  circle that contains just two of the colors, since that would require that  you have points on the boundary between two regions, but not all of them. And before explaining where this fact actually comes from,  it's fun to try just wrapping your mind around it a little bit. You could imagine presenting this to someone as a kind of art puzzle,  completely out of context, never mentioning Newton's method or anything like that,  where you say that the challenge is to construct a picture with at least three colors,  maybe we say red, green, and blue, so that the boundary of one color is the boundary  of all of them. So if you started with something simple like this,  that clearly doesn't work because we have this whole line of points that are on the  boundary of green and red, but not touching any blue,  and likewise you have these other lines of disallowed points. So to correct that, you might go and add some blue blobs along the boundary,  and then likewise add some green blobs between the red and blue,  and some red blobs between the green and blue, but of course,  now the boundary of those blobs are a problem, for example, touching just blue and red,  but no green. So maybe you go and try to add even smaller blobs,  with the relevant third color around those smaller boundaries to help try to correct. And likewise you have to do this for every one of the blobs that you initially added. But then all the boundaries of those tiny blobs are problems of their own,  and you would have to somehow keep doing this process forever. And if you look at Newton's fractal itself, this sort of blobs  on blobs on blobs pattern seems to be exactly what it's doing. The main thing I want you to notice is how this property implies you could  never have a boundary which is smooth, or even partially smooth on some small segment,  since any smooth segment would only be touching two colors. Instead, the boundary has to consist entirely of sharp corners, so to speak. So if you believe the property, it explains why the  boundary remains rough no matter how far you zoom in. And for those of you who are familiar with the concept of fractal dimension,  you can measure the dimension of the particular boundary I'm showing you right now to be  around 1.44. Considering what our colors actually represent,  remember this isn't just a picture for pictures' sake,  think about what the property is really telling us. It says that if you're near a sensitive point where some of the seed values go  to one root but other seed values nearby would go to another root,  then in fact every possible root has to be accessible from within that small neighborhood. For any tiny little circle that you draw, either all of the points in that  circle tend to just one root, or they tend to all of the roots,  but there's never going to be anything in between, just tending to a subset of the roots. For a little intuition, I found it enlightening to simply watch  a cluster like the one I'm showing on screen undergo this process. It starts off mostly sticking together, but at one iteration they all kind of explode  outward, and after that it feels a lot more reasonable that any root is up for grabs. And keep in mind I'm just showing you finitely many points,  but in principle you would want to think about what happens  to all uncountably infinitely many points inside some small disk. This property also kind of explains why it's okay for things to look  normal in the case of quadratic polynomials, with just two roots,  because there a smooth boundary is fine, there's only two colors to touch anyway. To be clear, it doesn't guarantee that the quadratic case would have a smooth boundary,  it is perfectly possible to have a fractal boundary between two colors,  it just looks like our Newton's method diagram is not doing anything more  complicated than it needs to under the constraint of this strange boundary condition. But of course all of this simply raises the question of why this bizarre boundary  property would have to be true in the first place, where does it even come from? For that I'd like to tell you about a field of math which studies this kind of question,  it's called holomorphic dynamics. And I think we've covered enough ground today, and there's certainly enough left to tell,  so it makes sense to pull that out as a separate video. To close things off here, there is something sort of funny to me about  the fact that we call this Newton's fractal, despite the fact that  Newton had no clue about any of this, and could never have possibly  played with these images the way you and I can with modern technology. And it happens a lot through math that people's names get  attached to things well beyond what they could have dreamed of. Hamiltonians are central to quantum mechanics,  despite Hamilton knowing nothing about quantum mechanics. Fourier himself never once computed a fast Fourier transform, the list goes on. But this overextension of nomenclature carries with it what I think is an inspiring point. It reflects how even the simple ideas, ones that could be discovered centuries ago,  often hold within them some new angle or a new domain of relevance that  can sit waiting to be discovered hundreds of years later. It's not just that Newton had no idea about Newton's fractal. There are probably many other facts about Newton's method,  or about all sorts of math that may seem like old news,  that come from questions that no one has thought to ask yet. Questions that are just sitting there, waiting for someone, like you, to ask them. For example, if you were to ask about whether this process we've been talking  about today ever gets trapped in a cycle, it leads you to a surprising connection  with the Mandelbrot set, and we'll talk a bit about that in the next part. At the time that I'm posting this, that second part  by the way is available as an early release to patrons. I always like to give new content a little bit  of time there to gather feedback and catch errors. The finalized version should be out shortly. On the topic of patrons, I do just want to say a  quick thanks to everyone whose name is on the screen. I know that in recent history new videos have been a little slow coming. Part of this has to do with other projects that have been in the works. Things I'm proud of, by the way, things like the Summer of Math Exposition,  which was a surprising amount of work, to be honest, but so worth it given the outcome. I will be talking all about that and announcing winners very shortly, so stay tuned. I just want you to know that the plan for the foreseeable future is definitely to shift  gears more wholeheartedly back to making new videos,  and more than anything I want to say thanks for your continued support,  even during times of trying a few new things. It means a lot to me, it's what keeps the channel going,  and I'll do my best to make the new lessons in the pipeline live up to your vote  of confidence there.

================================================================================
VIDEO ID: ojjzXyQCzso
TITLE: Make math videos! | Summer of Math Exposition announcement
URL: https://www.youtube.com/watch?v=ojjzXyQCzso
PUBLISHED: 2021-07-16T18:39:08Z
STATUS: SUCCESS
================================================================================
I want to tell you about a contest that I'm running with a friend of mine,  James Schloss, who some of you might recognize from the YouTube  channel LeosOS and his Twitch stream and things like that. Also, now there's a 3b1b podcast, but more on that in just a moment. Basically, we want there to be more math explanation online,  and we want to encourage more people to get started actually doing it. We're calling it the Summer of Math Exposition,  where essentially we're just inviting anyone who wants to to submit some kind  of math explainer, whether that's a video or a blog post or an interactive  game or whatever it is that explains math online in some way,  to the link that's on screen now by August 22nd. And then once we... Yes, I see you. Would you like to sniff at the microphone? Oh yes, that's very sweet. Very sweet. You're a very affectionate creature. All right, where was I? Anyway, after August 22nd, we're going to have a selection process to choose  some winners from among them, and then I'll feature them in a 3b1b video. And then for the rest, I'll probably also put together a playlist of all of the  videos and a list of links on the website somewhere to all the project submissions. And then I was also thinking maybe I would send something to the winners,  like creating some custom gold plushie pie creatures or something like that. But the main prize is to have your work featured  and hopefully get it out to a few more people. The reason I'm interested in doing this is I think there's a lot of people out there who  would be really good at doing this, would have some excellent explanation that would  genuinely help a lot of people or show a topic that's not really covered very well  elsewhere. And who might even be thinking about doing it. You know, there's that back of your mind spot that says maybe one  day I'll try my hand at a video or just write this up as a blog post. But you just never really got around to it. You know, life's busy. You're not sure where to start. It seems like there's a lot of other things out there. And my hope is that by dangling the tiniest carrot that I can provide,  just mentioning good work when it exists, then maybe that gets a couple more  people over this hump who might otherwise not have made something and then actually  make it. So one of the very few constraints on entries for this  particular contest is that it has to be something new. It can't be a thing that you made a while ago and you're just submitting  a link to it now, but something that you make between now and August 22nd. And the real spirit of this all is to encourage people  who have never tried it before to get started in it somehow. The other constraint is that it does have to be about math,  but math in the broadest possible sense of the term. So that could include physics or computer science,  as long as it's got some mathy components to it. So if you're doing physics and there's formulas that are relevant,  don't shy away from those formulas. Or if you're doing some computer science and there's some, you know,  algorithmic complexity or something mathematical to it,  try to lean into that a little bit more. Other than that, the topic matter is completely up to you. So maybe you have some topics that you've seen or that you've learned about,  but what you really feel aren't covered well online anywhere. And it would really be adding something new to the space. Maybe you're a physics buff who is interested in the philosophical side of things,  and you've learned about Conway's freewheel theorem,  and you want to talk about it and whether that's an appropriate name,  whether it's actually philosophically interesting or not,  or just share with people what it is. Or maybe you're someone who's into information theory and things like that,  and you've learned about how Kolmogorov complexity can be used to describe  some things about the distributions of primes,  and you think that's actually an interesting angle for how to introduce  Kolmogorov complexity in the first place. Or anything like this where it's something kind of new to the space,  if that's you, you should definitely consider submitting. But it doesn't have to be a topic that no one has  ever covered or that's severely under covered online. Even if it's something that's very standard, and especially if it's something  that a lot of students have to reach at some point,  coming up with a better way to explain it, kind of thinking about what's  the state-of-the-art explanation on any particular thing,  that could also add a lot to the space. Say for example you've taught students about partial fraction decomposition and tutoring  or teaching or something like that, and you feel like you've come across a way of  explaining it that makes it a little bit more memorable, you should definitely submit. Or maybe you have some really pretty way to visualize certain trig  identities that students run into that keeps them from very rote and  instead sheds a light on how beautiful math can be and all that kind of thing. If that's you and you feel passionate about it, you should definitely submit that. One set of people who I'm particularly interested in for this competition  are the teachers and the lecturers, and basically anyone with a lot of  boots-to-the-ground experience seeing people learn and seeing what actually works. Because I think there's a lot of outstanding explanations out there that stay  largely confined to the classroom or otherwise stay offline,  whereas if just a little bit of effort was put into producing it or sharing it  online in some way, those lessons might actually reach and benefit one to two orders  of magnitude more people. And I get it, teachers are absurdly busy, they don't have time for extra  things on the side, and it's kind of hard to know where to get started. So maybe one potential partnership here would be the teachers who have really good  instincts for what works in education, and then a student who maybe has a lot of energy  or desire to get started on YouTube or otherwise just has more free time on their hands,  and pairing something together like that might actually make for a good partnership. In either case, whatever category you fall into,  I do know there's a lot of people who do want to get started with this,  because they write to me a lot, and one of the most common sentiments out there is,  well I don't know where to get started, I want to make a video but I don't really have  any experience with video making, things like that. And I have a couple things to say for who feels like they're in that boat. In a kind of loose conjunction with this contest,  I decided to start a podcast where for the first many conversations I'll  be interviewing people who have some kind of experience in the space of  putting out explanations. So that could be other YouTubers, but it could also include mathematicians  who are really engaged with outreach, or the founder of Khan Academy,  like this, and essentially have conversations which act to either inspire  or otherwise inform anyone who might be getting started with this. After doing several of these interviews, one of the most useful pieces  of information that I think comes out from them is just how ramshackle  and unprofessional the setup for a lot of people is in the very beginning. And as a result, it should come as no surprise that one of the most common  pieces of advice, one of the most universal answers to the question of what  advice would you give to someone getting started with this is to just start. The things that differentiate the people who actually put stuff out there versus  the ones who don't is not a matter of having a lot more experience with it beforehand. It's a matter of having a kind of generative spirit that just wants to make stuff. Because my, I say persona, but this is, you know,  me, this is genuinely me is give it a go. You're probably going to fail, but it's worth a try. I get a lot of people kind of saying, oh, like you make YouTube videos. I've always wanted to make YouTube videos. And I'm like, great, just do it. And they're like, no, no, but I need to buy a nice camera and I need to get a good set. And I'm like, no, no, no, like, just do it. There's always this temptation. Wait, am I ready yet? Am I ready yet? And I just say, Sal, press record and start, see what happens. If I take the example, which I know best, which is my own,  there are so many really embarrassing things about the early videos on this channel or  my process in creating them. I mean, the sound quality was pretty terrible for a long time is that's one big thing. Uh, I edited in iMovie for way longer than I care to admit. Also, despite being now a like professional YouTuber,  when it comes to cameras and actually filming things like this,  I really have no idea what I'm doing. Like right now, I'm just using a phone, which I guess is fine. I find the process of being alone in a room and  just talking to a camera incredibly awkward. This is actually my second time recording this whole video because the first time  I thought I had a phone, I thought I would be really clever and have some notes to  like guide what I wanted to say and I'd put them on the monitor next to the camera. But what the result was is that I would just kind of have my eyes  darting back and forth between the two without me consciously realizing it. It was just this reminder that I really don't know what I'm doing. But this isn't a self-effacing thing. The point here is that if you find yourself with a potentially good explainer that  you want to make, but you're a little self-conscious about how to start,  or you're worried that you're going to make a mistake, just don't worry about it.  Just dive right in. So many of us have no idea what we're doing when we begin. All that said, sometimes this just do it advice is a  little bit frustrating because I mean it's not actionable. You say okay I'm gonna start, but then upon starting it tells you nothing. So in the spirit of some more concrete advice,  I do have a couple things that I might want to pass along that are specific  to the case of math explainers. The first one, and I do actually find this quite important,  is when you're putting together the explanation, whatever form, whatever medium,  whatever genre you choose, try to be aware of the layers of abstraction that are  relevant to your topic. So like if you're teaching a young child about fractions and  you're talking about two-thirds plus one-fifth,  there's two different layers of abstraction that that expression lives in. There's one where you have a very concrete example of two-thirds of something,  two-thirds of a cake, and then one-fifth of a cake,  and trying to get a sense of what that means. And then there's the symbols, and a big part of the lesson at play here  is understanding how the symbols relate to the actual case and why the  rules that we apply to the symbols make sense in light of the concrete case. And also why we opt to do the more abstract thing because it takes much less thinking  than actually trying to reason about you know two-thirds of a cake plus one-fifth of a  cake. And this happens at all levels. If you're teaching a calculus class and you're talking about optimizing functions,  you know there's the idea of a function as a very abstract thing that could be  any particular function or any differentiable function or what have you. And then there's lots of specific examples or maybe specific cases where they come up  like a function defining the profit of a company and that's the thing you want to  optimize. I made a whole video about group theory where in the middle I went on  for a while about the difference between thinking of group actions as  these abstract entities versus as something concrete like asymmetry  and why there exists the two and what the benefits and trade-offs are. But my point in this first piece of advice is not merely to address the layers  of abstraction, you don't even have to, but if you're clear in your own head try  very hard to structure your explanation to go from the concrete to the abstract. I think almost always when you understand something  the natural inclination is to go the other way around. I find myself doing this in pretty much any first draft of a script that I have. It seems like all the textbook authors that I ever read tend to do this. You start with the abstract idea, you put the examples later,  but I really do think that in the case of learning first trying to populate the  learner's mind with a bunch of examples of things that have a similar pattern  between them and letting their brain do the abstraction,  see that similar pattern between things such that when you bring in that higher  layer you start defining you know an abstract vector space or you're doing some  symbolic manipulations with particular rules. That once that happens you're articulating something in the brain of the learner that  was already sitting there in the first place, it wasn't just handed to them in a vacuum. Otherwise it's a little bit like trying to build a building from the top floor down. So that's one and that's very specific to math. As a more generic idea, piece of advice number two would be keep in the very  forefront of your mind the fact that content is king,  that the thing that you're explaining, the choice of the topic or how you're  explaining it, determines the majority of the value and the quality of the  thing that you make. All the things about production quality or you know how fancy the animations are  or the lighting or whatever it is, all of that is secondary to making sure you've  chosen an actually good topic and it's something that people would want to consume. They haven't seen it elsewhere, it's offering something fresh. Now that's so easy to nod along with and say like yes yes of course content is king,  but the thing is you end up spending about one percent of your time if  that choosing what you're going to explain and how you're going to explain  it and then like 99% of the time just carrying it out in some way and as  a result it can be easy to lose sight of that important part. So my encouragement to you would be spend more time  than you would otherwise tend to on choosing that topic. So maybe workshop a couple different things by doing sample lessons with  people or try to write out a list of all the different things that you  could and ask are they actually fresh, are they actually adding something to the space,  is there a reason someone would want to consume this. Spending that extra little bit of time on the thing that  determines the majority of the value is almost certainly worth it. And the third piece of advice which maybe plays into this a little bit is when you're  beginning if you're starting something fresh and there's no presence online at this  point, try to choose something much more esoteric and specific than you might be inclined  to. I've seen a lot of people who want to get started on YouTube for example and the way  that they try to go about it is to choose a topic that will appeal to the most people. After all they want their video to blow up, they  want a lot of subscribers and things like that. But there's a couple issues with this. First of all it's a much more competitive space if you're going to  try to describe something that a lot of people might be searching for. So if you go in saying I'm going to do a series about quantum mechanics,  well there's a billion others out there and yours is going to have to  stand out for some reason and you don't have a foothold at that point. But another one is that the very specific and niche things build a much more loyal  audience in that beginning because you're offering something which they could not find  anywhere else and sometimes to be the consumer of something very specific is such a  good feeling that you want to pay it back and you find yourself rooting for the creator. So you're more likely to get very good faith feedback, just a warmer community. And also oftentimes we tend to overestimate just how niche things are. Like sometimes something that's so weirdly specific,  some very esoteric bit of engineering actually appeals to hundreds of thousands  or millions of people, especially if you yourself are enthusiastic about it and  people can index on that. So by doing that you find yourself often with a topic that actually does have  a broader appeal but it's not competitive with the things that everyone thinks  will have broader appeal and you potentially get that audience loyalty. When I started this channel I really was thinking of it as a very niche thing,  I did not think it would be a thing that a lot of people would want to watch. I actually specifically wanted to find topics in math that no one would think to search  for, that was kind of the original conception that I wavered from a little bit afterward. The fourth piece of advice is to pick a genre that your piece falls into. So the other day I was giving this talk to a group of people and one  of them wanted to get started making online explainers and they asked  whether it was ethical for someone who's just barely learning a topic,  just starting to learn it, to also make explainers of it online. I mean after all they're more likely to make mistakes,  they don't know the broader context, and there's so many things I like  about that question. It's already demonstrating a kind of care and consideration for factual accuracy and  doing right by the student that more people who are making online explanations should  consider. So that very fact suggested to me that this person probably should be doing it. But one of the things I suggested is to acknowledge  there are different types of explainers out there. There's the type where the narrator is a little bit more distanced,  they're kind of standing on top of a hill and explaining the way that things are,  and to do that you really have to research the topic very deeply. You should probably know 10 times as much about the topic as what you're actually  saying in the content so that you know that you're teeing things up for where it  actually leads or you're being cognizant of whatever nuances there are, things like that. But another genre entirely is the discovery journalism,  where the person who is learning the topic kind of just admits that fact or is  open about the fact that they're just starting with it and taking the viewer  along a journey with them. And many times that's actually a better piece of content,  it's actually better for learning the topic, and it comes with  this inbuilt piece of humility that a lot of online content lacks. But there's lots of other genres like this. There's the worked example where you're explicitly helping people with homework,  there's the try to find an interesting demo and serve mainly to inspire,  and basically just before you get started, decide which one of those you feel like you're  the best fit for, and then when you're looking at other pieces out there,  other explainers and trying to index off of what seems to work, what doesn't,  be aware of which ones are in the lane that you intend to be in and don't necessarily  pattern match off of the ones that aren't. You know, one of the mistakes I think I made with my very first video is I  had this conception that sometimes if you talk faster than is comfortable on  the internet, that sort of works, that's like a satisfying thing to consume. Because there are videos out there that are this fire hose of information,  and something about that scratches a niche and I think people like it,  but what I didn't really appreciate was the fact that math should fall into a completely  different category than that. It is not fun at all to have math come at you at this fire hose rate,  and basically I was just pattern matching off of things that I should not have been  pattern matching off of. As point number five, or I don't actually know where I am at the list at this point,  especially in the case of math, if you're bringing up definitions of things,  try not to let them feel too arbitrary. Try to let them be well motivated. Explain why that's the definition, what else it could have been. Try to make it something that the learner feels like they discovered themselves,  because too often we hand these things down on high as the starting point,  and it's not really clear why or where that came from. So all of that is just on the content side, you know,  what exactly are you explaining independent of the multimedia component of it, you know,  the sound and the video and all that. And like I said, content is king, that definitely determines the majority of quality,  but it does actually matter a little bit beyond that to have at  least a little bit of production quality, I think. And I'll give a really good example. So I was watching this lecture the other day by Tadashi Tokieda on just a really  interesting set of ideas about applying physical intuition to solving math problems.  And he had in there maybe seven or eight outstanding little arguments that each  one of which could have been just a beautiful video in its own right. But the talk was over Zoom, and the intro was really long,  and the sound quality is everything that you assume from Zoom,  and the lighting of his shot was weird, and the talk was really good. And I do think, you know, it's great that it's online and a lot of people will be  consuming it, but it's probably fair to say that if all of that content,  the actual set of ideas, was instead, say, a Numberphile video,  it would reach a hundred times as many people. And more than that, it would be a more pleasant experience for those who are consuming it. And it really doesn't take that much. So I'll just end with a couple pieces of advice on that front. The first one, which again I acknowledge is very hypocritical here,  is sound quality actually matters, especially in an era of Zoom where we are all  inundated with this sort of sub-optimal version of the voices of all the people  in our lives. The learner will appreciate a respite from all that with something that  actually comes from a good microphone that you learned how to use at some point. On the side of visuals, you know, I'm obviously a big believer in the idea that a  well-chosen illustration or an animation can really make a mathematical idea a lot  more clear and be an example of that concretization and kind of going from the lower  layer of abstraction on upward by just showing exactly what it is on screen in some way. Now the way I do things is with programmatic animations. I sort of wrote this custom library called Manum to do that. And last year, actually, a group of people that called themselves the Manum  Community created a fork of it with the hope of making it a lot more user-friendly. And I think they succeeded with that. There's a lot better documentation, it's better tested, just all around friendlier to use. So you can use that tool and thanks to them, it's  actually a lot easier than it used to be. There's some other libraries that I've seen that mention Manum as an inspiration,  you know, one that's written in Julia or one in Haskell. And it doesn't have to be programmatic either. I think where programmatic animations make sense for math is if you're  somehow leveraging loops or conditionals or layers of abstraction. And in the right context, I think it can be a wonderful way to let  the visuals authentically reflect the math that you're describing,  if the code is essentially just that math as it's illustrating things. But it doesn't have to be. And a lot of times people use Manum or other programmatic animations for things that do  not need to be programmatic, that you could have easily done in something like Keynote or  which add flashiness for flashiness's sake that doesn't actually aid with the explanation. I think one really good example of using traditional  animation software is the channel Boerbach Tree. So he really has these friendly handwritten kind of whiteboard lectures,  but uses animation to help those whiteboards come alive. And he uses Adobe Animate for that. And I think it's a really nice way to make this friendly hand-drawn environment  come to life, which is different from kind of the platonic, stark,  this is precisely what the math would draw when you're illustrating a surface or  something like that. Also, I see a lot of people use Manum to manipulate  algebraic expressions and things like that. But if you look at other videos, things like Mathologer,  you know, he's doing a lot of that in PowerPoint. And again, content is king. The first thing is to focus on what are you actually describing and then just showing it,  however, is easiest to show it in that case works totally fine. You don't need anything extremely precise or that  leverages loops and abstraction for the formulas. I recognize a kind of hypocrisy here, but you know,  I have walked myself into a certain corner with the style that I want for the channel. If you do want to go down that hole of programmatic animations, though,  another tool which has popped up recently is something called smoothstep.io,  which I think is a really nice way for people to get started with shaders,  which are an absurdly powerful way to do absurdly beautiful things. And it's written by this guy, Matt Henderson, who has a Twitter  account that everyone should follow because he has some of the  most beautiful math illustrations that I think I've ever seen. So experimenting with software like that is another rabbit hole that you could go down  if, say, you want to use this competition as an excuse to try something new,  something that you've always wanted to get started with,  but never really had the excuse to do. Now, if you have some pieces of advice that you want to pass along to people,  or if you want to just engage with the community in some way to see what other people  are thinking of making or propose your own project ideas, get feedback,  talk about software, anything like that, we did set up a Discord space associated with  the Summer of Math Exposition. There's a link in the description. Just be mindful if you do contribute to that community that you want your comments  to be encouraging to others who are getting started and productive to that goal. And, you know, try to avoid anything that is the opposite of that goal. And again, another source of what will hopefully include  some inspirational or informative things will be the podcast. The first episode is out now. It's with the mathematician Alex Kontorovich, who some of you may recognize  from the video he did with Quanta or the video he did with Veritasium on Pi Day. The episode after that is going to be with Sal Khan. And there's just a really interesting lineup of people here. So I think you'll enjoy it. You can get it wherever you get your podcasts. There's a video version of it, which is going to live on  a second channel that is just my name, Grant Sanderson. And I figure for all future videos that are a little bit like this one,  that's not really animated math, but other stuff,  that's probably the channel that I'll put it on. So keep an eye on that channel if that's something that you're interested in. And I will say this about the podcast, even though the original intent  was something that was very much tied to this competition and the idea  of targeting people interested in getting started,  a lot of the times I would find myself with an interesting guest and I  just have a whole bunch of other things that I want to ask them that have  nothing to do with that. So maybe the better framing here is to say that the podcast is 20% about that goal. And the other 80% is just the usual interview  style podcast vibe where you have interesting guests. And I just want to ask things that I'm genuinely curious to know about them. And then I get to grad school and I'm moving into my office in grad school and I have my,  all my old papers and I just started, you know, for fun leafing through them. I don't know if you ever look back at the stuff you wrote freshman year. And I look at it, I'm like, what the hell was I writing? Oh my God, this is garbage. This is complete. The epsilons and deltas are backwards. You can't have the epsilons and deltas be backwards. And you only took off three points. I would have taken off, you know, nine or something like Ramy was so nice. So if lean was around back then, boy, would it have straightened me out. It's actually very inspiring to me because I feel one of the common pieces  of advice that I'll give to someone if they like want to learn more math.

================================================================================
VIDEO ID: e50Bj7jn9IQ
TITLE: A quick trick for computing eigenvalues | Chapter 15, Essence of linear algebra
URL: https://www.youtube.com/watch?v=e50Bj7jn9IQ
PUBLISHED: 2021-05-07T21:39:22Z
STATUS: SUCCESS
================================================================================
This is a video for anyone who already knows what eigenvalues and eigenvectors are,  and who might enjoy a quick way to compute them in the case of 2x2 matrices. If you're unfamiliar with eigenvalues, go ahead and take a look at this video here,  which is actually meant to introduce them. You can skip ahead if all you want to do is see the trick,  but if possible I'd like you to rediscover it for yourself. So for that, let's lay out a little background. As a quick reminder, if the effect of a linear transformation on a  given vector is to scale that vector by some constant,  we call it an eigenvector of the transformation,  and we call the relevant scaling factor the corresponding eigenvalue,  often denoted with the letter lambda. When you write this as an equation, and you rearrange a little bit,  what you see is that if the number lambda is an eigenvalue of a matrix A,  then the matrix A minus lambda times the identity must send some non-zero vector,  namely the corresponding eigenvector, to the zero vector,  which in turn means that the determinant of this modified matrix must be zero. Okay, that's all a little bit of a mouthful to say, but again,  I'm assuming that all of this is review for any of you watching. So, the usual way to compute eigenvalues, how I used to do it and how I believe  most students are taught to carry it out, is to subtract the unknown value  lambda off the diagonals, and then solve for the determinant is equal to zero. Doing this always involves a few extra steps to expand out and simplify to get a  clean quadratic polynomial, what's known as the characteristic polynomial of the matrix. The eigenvalues are the roots of this polynomial,  so to find them you have to apply the quadratic formula,  which itself typically requires one or two more steps of simplification. Honestly, the process isn't terrible, but at least for two by two matrices,  there is a much more direct way you can get at the answer. And if you want to rediscover this trick, there's only three  relevant facts you need to know, each of which is worth knowing  in its own right and can help you with other problem solving. Number one, the trace of a matrix, which is the sum of these two diagonal entries,  is equal to the sum of the eigenvalues. Or, another way to phrase it, more useful for our purposes,  is that the mean of the two eigenvalues is the same as the mean of these two  diagonal entries. Number two, the determinant of a matrix, our usual ad-bc formula,  is equal to the product of the two eigenvalues. And this should kind of make sense if you understand that eigenvalues describe  how much an operator stretches space in a particular direction,  and that the determinant describes how much an operator scales areas, or volumes,  as a whole. Now before getting to the third fact, notice how you can essentially read  these first two values out of the matrix without really writing much down. Take this matrix here as an example. Straight away, you can know that the mean of the  eigenvalues is the same as the mean of 8 and 6, which is 7. Likewise, most linear algebra students are pretty well practiced at  finding the determinant, which in this case works out to be 48 minus 8. So right away, you know that the product of the two eigenvalues is 40. Now take a moment to see if you can derive what will be our third relevant fact,  which is how you can quickly recover two numbers when you  know their mean and you know their product. Here, let's focus on this example. You know that the two values are evenly spaced around the number 7,  so they look like 7 plus or minus something, let's call that something d for distance. You also know that the product of these two numbers is 40. Now to find d, notice that this product expands really nicely,  it works out as a difference of squares. So from there, you can find d. d squared is 7 squared minus 40, or 9, which means that d itself is 3. In other words, the two values for this very specific example work out to be 4 and 10. But our goal is a quick trick, and you wouldn't want to think through this each time,  so let's wrap up what we just did in a general formula. For any mean m and product p, the distance squared  is always going to be m squared minus p. This gives the third key fact, which is that when two numbers  have a mean m and a product p, you can write those two numbers  as m plus or minus the square root of m squared minus p. This is decently fast to re-derive on the fly if you ever forget it,  and it's essentially just a rephrasing of the difference of squares formula. But even still, it's a fact that's worth memorizing so it's at the tip of your fingers. In fact, my friend Tim from the channel A Capella Science wrote  us a nice quick jingle to make it a little bit more memorable. Let me show you how this works, say for the matrix 3 1 4 1. You start by bringing to mind the formula, maybe stating it all in your head. But when you write it down, you fill in the appropriate values for m and p as you go. So in this example, the mean of the eigenvalues is the same as the mean of 3 and 1,  which is 2, so the thing you start writing is 2 plus or minus  the square root of 2 squared minus. Then the product of the eigenvalues is the determinant,  which in this example is 3 times 1 minus 1 times 4, or negative 1,  so that's the final thing you fill in, which means the eigenvalues are 2 plus  or minus the square root of 5. You might recognize that this is the same matrix I was using at the beginning,  but notice how much more directly we can get at the answer. Here, try another one. This time, the mean of the eigenvalues is the same as the mean of 2 and 8, which is 5. So again, you start writing out the formula, but this time writing 5 in place of m. And then the determinant is 2 times 8 minus 7 times 1, or 9. So in this example, the eigenvalues look like 5 plus or minus the square root of 16,  which simplifies even further as 9 and 1. You see what I mean about how you can basically just start  writing down the eigenvalues while you're staring at the matrix? It's typically just the tiniest bit of simplification at the end. Honestly, I've found myself using this trick a lot when I'm sketching quick  notes related to linear algebra and want to use small matrices as examples. I've been working on a video about matrix exponents,  where eigenvalues pop up a lot, and I realize it's just very handy  if students can read out the eigenvalues from small examples without  losing the main line of thought by getting bogged down in a different calculation. As another fun example, take a look at this set of three different matrices,  which comes up a lot in quantum mechanics. They're known as the Pauli spin matrices. If you know quantum mechanics, you'll know that the eigenvalues  of matrices are highly relevant to the physics that they describe. And if you don't know quantum mechanics, let this just be a little glimpse  of how these computations are actually very relevant to real applications. The mean of the diagonal entries in all three cases is zero. So the mean of the eigenvalues in all of these cases is zero,  which makes our formula look especially simple. What about the products of the eigenvalues, the determinants of these matrices? For the first one, it's 0, minus 1, or negative 1. The second one also looks like 0, minus 1, but it takes  a moment more to see because of the complex numbers. And the final one looks like negative 1, minus 0. So in all cases, the eigenvalues simplify to be plus and minus 1. Although in this case, you really don't need a formula to find two values if  you know that they're evenly spaced around 0 and their product is negative 1. If you're curious, in the context of quantum mechanics,  these matrices describe observations you might make about a particle's spin in the x,  y, or z direction. And the fact that their eigenvalues are plus and minus 1 corresponds with the idea  that the values for the spin that you would observe would be either entirely in one  direction or entirely in another, as opposed to something continuously ranging in between. Maybe you'd wonder how exactly this works, or why you would use 2x2  matrices that have complex numbers to describe spin in three dimensions. Those would be fair questions, just outside the scope of what I want to talk about here. You know, it's funny, I wrote this section because I wanted some case where  you have 2x2 matrices that aren't just toy examples or homework problems,  ones where they actually come up in practice, and quantum mechanics is great for that. The thing is, after I made it, I realized that the whole  example kind of undercuts the point that I'm trying to make. For these specific matrices, when you use the traditional method,  the one with characteristic polynomials, it's essentially just as fast. It might actually be faster. I mean, take a look at the first one. The relevant determinant directly gives you a characteristic polynomial  of lambda squared minus 1, and clearly that has roots of plus and minus 1. Same answer when you do the second matrix, lambda squared minus 1. And as for the last matrix, forget about doing any computations,  traditional or otherwise, it's already a diagonal matrix,  so those diagonal entries are the eigenvalues. However, the example is not totally lost to our cause. Where you will actually feel the speedup is in the more general case,  where you take a linear combination of these three matrices and then try to compute  the eigenvalues. You might write this as a times the first one,  plus b times the second, plus c times the third. In quantum mechanics, this would describe spin observations  in a general direction of a vector with coordinates a, b, c. More specifically, you should assume that this vector is normalized,  meaning a squared plus b squared plus c squared is equal to 1. When you look at this new matrix, it's immediate  to see that the mean of the eigenvalues is still 0. And you might also enjoy pausing for a brief moment to confirm  that the product of those eigenvalues is still negative 1. And then from there, concluding what the eigenvalues must be. And this time, the characteristic polynomial approach would be by  comparison a lot more cumbersome, definitely harder to do in your head. To be clear, using the mean product formula is not fundamentally  different from finding roots of the characteristic polynomial. I mean, it can't be, they're solving the same problem. One way to think about this actually is that the mean  product formula is a nice way to solve quadratics in general. And some viewers of the channel may recognize this. Think about it, when you're trying to find the roots of a quadratic,  given the coefficients, that's another situation where you know the sum of two values,  and you also know their product, but you're trying to recover the original two values. Specifically, if the polynomial is normalized, so that this leading coefficient is 1,  then the mean of the roots will be negative 1 half times this linear coefficient,  which is negative 1 times the sum of those roots. With the example on the screen, that makes the mean 5. And the product of the roots is even easier, it's just the constant term,  no adjustments needed. So from there, you would apply the mean product formula, and that gives you the roots. And on the one hand, you could think of this as a lighter  weight version of the traditional quadratic formula. But the real advantage is not just that it's fewer symbols to memorize,  it's that each one of them carries more meaning with it. I mean, the whole point of this eigenvalue trick is that because you can read  out the mean and product directly from looking at the matrix,  you don't need to go through the intermediate step of setting up the characteristic  polynomial. You can jump straight to writing down the roots without ever  explicitly thinking about what the polynomial looks like. But to do that, we need a version of the quadratic  formula where the terms carry some kind of meaning. I realize this is a very specific trick for a very specific audience,  but it's something I wish I knew in college, so if you happen to know  any students who might benefit from this, consider sharing it with them. The hope is that it's not just one more thing that you memorize,  but that the framing reinforces some other nice facts that are worth knowing,  like how the trace and the determinant are related to eigenvalues. If you want to prove those facts, by the way, take a moment to  expand out the characteristic polynomial for a general matrix,  and then think hard about the meaning of each of these coefficients. Many thanks to Tim for ensuring that this mean product formula  will stay stuck in all of our heads for at least a few months. If you don't know about alcappella science, please do check it out. The molecular shape of you in particular is one of the greatest things on the internet.

================================================================================
VIDEO ID: O85OWBJ2ayo
TITLE: How (and why) to raise e to the power of a matrix | DE6
URL: https://www.youtube.com/watch?v=O85OWBJ2ayo
PUBLISHED: 2021-04-01T15:50:30Z
STATUS: SUCCESS
================================================================================
Let me pull out an old differential equations textbook that I learned from in college, and let's turn to this funny little exercise in here that asks the reader to compute 'E' to the power 'A' 't', where 'A' we're told is going to be a matrix, and the insinuation seems to be that the results will also be a matrix. It then offers several examples for what you might plug in for a. Now, take it out of context, putting a matrix into an exponent like this probably seems like total nonsense, but what it refers to is an extremely beautiful operation, and the reason it shows up in this book is that it's useful! It's used to solve a very important class of differential equations. In turn, given that the universe is often written in the language of differential equations, you see this pop up in physics all the time too, especially in quantum mechanics, where matrix exponents are littered throughout the place. They play a particularly prominent role. This has a lot to do with Schrodinger's equation, which we'll touch on a bit later, and it may also help in understanding your romantic relationships, but again, all in due time. A big part of the reason I want to cover this topic is that there is an extremely nice way to visualize what matrix exponents are actually doing using flow that not a lot of people seem to talk about, but for the bulk of this chapter, let's start by laying out what exactly the operation is, and see if we can get a feel for what kinds of problems it helps us to solve. The first thing you should know is that this is not some bizarre way to multiply the constant 'E' by itself multiple times. You would be right to call that nonsense. The actual definition is related to a certain infinite polynomial for describing real number powers of 'E', what we call its Taylor series. For example, if I took the number 2 and plugged it into this polynomial, then as you add more and more terms, each of which looks like some power of 2 divided by some factorial. The sum approaches a number near 7.389, and this number is precisely 'E' times 'E'. If you increment this input by one, then somewhat miraculously, no matter where you started from, the effect on the output is always to multiply it by another factor of 'E'. For reasons that you're going to see in a bit, mathematicians became interested in plugging all kinds of things into this polynomial, things like complex numbers, and for our purposes today, matrices, even when those objects do not immediately make sense as exponents. What some authors do is give this infinite polynomial the name 'exp' when you plug in more exotic inputs. It's a gentle nod to the connection that this has to exponential functions in the case of real numbers, even though obviously these inputs don't make sense as exponents. However, an equally common convention is to give a much less gentle nod to the connection and just abbreviate the whole thing as 'E' to the power of whatever object you're plugging in, whether that's a complex number or a matrix or all sorts of more exotic objects. So while this equation is a theorem for real numbers, it's a definition for more exotic inputs. Cynically, you could call this a blatant abuse of notation. More charitably, you might view it as an example of the beautiful cycle between discovery and invention in math. In either case, plugging in a matrix even to a polynomial might seem a little strange, so let's be clear on what we mean here. The matrix has to have the same number of rows and columns. That way you can multiply it by itself according to the usual rules of matrix multiplication. This is what we mean by squaring it. Similarly, if you were to take that result and then multiply it by the original matrix again, this is what we mean by cubing the matrix. If you carry on like this, you can take any whole number power of a matrix, it's perfectly sensible. In this context, powers still mean exactly what you would expect, repeated multiplication. Each term in this polynomial is scaled by one divided by some factorial, and with matrices, all that means is that you multiply each component by that number. Likewise, it always makes sense to add together two matrices, this is something you again do term by term. The astute among you might ask how sensible it is to take this out to infinity, which would be a great question, one that I'm largely going to postpone the answer to, but I can show you one pretty fun example here now. Take this 2x2 matrix that has negative pi and pi sitting off its diagonal entries. Let's see what the sum gives. The first term is the identity matrix, this is actually what we mean by definition when we raise a matrix to the zeroth power. Then we add the matrix itself, which gives us the pi off the diagonal terms, and then add half of the matrix squared, and continuing on I'll have the computer keep adding more and more terms, each of which requires taking one more matrix product to get the new power, and then adding it to a running tally. And as it keeps going, it seems to be approaching a stable value, which is around negative one times the identity matrix. In this sense, we say the infinite sum equals that negative identity. By the end of this video, my hope is that this particular fact comes to make total sense to you. For any of you familiar with Euler's famous identity, this is essentially the matrix version of that. It turns out that in general, no matter what matrix you start with, as you add more and more terms, you eventually approach some stable value, though sometimes it can take quite a while before you get there. Just seeing the definition like this in isolation raises all kinds of questions, most notably, why would mathematicians and physicists be interested in torturing their poor matrices this way? What problems are they trying to solve? And if you're anything like me, a new operation is only satisfying when you have a clear view of what it's trying to do, some sense of how to predict the output based on the input before you actually crunch the numbers. How on earth could you have predicted that the matrix with pi off the diagonals results in a negative identity matrix like this? Often in math you should view the definition not as a starting point, but as a target. Contrary to the structure of textbooks, mathematicians do not start by making definitions and then listing a lot of theorems and proving them and then showing some examples. The process of discovering math typically goes the other way around. They start by chewing on specific problems, and then generalizing those problems, then coming up with constructs that might be helpful in those general cases, and only then do you write down a new definition, or extend an old one. As to what sorts of specific examples might motivate matrix exponents, two come to mind. One involving relationships, and the other quantum mechanics. Let's start with relationships. Suppose we have two lovers, let's call them Romeo and Juliet, and let's let x represent Juliet's love for Romeo, and y represent his love for her, both of which are going to be values that change with time. This is an example we actually touched on in chapter 1, based on a Steven Strogatz article, but it's okay if you didn't see that. The way their relationship works is that the rate at Juliet's love for Romeo changes, the derivative of this value, is equal to negative one times Romeo's love for her. So in other words, when Romeo is expressing cool disinterest, that's when Juliet's feelings actually increase, whereas if he becomes too infatuated, her interest will start to fade. Romeo, on the other hand, is the opposite. The rate of change of his love is equal to the of Juliet's love, so while Juliet is mad at him, his affections tend to decrease, whereas if she loves him, that's when his feelings grow. Of course, neither one of these numbers is holding still. As Romeo's love increases in response to Juliet, her equation continues to apply and drives her love down. Both of these equations always apply, from each infinitesimal point in time to the next, so every slight change to one value immediately influences the rate of change of the other. This is a system of differential equations. It's a puzzle, where your challenge is to find explicit functions for x of t and y of t that make both of these expressions true. Now, as systems of differential equations go, this one is on the simpler side, enough so that many calculus students could probably just guess at an answer. But keep in mind, it's not enough to find some pair of functions that makes this true. If you want to actually predict where Romeo and Juliet end up after some starting point, you have to make sure that your functions match the initial set of conditions at time t equals 0. More to the point, our actual goal today is to systematically solve more general versions of this equation, without guessing and checking, and it's that question that leads us to matrix exponents. Very often when you have multiple changing values like this, it's helpful to package them together as coordinates of a single point in a higher dimensional space. So for Romeo and Juliet, think of their relationship as a point in a 2D space, the x-coordinate capturing Juliet's feelings, and the y-coordinate capturing Romeo's. Sometimes it's helpful to picture this as an arrow from the origin, other times just as a point. All that really matters is that it encodes two numbers, and moving forward we'll be writing that as a column vector. And of course, this is all a function of time. You might picture the rate of change of this state, the thing that packages together the derivative of x and the derivative of y, as a kind of velocity vector in this state space, something that tugs at our point in some direction and with some magnitude that indicates how quickly it's changing. Remember, the rule here is that the rate of change of x is negative y, and the rate of change of y is x. Set up as vectors like this, we could rewrite the right hand side of this equation as a product of this matrix with the original vector xy. The top row encodes Juliet's rule, and the bottom row encodes Romeo's rule. So what we have here is a differential equation telling us that the rate of change of some vector is equal to a certain matrix times itself. In a moment we'll talk about how matrix exponentiation solves this kind of equation, but before that let me show you a simpler way that we can solve this particular system, one that uses pure geometry, and it helps set the stage for visualizing matrix exponents a bit later. This matrix from our system is a 90 degree rotation matrix. For any of you rusty on how to think about matrices as transformations, there's a video all about it on this channel, a series really. The basic idea is that when you multiply a matrix by the vector 1 0, it pulls out the first column, and similarly if you multiply it by 0 1, that pulls out the second column. What this means is that when you look at a matrix, you can read its columns as telling you what it does to these two vectors, known as the matrix. The way it acts on any other vector is a result of scaling and adding these two basis results by that vector's coordinates. So looking back at the matrix from our system, notice how from its columns we can tell it takes the first basis vector to 0 1, and the second to negative 1 0, hence why I'm calling it the 90 degree rotation matrix. What it means for our equation is that it's saying wherever Romeo and Juliet are in this space, their rate of change has to look like a 90 degree rotation of this position vector. The only way velocity can permanently be perpendicular to position like this is when you rotate around the origin in circular motion, never growing or shrinking because the rate of change has no component in the direction of the position. More specifically, since the length of this velocity vector equals the length of the position vector, then for each unit of time, the distance that this covers is equal to one radius's worth of arc length along that circle. In other words, it rotates at one radian per unit time, so in particular it would take 2 pi units of time to make a full revolution. If you want to describe this kind of rotation with a formula, we can use a more general rotation matrix, which looks like this. Again, we can read it in terms of the columns. Notice how the first column tells us that it takes that first basis vector to cos t sin t, and the second column tells us that it takes the second basis vector to negative sin t cos t, both of which are consistent with rotating by t radians. So, to solve the system, if you want to predict where Romeo and Juliet end up after t units of time, you can multiply this matrix by their initial state. The active viewers among you might also enjoy taking a moment to pause and confirm that the explicit formulas you get out of this for x of t and y of t really do satisfy the system of differential equations that we started with. The mathematician in you might wonder if it's possible to solve not just this specific system, but equations like it for any other matrix, no matter its coefficients. To ask this question is to set yourself up to rediscover matrix exponents. The main goal for today is for you to understand how this equation lets you intuitively picture the operation which we write as e raised to a matrix, and on the flip side, how being able to compute matrix exponents lets you explicitly solve this equation. A much less whimsical example is Schrodinger's famous equation, which is the fundamental equation describing how systems in quantum mechanics change over time. It looks pretty intimidating, and I mean it's quantum mechanics so of course it will, but it's actually not that different from the Romeo-Juliet setup. This symbol here refers to a certain vector. It's a vector that packages together all the information you might care about in a system, like the various particles' positions and momenta. It's analogous to our simpler 2D vector that encoded all the information about Romeo and Juliet. The equation says that the rate at which this state vector changes looks like a certain matrix times itself. There are a number of things that make Schrodinger's equation notably more complicated, but in the back of your mind you might think of it as a target point that you and I can build up to, with simpler examples like Romeo and Juliet offering more friendly stepping stones along the way. Actually the simplest example, which is tied to ordinary real number powers of e, is the one-dimensional case. This is when you have a single changing value, and its rate of change equals some constant times itself. So the bigger the value, the faster it grows. Most people are more comfortable visualizing this with a graph, where the higher the value of the graph, the steeper its slope, resulting in this ever-steepening upward curve. Just keep in mind that when we get to higher dimensional variance, graphs are a lot less helpful. This is a highly important equation in its own right. It's a very powerful concept when the rate of change of a value is proportional to the value itself. This is the equation governing things like compound interest, or the early stages of population growth before the effects of limited resources kick in, or the early stages of an epidemic while most of the population is susceptible. Calculus students all learn about how the derivative of e^(rt) is r *e^(rt)
. In other words, this self-reinforcing growth phenomenon is the same thing as exponential growth, and e^(rt) solves this equation. Actually, a better way to think about it is that there are many different solutions to this equation, one for each initial condition, something like an initial investment size or an initial population, which we'll just call x0. Notice, by the way, how the higher the value for x0, the higher the initial slope of the resulting solution, which should make complete sense given the equation. The function e^(rt) is just a solution when the initial condition is 1, but if you multiply by any other initial condition, you get a new function which still satisfies this property. It still has a derivative which is r times itself, but this time it starts at x0 since e to the 0 is 1. This is worth highlighting before we generalize to more dimensions. Do not think of the exponential part as being a solution in and of itself. Think of it as something that acts on an initial condition in order to give a solution. You see, up in the two-dimensional case, when we have a changing vector whose rate of change is constrained to be some matrix times itself, what the solution looks like is also an exponential term acting on a given initial condition, but the exponential part in that case will produce a matrix that changes with time, and the initial condition is a vector. In fact, you should think of the definition of matrix exponentiation as being heavily motivated by making sure that this fact is true. For example, if we look back at the system that popped up with Romeo and Juliet, the claim now is that solutions look like e raised to this 0, negative 1, 1, 0 matrix all times time multiplied by some initial condition. But we've already seen the solution in this case, we know it looks like a rotation matrix times the initial condition. So let's take a moment to roll up our sleeves and compute the exponential term using the definition that I mentioned at the start, and see if it lines up. Remember, writing e to the power of a matrix is a shorthand, a shorthand for plugging it in to this long infinite polynomial, the Taylor series for e to the x. I know it might seem pretty complicated to do this, but trust me, it's very satisfying how this particular one turns out. If you actually sit down and you compute successive powers of this matrix, what you'd notice is that they fall into a cycling pattern every four iterations. This should make sense given that we know it's a 90 degree rotation matrix. So when you add together all infinitely many matrices term by term, each term in the result looks like a polynomial in t with some nice cycling pattern in its coefficients, all of them scaled by the relevant factorial term. Those of you who are savvy with Taylor series might be able to recognize that each one of these components is the Taylor series for either sine or cosine, though in that top right corner's case it's actually negative sine. So what we get from the computation is exactly the rotation matrix we had from before. To me, this is extremely beautiful. We have two completely different ways of reasoning about the same system, and they give us the same answer. It's reassuring that they do, but it's wild just how different the mode of thought is when you're chugging through this polynomial versus when you're geometrically reasoning about what a velocity perpendicular to a position must imply. Hopefully the fact that these line up inspires a little confidence in the claim that matrix exponents really do solve systems like this. This explains the computation we saw at the start, by the way, with the matrix that had negative pi and pi off the diagonals, producing the negative identity. This expression is exponentiating a 90 degree rotation matrix times pi, which is another way to describe what the Romeo-Juliet setup does after pi units of time. As we now know, that has the effect of rotating everything 180 degrees in this state space, which is the same as multiplying by negative 1. Also, for any of you familiar with imaginary number exponents, this particular example is ringing a ton of bells. It is 100% analogous. In fact, we could have framed the entire example where Romeo and Juliet's feelings were packaged into a complex number, and the rate of change of that complex number would have been i times itself, since multiplication by i also acts like a 90 degree rotation. The same exact line of reasoning, both analytic and geometric, would have led to this whole idea that e to the power i t describes rotation. These are actually two of many different examples throughout math and physics when you find yourself exponentiating some object which acts as a 90 degree rotation times time. It shows up with quaternions or many of the matrices that pop up in quantum mechanics. In all of these cases, we have this really neat general idea that if you take some operation that rotates 90 degrees in some plane, often it's a plane in some high dimensional space that we can't visualize, then what we get by exponentiating that operation times time is something that generates all other rotations in that same plane. One of the more complicated variations on this same theme is Schrodinger's equation. It's not just that this has the derivative of a state equals some matrix times that state form. The nature of the relevant matrix here is such that the equation also describes a kind of rotation, though in many applications of Schrodinger's equation it'll be a rotation in a kind of function space. It's a little more involved though because typically there's a combination of many different rotations. It takes time to really dig into this equation and I would love to do that in a later chapter, but right now I cannot help but at least allude to the fact that this imaginary unit i that sits so impishly in such a fundamental equation for all of the universe is playing basically the same role as the matrix from our Romeo-Juliet 
example. What this i communicates is that the rate of change of a certain state is, in a sense, perpendicular to that state, and hence that the way things have to evolve over time will involve a kind of oscillation. But matrix exponentiation can do so much more than just rotation. You can always visualize these sorts of differential equations using a vector field. The idea is that this equation tells us the velocity of a state is entirely determined by its position, so what we do is go to every point in the space and draw a little vector indicating what the velocity of a state must be if it passes through that point. For our type of equation, this means that we go to each point v in space and we attach the vector M times v. To intuitively understand how any given initial condition will evolve, you let it flow along this field with a velocity always matching whatever vector it's sitting on at any given point in time. So if the claim is that solutions to this equation look like e to the Mt times some initial condition, it means you can visualize what the matrix e to the Mt does by letting every possible initial condition flow along this field for t units of time. The transition from start to finish is described by whatever matrix pops out from the computation for e to the Mt. In our main example with the 90 degree rotation matrix, the vector field looks like this, and as we saw e to the Mt describes rotation in that case, which lines up with flow along this field. As another example, the more Shakespearean Romeo and Juliet might have equations that look a little more like this, where Juliet's rule is symmetric with Romeo's, and both of them are inclined to get carried away in response to one another's feelings. Again, the way the vector field you're looking at has been defined is to go to each point v in space and attach the vector M times v. This is the pictorial way of saying that the rate of change of a state must always equal M times itself. But for this example, flow along the field looks a lot different from how it did before. If Romeo and Juliet start off anywhere in this upper right half of the plane, their feelings will feed off of each other and they both tend towards infinity. If they're in the other half of the plane, well let's just say that they stay more true to their in Montague family traditions. So even before you try calculating the exponential of this particular matrix, you can already have an intuitive sense for what the answer should look like. The resulting matrix should describe the transition from time 0 to time t, which if you look at the field seems to indicate that it will squish along one diagonal while stretching along another, getting more extreme as t gets larger. Of course, all of this is presuming that e to the Mt times an initial condition actually solves these systems. This is one of those facts that's easiest to believe when you just work it out yourself. But I'll run through a quick rough sketch. Write out the full polynomial that defines e to the Mt and multiply by some initial condition vector on the right. And then take the derivative of this with respect to t. Because the matrix M is constant, this just means applying the power rule to each one of the terms. And that power rule really nicely cancels out with the factorial terms. So what we're left with is an expression that looks almost identical to what we had before, except that each term has an extra M hanging on to it, but this can be factored out to the left. So the derivative of the expression is M times the original expression, and hence it solves the equation. This actually sweeps under the rug some details required for rigor, mostly centered around the question of whether or not this thing actually converges, but it does give the main idea. In the next chapter I would like to talk more about the properties that this operation has, most notably its relationship with eigenvectors and eigenvalues, which leads us to more concrete ways of thinking about how you actually carry out this computation, which otherwise seems insane. Also, time permitting, it might be fun to talk about what it means to raise e to the power of the derivative operator. Thank you.

================================================================================
VIDEO ID: lG4VkPoG3ko
TITLE: The medical test paradox, and redesigning Bayes' rule
URL: https://www.youtube.com/watch?v=lG4VkPoG3ko
PUBLISHED: 2020-12-22T17:42:00Z
STATUS: SUCCESS
================================================================================
Some of you may have heard this paradoxical fact about medical tests. It's very commonly used to introduce the topic of Bayes' rule in probability. The paradox is that you could take a test which is highly accurate,  in the sense that it gives correct results to a large majority of the people taking it. And yet, under the right circumstances, when assessing the  probability that your particular test result is correct,  you can still land on a very low number, arbitrarily low, in fact. In short, an accurate test is not necessarily a very predictive test. Now when people think about math and formulas,  they don't often think of it as a design process. I mean, maybe in the case of notation it's easy to see that different choices  are possible, but when it comes to the structure of the formulas themselves  and how we use them, that's something that people typically view as fixed. In this video, you and I will dig into this paradox,  but instead of using it to talk about the usual version of Bayes' rule,  I'd like to motivate an alternate version, an alternate design choice. Now, what's up on the screen now is a little bit abstract,  which makes it difficult to justify that there really is a substantive difference here,  especially when I haven't explained either one yet. To see what I'm talking about though, we should really start by spending some  time a little more concretely, and just laying out what exactly this paradox is. Picture a thousand women and suppose that 1% of them have breast cancer. And let's say they all undergo a certain breast cancer screening,  and that 9 of those with cancer correctly get positive results,  and there's one false negative. And then suppose that among the remainder without cancer,  89 get false positives, and 901 correctly get negative results. So if all you know about a woman is that she does the screening and she gets a positive  result, you don't have information about symptoms or anything like that,  you know that she's either one of these 9 true positives or one of these 89 false  positives. So the probability that she's in the cancer group given the test  result is 9 divided by 9 plus 89, which is approximately 1 in 11. In medical parlance, you would call this the positive predictive value of the test,  or PPV, the number of true positives divided by the total number of positive test results. You can see where the name comes from. To what extent does a positive test result actually predict that you have the disease? Now, hopefully, as I've presented it this way where we're thinking  concretely about a sample population, all of this makes perfect sense. But where it comes across as counterintuitive is if you just look  at the accuracy of the test, present it to people as a statistic,  and then ask them to make judgments about their test result. Test accuracy is not actually one number, but two. First, you ask how often is the test correct on those with the disease. This is known as the test sensitivity, as in how  sensitive is it to detecting the presence of the disease. In our example, test sensitivity is 9 in 10, or 90%. And another way to say the same fact would be to say the false negative rate is 10%. And then a separate, not necessarily related number is how often it's correct for those  without the disease, which is known as the test specificity,  as in are positive results caused specifically by the disease,  or are there confounding triggers giving false positives. In our example, the specificity is about 91%. Or another way to say the same fact would be to say the false positive rate is 9%. So the paradox here is that in one sense, the test is over 90% accurate. It gives correct results to over 90% of the patients who take it. And yet, if you learn that someone gets a positive result without any added information,  there's actually only a 1 in 11 chance that that particular result is accurate. This is a bit of a problem, because of all of the places for math to be counterintuitive,  medical tests are one area where it matters a lot. In 2006 and 2007, the psychologist Gerd Gigerenzer gave a series of statistics  seminars to practicing gynecologists, and he opened with the following example. A 50-year-old woman, no symptoms, participates in a routine mammography screening. She tests positive, is alarmed, and wants to know from you  whether she has breast cancer for certain or what her chances are. Apart from the screening result, you know nothing else about this woman. In that seminar, the doctors were then told that the prevalence of  breast cancer for women of this age is about 1%,  and then to suppose that the test sensitivity is 90% and that its specificity was 91%. You might notice these are exactly the same numbers  from the example that you and I just looked at. This is where I got them. So, having already thought it through, you and I know the answer. It's about 1 in 11. However, the doctors in this session were not primed with the suggestion to  picture a concrete sample of a thousand individuals, the way that you and I had. All they saw were these numbers. They were then asked, how many women who test positive actually have breast cancer? What is the best answer? And they were presented with these four choices. In one of the sessions, over half the doctors present  said that the correct answer was 9 in 10, which is way off. Only a fifth of them gave the correct answer, which is worse  than what it would have been if everybody had randomly guessed. It might seem a little extreme to be calling this a paradox. I mean, it's just a fact. It's not something intrinsically self-contradictory. But, as these seminars with Gigerenzer show, people, including doctors,  definitely find it counterintuitive that a test with high accuracy can give you such a  low predictive value. We might call this a veridical paradox, which refers to facts that are provably true,  but which nevertheless can feel false when phrased a certain way. It's sort of the softest form of a paradox, saying  more about human psychology than about logic. The question is how we can combat this. Where we're going with this, by the way, is that I want you to be able  to look at numbers like this and quickly estimate in your head that it  means the predictive value of a positive test should be around 1 in 11. Or, if I changed things and asked, what if it  was 10% of the population who had breast cancer? You should be able to quickly turn around and say  that the final answer would be a little over 50%. Or, if I said imagine a really low prevalence,  something like 0.1% of patients having cancer,  you should again quickly estimate that the predictive value of the test is around 1 in  100, that 1 in 100 of those with positive test results in that case would have cancer. Or, let's say we go back to the 1% prevalence, but I make the test more accurate. I tell you to imagine the specificity is 99%. There, you should be able to relatively quickly  estimate that the answer is a little less than 50%. The hope is that you're doing all of this with minimal calculations in your head. Now, the goals of quick calculations might feel very different from the goals of  addressing whatever misconception underlies this paradox,  but they actually go hand in hand. Let me show you what I mean. On the side of addressing misconceptions, what would you  tell to the people in that seminar who answered 9 and 10? What fundamental misconception are they revealing? What I might tell them is that in much the same way that you shouldn't think  of tests as telling you deterministically whether you have a disease,  you shouldn't even think of them as telling you your chances of having a disease. Instead, the healthy view of what tests do is that they update your chances. In our example, before taking the test, a patient's  chances of having cancer were 1 in 100. In Bayesian terms, we call this the prior probability. The effect of this test was to update that prior by almost an order of magnitude,  up to around 1 in 11. The accuracy of a test is telling us about the strength of this updating. It's not telling us a final answer. What does this have to do with quick approximations? Well, a key number for those approximations is something called the Bayes factor,  and the very act of defining this number serves to reinforce this  central lesson about reframing what it is the tests do. You see, one of the things that makes test statistics so very confusing  is that there are at least 4 numbers that you'll hear associated with them. For those with the disease, there's the sensitivity and the false negative rate,  and then for those without, there's the specificity and the false positive rate,  and none of these numbers actually tell you the thing you want to know. Luckily, if you want to interpret a positive test result,  you can pull out just one number to focus on from all this. Take the sensitivity divided by the false positive rate. In other words, how much more likely are you to see  the positive test result with cancer versus without? In our example, this number is 10. This is the Bayes factor, also sometimes called the likelihood ratio. A very handy rule of thumb is that to update a small prior,  or at least to approximate the answer, you simply multiply it by the Bayes factor. So in our example, where the prior was 1 in 100,  you would estimate that the final answer should be around 1 in 10,  which is in fact slightly above the true correct answer. So based on this rule of thumb, if I asked you what would happen if the  prior from our example was instead 1 in 1000, you could quickly estimate  that the effect of the test should be to update those chances to around 1 in 100. And in fact, take a moment to check yourself by thinking through a sample population. In this case, you might picture 10,000 patients where only 10 of them really have cancer. And then based on that 90% sensitivity, we would  expect 9 of those cancer cases to give true positives. And on the other side, a 91% specificity means that  9% of those without cancer are getting false positives. So we'd expect 9% of the remaining patients, which is around 900,  to give false positive results. Here, with such a low prevalence, the false positives  really do dominate the true positives. So the probability that a randomly chosen positive case from this population  actually has cancer is only around 1%, just like the rule of thumb predicted. Now, this rule of thumb clearly cannot work for higher priors. For example, it would predict that a prior of  10% gets updated all the way to 100% certainty. But that can't be right. In fact, take a moment to think through what the answer should be,  again, using a sample population. Maybe this time we picture 10 out of 100 having cancer. Again, based on the 90% sensitivity of the test,  we'd expect 9 of those true cancer cases to get positive results. But what about the false positives? How many do we expect there? About 9% of the remaining 90. About 8. So, upon seeing a positive test result, it tells you that you're  either one of these 9 true positives or one of the 8 false positives. So this means the chances are a little over 50%, roughly 9 out of 17, or 53%. At this point, having dared to dream that Bayesian updating could look  as simple as multiplication, you might tear down your hopes and pragmatically  acknowledge that sometimes life is just more complicated than that. Except it's not. This rule of thumb turns into a precise mathematical fact as long as we  shift away from talking about probabilities to instead talking about odds. If you've ever heard someone talk about the chances of an event being 1 to 1 or 2 to 1,  things like that, you already know about odds. With probability, we're taking the ratio of the number  of positive cases out of all possible cases, right? Things like 1 in 5 or 1 in 10. With odds, what you do is take the ratio of all positive cases to all negative cases. You commonly see odds written with a colon to emphasize the distinction,  but it's still just a fraction, just a number. So an event with a 50% probability would be described as having 1 to 1 odds. A 10% probability is the same as 1 to 9 odds. An 80% probability is the same as 4 to 1 odds. You get the point. It's the same information. It still describes the chances of a random event,  but it's presented a little differently, like a different unit system. Probabilities are constrained between 0 and 1, with even chances sitting at 0.5. But odds range from 0 up to infinity, with even chances sitting at the number 1. The beauty here is that a completely accurate,  not even approximating things way to frame Bayes' rule is to say,  express your prior using odds, and then just multiply by the Bayes' factor. Think about what the prior odds are really saying. It's the number of people with cancer divided by the number without it. Here, let's just write that down as a normal fraction for a moment so we can multiply it. When you filter down just to those with positive test results,  the number of people with cancer gets scaled down,  scaled down by the probability of seeing a positive test result given  that someone has cancer. And then similarly, the number of people without cancer also gets scaled down,  this time by the probability of seeing a positive test result, but in that case. So the ratio between these two counts, the new odds upon seeing the test,  looks just like the prior odds except multiplied by this term here,  which is exactly the Bayes' factor. Look back at our example, where the Bayes' factor was 10. And as a reminder, this came from the 90% sensitivity  divided by the 9% false positive rate. How much more likely are you to see a positive result with cancer versus without? If the prior is 1%, expressed as odds, this looks like 1 to 99. So by our rule, this gets updated to 10 to 99,  which if you want you could convert back to a probability. It would be 10 divided by 10 plus 99, or about 1 in 11. If instead, the prior was 10%, which was the example that tripped up  our rule of thumb earlier, expressed as odds, this looks like 1 to 9. By our simple rule, this gets updated to 10 to 9,  which you can already read off pretty intuitively. It's a little above even chances, a little above 1 to 1. If you prefer, you can convert it back to a probability. You would write it as 10 out of 19, or about 53%. And indeed, that is what we already found by thinking  things through with a sample population. Let's say we go back to the 1% prevalence, but I make the test more accurate. Now what if I told you to imagine that the false positive rate was only 1% instead of 9%? What that would mean is that our Bayes factor is 90 instead of 10. The test is doing more work for us. In this case, with the more accurate test, it gets updated to 90 to 99,  which is a little less than even chances, something a little under 50%. To be more precise, you could make the conversion  back to probability and work out that it's around 48%. But honestly, if you're just going for a gut feel, it's fine to stick with the odds. Do you see what I mean about how just defining this  number helps to combat potential misconceptions? For anybody who's a little hasty in connecting test accuracy directly to your probability  of having a disease, it's worth emphasizing that you could administer the same test with  the same accuracy to multiple different patients who all get the same exact result,  but if they're coming from different contexts,  that result can mean wildly different things. However, the one thing that does stay constant in every case  is the factor by which each patient's prior odds get updated. And by the way, this whole time we've been using the prevalence of the disease,  which is the proportion of people in a population who have it,  as a substitute for the prior, the probability of having it before you see a test. However, that's not necessarily the case. If there are other known factors, things like symptoms,  or in the case of a contagious disease, things like known contacts,  those also factor into the prior, and they could potentially make a huge difference. As another side note, so far we've only talked about positive test results,  but way more often you would be seeing a negative test result. The logic there is completely the same, but the base  factor that you compute is going to look different. Instead, you look at the probability of seeing this negative  test result with the disease versus without the disease. So in our cancer example, this would have been the 10% false  negative rate divided by the 91% specificity, or about 1 in 9. In other words, seeing a negative test result in that example  would reduce your prior odds by about an order of magnitude. When you write it all out as a formula, here's how it looks. It says your odds of having a disease given a test result equals your  odds before taking the test, the prior odds, times the base factor. Now let's contrast this with the usual way Bayes' rule is written,  which is a bit more complicated. In case you haven't seen it before, it's essentially just what we were  doing with sample populations, but you wrap it all up symbolically. Remember how every time we were counting the number of true positives and  then dividing it by the sum of the true positives and the false positives? We do just that, except instead of talking about absolute amounts,  we talk of each term as a proportion. So the proportion of true positives in the population comes  from the prior probability of having the disease multiplied  by the probability of seeing a positive test result in that case. Then we copy that term down again into the denominator,  and then the proportion of false positives comes from the prior  probability of not having the disease times the probability of a positive  test in that case. If you want, you could also write this down with words instead of symbols,  if terms like sensitivity and false positive rate are more comfortable. And this is one of those formulas where once you say it out loud it seems like a bit  much, but it really is no different from what we were doing with sample populations. If you wanted to make the whole thing look simpler,  you often see this entire denominator written just as the probability of seeing a  positive test result, overall. While that does make for a really elegant little expression,  if you intend to use this for calculations, it's a little disingenuous,  because in practice, every single time you do this you need to break  down that denominator into two separate parts, breaking down the cases. So taking this more honest representation of it,  let's compare our two versions of Bayes' rule. And again, maybe it looks nicer if we use the words sensitivity and false positive rate. If nothing else, it helps emphasize which parts of the  formula are coming from statistics about the test accuracy. I mean, this actually emphasizes one thing I really like about the framing with  odds and a Bayes' factor, which is that it cleanly factors out the parts that  have to do with the prior and the parts that have to do with the test accuracy. But over in the usual formula, all of those are very intermingled together. And this has a very practical benefit. It's really nice if you want to swap out different priors and easily see their effects. This is what we were doing earlier. But with the other formula, to do that, you have to recompute everything each time. You can't leverage a precomputed Bayes' factor the same way. The odds framing also makes things really nice if you want to do  multiple different Bayesian updates based on multiple pieces of evidence. For example, let's say you took not one test, but two. Or you wanted to think about how the presence of symptoms plays into it. For each piece of new evidence you see, you always ask the question,  how much more likely would you be to see that with the disease versus without the disease? Each answer to that question gives you a new Bayes' factor,  a new thing that you multiply by your odds. Beyond just making calculations easier, there's something I really like about  attaching a number to test accuracy that doesn't even look like a probability. I mean, if you hear that a test has, for example,  a 9% false positive rate, that's just such a disastrously ambiguous phrase. It's so easy to misinterpret it to mean there's a  9% chance that your positive test result is false. But imagine if instead the number that we heard tacked on to test  results was that the Bayes' factor for a positive test result is, say, 10. There's no room to confuse that for your probability of having a disease. The entire framing of what a Bayes' factor is,  is that it's something that acts on a prior. It forces your hand to acknowledge the prior as something that's separate entirely,  and highly necessary to drawing any conclusion. All that said, the usual formula is definitely not without its merits. If you view it not simply as something to plug numbers into,  but as an encapsulation of the sample population idea that we've been using throughout,  you could very easily argue that that's actually much better for your intuition. After all, it's what we were routinely falling back on in order to check  ourselves that the Bayes' factor computation even made sense in the first place. Like any design decision, there is no clear-cut objective best here. But it's almost certainly the case that giving serious consideration  to that question will lead you to a better understanding of Bayes' rule. Also, since we're on the topic of kind of paradoxical things,  a friend of mine, Matt Cook, recently wrote a book all about paradoxes. I actually contributed a small chapter to it with thoughts  on the question of whether math is invented or discovered. And the book as a whole is this really nice connection of thought-provoking  paradoxical things ranging from philosophy to math and physics. You can, of course, find all the details in the description.
352
00:20:58,100 --> 00:20:51,040
.

================================================================================
VIDEO ID: b3NxrZOu_CE
TITLE: Hamming codes part 2: The one-line implementation
URL: https://www.youtube.com/watch?v=b3NxrZOu_CE
PUBLISHED: 2020-09-04T15:36:24Z
STATUS: SUCCESS
================================================================================
I'm assuming that everybody here is coming from part 1. We were talking about Hamming codes, a way to create a block of data  where most of the bits carry a meaningful message,  while a few others act as a kind of redundancy,  in such a way that if any bit gets flipped, either a message bit or a redundancy bit,  anything in this block, a receiver is going to be able to identify that  there was an error, and how to fix it. The basic idea presented there was how to use multiple  parity checks to binary search your way down to the error. In that video the goal was to make Hamming codes  feel as hands-on and rediscoverable as possible. But as you start to think about actually implementing this,  either in software or hardware, that framing may actually undersell how elegant  these codes really are. You might think that you need to write an algorithm that keeps  track of all the possible error locations and cuts that group in half with each check,  but it's actually way, way simpler than that. If you read out the answers to the four parity checks we did in the last video,  all as 1s and 0s instead of yeses and nos, it literally spells  out the position of the error in binary. For example, the number 7 in binary looks like 0111,  essentially saying that it's 4 plus 2 plus 1. And notice where the position 7 sits, it does affect the first of our parity groups,  and the second, and the third, but not the last. So reading the results of those four checks from bottom  to top indeed does spell out the position of the error. There's nothing special about the example 7, this works in general,  and this makes the logic for implementing the whole scheme in hardware shockingly simple. Now if you want to see why this magic happens,  take these 16 index labels for our positions, but instead of writing them in base 10,  let's write them all in binary, running from 0000 up to 1111. As we put these binary labels back into their boxes,  let me emphasize that they are distinct from the data that's actually being sent. They're nothing more than a conceptual label to help you  and me understand where the four parity groups came from. The elegance of having everything we're looking at be described in binary is maybe  undercut by the confusion of having everything we're looking at being described in binary. It's worth it, though. Focus your attention just on that last bit of all of these labels,  and then highlight the positions where that final bit is a 1. What we get is the first of our four parity groups,  which means you can interpret that first check as asking, hey,  if there's an error, is the final bit in the position of that error a 1? Similarly, if you focus on the second to last bit,  and highlight all the positions where that's a 1,  you get the second parity group from our scheme. In other words, that second check is asking, hey, me again,  if there's an error, is the second to last bit of that position a 1? And so on. The third parity check covers every position whose third to last bit is turned on,  and the last one covers the last eight positions,  those ones whose highest order bit is a 1. Everything we did earlier is the same as answering these four questions,  which in turn is the same as spelling out a position in binary. I hope this makes two things clearer. The first is how to systematically generalize  to block sizes that are bigger powers of two. If it takes more bits to describe each position, like six bits to describe 64 spots,  then each of those bits gives you one of the parity groups that we need to check. Those of you who watched the chessboard puzzle I did  with Matt Parker might find all this exceedingly familiar. It's the same core logic, but solving a different problem,  and applied to a 64-squared chessboard. The second thing I hope this makes clear is why our parity bits are  sitting in the positions that are powers of two, for example 1, 2, 4, and 8. These are the positions whose binary representation has just a single bit turned on. What that means is each of those parity bits sits  inside one and only one of the four parity groups. You can also see this in larger examples, where no matter how big you get,  each parity bit conveniently touches only one of the groups. Once you understand that these parity checks that we've focused so much of  our time on are nothing more than a clever way to spell out the position  of an error in binary, then we can draw a connection with a different way  to think about hamming codes, one that is arguably a lot simpler and more elegant,  and which can basically be written down with a single line of code. It's based on the XOR function. XOR, for those of you who don't know, stands for exclusive or. When you take the XOR of two bits, it's going to return a 1 if either  one of those bits is turned on, but not if both are turned on or off. Phrased differently, it's the parity of these two bits. As a math person, I prefer to think about it as addition mod 2. We also commonly talk about the XOR of two different bit strings,  which basically does this component by component. It's like addition, but where you never carry. Again, the more mathematically inclined might prefer to  think of this as adding two vectors and reducing mod 2. If you open up some Python right now and apply the caret operation between two integers,  this is what it's doing but to the bit representations of those numbers under the hood. The key point for you and me is that taking the XOR of many different  bit strings is effectively a way to compute the parodies of a bunch of separate groups,  like so with the columns, all in one fell swoop. This gives us a rather snazzy way to think about the multiple parity checks from  our Hamming code algorithm as all being packaged together into one single operation. Though at first glance it does look very different. Specifically write down the 16 positions in binary, like we had before,  and now highlight the positions where the message bit is turned on to a 1,  and then collect these positions into one big column and take the XOR. You can probably guess that the 4 bits sitting at the bottom as  a result are the same as the 4 parity checks we've come to know and love,  but take a moment to actually think about why exactly. This last column, for example, is counting all of the positions whose last bit is a 1,  but we're already limited only to the highlighted positions,  so it's effectively counting how many highlighted positions came from the first  parity group. Does that make sense? Likewise, the next column counts how many positions are in the second parity group,  the positions whose second to last bit is a 1, and which are also highlighted, and so on. It's really just a small shift in perspective on the same thing we've been doing. And so you know where it goes from here. The sender is responsible for toggling some of the special  parity bits to make sure the sum works out to be 0000. Now once we have it like this, this gives us a really nice way to think about why  these four resulting bits at the bottom directly spell out the position of an error. Let's say some bit in this block gets toggled from a 0 to a 1. What that means is that the position of that bit is now going to  be included in the total XOR, which changes the sum from being 0  to instead being this newly included value, the position of the error. Slightly less obviously, the same is true if there's an error that changes a 1 to a 0. You see, if you add a bit string together twice,  it's the same as not having it there at all, basically because in this  world 1 plus 1 equals 0. So adding a copy of this position to the total sum has the same effect as we're moving it. And that effect, again, is that the total result at  the bottom here spells out the position of the error. To illustrate how elegant this is, let me show that one line of Python code I  referenced before, which will capture almost all of the logic on the receiver's end. We'll start by creating a random array of 16 1s and 0s to simulate the data block,  and I'll give it the name bits, but of course in practice this would be  something we're receiving from a sender, and instead of being random it  would be carrying 11 data bits together with 5 parity bits. If I call the function enumerateBits, what it does is pair together each of  those bits with a corresponding index, in this case running from 0 up to 15. So if we then create a list that loops over all of these pairs,  pairs that look like i, and then we pull out just the i value, just the index,  well it's not that exciting, we just get back those indices 0 through 15. But if we add on the condition to only do this if bit,  meaning if that bit is a 1 and not a 0, well then it pulls out only the positions where  the corresponding bit is turned on. In this case it looks like those positions are 0, 4, 6, 9, etc. What we want is to collect together all of those positions,  the positions of the bits that are turned on, and then XOR them together. To do this in Python, let me first import a couple helpful functions. That way we can call reduce() on this list, and use the XOR function to reduce it. This basically eats its way through the list, taking XORs along the way. If you prefer, you can explicitly write out that XOR  function without having to import it from anywhere. So at the moment it looks like if we do this on our random block of 16 bits,  it returns 9, which has the binary representation 1001. We won't do it here, but you could write a function where the sender uses that binary  representation to set the four parity bits as needed,  ultimately getting this block to a state where running this line of code on the full  list of bits returns a 0. This would be considered a well-prepared block. What's cool is that if we toggle any one of the bits in this list,  simulating a random error from noise, then if you run this same line of code,  it prints out that error. Isn't that neat? You could get this block from out of the blue, run this single line on it,  and it'll automatically spit out the position of an error, or a 0 if there wasn't any. And there's nothing special about the size 16 here. The same line of code would work if you had a list of, say, 256 bits. Needless to say, there is more code to write here,  like doing the meta parity check to detect 2-bit errors,  but the idea is that almost all of the core logic from our scheme comes  down to a single XOR reduction. Now, depending on your comfort with binary and XORs and software in general,  you may either find this perspective a little bit confusing,  or so much more elegant and simple that you're wondering why we didn't just start  with it from the get-go. Loosely speaking, the multiple parity check perspective is easier to think about  when implementing Hamming codes in hardware very directly,  and the XOR perspective is easiest to think about when doing it in software,  from kind of a higher level. The first one is easiest to actually do by hand,  and I think it does a better job instilling the core intuition underlying all of this,  which is that the information required to locate a single error is related to  the log of the size of the block, or in other words,  it grows one bit at a time as the block size doubles. The relevant fact here is that that information  directly corresponds to how much redundancy we need. That's really what runs against most people's knee-jerk reaction when  they first think about making a message resilient to errors,  where usually copying the whole message is the first instinct that comes to mind. And then, by the way, there is this whole other way that you sometimes see  Hamming codes presented, where you multiply the message by one big matrix. It's kind of nice because it relates it to the broader family of linear codes,  but I think that gives almost no intuition for where it comes from or how it scales. And speaking of scaling, you might notice that the efficiency  of this scheme only gets better as we increase the block size. For example, we saw that with 256 bits, you're using only 3% of that  space for redundancy, and it just keeps getting better from there. As the number of parity bits grows one by one, the block size keeps doubling. And if you take that to an extreme, you could have a block with,  say, a million bits, where you would quite literally be playing 20  questions with your parity checks, and it uses only 21 parity bits. And if you step back to think about looking at a million  bits and locating a single error, that genuinely feels crazy. The problem, of course, is that with a larger block,  the probability of seeing more than one or two bit errors goes up,  and Hamming codes do not handle anything beyond that. So in practice, what you'd want is to find the right size  so that the probability of too many bit flips isn't too high. Also, in practice, errors tend to come in little bursts,  which would totally ruin a single block, so one common tactic to help spread out a  burst of errors across many different blocks is to interlace those blocks, like this,  before they're sent out or stored. Then again, a lot of this is rendered completely moot by more modern codes,  like the much more commonly used Reed-Solomon algorithm,  which handles burst errors particularly well, and it can be tuned to be resilient to  a larger number of errors per block. But that's a topic for another time. In his book The Art of Doing Science and Engineering,  Hamming is wonderfully candid about just how meandering his discovery of this code was. He first tried all sorts of different schemes involving organizing the bits  into parts of a higher dimensional lattice and strange things like this. The idea that it might be possible to get parity checks to conspire in a way that spells  out the position of an error only came to Hamming when he stepped back after a bunch of  other analysis and asked, okay, what is the most efficient I could conceivably be about  this? He was also candid about how important it was that parity checks were already on  his mind, which would have been way less common back in the 1940s than it is today. There are like half a dozen times throughout this book that he  references the Louis Pasteur quote, luck favors a prepared mind. Clever ideas often look deceptively simple in hindsight,  which makes them easy to underappreciate. Right now my honest hope is that Hamming codes,  or at least the possibility of such codes, feels almost obvious to you. But you shouldn't fool yourself into thinking that they actually are obvious,  because they definitely aren't. Part of the reason that clever ideas look deceptively easy is that we only  ever see the final result, cleaning up what was messy,  never mentioning all of the wrong turns, underselling just how vast the  space of explorable possibilities is at the start of a problem solving process,  all of that. But this is true in general. I think for some special inventions, there's a second,  deeper reason that we underappreciate them. Thinking of information in terms of bits had only really coalesced into a  full theory by 1948, with Claude Shannon's seminal paper on information theory. This was essentially concurrent with when Hamming developed his algorithm. This was the same foundational paper that showed, in a certain sense,  that efficient error correction is always possible,  no matter how high the probability of bit flips, at least in theory. Shannon and Hamming, by the way, shared an office in Bell Labs,  despite working on very different things, which hardly seems coincidental here. Fast forward several decades, and these days, many of us are  so immersed in thinking about bits and information that it's  easy to overlook just how distinct this way of thinking was. Ironically, the ideas that most profoundly shape the ways that a future generation  thinks will end up looking to that future generation simpler than they really are.

================================================================================
VIDEO ID: X8jsijhllIA
TITLE: But what are Hamming codes? The origin of error correction
URL: https://www.youtube.com/watch?v=X8jsijhllIA
PUBLISHED: 2020-09-04T15:32:50Z
STATUS: SUCCESS
================================================================================
Have you ever wondered how it's possible to scratch a CD  or a DVD and still have it play back whatever it's storing? The scratch really does affect the 1s and 0s on the disk,  so it reads off different data from what was stored,  but unless it's really scratched up, the bits it reads off are decoded  into precisely the same file that was encoded onto it, a bit for bit copy,  despite all those errors. There is a whole pile of mathematical cleverness that allows us to store data,  and just as importantly to transmit data, in a way that's resilient to errors. Well, okay, actually it doesn't take that much  cleverness to come up with a way to do this. Any file, whether it's a video or sound or text, some code,  an image, whatever, is ultimately some sequence of 1s and 0s. And a simple strategy to correct any bit that gets  flipped would be to store three copies of each bit. Then the machine reading this file could compare these three copies  and always take the best 2 out of 3 whenever there's a discrepancy. But what that means is using two thirds of your space for redundancy. And even then, for all of that space given up,  there's no strong guarantee about what happens if more than one bit gets flipped. The much more interesting question is how to make it so that  errors can be corrected while giving up as little space as possible. For example, using the method you'll learn about this video,  you could store your data in 256-bit blocks, where each block uses 9 bits, 9(!),  to act as a kind of redundancy, and the other 247 bits are free to carry whatever  meaningful message or data you want. And it will still be the case that if any bit gets flipped here,  just by looking at this block and nothing more,  a machine will be able to identify that there was an error and precisely where  it was so that it knows how to correct it. And honestly, that feels like magic. And for this particular scheme, if two bits get flipped,  the machine will at least be able to detect that there were two errors,  though it won't know how to fix them. We'll talk a little bit later about how this scales for blocks with different sizes. Methods that let you correct errors like this are known,  reasonably enough, as error correction codes. For the better part of the last century, this field has been a really rich source  of surprisingly deep math that gets incorporated into devices we use every day. The goal here is to give you a very thorough understanding  of one of the earliest examples, known as a Hamming code. And by the way, the way I'm thinking about the structure of this video is less  about explaining it as directly as possible, and more a matter of prompting  you to invent it for yourself, with a little gentle guidance here and there. So when you feel like you see where it's going at some point, take that moment to pause,  actively predict what the scheme is going to be before I tell you. Also, if you want your understanding to get down to the hardware level,  Ben Eater has made a video in conjunction with this one showing you how to  actually implement Hamming codes on breadboards, which is extremely satisfying. You should know, Hamming codes are not as widely used as more modern codes,  like the Reed-Solomon algorithm, but there is a certain magic to the  contrast between just how impossible this task feels at the start,  and how utterly reasonable it seems once you learn about Hamming. The basic principle of error correction is that in a vast space of all possible messages,  only some subset are going to be considered valid messages. As an analogy, think about correctly spelled words vs incorrectly spelled words. Whenever a valid message gets altered, the receiver is responsible for correcting  what they see back to the nearest valid neighbor, as you might do with a typo. Coming up with a concrete algorithm to efficiently categorize messages like this,  though, takes a certain cleverness. The story begins in the 1940s, when a young Richard Hamming was working for Bell Labs,  and some of his work involved using a very big expensive punch card  computer that he had only limited access to. And the programs he kept putting through it kept failing,  because every now and then a bit would get misread. Frustration being the crucible of invention, he got so fed  up that he invented the world's first error correction code. There are many different ways to frame Hamming codes,  but as a first pass we're going to go through it the way Hamming himself  thought about them. Let's use an example that's simple, but not too simple, a block of 16 bits. We'll number the positions of these bits from 0 up to 15. The actual data we want to store is only going to make up 12 of these bits,  while 4 of the positions are reserved as a kind of redundancy. The word redundant here doesn't simply mean copy, after all,  those 4 bits don't give us enough room to blindly copy the data. Instead, they'll need to be a much more nuanced and clever kind of redundancy,  not adding any new information, but adding resilience. You might expect these 4 special bits to come nicely packaged together,  maybe at the end or something like that, but as you'll see,  having them sit in positions which are powers of 2 allows for something that's  really elegant by the end. It also might give you a little hint about how this scales for larger blocks. Also technically it ends up being only 11 bits of data,  you'll find there's a mild nuance for what goes on at position 0,  but don't worry about that for now. Like any error correction algorithm, this will involve two players,  a sender who's responsible for setting these 4 special bits,  and a receiver who's responsible for performing some kind of check and  correcting the errors. Of course, the words sender and receiver really refer to machines  or software that's doing all the checks, and the idea of a  message is meant really broadly, to include things like storage. After all, storing data is the same thing as sending a message just  from the past to the future instead of from one place to another. So that's the setup, but before we can dive in we need to talk about a related idea which  was fresh on Hamming's mind in the time of his discovery,  a method which lets you detect any single bit errors, but not to correct them,  known in the business as a parity check. For a parity check, we separate out only one single bit that the sender  is responsible for tuning, and the rest are free to carry a message. The only job of this special bit is to make sure that  the total number of 1s in the message is an even number. So for example right now, that total number of 1s is 7, that's odd,  so the sender needs to flip that special bit to be a 1, making the count even. But if the block had already started off with an even number of 1s,  then this special bit would have been kept at a 0. This is pretty simple, deceptively simple, but it's an incredibly elegant way to distill  the idea of change anywhere in a message to be reflected in a single bit of information. Notice if any bit of this message gets flipped, either from 0 to 1 or 1 to 0,  it changes the total count of 1s from being even to being odd. So if you're the receiver, you look at this message,  and you see an odd number of 1s, you can know for sure that some error has occurred,  even though you might have no idea where it was. In the jargon, whether a group of bits has an  even or odd number of 1s is known as its parity. You could also use numbers and say the parity is 0 or 1,  which is typically more helpful once you start doing math with the idea. And this special bit that the sender uses to control the parity is called the parity bit. And actually, we should be clear, if the receiver sees an odd parity,  it doesn't necessarily mean there was just one error, there might have been 3 errors,  or 5, or any other odd number, but they can know for sure that it wasn't 0. On the other hand, if there had been 2 errors, or any even number of errors,  that final count of 1s would still be even, so the receiver can't have full  confidence that an even count necessarily means the message is error-free. You might complain that a message which gets messed up by only  2 bit flips is pretty weak, and you would be absolutely right. Keep in mind, though, there is no method for error detection or correction that could  give you 100% confidence that the message you receive is the one the sender intended. After all, enough random noise could always change one  valid message into another valid message just by pure chance. Instead, the goal is to come up with a scheme that's robust up to a certain maximum  number of errors, or maybe to reduce the probability of a false positive like this. Parity checks on their own are pretty weak, but by distilling the  idea of change across a full message down to a single bit,  what they give us is a powerful building block for more sophisticated schemes. For example, as Hamming was searching for a way to identify where an error happened,  not just that it happened, his key insight was that if you apply some parity checks  not to the full message, but to certain carefully selected subsets,  you can ask a more refined series of questions that pin down the location of any  single bit error. The overall feeling is a bit like playing a game of 20 questions,  asking yes or no queries that chop the space of possibilities in half. For example, let's say we do a parity check just on these 8 bits,  all of the odd numbered positions. Then if an error is detected, it gives the receiver a little more information  about where specifically the error is, namely that it's in an odd position. If no error is detected among those 8 bits, it either means there's no error at all,  or it sits somewhere in the even positions. You might think that limiting a parity check to half the bits makes it less effective,  but when it's done in conjunction with other well-chosen checks,  it counterintuitively gives us something a lot more powerful. To actually set up that parity check, remember,  it requires earmarking some special bit that has control for the parity  of that full group. Here let's just choose position 1. For the example shown, the parity of these 8 bits is currently odd,  so the sender is responsible for toggling that parity bit, and now it's even. This is only 1 out of 4 parity checks that we'll do. The second check is among the 8 bits on the right half of the grid,  at least as we've drawn it here. This time we might use position 2 as a parity bit,  so these 8 bits already have an even parity, and the sender can feel good leaving  that bit number 2 unchanged. Then on the other end, if the receiver checks the parity of this group and they find  that it's odd, they'll know that the error is somewhere among these 8 bits on the right. Otherwise it means either there's no error, or the error is somewhere on the left half. Or I guess there could have been two errors, but for right now we're  going to assume that there's at most one error in the entire block. Things break down completely for more than that. Here, before we look at the next two checks, take a moment to think  about what these first two allow us to do when you consider them together. Let's say you detect an error among the odd columns, and among the right half. It necessarily means the error is somewhere in the last column. If there was no error in the odd column but there was one in the right half,  that tells you it's in the second to last column. Likewise if there is an error in the odd columns but not in the right half,  you know it's somewhere in the second column. And if neither of those two parity checks detects anything,  it means the only place that an error could be is in that leftmost column. But it also might simply mean there's no error at all. Which is all a rather belabored way to say that  two parity checks let us pin down the column. From here, you can probably guess what follows. We do basically the same thing but for the rows. There's going to be a parity check on the odd rows, using position 4 as a parity bit. So in this example that group already has an even parity, so bit 4 would be set to a 0. And finally there's a parity check on the bottom two rows,  using position 8 as a parity bit. In this case, it looks like the sender needs to turn  that bit 8 on in order to give the group even parity. Just as the first two checks let us pin down the column,  these next two let you pin down the row. As an example, imagine that during the transmission there's an error at, say, position 3. Well this affects the first parity group, and it also affects the second parity group,  so the receiver knows that there's an error somewhere in that right column. But it doesn't affect the third group, and it doesn't affect the fourth group. And that lets the receiver pinpoint the error up to the first row,  which necessarily means position 3, so they can fix the error. You might enjoy taking a moment to convince yourself that the  answers to these four questions really will always let you pin down a specific location,  no matter where they turn out to be. In fact, the astute among you might even notice a  connection between these questions and binary counting. And if you do, again let me emphasize, pause, try  for yourself to draw the connection before I spoil it. If you're wondering what happens if a parity bit itself gets affected,  well, you can just try it. Take a moment to think about how any error among these four special bits is going  to be tracked down just like any other, with the same group of four questions. It doesn't really matter, since at the end of the day what we want is to  protect the message bits, the error correction bits are just riding along. But protecting those bits as well is something that  naturally falls out of the scheme as a byproduct. You might also enjoy anticipating how this scales. If we used a block of size 256 bits, for example, in order to pin down a location,  you need only eight yes or no questions to binary search your way down to some specific  spot. And remember, each question requires giving up only  a single bit to set the appropriate parity check. Some of you may already see it, but we'll talk later about the  systematic way to find what these questions are in just a minute or two. Hopefully this sketch is enough to appreciate  the efficiency of what we're developing here. The first thing, except for those eight highlighted parity bits,  can be whatever you want it to be, carrying whatever message or data you want. The 8 bits are redundant in the sense that they're completely determined by the rest of  the message, but it's in a much smarter way than simply copying the message as a whole. And still, for so little given up, you would be  able to identify and fix any single bit error. Well, almost. Okay, so the one problem here is that if none of the four parity checks detect an error,  meaning that the specially selected subsets of 8 bits all have even parities,  just like the sender intended, then it either means there was no error at all,  or it narrows us down into position 0. You see, with four yes or no questions, we have 16 possible outcomes for our parity  checks, and at first that feels perfect for pinpointing 1 out of 16 positions in  the block, but you also need to communicate a 17th outcome, the no error condition. The solution here is actually pretty simple, just forget about that 0th bit entirely. So when we do our four parity checks and we see that they're all even,  it unambiguously means that there is no error. What that means is rather than working with a 16-bit block, we work with a 15-bit block,  where 11 of the bits are free to carry a message and 4 of them are there for redundancy. And with that, we now have what people in the  business would refer to as a 15-11 Hamming code. That said, it's nice to have a block size that's a clean power of 2,  and there's a clever way we can keep that 0th bit around and get it to do a little  extra work for us. If we use it as a parity bit across the whole block,  it lets us actually detect, even though we can't correct, 2-bit errors. Here's how it works. After setting those four special error-correcting bits,  we set that 0th one so that the parity of the full block is even,  just like a normal parity check. Now, if there's a single bit error, then the parity of the full block toggles to be odd,  but we would catch that anyway thanks to the four error-correcting checks. However, if there's two errors, then the overall parity is going to toggle  back to being even, but the receiver would still see that there's been at  least some error because of what's going on with those four parity checks. So if they notice an even parity overall, but something non-zero happening  with the other checks, it tells them there were at least two errors. Isn't that clever? Even though we can't correct those 2-bit errors,  just by putting that one little bothersome 0th bit back to work, it lets us detect them. This is pretty standard, it's known as an extended Hamming code. Technically speaking, you now have a full description of what a Hamming code does,  at least for the example of a 16-bit block. But I think you'll find it more satisfying to check your understanding and solidify  everything up to this point by doing one full example from start to finish yourself. I'll step through it with you though so you can check yourself. To set up a message, whether that's a literal message you're translating over space or  some data you want to store over time, the first step is to divide it up into 11-bit  chunks. Each chunk is going to get packaged into an error-resistant 16-bit block. So let's take this one as an example and actually work it out. Go ahead, actually do it! Let's pause and try putting together this block. Okay, you ready? Remember, position 0 along with the other powers of 2 are reserved for error correction  duty, so you start by placing the message bits in all of the remaining spots, in order. You need this group to have an even parity, which it already does,  so you should have set that parity bit in position 1 to be a 0. The next group starts off with an odd parity,  so you should have set its parity bit to be 1. The group after that starts with an odd parity,  so again you should have set its parity bit to 1. And the final group also has an odd parity, meaning  we set that bit in position 8 to be a 1. And then as the final step, the full block now has an even parity,  meaning you can set that bit number 0, the overarching parity bit, to be 0. So as this block is sent off, the parity of the four special  subsets and the block as a whole will all be even, or 0. As the second part of the exercise, let's have you play the role of the receiver. Of course, that would mean you don't already know what this message is,  maybe some of you memorized it, but let's assume that you haven't. What I'm going to do is change either 0, 1, or 2 of the bits in that block,  and then ask you to figure out what it is that I did. So again, pause and try working it out. Okay, so you as the receiver now check the first parity group and you can see  that it's even, so any error that exists would have to be in an even column. The next check gives us an odd number, telling us both that there's at least one error,  and narrowing us down into this specific column. The third check is even, chopping down the possibilities even further. And the last parity check is odd, telling us there's an error somewhere in the bottom,  which by now we can see must be in position number 10. What's more, the parity of the whole block is odd,  giving us confidence that there was one flip and not two. If it's three or more, all bets are off. After correcting that bit number 10, pulling out the 11 bits that were not  used for correction gives us the relevant segment of the original message,  which if you rewind and compare is indeed exactly what we started the example with. And now that you know how to do all this by hand,  I'd like to show you how you can carry out the core part of all of this logic with  a single line of Python code. You see, what I haven't told you yet is just how elegant this algorithm really is,  how simple it is to get a machine to point to the position of an error,  how to systematically scale it, and how we can frame all of this as one  single operation rather than multiple separate parity checks. To see what I mean, come join me in part 2.

================================================================================
VIDEO ID: mH0oCDa74tE
TITLE: Group theory, abstraction, and the 196,883-dimensional monster
URL: https://www.youtube.com/watch?v=mH0oCDa74tE
PUBLISHED: 2020-08-19T14:01:39Z
STATUS: SUCCESS
================================================================================
Today, many members of the YouTube math community are getting  together to make videos about their favorite numbers over 1 million,  and we're encouraging you, the viewers, to do the same. Take a look at the description for details. My own choice is considerably larger than a million, roughly 8x10 to the 53. For a sense of scale, that's around the number of atoms in the planet Jupiter,  so it might seem completely arbitrary. But what I love is that if you were to talk with an alien civilization or a  super-intelligent AI that invented math for itself without any connection to  our particular culture or experiences, I think both would agree that this  number is something very peculiar and that it reflects something fundamental. What is it, exactly? Well, it's the size of the monster, but to explain what that  means we're going to need to back up and talk about group theory. This field is all about codifying the idea of symmetry. For example, when we say a face is symmetric, what we mean is that you  can reflect it about a line and it's left looking completely the same. It's a statement about an action that you can take. Something like a snowflake is also symmetric, but in more ways. You can rotate it 60 degrees or 120 degrees, you can flip it along  various different axes, and all these actions leave it looking the same. A collection of all the actions like this taken together is called a group. Kind of, at least. Groups are typically defined a little more abstractly than this,  but we'll get to that later. Take note, the fact that mathematicians have co-opted such an  otherwise generic word for this seemingly specific kind of  collection should give you some sense of how fundamental they find it. Also take note, we always consider the action of doing nothing to be part of the group. So if we include that do-nothing action, the group of  symmetries of a snowflake includes 12 distinct actions. It even has a fancy name, D6. The simple group of symmetries that only has two  elements acting on a face also has a fancy name, C2. In general, there is a whole zoo of groups with no shortage of jargon to their  names categorizing the many different ways that something can be symmetric. When we describe these sorts of actions, there's  always an implicit structure being preserved. For example, there are 24 rotations that I can apply to a cube that leave it  looking the same, and those 24 actions taken together do indeed constitute a group. But if we allow for reflections, which is a kind of way of saying  that the orientation of the cube is not part of the structure we intend to preserve,  you get a bigger group, with 48 actions in total. If you loosen things further and consider the faces to be a little less rigidly attached,  maybe free to rotate and get shuffled around, you would get a much larger set of actions. And yes, you could consider these symmetries in the sense that they  leave it looking the same, and all of these shuffling rotating actions  do constitute a group, but it's a much bigger and more complicated group. The large size in this group reflects the much  looser sense of structure which each action preserves. The loosest sense of structure is if we have a collection of points and we consider  any way you could shuffle them, any permutation, to be a symmetry of those points. Unconstrained by any underlying property that needs to be preserved,  these permutation groups can get quite large. Here, it's kind of fun to flash through every possible  permutation of six objects and see how many there are. In total, it amounts to 6! or 720. By contrast, if we gave these points some structure,  maybe making them the corners of a hexagon and only considering the permutations that  preserve how far apart each one is from the other,  well then we only get the 12 snowflake symmetries we saw earlier. Bump the number of points up to 12, and the number  of permutations grows to about 479 million. The monster we'll get to is rather large, but it's important to understand  that largeness in and of itself is not that interesting when it comes to groups. The permutation groups already make that easy to see. If we were shuffling 101 objects, for example,  with the 101 factorial different actions that can do this,  we have a group with a size of around 9x10 to the 159. If every atom in the observable universe had a copy of that universe inside itself,  this is roughly how many sub-atoms there would be. These permutation groups go by the name S-sub-n,  and they play a very important role in group theory. In a certain sense, they encompass all other groups. And so far you might be thinking, okay, this is intellectually playful enough,  but is any of this actually useful? One of the earliest applications of group theory came when  mathematicians realized that the structure of these permutation  groups tells us something about solutions to polynomial equations. You know how, in order to find the two roots of a quadratic equation,  everyone learns a certain formula in school? Slightly lesser known is the fact that there's also a cubic formula,  one that involves nesting cube roots with square roots in a larger expression. There's even a quartic formula for a degree 4 polynomial, which is an absolute mess. It's almost impossible to write without factoring things out. And for the longest time, mathematicians struggled  to find a formula to solve degree 5 polynomials. Maybe there's one, but it's just super complicated. It turns out, though, if you think about the group which permutes  the roots of such a polynomial, there's something about the  nature of this group that reveals no quintic formula can exist. For example, the five roots of the polynomial you see on screen now have definite values,  you could write out decimal approximations, but what you can never do is write those  exact values by starting with the coefficients of the polynomial and using only the four  basic operations of arithmetic together with radicals,  no matter how many times you nest them. And that impossibility has everything to do with  the inner structure of the permutation group S5. A theme in math through the last two centuries has been that  the nature of symmetry in and of itself can show us all sorts  of non-obvious facts about the other objects that we study. To give just a hint of the many many ways that this applies to physics,  there's a beautiful fact known as Noether's theorem saying that every  conservation law corresponds to some kind of symmetry, a certain group. So all those fundamental laws like conservation of momentum  and conservation of energy each correspond to a group. More specifically, the actions we should be able to apply  to a setup such that the laws of physics don't change. All of this is to say that groups really are fundamental,  and the one thing I want you to recognize right now is that they are one of the most  natural things that you could study. What could be more universal than symmetry? So you might think that the patterns among groups  themselves would somehow be very beautiful and symmetric. The monster, however, tells a different story. Before we get to the monster, though, at this point some mathematicians  might complain that what I've described so far are not groups exactly,  but group actions, and that groups are something slightly more abstract. By way of analogy, if I mention the number 3, you  probably don't think about a specific triplet of things. You probably think about 3 as an object in and of itself,  an abstraction, maybe represented with a symbol. In much the same way, when mathematicians discuss the elements of a group,  they don't necessarily think about specific actions on specific objects,  they might think of these elements as a kind of thing in and of itself,  maybe represented with a symbol. For something like the number 3, the abstract symbol does us very little good unless we  define its relation with other numbers, for example the way it adds or multiplies with  them. For each of these, you could think of a literal triplet of something, but again,  most of us are comfortable, probably even more comfortable, using the symbols alone. Similarly, what makes a group a group are all of  the ways that its elements combine with each other. And in the context of actions, this has a very vivid meaning. What we mean by combining is to apply one action after the other, read from right to left. If you flip a snowflake about the x-axis, then rotate it 60 degrees counterclockwise,  the overall action is the same as if you had flipped it about a diagonal line. All possible ways that you can combine two elements  of a group like this defines a kind of multiplication. That is what really gives a group its structure. Here, I'm drawing out the full 8x8 table of the symmetries of a square. If you apply an action from the top row and follow it by an action from the left column,  it'll be the same as the action in the corresponding grid square. But if we replace each one of these symmetric actions with something purely symbolic,  well, the multiplication table still captures the inner structure of the group,  but now it's abstracted away from any specific object that it might act on,  like a square or roots of a polynomial. This is entirely analogous to how the usual multiplication table is written symbolically,  which abstracts away from the idea of literal counts. Literal counts, arguably, would make it much clearer what's going on,  but since grade school we all grow comfortable with the symbols. After all, they're less cumbersome, they free us to think about more complicated numbers,  and they also free us to think about numbers in new and very different ways. All of this is true of groups as well, which are best  understood as abstractions above the idea of symmetry actions. I'm emphasizing this for two reasons. One is that understanding what groups really are gives a better  appreciation for the monster, and the other is that many students  learning about groups for the first time can find them frustratingly opaque. I know that I did. A typical course starts with this very formal and abstract definition,  which is that a group is a set in a collection of things,  with a binary operation, a notion of multiplication between those things,  such that this multiplication satisfies four special rules, or axioms. And all of this can feel, well, kind of random,  especially when it isn't made clear that all of these axioms arise from  the things that must obviously be true when you're thinking about actions  and composing them. To any students among you with such a course in the future,  I would say if you appreciate that the relationship groups have with symmetric actions  is analogous to the relationship numbers have with counts,  it can help to make the course a lot more grounded. An example might help to see why this kind of abstraction is desirable. Consider the symmetries of a cube and the permutation group of four objects. At first, these groups feel very different. You might think of the one on the left as acting on eight corners in  a way that preserves the distance and orientation structure among them. But on the right, we have a completely unconstrained  set of actions on a much smaller set of points. As it happens, though, these two groups are really the same,  in the sense that their multiplication tables will look identical. Anything that you can say about one group will be true of the other. For example, there are eight distinct permutations where applying it three  times in a row gets you back to where you started, not counting the identity. These are the ones that cycle three different elements together. There are also eight rotations of the cube that have this property,  the various 120 and 240 degree rotations about each diagonal. This is no coincidence. The way to phrase this more precisely is to say there is a one-to-one mapping between  rotations of a cube and permutations of four elements, which preserves composition. For example, rotating 180 degrees about the y-axis followed by 180 degrees about  the x-axis gives the same overall effect as rotating 180 degrees around the z-axis. Remember, that's what we mean by a product of two actions. And if you look at the corresponding permutations under a certain one-to-one association,  this product will still be true. Applying the two actions on the left gives the  same overall effect as the one on the right. When you have a correspondence where this remains true for all products,  it's called an isomorphism, which is maybe the most important idea in group theory. This particular isomorphism between cube rotations and permutations of four  objects is a bit subtle, but for the curious among you,  you may enjoy taking a moment to think hard about how the rotations of a cube  permute its four diagonals. In your mathematical life, you'll see more examples of a given  group arising from seemingly unrelated situations, and as you do,  you'll get a better sense for what group theory is all about. Think about how a number like 3 is not really about a particular triplet of things,  it's about all possible triplets of things. In the same way, a group is not really about symmetries of a particular object,  it's an abstract way that things can even be symmetric. There are even plenty of situations where groups come up in a way that does not feel  like a set of symmetric actions at all, just as numbers can do a lot more than count. In fact, seeing the same group come up in different situations is a great way to reveal  unexpected connections between distinct objects,  that's a very common theme in modern math. And once you understand this about groups, it leads you to a natural question,  which will eventually lead to the monster. What are all the groups? But now you're in a position to ask that question in a more sophisticated way. What are all the groups up to isomorphism? Which is to say, we consider two groups to be  the same if there's an isomorphism between them. This is asking something more fundamental than what are all the symmetric things. It's a way of asking, what are all the ways that something can be symmetric? Is there some formula or procedure for producing them all,  some meta-pattern lying at the heart of symmetry itself? This question turns out to be hard, exceedingly hard. For one thing, there's the division between infinite groups,  for example the ones describing the symmetries of a line or a circle,  and finite groups, like the ones we've looked at up to this point. To maintain some hope of sanity, let's limit our view to finite groups. In the same way that numbers can be broken down into their prime factorization,  or molecules can be described based on the atoms within them,  there's a certain way that finite groups can be broken down into a kind of composition  of smaller groups. The ones which can't be broken down any further,  analogous to prime numbers or atoms, are known as the simple groups. To give a hint for why this is useful, remember how we said that  group theory can be used to prove that there's no formula for  a degree 5 polynomial the way there is for quadratic equations? Well, if you're wondering what that proof actually looks like,  it involves showing that if there were some kind of mythical quintic formula,  something which uses only radicals and the basic arithmetic operations,  it would imply that the permutation group on 5 elements decomposes into a  special kind of simple group, known fancifully as the cyclic groups of prime order. But the actual way that this breaks down involves a different kind of simple group,  a different kind of atom, one which polynomial solutions built from radicals would never  allow. That is a super high-level description of course,  with about a semester's worth of details missing,  but the point is that you have this really not obvious fact about a different part of  math whose solutions come from finding the atomic structure of a certain group. This is one of many different examples where understanding the nature of  these simple groups, these atoms, actually matters outside of group theory. The task of categorizing all finite groups breaks down into two steps. One, find all the simple groups, and two, find all of the ways to combine them. The first question is like finding the periodic table,  and the second is a bit like doing all of chemistry thereafter. The good news is that mathematicians have found all of the finite simple groups. Well, more pertinent is that they proved that the ones they found are,  in fact, all the ones out there. It took many decades, tens of thousands of dense pages of advanced math,  hundreds of some of the smartest minds out there, and significant help from computers. But by 2004, with a culminating 12,000 pages to tie up the loose ends,  there was a definitive answer. Many experts agree, this is one of the most monumental  achievements in the history of math. The bad news, though, is that the answer is absurd. There are 18 distinct infinite families of simple groups,  which makes it really tempting to lean into the whole periodic table analogy. But groups are stranger than chemistry, because there are also these 26  simple groups that are just left over, they don't fit the other patterns. These 26 are known as the sporadic groups. That a field of study rooted in symmetry itself has such a patched  together fundamental structure is, well I mean it's just bizarre. It's like the universe was designed by committee. If you're wondering what we mean by an infinite family, examples might help. One such family of simple groups includes all of these cyclic groups with prime order. These are essentially the symmetries of a regular polygon with a prime number of sides,  but where you're not allowed to flip the polygon over. Another of these infinite families is very similar to the permutation groups we saw  earlier, but there's the tiniest constraint on how they're allowed to shuffle n items. If they act on 5 or more elements, these groups are simple. Which incidentally is heavily related to why polynomials with degree  5 or more have solutions that can't be written down using radicals. The other 16 families are notably more complicated,  and I'm told that there's at least a little ambiguity in how to organize  them into cleanly distinct families without overlap,  but what everybody agrees on is that the 26 sporadic groups stand out  as something very different. The largest of these sporadic groups is known, thanks to John Conway,  as the monster group, and its size is the number I mentioned at the start. The second largest, and I promise this isn't a joke, is known as the baby monster group. Together with the baby monster, 19 of these sporadic groups are in a certain  sense children of the monster, and Robert Gries called these 20 the happy family. He also called the other six, which don't even fit that pattern, the pariahs. As if to compensate for how complicated the underlying math here is,  the experts really let loose on their whimsy while naming things. Let me emphasize, having a group which is big is not that big a deal,  but the idea that one of the fundamental building blocks for one of the most  fundamental ideas in math comes in a collection that just abruptly stops around  8x10 to the 53. That's weird. Now, at this point, given that I introduced groups as symmetries,  a collection of actions, you might wonder what it is that the monster acts on. What object does it describe the symmetries of? Well, there is an answer, but it doesn't fit into two or three dimensions to draw,  nor does it fit into four or five. Instead, to see what the monster acts on, we would have to jump up to... Wait for it... 196,883 dimensions. Just describing one of the elements of this group takes about 4 GB of data,  even though plenty of groups that are way bigger have a much smaller computational  description. The permutation group on 101 elements was, if you'll recall,  dramatically bigger, but we can describe each one of its elements with very little data,  for example a list of 100 numbers. Why the Sporadic Groups? No one really understands why the sporadic groups,  and the monster in particular, are there. Maybe in a few decades there will be a clearer answer,  maybe one of you will come up with it, but despite knowing that they are  deeply fundamental to math, and arguably to physics as well,  a lot about them remains mysterious. In the 1970s, mathematician John McKay was making a switch from studying  group theory to an adjacent field, and he noticed that a number very similar  to this 196,883 showed up in a completely unrelated context, or at least almost. A number one bigger than this was in the series expansion of a  fundamental function in a totally different part of math,  relevant to these things called modular forms and elliptic functions. Assuming that this was more than a coincidence seemed crazy,  enough that it was playfully deemed moonshine by John Conway. But after more numerical coincidences like this were noticed,  it gave rise to what became known as the monstrous moonshine conjecture. Whimsical names just don't stop. This was proved by Richard Borcherds in 1992, solidifying a connection  between very different parts of math that at first glance seemed crazy. Six years later, by the way, he won the Fields Medal,  in part for the significance of this proof. And related to this moonshine is a connection between the monster and string theory. Maybe it shouldn't come as a surprise that something that arises from  symmetry itself is relevant to physics, but in light of just how random  the monster seems at first glance, this connection still elicits a double take. To me, the monster and its absurd size is a nice reminder  that fundamental objects are not necessarily simple. The universe doesn't really care if its final answers look clean. They are what they are by logical necessity, with no  concern over how easily we'll be able to understand them.

================================================================================
VIDEO ID: wTJI_WuZSwE
TITLE: The impossible chessboard puzzle
URL: https://www.youtube.com/watch?v=wTJI_WuZSwE
PUBLISHED: 2020-07-05T18:50:36Z
STATUS: SUCCESS
================================================================================
You walk alone into a room and find a chessboard. Each of the 64 squares has a coin sitting on top of it. Taking a step back, this is one of those classic prisoner puzzles where a  strangely math-obsessed warden offers you and a fellow inmate a chance for freedom,  but only if the two of you solve some elaborate scheme they've laid out. In this case, what they've done is carefully turned over each of the coins to be heads  or tails according to whatever pattern they want it to be, and then they show you a key. They put that key inside one of the chessboard squares,  each square is a secret compartment or something like that, so you know where the key is. The goal is to get prisoner number 2 to also know where the key is,  but the only thing that the warden allows you to do before you  leave the room is to turn over one and only one of these coins. At that point, you walk out, your fellow prisoner walks in,  and with no information other than the set of heads and tails they're looking at,  which you've only barely tweaked, they're supposed to deduce where the key is hidden,  potentially winning freedom for the both of you. As is typical with these puzzles, the two of you can strategize ahead of time  if you want, but you won't know what the specific layout of heads and tails is,  and moreover the warden can listen in on your strategy and do their absolute  best to thwart it with some adversarial arrangement of the coins and the key. So, I first heard about this puzzle over dinner conversation at a wedding,  and it totally sucked me in. I remember the drive home was maybe 3 hours, and I think my mind was  glued to the topic of flipping coins and encoding state that whole time. But the puzzle sticks with you even after that. After I solved it, I fell into these two surprisingly interesting rabbit holes. One was to prove that the challenge is actually impossible if you vary the setup a  little bit, maybe making it a 6x6 chessboard, or maybe removing one of the squares. And to give you a little sense for where that rabbit hole leads,  this video is going to end with an especially pleasing way to paint the corners of  a 4-dimensional cube. The other rabbit hole was to work out how closely you can connect  the solution of this puzzle with error correction,  which is a super important topic in computer science and information theory. The idea is that when computers send and store data,  the messiness of the real world inevitably flips a bit now and then,  and that can completely change how the data is read. So error correcting codes are a way to add a shockingly small amount of  information to a message that makes it possible for the receiver to identify  both when there is an error, and more impressively, precisely how to fix it. It turns out that the intuition for solving this puzzle is essentially  the same as the intuition behind these things called Hamming codes,  which are one of the earliest examples of highly efficient error correction. Which is all to say, time spent mulling over this  problem is not as useless as you might think it is. Now you and I aren't actually going to go through the solution here. Instead, I filmed a video all about that on standup maths with Matt Parker,  who I'm sure many of you recognize from his combined YouTube and standup and book fame. We each talk through our thought process in solving it,  and it's good fun, because there are multiple ways of looking at it. Instead, what I want to do with you here is take a more global view  of every possible strategy for this puzzle, and bring you with me down  that first rabbit hole of proving why certain variations necessarily  leave room for the warden to thwart you, no matter how clever you are. The proof itself is one of those satisfying moments where you shift  perspective and it reveals the solution, and the whole context leading  up to it is a nice chance to practice reasoning about higher dimensional  objects as a way to draw conclusions about information and data. Plus, it does more to help you appreciate the solution to the original  puzzle when you can see how it is, in a sense, almost impossible. Where to start? What we want is some kind of visualization for what it even means to solve this puzzle. And to build up to the general case, let's knock things down to the  simplest case that we can that still has any kind of meaning to it. Two squares, two coins, and two possibilities for where the key is. One way that you could solve this is to simply  let the second coin communicate where the key is. If it's tails, it means the key is in the left square. If it's heads, it means the key is in the right square. Not a big deal, right? It's one bit of information, so when you need to change that coin, you can flip it,  but if you don't need to change it, you can just flip the other coin. First things first, let's stop thinking about these as  heads and tails and start thinking of them as ones and zeros. That's much easier to do math with. Then you can think of these pairs of coins as a set of coordinates,  where each of the four possible states that the board can be in sit at the corners of a  unit square, like this. This might feel like a silly thing to do when we already know how to solve this case,  but it's a good warmup for turning the larger cases into a kind of geometry. Notice, flipping one of the coins moves you along an edge of the square,  since it's only changing one of the coordinates. Our strategy of letting that second coin encode the key location could  be drawn by associating the bottom two corners, where the y-coordinate is 0,  with the key is under square zero state, which means those top two  corners are associated with the key is under square one state. So think about what it means for our solution to actually work. It means that no matter where you start, if you're forced to take a step along an edge,  forced to flip one of the coins, you can always guarantee that you  end up in whichever of these two regions you want to. Now the question is, what does it look like for a bigger chess board? The next simplest case would be three squares,  three coins, and three possibilities for where the key is. This gives us eight possible states that the coin can be in. Playing the same game we did before, interpreting these states as coordinates,  brings us up into three-dimensional space, with each state sitting at the corner of a  unit cube. The usefulness in a picture like this is that it gives a very  vivid meaning to the idea of turning over one of the coins. Every time you flip a coin, you're walking along the edge of a cube. Now, what would it mean for you and your fellow inmate to have a strategy for this puzzle? Whenever prisoner two walks into that room, they need to be able to associate the  state that they're looking at, three bits basically, with one of three possible squares. We're already thinking very visually, so let's associate those squares with colors,  maybe red for square zero, green for square one, and blue for square two. In this conception, coming up with a strategy, any possible strategy,  is the same thing as coloring each of the eight corners of the cube, either red,  green, or blue. So for example, let's say you colored the whole cube red. Well, I don't know if you'd call this a strategy exactly,  but it would correspond with always guessing that the key is under square zero. Let's say instead your strategy was to add the first two coins together and use  that as an encoding for the key location, well then the cube would look like this. What's kind of fun is we can count how many total strategies exist. With three choices for the color of each vertex and eight total vertices,  we get 3 to the power 8. Or if you're comfortable letting your mind stray to the thought of painting  a 64-dimensional cube, you can have fun thinking about the sense in which  there are 64 to the 2 to the 64 total possible strategies for the original puzzle. This is the size of the haystack when you're looking for the needle. Another attempt for the 3-square case might look like taking 0 times coin 0 plus  1 times coin 1 plus 2 times coin 2, and then reduce that some mod 3 if you need to. Over on Stand Up Maths, Matt and I both talk about trying a version  of this for the 64-square case, and why it works decently well  for a random arrangement of coins, but why it's ultimately doomed. From our view over here, it just looks like one more way to color the cube,  but it's worth taking a moment to walk through some of those corners. Let's say you get into the room and all three coins are set to tails,  so it's like you're starting at the corner 0,0,0. If you were to flip coin 0, that doesn't change the sum,  so it takes you to another red corner. If you flipped coin 1, it increases the sum by 1, so it takes you to a green corner. And flipping coin 2 takes you up to 2, which looks like a blue corner. The fact that you always have access to whichever color you want is a reflection of  the fact that this strategy will always win if this is the corner you're starting on. On the other hand, let's say you started at 0,1,0. In that case, flipping coin 0 takes you to another green corner,  since it doesn't change the sum, but flipping either coin 1 or coin 2 take you  to a red corner. There's simply no way to get to a blue corner. Basically, what's happening here is that you have the options to  subtract 1 by turning off coin 1, or to add 2 by turning on coin 2,  and if you're working mod 3, those are both actually the same operation. But that means there's no way to change the sum to be 2. An adversarial warden who knows your strategy could start with this configuration,  put the key under square 2, and call it done. But even without thinking about sums mod 3 or anything like that,  whatever the implementation details, you can see this in our picture,  manifested as a corner that has two neighbors of the same color. If you don't have a bird's eye view of all possible strategies,  when you find that any specific one of them just doesn't work, you're left to wonder,  okay, maybe there's a sneaky clever strategy that I just haven't thought of yet. But when we're thinking about colors on the cube,  you're naturally led to an interesting combinatorial question. Is there some way you can paint this so that the three neighbors  of any given vertex always represent red, green, and blue? Maybe it seems bizarre, even convoluted, to go from a puzzle with  chessboards and coins to talking about painting corners of a cube,  but this is actually a much more natural step than you might expect. I've talked with a lot of people about this puzzle,  and what I love is that many of the experienced problem solvers immediately jump,  unprompted, to talking about coloring the corners of a cube,  as if it's a kind of de facto language for this puzzle. And it really is. Thinking about binary strings as vertices of a high dimensional cube,  with bit flips corresponding to edges, that actually comes up a lot,  especially in coding theory, like the error correction stuff I referenced earlier. What's more, you often hear mathematicians talk about coloring  things as a way to describe partitioning them into distinct sets. If you've ever heard of that hilariously enormous number grams constant,  for example, the problem where that came up was also phrased in terms  of assigning colors to a high dimensional cube,  though in that case colors were given to pairs of vertices instead of individual ones. The point is, analyzing how to color a high dimensional  cube is more of a transferable skill than you might expect. So to our question, can you make it so that every vertex has a red,  a green, and a blue neighbor? Remember, this is the same thing as having an encoding for key locations so that  you're always one flip away from communicating whichever location you want to. It would actually be enlightening if you paused the video and tried this now. It's like a weird three-dimensional variant of a sudoku. Very similar to sudoku's, in the sense that you want  certain subsets to be filled with all three possible states. For example, you might start by painting one of the corners an arbitrary color,  let's say red, so you know its three neighbors need to be red,  green, and blue, doesn't really matter how you do it. And then maybe we move to the red neighbor and say that the other  two adjacencies need to be green and blue, maybe we do it like this. But at least how I've drawn it here, you're stuck,  you're unable to choose a correct color for the next two. Can you see why? What I'd like to share is a lovely little argument that explains  not only why this will never work in three dimensions,  but also why it can't work in any dimension that's not a power of two. The idea is that the symmetry in the property that we're looking at will end up  implying that there have to be an equal number of red, green, and blue vertices.  But that would mean that there's eight-thirds of each, which is not possible. And before I go on, pause and see if you can think of a way to solidify that intuition. It's a fun exercise in turning a vague instinct into a solid proof. Alright, you ready? One way to do this is to imagine a process where you go through each  corner and count how many of its neighbors are a particular color, say red. So, each step here, we're looking at the three neighbors of a given vertex,  counting up the red ones, and adding that to a total tally. For this specific coloring, that count came out to be 12,  but if we had the property we wanted, every corner would have exactly one red neighbor,  so that count should be 8. On the other hand, every red corner is counted exactly three times,  once for each instance where it's somebody's neighbor,  so that final tally has to be three times the total number of red corners. So, you know, it's simple. Find a coloring where eight-thirds of the corners are red. Isn't that nice? Counting how many times some corner has a red neighbor is the same as counting how  many times a red corner has some neighbor, and that's enough to get us a contradiction. What's also nice is that this argument immediately generalizes to higher dimensions. Think about solving the chessboard puzzle with n squares. Again, the puzzle is to associate each arrangement of coins with some state,  some possible location for the key. And the goal is to make it so that the arrangements you can get to with one flip of a  coin represent all possible states, all possible places the warden might have hidden that  key. Even if you can't visualize most higher dimensional cubes,  we can still talk about things like vertices of such a cube and their neighbors,  basically as a way to describe bitstrings and the ones which are one bitflip away. Really, there's just two relevant facts you need to know. If you're standing at one of these vertices, you have n distinct neighbors,  and the total number of vertices is 2 to the n, one for each bitstring of length n. From here, you can play the same game we did in three dimensions. You can go through each corner and count how many red neighbors it has. If it's possible to do the coloring we want, this sum should be 2 to the n,  one for each vertex. On the other hand, each red corner is counted once for each of its neighbors,  so that means that we need to end up with n times the total number of red corners. Since that left hand side is a power of 2, the right hand side also has to be a  power of 2, which could only ever happen if n itself is some smaller power of 2. So for example, if we were in 4 dimensions, or 64 dimensions, there is no contradiction. It's at the very least possible to evenly divide the vertices among the different colors. To be clear, that is not the same thing as saying there necessarily is a  solution for the power of 2 case, it's just that it can't be ruled out yet. To me, this is completely delightful. Just by imagining coloring the corners of a cube, and then counting how many there are,  you can conclude that no possible strategy, no matter how clever you are,  can work in all of the cases for this chessboard puzzle,  if the number of squares isn't a power of 2. So even though it might seem to make it easier if you knock off a couple  squares or reduce the size of the board, it actually makes the task hopeless. It also means that the solution to this puzzle, which I'll point you to in a moment,  can be viewed as a particularly symmetric way to color the corners of a high  dimensional cube in a way that's disallowed in most dimensions. And if you're curious, I just couldn't resist  showing this explicitly for a 4-dimensional cube. So in the same way that you can take a 3d cube and kind of squish it down  into 2 dimensions, maybe with a little perspective,  and get the same graph structure for how the vertices and edges are all connected,  we can do the same thing projecting a 4-dimensional cube into 3-dimensional space,  and still get a complete view for how all of the vertices and edges are hooked together. If you wanted to try your hand at a weird sort of 4-dimensional cousin of a sudoku,  you could pause right now and try to figure out how to color these vertices in such  a way that each of the 4 neighbors of any one represent all 4 different colors. Using essentially the same computation that solves the chessboard puzzle for  the 4-square case, I can get the computer to explicitly draw that out for us. And at this point, when you're hopefully burning to know what the actual solution is,  I'd like you to hop on over to Stand Up Maths, where Matt and I show you how it works. If any of you are somehow not yet familiar with Stand Up Maths,  it's one of my favorite channels run by one of my favorite people,  so please do immediately subscribe once you land over there. I promise, you're in for quite a few delights with everything else he has to offer. Before explaining it, he and I simply walk through what it looks like for us to  actually perform the solution, and as we do, I really want you to try thinking  of the solution yourself, and to predict what it is we're doing before we tell you. And if you're curious about the connection with Hamming codes and error correction,  I'm definitely game to make a video on that, just let me know in the comments. I've been told that as far as motivating puzzles go,  not everyone is as interested in symmetrical ways to paint a 64-dimensional cube as I am. But reliable data transmission? Come on, I think we can all agree that that's universally sexy.  Come on, I think we can all agree that that's universally sexy. you

================================================================================
VIDEO ID: QvuQH4_05LI
TITLE: Tips to be a better problem solver [Last live lecture] | Ep. 10 Lockdown live math
URL: https://www.youtube.com/watch?v=QvuQH4_05LI
PUBLISHED: 2020-05-22T20:14:56Z
STATUS: SUCCESS
================================================================================
Welcome back, everybody. It's hard to define exactly what mathematicians  mean when they use the phrase problem solving. However you go about it, it's going to involve some notion of  approaching puzzles that you've never seen before and still being  able to systematically and creatively find some solution to them. But that's a weird thing when you think about it  because it makes it a very hard thing to teach. I mean, you can teach someone how to solve one particular problem,  maybe even a class of problems, and teach them how to solve another problem. But how do you teach someone how to approach a problem that  they've never seen before and still make progress on it? Well, I honestly don't know how, but what I want to do for this  lecture is to talk through a couple different problem solving principles. I've enumerated nine of them in total, and each one we're  going to walk through in the context of a specific example. And I think each one is kind of simple. You'll look at it and you'll nod along thinking, yeah,  yeah, of course, that's a thing that you should do. But I would argue that each one is deceptively simple,  that you would be shocked at how often you can make very meaningful  progress in very hard problems just by keeping some of these tips in  the back of your mind. And to give you a little flavor for where we're going to be going today,  I want to ask, not as a quiz that I expect you to necessarily be able to solve  here on the spot, I want to ask you a question that we will be solving later  on in the lecture, just so you can have it in the back of your mind,  a little thing to mull over, and a hard problem that will be fun to tackle when  the time comes. So the question asks, suppose the two numbers are chosen at random from  the range 0 through 1, and it's done according to a uniform distribution. So maybe you pick like 0.385 and 0.58962 or something like that. Each one is chosen at random. Suppose p is the probability that the ratio of the  first number to the second rounds down to an even number. So, you know, maybe it rounds down to 0 or it rounds down to 2 or to 4. And basically it's asking you to guess where is this probability, you know? We'll solve it exactly, we'll get an exact expression. But just intuitively as you hear the problem and you think  of choosing two random numbers between 0 and 1,  looking at their ratio, what do you think that probability is going to be? We'll return back to this later. And one thing I want to say is that this whole live quizzing software,  it's something that's being built by some friends of mine, Ben Eater,  who many of you may know because of his YouTube fame,  and then another person who used to work with us at Khan Academy named Cam Christensen. And this is just one small little outcropping  of what's actually a much deeper product at play. And I want to give you a little preview of some of the other  things that they've been working on that we'll be developing. So if any of you want to share some of the lectures here or go back and kind of go  through the live quizzing experience, if you go to the link that it's in the description,  but it's at itempool.com slash c slash 3b1b, but you can follow the description. You can basically watch the lectures in a way where you can do these live quizzes  along with it and your progress is tracked and you get scores and things like that. So as you skip ahead to various different questions,  it will skip you to the right point in the video. And as the video plays forward, you'll also get to, yeah,  there's just me talking through some problem, you'll also get to whatever the appropriate  part of the problem is. They often have explanations associated with them and hints and things like that. And ultimately, if you look back in just a couple days,  I'm going to fill out like homework and challenge problems. So if you like challenging problem solving, contest math type stuff,  I'm going to put things that are relevant to the lectures in there,  which I think should be fun. It's not quite there yet, but definitely check back. And I'm sure just over the next couple months  there will be more item pool shenanigans going on. If any of you want to use this, maybe to do some live polling in your own  live classes for teachers who are dealing with the whole remote landscape. Or if you have your own streams, anything like that. They are looking for beta users, so feel free to reach out to them. It should be available on the website. Now let's dive into the actual content, shall we? Some of the nine deceptively simple problem solving tricks. And before we do, I want to specify that at some point today,  in the next hour, I'm going to purposefully make a mistake. Okay, and I tell you that for two reasons. One, so that you keep your eye out and you, you know,  you're a little bit skeptical of each of the claims that I make. And two, so that when I make that mistake and you notice it, and you're just,  you know, throwing things at the screen, you're getting angry,  you're clicking that unsubscribe button, you can at least quell a little bit of  what you're thinking. So just keep that in mind. There will be one very purposeful mistake. Now before we get to the problem solving tip, I want to talk about geometry. This is one thing I was hoping to do a little bit more of in this series,  but this would be just a fun time to give a little example of it. And in particular, I want to talk about one of my favorite little bits of geometry. It's not too simple, but it's also not too hard. It's called the inscribed angle theorem. It comes up way more than is reasonable for a simple little  theorem like this to actually come up when you're solving problems. Okay. And basically an inscribed angle of a circle refers to if you have two lines that  meet at a point of that circle, and what we care about is this little angle in here. Okay. And if you were just studying this, if you're an early mathematician trying  to make sense out of this, you might make a guess that something about this  angle is going to be related to the arc of the circle that those lines hit. I mean that arc can also be described as an angle of some kind if we draw  lines from the center of the circle, it makes it a little bit clearer. So I'm just going to draw a couple green lines  here and mark that we have a different angle here. And maybe I give them names. I'll call this one theta L for like the large angle,  and this one I'm going to call theta S. It's the small angle. And you might wonder is there a relationship between these two angles? And if so, what is it? And for our purposes today, the question is how  do you systematically approach a puzzle like this? Find a relationship between these two and prove, prove its existence. So problem solving tip, not problem sip, problem solving tip number one,  which is just, just so useful in a way that again is kind of deceptively simple. Make sure you're always using the defining features of whatever your setup is. I swear a good 70% of the problem sets that I did as an undergraduate  math major essentially came down to looking at what was given,  asking very critically what is the definition of each term involved here,  unraveling those definitions, and then just seeing how they piece together. So use whatever's the defining feature. In our context, what is defining the various points and intersections that we have here? Well, it's the idea that they're on a circle. A circle is by definition all of the points that are a common distance from the center. So in particular, we know that this length is a radius  of the circle and this length is a radius of the circle. We should use the fact that those are the same. But moreover this other point P, that was not just chosen at random,  it's defined to be on the circle. And unraveling what that means, it means it is a common distance away  and is the same distance away from the center as these other points. So I am then inspired to draw a line to add something  to the picture and to note that it's the same there. You know quite often when you see people solve hard geometry problems,  it comes down to adding something to the picture. And the most beautiful geometry involves adding something that seems out of  left field and it just illuminates everything, you shift your perspective. And sometimes you look at it and you wonder like, how would you have known what to add? Like again, I'm supposed to draw an extra circle here or put a, you know,  put a rectangle around this triangle, whatever it is you're doing. But how do you, how do you systematically know what you should add? So in this context, if it relates to the definition of your objects, probably a good idea. And that line actually will be helpful to us. We can start giving a couple things names. That's something that again, maybe it shouldn't even be described as a tip,  but I've put it down as number two, that when you give things meaningful names,  that actually helps you move forward in your problem. And in this context, it might seem like an innocuous thing. I'll call this little angle that we formed with  our radius alpha and this little angle beta. And just to see if that helps us move forward, you know,  recognizing if alpha and beta show up elsewhere, rather than me telling you,  I would like you to tell me in the context of our next quiz question. So before I answer that probability one for you,  I'm going to pull up question number two for today. We've got a diagram, essentially what we just drew. The dot in the middle is the center of the circle and I've labeled seven different angles. I've just labeled them a through g. And what I want you to do is tell me which of these equations is true. One possibility is that four of the angles a, b, d,  and e have a sum that's the same as c plus f plus g. Which, just looking at c, f, and g, that would be 360 degrees, right? The other is that a is equal to b and d is equal to e. Another possibility is that c is equal to f. And then maybe it's all of those or maybe it's none of those. And it looks like we already have strong strong consensus on this one with 360, 400,  just a strong large number of people coming in agreeing what they believe the right  answer is. And you know, if you if you want to be involved, the place to go, 3b1b.co live,  that redirects you to an item pool page so that you can follow along. And for those who are watching in the future, maybe you're watching it  in the embedded page where the problem is just sitting right below you. And even if you're not technically participating in the data contributing  to the live statistics, when I was going through it,  it's honestly pretty fun to just kind of click and like, oh,  I know I'm not a part of this, but it kind of feels like I am a part  of what was happening. So I just love it. All right, so because there's such strong consistent- consensus,  I feel comfortable grading this. Oh, I thought I got it right on 1 1 1 1. So the correct answer is that a is equal to b, d is equal to e,  and then none of the others are necessarily true. And let's walk through why that's the case, okay? It comes down to exactly what we just highlighted, that these radii are common,  which means, you know, let me just give more things names. Let's call this point a, and this point b. Maybe that's confusing because I was just naming angles a and b,  but separate context, separate picture, you know what I mean. The triangle a, p, and then the center of the circle, that's isosceles. You know, there's this symmetry about, I could even draw the little axis of symmetry,  and that tells us that this is also alpha. Likewise, the triangle up here is isosceles, and  that tells us that this has an angle of beta. And what we just did, in effect, is leverage a little bit of symmetry. In this case, it was innocuous, but quite often looking for symmetry in much harder  setups, it's super generalizable and it definitely will help you move forward. If you recognize that there's something symmetric,  use that symmetry in some way, which is effectively what we've just done. Giving things a couple more names, I might want to call this angle,  I'll call it something related to the alphas, so maybe I just call it alpha prime,  and similarly this angle over here is beta prime. And by noting those facts, I have everything I need to do to  draw a connection between this small angle and this large angle. You essentially just write down the facts that  we have based on the triangles we're looking at. So the triangle with all of the alpha angles, the sum of those angles  has to be 180 degrees, and there's two different alphas in there,  and then there's an alpha prime, and instead of writing 180 degrees,  of course we like radians, so I'm going to say that equals pi radians. Similarly, the one with all of the betas tells us that if  we take 2 times beta and we add beta prime, that's also pi. And then the other fact that we have that's just popping right out from the  image is that alpha prime, beta prime, and theta L add up to 360 degrees, or 2 pi. So just writing down all of the relevant facts that we have,  now we have some objects that we can manipulate and work with to draw some kind  of conclusion, which again, we're looking for a connection between theta small  and theta large. And I know a lot of you, your 3Blue and Brown audience members,  you know about the inscribed angle theorem, but I really want you to think about this  from a beginner's mind, right? If you were just approaching this and you didn't necessarily already know about it,  what would you have done to find that solution,  and what principles can you take away as you do that? Because that helps us as we start to get to harder and harder geometry setups. So in this context, once I have these three equations,  recognizing that there's an alpha prime here and one here,  there's a beta prime here and one here, I might think about canceling them out. So I'm gonna, you know, add this top equation  and maybe I subtract off the other two equations. And to subtract these off, and what that means is the alpha prime gets cancelled,  so does the beta prime, I'm left with my large angle,  I'm subtracting off 2 times alpha plus beta. You know, each of those gets subtracted off with the coefficient 2. , and then we have two pi minus two copies of pi. So that's all equal to zero,  which is saying the same thing as theta l is equal to two times,  well rather than writing alpha plus beta, I'll just recognize that that is the small  little angle that we had. It's 2 times the small angle. Again, I can't emphasize enough just what a weirdly useful fact  this turns out to be in various geometry puzzles you might do. It's definitely come up on the channel a number of times in circumstances regarding,  you know, complex numbers or pure geometry situations, of course. Just anytime you want to relate an angle to 2 times that angle,  realizing them in the context of a circle like this can be strangely useful. So this is just an image to have burned in your mind as you're solving problems. And to give you one example of a problem that you can solve once this is sitting there,  burned in the back of your mind, I want you to remember back to the lecture that we did  on trigonometry, which conveniently is actually the example that I had pulled up here. So one of the central things we were talking about was how just playing  with graphs you can get this bizarre looking fact that if you square the cosine function,  you get something that looks again just like a cosine graph. And you can get more exact about that where if we start with an initial cosine  graph and you manipulate it a little, you know, we shift it up, we scale it down,  we say we need to double the frequency, you get the exact same graph. So we have two different expressions for the same thing,  but it's not at all obvious why these would be related. One of them involves doubling the angle it's a reference to,  the other involves squaring the output. Okay, so it's a not obvious fact. We proved it using complex numbers, but what I'd like to do is try to prove this  using geometry to kind of viscerally see the fact pop out right in front of us. And to do that, let's go ahead and write down what the  fact is again so that we can start thinking about it. We want to find that the cosine squared of theta,  which is just saying take the cosine of theta and square it,  it's that awkward notation, is equal to one half of one plus cosine of two theta. You've got the strained relationship between squaring things and doubling the angle,  which as we've talked about in the whole series is really a reflection of  the fact that a cosine is a shadow of an exponential function. But let's say you didn't know that, we want to see it viscerally and geometrically,  so you don't already know the double angle identities or anything like that. You just want a very direct understanding of this particular equation. Well, one common thing that comes up is that a way to show the  two non-obvious things are related or even equal is to see if  you can find one object that you can describe in two different ways. So we're going to look for one object that we have two different descriptions of,  and this often can give you nice equations in this context. It might mean relating the left and right hand side. This comes up in combinatorics all the time when you have a counting puzzle where,  you know, you do something like count how many ways you can have a string of five bits  that are either zeros or ones, and on the one hand you can count it multiplicatively  kind of going through each one and saying well you're multiplying the possibilities by  two. But on the other hand you can go iteratively and say well how many of them have no ones? How many of them have one one, two ones? Something that kind of seems harder and a more awkward way to count. But by describing the same thing twice you end up with  this really not obvious fact from an algebraic standpoint. And we're going to do the same thing more geometrically here. But again, just got to emphasize how like how general this ends up being. So what we want is some kind of object that each of these describes. And to do that, maybe we just think okay, let's let's draw a unit circle,  which is where something like a cosine typically comes up. Oh, for the first time in my life I drew a quarter circle arc that wasn't terrible. It's not great, but usually that comes out much more disastrous. How pleasing. I should not be so pleased with a terrible quarter circle. Great, okay. So that's our angle theta, right? And what does cosine mean in this context? Not cosine squared, but just plain vanilla cosine. Well, it tells us if we look at the x-coordinate of this point,  that's the cosine of our angle. And so now I want you to think about how can we  represent the square of the cosine as some kind of object? Some geometric thing that we can point to in this image. And the first instinct might be something like, well,  let's draw a square off the side of this, you know,  something with area to it and interpret it like that. But then there's going to be a problem if the principle that we're  trying to apply is describing the same object in two different ways. Because if we describe this left-hand side as some kind of area,  that would mean that we have to find another description of that same area,  that same object, with the right-hand side. But that's going to be weird, because this doesn't involve squaring or anything like that. If it's just a plain vanilla cosine term, it seems much more natural  to describe that as some kind of ratio, or maybe some kind of length. It's just that we need the 2 theta to pop up somehow. So instead, let's seek a way to describe cosine squared that does not involve area,  but is instead something more of the flavor of a ratio or a length. And in this context, the key comes down to leveraging symmetry again. And it's a sneaky bit of symmetry. It's something we did talk about in the trig lecture,  but I love it so much I'll talk about it again. If we think of this angle theta, on the one hand it's telling us  the angle between the x-axis and the line, but on the other hand  it's also telling us the angle between the line and the x-axis. And I know that sounds like the same thing, but it means when I say  project down the point at the end of our radius, which was length 1,  perpendicularly onto the x-axis, that length got scaled down by cosine theta. But now what if I do things the other way? What if I say I want to project down in a perpendicular fashion onto this line? Well again, I just have two lines separated by an angle theta,  I'm doing a projection, which means it gets scaled down by the cosine of that angle. So now I'm taking the cosine of theta scaled down by the cosine of theta,  and it gets me cosine squared of theta. So cosine squared refers to this length, a portion of the hypotenuse of our right  triangle, if that hypotenuse had a length of 1, which in our unit circle it always does. And incidentally, you can show very similar reasoning that the sine of theta is this  other other portion of that hypotenuse, and this gives you a nice,  sort of a clever proof of the Pythagorean theorem,  the idea of double projecting based on asking, you know,  is this line theta degrees away from that, or is that line theta degrees away from this? Sounds like you're saying the same thing, but it gets you  something of mathematical substance to recognize that symmetry. Now, why do I say this? Well, we have a representation of cosine squared. What we want now is to do something in terms of 2 theta. We just were thinking about a context where we're able to relate an angle to 2 theta,  to 2 times that angle. So somehow we want to realize this angle as an inscribed angle of some kind of triangle. And I'll show you how you can do that. But before I do, just to mention another fact that if you've been puzzling  around with these sorts of things, might be burning in your mind,  is a specific instance of the inscribed angle theorem called Thales theorem. So let's say that that large angle we had, 2 theta, was actually 180 degrees, right? It was pi radians. What would that mean in terms of the inscribed angle theorem? It means that if we take that diameter of the circle, if it's 180 degrees,  it's just drawing out a diameter, and we have an inscribed angle with lines  that hit either end of that diameter, then this angle is necessarily half of that. So what it means is that we can put a right triangle inside a circle,  and whenever you do that, the hypotenuse of the right triangle is exactly the diameter  of that circle. It's a very cute fact. If you wanted another proof of it, that's not just via the inscribed angle theorem,  there's another very wonderful leveraging of symmetry that you can do,  where basically you take this point and you say,  I'm going to reflect it through the origin, reflect it through the center of my circle,  and see where I get. And recognize that reflecting through the center  is the same as rotating the whole image 90 degrees. So if I rotated the image, not 90, 180 degrees,  my other vertex would end up at that same point. But now what we have is a quadrilateral, and one of the diagonals is the diameter  of the circle, but the other diagonal is also diameter of the circle,  which in particular means they have the same midpoint and they're the same distance  apart, and you can convince yourself a little that implies it must be a rectangle,  that could also be a little side homework problem if you wanted to chase around the  relevant angles. But I think that's a very beautiful way to think about Thale's theorem,  that you reflect everything 180 degrees, and you necessarily conclude  it must be a rectangle, which means that this is a right angle. Now for our purposes, what does that mean? Well, we've got a right triangle sitting here that's from zero,  we've got one of the points here, another point on the circle. Let's inscribe that in a separate circle, okay? So I'm going to take a copy of that triangle, but I'm going to,  instead of making the hypotenuse a radius of the circle,  I'm going to make that hypotenuse a diameter of the circle. So this is still going to be an angle of theta, sitting right here. The, uh, basically I flipped it around, so previously it was here,  but I flipped it around so that my 90 degree angle is sitting up and to the right,  rather than sitting down here. The length that we care about is what happens when we project from the point at that 90  degree angle in a perpendicular fashion down onto the hypotenuse,  which now looks like this. And what we care about is this long length, okay? And actually, let me ask you as a live quiz, to see if you can come up with an  expression for that length in the context of the diagram that we're now looking at. So, pulling up our quiz again, congratulations to everyone who got this one correct. Let me give you a little bit of time to think about this one,  because this is, uh, this is kind of a heart, part of the heart of this particular proof,  and I think it's very, very pleasing to see. So it specifies that the hypotenuse of the large right triangle above has a length of one. Our context is because it came from the hypotenuse of the triangle  drawn in a unit circle, so the hypotenuse has a length of one. What is the length l in terms of theta? Okay, so can you find an expression for l in terms of theta? And I'll give you a little bit of, uh, a little bit of time for that,  bring back our pause and ponder music, get myself a chance to take a drink. So, once again, it looks like we have some strong consensus for today. So while answers are rolling in, before I grade it,  I'm just going to go ahead and start describing how it goes,  since it seems like a lot of you are already well ahead of me. It's fun to have though. So of course, we're going to use the inscribed angle theorem. That is the whole reason I'm bringing it up here. It's a way to relate a single angle to twice that angle. So in this context, I would draw some lines from the center of my, uh,  of my new smaller circle that has radius only one half,  and recognize that this is 2 theta. And this is just lovely now, isn't it? Because what is the length we care about? Part of it, excuse me, part of it is the radius, which is one half,  but then the projection down according to 2 theta onto this remaining  leg ends up being that radius one half times the cosine of 2 theta. And of course, that's exactly what we want it to be. We've got the whole radius, which is one half,  and then we're multiplying that by 1 plus the cosine of 2 theta. It's a radius of the circle times a scaled down version of that radius. So that's two different ways of viewing the same object,  which is what we get when we take this right triangle and we  project down and look at what part of the hypotenuse that cuts off. And it gives us this non-trivial relationship in trigonometry  between the cosine squared and the cosine of 2 theta. The fact that otherwise we were going into like  complex numbers and exponentials to understand. So I think that's quite beautiful. I think that's just, um, one of the many many instances of where  the inscribed angle theorem suspiciously slos- suspiciously shows up. Um, and again, what I want you to take away is this principle that if you  can have one object described in two different ways,  very powerful in terms of showing non-obvious, um,  algebraic relations or anything that's kind of written down symbolically  without immediate intuition on top of it. So with all of that, let's actually turn to the probability  question that I asked at the beginning of the lecture. So going back to our live quiz, uh, I will go ahead  and grade what we- we all know know the correct answer. So for those of you- wait a minute. Oh, it was marked incorrectly. Oh, that's my bad. No, I just slipped this one in like last minute before the lesson today. Um, so I might have like swapped around what the answers were. So, uh, well, it looks like 1380 if we were absolutely  wrong according to whatever jerk wrote this quiz. So, I don't know how that shows up on the user interface if it's like shocking red like,  oh no, but, uh, D was the actual correct answer here. So congratulations to those of you who got that. Now back to our probability question. I'm curious to see what people said on this one just in terms of their instincts. So this one we had a little bit more of a spread and, ah, interesting,  here the actual correct answer does show up quite a bit- quite a bit lower than- and  now I'm questioning myself to make sure that I've actually, um,  written the thing appropriately. So just as a reminder of what the question is,  we're choosing two random numbers from the range zero through one,  each according to a uniform distribution, and we're- we're guessing  what the probability that they round down- the ratio of these numbers  rounds down to an even number. Remember zero is an even number, so that it rounds  down to zero or two or four or anything like that. Now this is a tricky problem to think about and, uh, definitely no- no fault at all for,  uh, anyone who isn't immediately able to see roughly where it should be. But I think, um, with a- with a little bit of progress on our way,  even before we get the exact solution, we can get to a point where  you might be able to intuitively give some kind of ballpark estimate. So what have we got here? Choosing two random numbers between zero and one. I think that's a weird thing to think about, um,  especially if you're not familiar with probability that well or  when the phrase uniform distribution is thrown up if it's not clear what that means. Um, but essentially, uh, it's what you would expect where you're choosing some  random point on this line, and the idea is that each point is as likely as another,  or more specifically a given range of points of a certain size,  should have a given probability that's independent of where that range showed up. It's only dependent on its size. You know, so you might have in the back of your mind the idea that  we've chosen two points, they're each somewhere between zero and one. And just to give an example of what we mean by uniform distribution,  the probability that x sits between 0.3 and like 0.5. Because it's going to be somewhere between zero and one,  and the length of that range is 0.2, about a fifth of the entire length it  could have come from. What it means to be uniform is that that probability is  actually just the length of the segment that it came from. Now, one thing you might ask is, well, what if,  what about the probability that it's precisely 0.3 or precisely 0.5? Would it matter if we made these less than or equal to signs? And the answer is it doesn't actually matter, because the probability  of hitting any specific value on a real number line ends up being zero. This is a thing many find very confusing. How can a probability of an event that's possible,  it's definitely possible to hit 0.3, have probability zero? Made a whole video about it trying to describe this,  but really what it comes down to is that the things that have probability,  you should think of ranges. Those are the fundamental objects, and it doesn't really matter  how we treat the boundary and just think in terms of ranges. Even still though, what we're asking is a very bizarre question,  which is if we take the ratio of x and y and we round that down, which sometimes,  you know, mathematicians write using this floor function,  saying we find the greatest integer smaller than that,  how do we know if that's an even number? That's a weird thing to think about, it's a hard problem in that way. So, you know, if you think through the principles here,  it's kind of like use the defining features of the setup. Well, not clear how to use the fact that it's a uniform distribution. I guess we'll be using lengths in some way to yield probabilities,  so maybe that gives us some geometry, but that's not really helpful. Give things meaningful names, you know, maybe x and y  are meaningful or some something suggestive like that. Symmetry, okay, maybe, you know, the idea that choosing x and then y is  as likely as choosing y than x, you could use that to conclude that this  ratio x over y is as likely to be above one as it is to be below one. And that actually does tell you something, because if we're wondering how  often do you round down to be zero, right, you can say well x over y is as likely to be,  x is as likely to be bigger than y as y is likely to be bigger than x. So there's a 50-50 chance that this should happen. This would be a probability of 50 percent. So that gets you somewhere, which is kind of nice,  but it's not clear how you would apply that to things like even numbers, same object,  two different ways, unclear. So principle number five here is where we're going to come in. Again, it seems simple. It's something that you can not be like, yeah, yeah,  drawing pictures, it helps to think through what I'm looking at. But really, when you find yourself struggling with some setup that's not already  visual or pictorial, you know, it doesn't have to be making a geometric,  but just having some kind of sketch, uh, to give meaning to your terms can be very  helpful. And as a more specific problem solving tip, when you have some numbers,  multiple different numbers, see if you can make them coordinates in some space. So rather than thinking about x and y as separate things here,  we'll want to think about a single point with xy coordinates. And what that does for us is it actually turns the  whole problem two-dimensional in a very helpful way. So first of all, I've lost track of my straight edge,  which, where have you gone little straight edge? I can only throw you so far. Oh, here we go. Things, they run away from you. Even your objects sometimes get tired of math class and want to play truant now and then,  but he has to stay whether he likes to or not. All right. All right, absurd. So let's say this is our x coordinate. x can fall anywhere between 0 and 1 with uniform probability. y can fall between 0 and 1. So when we have a pair of numbers, you know, something like 0.2, what is that,  maybe like 0.8, pair of numbers, it's just a single point in this diagram. And now to choose both of those numbers uniformly at random means that  we're choosing a random point inside a square, a square with side length 1. And now maybe we can make a little bit of progress,  because it's going to come down to some view of what's going on in this square. Now with this specific example, if we're thinking about the ratio x over y,  and taking its floor, taking, just rounding it down, well, that's 0.2 over 0.8,  that's going to round down to 0, so this would end up being even. And like I just said, that that happens with 50% probability. But let's see if we can try to find a way of thinking  about that that generalizes up to other examples. And again, one very useful thing, if you get stuck,  that I have enumerated down here as principle number six,  is to ask a simpler variant of the problem. You're solving something, it's hard. It's too hard. See if you can make it simpler in a way that you  actually can solve and get some kind of foothold. Maybe that means loosening the constraints of the problem in some setups,  or maybe it means looking at a sub-problem. So in our context, rather than asking the probability that it rounds down to be even,  let me just ask the probability that it becomes one,  but I want you to answer it in a geometric way,  something that will generalize to rounding to other things,  because the next simpler question might be probability that it rounds down to two,  and things like that. You know where this is going to go. We're going to do it as a live quiz because rather than me answering things,  I want you guys to answer things for me. So jumping up to question number four at this point,  it's going to give us a couple different diagrams. Okay, we've got a, b, c, and d, and it's asking us which of these four regions  corresponds to values of x and y, where taking the floor of x divided by y is  equal to zero, which is to say you take the ratio, you round it down, you get zero. Which region corresponds to that fact? So, okay, I'm going to go ahead and lock in answers,  but if you want to keep thinking about it, definitely feel free to pause  the video and do so. I don't want to rush anyone. So it looks like 1265 of you, 1273, always answers rolling in at the end,  correctly answered that it's c. And let's take a moment to think about why that's the case. Okay, you can do so just with a pile of examples and just see which one  seemed to fall in the region or not, but let's see if we can understand  this in a way that lets us make progress onto the other even numbers. So when we say that it rounds down to zero, what we're basically  saying is that that ratio sits somewhere between zero and one. And it's awkward to think of x divided by y, we kind of like to think of y in terms of x,  so if I multiply everything by y, which is okay to do with these inequalities because y  is always positive, so that's not going to affect whether the inequality flips one way  or another, I multiply everything by y, and we're basically asking when is x less than y? And whenever you see an inequality, the boundary of  that region is going to be described by the equality. So we're going to wonder when is it the case that y equals x? Well, that's just a straight line that goes diagonally. If we draw our line y equals x, that's what we get. Now that's the boundary of our region, and to know whether we should  look to the left of it or to the right of it, either you can think very directly and say,  well, you know, y should be greater than x, so at a given point we  want to move upward in the positive y direction. You could look at a specific example like this, but however you do it,  you'll draw the conclusion that geometrically the region of points such that  x divided by y rounds down to zero is this sort of grilled cheese cut of our diagram. So with that, maybe you can start to think about the harder variant,  which is when is it that x divided by y rounds down to be two? And again, I don't want to answer it. I want you to answer it. When is it that x divided by y inside our unit  square of points x comma y rounds down to two? And we've got four possible geometric regions that this could correspond to,  a, b, c, and d. And really, you know, rather than just thinking about which of these is it,  really try to think through why it's the case and how you can prove  that one of these boundaries is actually what it's supposed to be. For example, I want it to be the case that if I didn't show the correct answer here,  let's say I was just trolling with everyone and I didn't show the correct answer,  you would be able to confidently come and say like, no,  I'm quite positive that the correct answer is nothing that you've shown here. See if that's the level of reasoning that you can put behind it. So again, I'll give you give you a little moment to think about that. So so Okay, so once again, I'm going to lock in answers potentially  earlier than you want me to, but keep the lesson moving forward. No hard feelings if things haven't clicked yet,  because hopefully the explanation will make them do so. So the correct answer is c, which it looks like most of you got,  and let's go ahead and think through why that's the case. Very similar reasoning to what we were just doing. The idea is that rather than thinking about this ratio and a floor,  which is kind of a kind of an awkward thing, let's explicitly write out the inequality  this is referring to. It's saying that x divided by y is greater than or equal to 2 if it's  rounding down to that, but it's not greater than 3, so it's less than 3. And, you know, again, it's a little bit awkward to think of this ratio. So let's write that as 2 times y is less than or equal to x,  which is less than or equal to 3 times y. Now quite often we don't think of y as a function of x,  we think of x as a function of y, if that makes you feel more comfortable. So if you want in the back of your mind, you can kind of think 2y less than or equal to x. Well, that's the same thing as saying y is less than or equal to x halves. And same deal, 3y being greater than x, that's the  same thing as saying y is greater than x divided by 3. Because that way we can look at the equalities associated with each of these. The line y equals x halves, which has a slope of one half,  you can think of it as intersecting at the point where y equals one half when x equals 1. Right, so it'll be a line like this that describes part of the boundary of our region. And the other line is when y is equal to x thirds. So we know we actually have to be above this line that I'm about to draw,  where one of these represents x over 2, and one of these represents x over 3. And then part of the part of the intrusion into the space of my last inequality. All right, so we want to be above the x equals x over 3 below the x divided by 2. This region here shows us everything where rounding down gets to 2. And I want you to appreciate how this is a kind of complicated thing to  think about if we hadn't gone into a picture that involves two dimensions. If you were just thinking of x and y varying along this line and wondering when  is it the case that x is more than twice, or y is more than two times what x is. No, yeah, sorry. x is more than two times what y is, but it's not three times more than what y is. It's not, not, no, I said it wrong. I said it wrong. When y is more than two times what x is, but it's not three times more than x is. It's very, it's very easy to get confuddled in that way. And it's even harder to try to give some sort of probability to that,  whereas in our diagram it has a very clear meaning. It is the area of this region because the full area of possibilities already is one,  so this, the probability of something happening should be one,  and we just need to look at the area of that. And now maybe you can see where this is going to go,  because for the next term when we want to know when does x divided by  y sit between four and five, we're going to be drawing lines that  intersect at x over four. Maybe I'll go to a different color for this one. x over four and x over five, which is going to require very small  handwriting at this point, but I'm going to give it a try nevertheless. x fourths, y equals x fifths, and this little sliver of area  gives us all of the times that our ratio x over y rounds to be four. And we're going to have to add infinitely many of these,  so that gives us sort of another phase of challenge to the problem. I've drawn this all out in Desmos, by the way,  if you want to just sort of see what some of these regions look like,  where we've got our top region of places where it rounds to zero,  then we've got another region corresponding to rounding to two, rounding to four,  rounding to six, and just on and on each one of these regions. Rounding and rounding, rounding. I only went out to like a hundred or something like that,  but that gives you a sense of what we're trying to do. So we've made progress, but this is still hard. What is the area of all of those triangles added together? Right, that's not necessarily an obvious thing. So let's just start by writing it out and seeing what help that can give us. So every one of these is a triangle, it's going to look like one half base times height. And in fact every one of them, if we think of the left right  direction as being their height, every one of them has a height of one. So each one is going to look like one half times a base of some kind. So I'm going to take, maybe I'll write this out on a  different piece of paper actually so I can keep it up close. I'll take one half times whatever the base of the triangle is times the height. So our first triangle, that base is, that base has a length one. So that's going to correspond to the one half probability of going to zero. The next triangle, we have to look at this length here between one third and one half. What is that length? Well, actually I'm just going to write it out as a half minus a third. It equals a sixth, but writing it out like that kind of reminds us where it came from,  so we don't want to collapse things too soon. That could maybe be another problem solving tip, don't collapse things too soon. Try to let your notation have a memory for where things  came from because sometimes that helps see overall patterns. This next one, what's the distance between these two points? Well, it's a fourth minus a fifth. That's the distance between these given how they were defined. So we have a fourth minus a fifth. And in general we have this kind of oscillating sum, a sixth minus a seventh,  where we have all the reciprocals of the natural numbers,  but we're adding that up infinitely many different times, okay,  and we want to know what that sum happens to be. And from here, the problem solving tip associated with this will seem a little bit  strange, but it might be the case that you recognize this fact from somewhere else. You might recognize, let's say if you were watching a particular lockdown math  lecture a week or two ago, that this alternating sum,  one minus a half plus a third minus fourth plus a fifth, on and on,  actually equals the natural log of two. Okay. And the way this actually came about, it's such a weird procedure,  it's worth just like walking through again really quickly because it's a bizarre  thing that you're not gonna, you're not gonna be able to just stare at this  formula and then immediately see that this is how you're going to solve it,  unless it's something that you've seen before, which can make it seem all the more opaque. We did this strange thing where we made it seem like a harder question at first,  where rather than asking about one particular sum, we turned it into a function,  which is effectively asking about infinitely many different sums like this. So x to the fourth over four, then we're adding x to the fifth over five. And the reason for doing this is that this plays nicely in calculus land,  because those denominators are now related to the exponents in a way that  we can kind of cancel out by doing an integration trick,  each one of those terms I can nicely express as an integral of a much more  simple monomial term. x cubed minus, now let's see, plus x to the fourth. If I integrate this thing, each one of them has an exponent  that increases and then we divide by what the exponent is. And the reason that you would want to do this is  that this now has a nice way to collapse itself. So just to make this maybe more explicit, if we evaluate the integral from zero to one,  that's the same as taking this whole expression and evaluating  it at one and subtracting at zero. So that will give us what happens when we plug in at one. And again, this is just such a bizarre thing that if you hadn't recognized the sum,  seeing someone prove it to you like this doesn't necessarily make it feel  like something that you could have found, which is frustrating in the context  of trying to develop problem solving tips that are generalizable. But I'll keep walking through it just to give a little bit of closure to this. We've got this infinite sum that if you had been familiar with geometric sums,  where each term looks like a certain product from the last,  you would be able to write this as 1 over 1 plus x,  because we're always multiplying by negative x. So you always take 1 over 1 minus the thing you're multiplying by, which again,  it's kind of one of these things where it's relying on you recognizing it in some way. And then the last bit of recognition is knowing  how to take integrals of 1 divided by a thing. And in this context it works out very nicely to just be the natural log. And we're evaluating this between 0 and 1, which is to say we're taking  the natural log of 1 plus 1, or 2, minus the natural log of 1, which is 0. And that's why all of these things are the natural log of 2. And think about what has to go on there in order to be able  to take this and then apply it to our probability question. You would have to recognize the alternating sum as something that you had seen from  another context, or if you didn't, you would have to be aware of this trick to somehow  turn it into a polynomial that can be nicely expressed as an integral,  that can be collapsed because of geometric series,  which can be integrated because of the natural log of x. And then thinking about like, what is what is the thing that you can teach  someone to say come away and be able to solve problems in the same way? I have what might seem like kind of a facetious tip,  but I actually think it's maybe the most potent one and the most honest one. The way that you can get to this sort of point, just read a lot. Read as much as you can. You know, watch YouTube videos on math if they're substantive, things like that. And think a lot about problems, which is maybe frustrating  because what you want is to be able to say like, well,  how could I have come to this on my own without having merely recognized it? But I think the truth of the matter is a lot of what looks like insight and ingenuity  is really just pattern recognition, but wearing a little bit of added clothing. And sometimes it's patterns not so much that you're directly recognizing exactly this,  but maybe you had seen a series like this or a tactic like this before. Like geometric series, that comes up a lot. If you read a lot, and if you think a lot about problems,  you will recognize geometric series, even if it's in a context that you've  never actually seen before, or a specific geometric series that you've never seen before. Similarly, if you read a lot and you think a lot about calculus,  knowing that you can have the natural log pop out of an integral like this,  it becomes second nature. And I think recognizing the truth of this as being the key  to a lot of problem solving is actually pretty inspiring. Because oftentimes you find yourself in a situation where somebody is,  they're just faster, they're just better, they just recognize things more so than you do. And that can be a little bit intimidating, right? To look at one problem, think of yourself as pretty savvy with math and knowing  what's going on, and then just having someone burn through with a wonderful bit of  cleverness, this super beautiful argument, that leaves you sitting there in the dust  wondering like, wow, I just, you know, I'm just not in the same league at all, right? And you sometimes even think, well, he just has a math gene, right? That person, they just have some sort of innate  instinct that makes them really good at this stuff. But I think the truth of the matter is that the people who are  showing that kind of ingenuity, they've just exposed themselves  to a huge number of patterns, and you too could get there, right? There is a path towards that which takes the form of practice. But not just practice, practice where you're taking each problem that  you're looking at and trying to digest the deeper principles behind it. Maybe some of the ones I'm trying to talk through today, like,  okay, I can say leverage symmetry, but what does that actually mean? You know, what does it mean to look at a symmetry of a problem  and turn that into something that's formulaically useful? You just have to see it a lot, and then be pensive when you do. Don't just be satisfied with the answer, see if  you can understand why that answer came out. So in that way, this number seven, like, it's the most frustrating,  but it's the most real of all the problem solving tips that there can be,  which is that true problem solving comes down to a kind of pattern recognition,  and there's no two ways around it. You just have to do a lot of practice and expose yourself to a lot. Now I would bet that when we did talk about this infinite series a couple lectures back,  you wouldn't have thought that that's a thing that you're going to  be using in a probability question one day. But that's just how these things go. They show up in unexpected places. So what you can do then, is say, well, we've got our whole expression that  involves this very alternating sum, and you'd say, okay,  that means that the answer to our final question is, you know,  one half of the natural log of two. It's one half of what that alternating sum came out to be, which is very nice,  you know, it involves this natural log expression, and it's very clean,  and we've got this picture for where it came from adding up all of these,  all of these areas. Now at this point, there is one thing that I think separates really good problem solvers,  the ones who get like nearly perfect scores all the time,  to ones who are like merely good, who, you know, they aren't necessarily perfect scores. There's some like silly mistakes that come in here or there. At this point, when you've done the problem and you've got your nice elegant solution,  you want to draw a box around it, you're not done. Just always, always, principle number eight here, always gut check your answer. Okay, because there's going to be some little mistake that happens all the time. The great problem solvers aren't the ones who just never make little mistakes,  they're the ones who have some way of recognizing what those mistakes are. So in this context, let's say I, I just want to see  numerically what my answer turns out to be, right? We said that it was one half times the natural log of two. So let's just see what does that end up being? And natural log of two is around 0.69, so maybe it's not too surprising,  we're around 0.346, around 0.35, okay? So if we write that down as one of the, as the answer that we just got,  I told you I would purposefully make a mistake,  so hopefully you're not yelling too loud at this point, does that make sense? Does that pass a basic reasonability test? And if you look at our picture, well, the probability has to be at least a half,  because that's the region where it rounds down to zero. So certainly it couldn't be the case that the whole thing adds up to be only 0.35,  so there must have been some mistake we had along the way. Everybody makes silly mistakes, everybody drops a minus sign  or applies some rule that doesn't quite apply in a circumstance. You're not going to make, you're not going to  approach perfection by avoiding silly mistakes. The way to do it is to be able to systematically know when you've, when you've made them. So always gut check your answer, have like two different  perspectives that can give you a reasonability check. In this context, if it inspired us to go and look a little bit  more carefully at how we were applying things,  this sum isn't quite the alternating sum that converges to natural log of 2. In particular, we added the 1, but then we also add one half,  and it's only after that that we start alternating. It was plus plus, then minus plus, minus plus, on and on. And you might see this by recognizing we were subtracting all the even numbers here,  but we're subtracting all the odd numbers here. So it's similar, but it's not the same. We will be able to use our knowledge, but let me just give this part  where things actually start alternating a name, something like s. What this bottom equation is telling us is that when we take 1 minus s,  so that would mean we're subtracting the one half, then we're adding the one third,  then we're subtracting the one fourth, we're flipping all of the signs of  everything beyond that 1, that is the thing that equals the natural log of 2. Which in turn implies that that remainder of the  sum looks like 1 minus the natural log of 2. Okay, so all of that, what does that tell us? When we plug it into our original expression, it's saying that  the actual answer should not be one half the natural log of 2. That didn't even pass our basic reasonability test. Instead, it'll be one half of one plus one minus the natural log of two,  which is just two minus the natural log of two. So does that pass our reasonability check? What does this actually equal numerically? You can get a loose approximation in your head if you want,  or if you want to see more precisely, we can pull up a calculator. So if we go over here and we're saying, no, no, no,  we don't want the natural log of 2, that was wrong. 2 minus that, maybe 0.653. Does that pass our basic reasonability test? Yeah, I think so, right? 0.65, that looks like a reasonable answer to what the area in our diagram was,  because if we looked at that diagram, which was, you know,  we've got one wedge here that's covering 0.5, and then this other one covers,  well, about one sixth, half of a sixth, basically,  because this length was a half minus a third, which makes it a sixth,  and then it's a triangle, so one half base times height. So that's about a 12th, or 0.083. And then the rest of it, you know, it's not going to fill a huge amount. Something around 0.65 seems pretty reasonable. And so that, you know, we could call that good on our gut check,  that this is probably the correct answer. But we could go one level further if we wanted,  because probability questions very often you can kind of cheat and just  see the answer by simulating it, and actually taking a bunch of samples  and seeing what happens. So I want to do that actually on this one, just to give us a little bit of confidence  that our answer of 0.65, that there wasn't some other silly mistake that we made along  the way, because everyone knows there certainly are silly mistakes that we can make. Before I jump to the programming, though, I just want to see if there's  any questions from the audience, and it certainly looks like there are. So let's see if we can address some of these, get myself out of the way of the questions. This is like from the book The Chosen, where the rabbi makes  an intentional mistake in his long speech to test his son. It is exactly like that, my children. I just want to test you. Every time I make a mistake, it was always purposeful,  and I was always doing it just to test you. All right, keep making more episodes. Why am I stopping? Two reasons. You know, the main one, honestly, if I go much longer in this lockdown  without getting a haircut, we're going to have to start filming these in  the style of like a 1980s music video, just to keep stylistic consistency. I'm not up for that. You know, I think that's just going to be a little bit too much effort,  so I'll have to wait until whenever it's possible to get a haircut again, then we can go. Really, though, I also just miss my old content. I love visualizing stuff. I've got a long pile of things I want to get to, and you know, the lectures take time. I might spin up something like this again, might do it on a separate channel. We'll see what plays out, but I would love to do like a full course where it's a  little bit more clear exactly what we're going to talk about from beginning to end. Loosely, I'm thinking like combinatorics would be fun, but don't hold me to that. And lastly, can you help us understand derangements and the principles  of inclusion and exclusion, just like combinatorics intuitive? Yeah, boy. How much time do we have today? Tell you what, maybe just a separate video. If I do the combinatorics course, actually, that would be a perfect example for it. It takes a little bit too much to describe here,  but very naturally what you end up with is taking 1 over 1 factorial minus 1 over 2  factorial plus 1 over 3 factorial minus, and you're doing this alternating sum with  factorials, which is why e pops out. And if you think of e as fundamentally being the sum of the reciprocals of factorials,  it doesn't seem crazy surprising that it's related to counting problems in that way. But for another day, I'll say, because I don't know if we have time today. Because I would love to just show how you could maybe gut check this programmatically  if you wanted to, because the very last principle I have for problem solving,  for mathematical problem solving, is to learn at least a little bit of programming. Okay, and the reason here, one, for what we're about to do,  you can sometimes basically cheat and see what an answer is numerically,  to see that that verifies how you're thinking about it analytically. But also, importantly, it forces you to think about things in two separate ways. Sometimes you can go about it mathematically, but then when you try to make it  computational, you run into certain walls about like, how are things actually defined? Or, I don't have infinity available to me, how can I do this in a more approximate way? Very often when I'm animating things for usual videos,  the piece of math that I'm describing, you know,  it lines up with some way that I'm programming it to give the illustrations. And when those mismatch, that's actually what's most interesting,  when it's not computationally viable to give a perfect illustration of what  I'm describing. And I actually think that does make for better problem solving in general,  where you're coming at it from two different angles. So let's just try this out, see if we can understand the probability question we  were just looking at in terms of just, you know, what's the word I'm looking for? Cheating! Seeing what it turns out to be. So I'm going to import numpy, which evidently some heathens refer to as numpy,  which just, I just can't, that seems awful to me. So we can find random numbers if you just call random,  this first random refers to the library, the second one is a function. It will return a number between 0 and 1 according to a uniform distribution. So it is as likely to choose something between, you know,  0.1 and 0.2 as it is to choose something between 0.8 and 0.9. And what's nice is I can get a list of them, so in this case I get a list of 10 random  numbers, and maybe I call that something like x, and maybe I create another list of y. So x, some random numbers, y, some random numbers,  and if I take x divided by y, it does it term by term. So for example this first number that we see in here,  that's 0.739, that's taking the 0.52 divided by the 0.7. This next one is taking 0.66 divided by 0.56 on and on,  so we can see all of our ratios like that. And in general I might just define a ratios list where I'm going to take my,  a bunch of random numbers of size n, and then divide it by  another bunch of random numbers of the same size. n is not defined, but I'll give it a definition, some nice and big number like a million. Okay. And now I'm holding on to a million ratios, a million examples of x divided by y,  where x and y are chosen according to our constraints,  which is kind of cool if you think about it. So, you know, we can see some examples here, some that have come up to zero,  and some that would round down to zero, some that would round down to two,  some that would round down to one, so that's nice. And now I can start asking questions, like, you know,  when is it that I take these ratios, I take the floor function of them,  not the four, the floor, and I want to know when is that equal to zero. This gives me a list of trues and falses, basically saying it is or it isn't zero,  and if I take the mean of that, which is treating the trues and falses as ones and zeros,  this tells me the proportion in total that will actually be zeros. So we expect it to be about a half, and we can verify, yeah, okay, it's about a half. We could have also asked when is it about two, okay, and it looks like 0.83. And remember from our diagram what we were looking for is when when it's in this green  region here, when it's in that green triangle,  which has an area that was a half minus a third, but all times a half,  because it's one half base times height for a triangle. So if we pop back over to our terminal and say, okay,  if we were looking for one half times the base of that triangle,  which was a half minus a third, we would expect that proportion to have been 0.83. And yeah, it looks like it was about that. And we could even answer our actual question, which is to take the floor,  and then if I say I want to divide by two and ask when the remainder is zero,  that's a way of asking when it's even, and then taking that whole list and taking  a mean of it is a way of asking how often that ends up looking like true,  what proportion of them give me true, and yeah, 0.65,  which is about the answer that we were looking for. You know, we were looking for something that was too half of two minus the natural log,  natural log of two. So we have this wonderful way to kind of empirically verify. And of course, and most of the times with in-lockdown math that I've pulled up Python,  I'm just doing relatively simple things numerically. If you wanted to, you could try to visualize stuff. So something like matplotlib is definitely a great pyplot. I'll import it as plt. This is a very good library for just like simple data  visualization that you can pull up pretty quickly. So in our context, I can pull up a histogram. So I'm going to take a histogram of all of my data, and I have to specify a range. So maybe we just want to look at when the, when  those values get bucketed in between like 0 and 20. So my number of bins is 20. I was about to sneeze, but I held it in. Don't you love when that happens when like a sneeze  is coming and you don't have to catch it? It just recedes into the darkness because it knows that you're better than the sneeze. Right. Again, I'm more pleased with myself than I should be there. And um, I always, you always have to add a relative width on these sorts of histograms  because they just look ugly if they're all like side by side, I think sometimes. So if I do this, um, and then I show what the plot ends up being,  I have something that has shown up on my screen, but not your screen. So let's pop it on over. Yeah, there we go. So you can get a sense of, you know, this bar represents all of the ones that  rounded down to zero, and you see it's about half of them, about half a million. All the ones that rounded down to one, rounded down to two. And you can get this, um, this nice sense for what all of your data is. Again, just adding that kind of empirical validation  on top of whatever you find more analytically. And that back and forth I really do think is helpful  for more like pure mathematical problem solving. So with that, that's actually all that I have for the lesson today. Just two quick things that I want to go over before we end things here. I've been using Desmos a lot to like show graphs of things because I just love Desmos. And I'm actually friends with some of the people who work there  because quite often a company's people are as delightful as its products. And the CEO Eli shared with me the fact that they  were doing like an art contest among some students. And I just wanted to showcase some of, I'm not sure if these are the winners  or the finalists of the art contest, but basically in various different  categories of students who are, I think it was like 12 through 14, 15 through 17,  or something like that, using like mathematical graphs to try to draw pictures. Okay, so keep in mind what I'm about to show you are mathematical  graphs that someone wrote just with an analytic description and they were,  they were just prompted to create something artistic from that. Okay, so one of my favorites, and I think this one was from someone named Carrie,  is two giraffes that just from an artistic standpoint, it's actually quite lovely. And then to think through like actually mathematically describing everything  involved here, it's such a beautiful blend of well, like the creative side of things,  the artistic side with aesthetics and everything, and the analytic side. Another that was, this is just genuinely insane. This is by Katsini, is a BÃ©zier Knight. So I definitely wanted to highlight this on behalf of the team over at Desmos,  where each one of the curves here is described according to something  that's called a BÃ©zier curve, very useful for computer graphics. It's a kind of cubic parametric term, and they just recreated  a starry knight in a way that's completely beautiful, I think. And then the very last one, which is genuinely shocking that you can do with mathematical  graphs in any way, was a self-portrait by Jared, that's just like genuinely insane. I mean, I remember playing around with like a TI-84 and trying to come  up with little pictures of like a smiley face and things like that. So the amount that things have changed in terms of when someone's noodling off  with their graphing calculator in class and what they can do truly next level. And then at the very end, I just want to say again like a highlighted  thank you to Ben Eater and to Cam, who've been extremely helpful with  the whole series in ways that's like hard to even articulate properly. Eater in particular, I mean, he's let me borrow a lot of his equipment and helped  out with like figuring out live footage type stuff because that's not something I  usually do, which is not even to mention the work on the live stats and live quizzes. So if you aren't already familiar with his channel, it's simply named Ben Eater,  like 100% check it out, definitely subscribe to it, try some of the projects. He has a very project-oriented way of teaching. I think it's absolutely great. So cannot emphasize enough how grateful I am in the direction of both of those two. And check out the the item pool site where we are going to let  you kind of relive the lockdown math experience and have like  homework and actual challenges associated with each one of them. So stay tuned on that. And if you're interested in being a beta user of it,  there will be forums for how you can how you can reach out to both of them. Thank you everyone for joining in the whole series. This has been very fun for me, very different for me. And I will shortly get back to the more usual videos, which I'm very excited about. There's a couple topics that I just think you're thoroughly going to enjoy,  especially if you like problem solving stuff like this,  like really getting into good meaty problem solving. That's some of what's on the horizon. And with that I will simply say keep loving math and enjoy the rest of your day. So Thank you.

================================================================================
VIDEO ID: pq9LcwC7CoY
TITLE: Intuition for i to the power i | Ep. 9 Lockdown live math
URL: https://www.youtube.com/watch?v=pq9LcwC7CoY
PUBLISHED: 2020-05-15T21:23:19Z
STATUS: SUCCESS
================================================================================
Welcome back to what is now the second to last in the Lockdown Math series. So we've been talking a lot about exponential functions and complex numbers and the  interplay of the two of them, and I thought what might be a very nice culminating  topic to help bring it all together and show really the full breadth of what exponential  functions are and what they can be would be to talk about raising i to the power i. Now this is a, this is a funny little expression because usually if we  think about powers, if we were doing something like i to the fourth,  you know, we know how to think about it in terms of repeated multiplication. We're just multiplying something by itself four different times. And in general you'd like to think of i to the x as some variant of that,  but as soon as x becomes a complex number, we should realize that it's really nothing  like the above. So it's really nothing like this. Instead, the way that we think about it is going to have to  be very related to the way that we think about raising e to various different numbers,  e being that kind of home base for us. And in fact if we go, oh no, that's not sure where things are going too much here,  if we go ahead and rewrite that base i in terms of e,  it can help us make sense out of this expression. But I don't want to do that, I want you to do that for me. So if you head on over to 3b1b.co.live, link is in the description,  it'll forward you on over to item pool, which now asks us write a value of x so that e to  the x is equal to i. That way we'll be able to replace it in the base of our expression. And then once we do that, maybe we can use our knowledge of e and  exponentials of e in order to make some sense out of this expression. Now let me just add as a quick reminder while everyone is rolling in  with answers for that, that when we write e to the x and complex numbers are in the mix,  we are no longer talking about repeated multiplication. And instead I think the healthiest way to think about it is that  e to the x is a shorthand for this polynomial that I might call exp. It's the, it's sort of the main exponential function. All other exponential functions derive from this in a  way that I'll describe later on in this episode actually. And it's, it's a lovely polynomial. It's 1 plus x plus x squared over 2 plus x cubed over 6. Each term looks like a power of x divided by the factorial of that power. So the reason for doing that is then it can actually  make sense to plug in things like complex values. And one of the things that we looked at earlier in the series was how if you're  plugging in imaginary values, you know, let's say I go over here and I'm going  to plug in i, where i is the square root of negative 1 times some value theta,  we can very literally read off what it means to exponentiate it in that context. For example, this very first term 1 we might think of as a vector pointing from 0 to 1. The next term, which is some scaled version of i, well,  it's a 90 degree rotation of that first vector scaled a little bit differently. Then the next vector is a 90 degree rotation of that scaled differently. And depending on what this value theta equals,  the way that these things scale is going to look very different. And it's in general a difficult thing to think about,  but it's at least a sensible thing to think about, right? So that when we go to our expression, e to the x,  and we're going to start thinking about i in various complex numbers,  it makes sense computationally what it means. And then there's going to be a separate illustration that I'll pull up  in a moment for how it makes sense in terms of intuition what it means. But first let's just see how people are doing on our live quiz,  finding a value of x so that e to the x is equal to i. Now. How have people done here? Okay, so the top answer is in a sense absolutely correct, you could say. By definition, the natural log is the inverse function of exponentiation. So whatever the answer is here, we should be able to write it as natural log of i. The problem is that's not really helpful. It's not going to move us forward, because if we if we tried to use that, you know,  we pop over here and we say instead of writing i,  I'm going to write e to the natural log of i, and then I'm going to be raising  that to some kind of power. It begs the question, and the only thing I can really do from  here is simplify that down to be i, which sort of gets us nowhere. So to move forward and to think is there a number,  some concrete point on the plane that I can plug in,  for that we'd want to look at, I accidentally skipped ahead of my questions here. Let me go back, pull up people's answers. Got a little excited, a little trigger happy with some of my clicking around here. And the second most common answer is something that's going to  actually help us move forward here, which was one half of i times pi. And then that's the same as what was written, what was categorized as the  third most common one, one half pi times i, just swapping the two numbers there. and I think, yeah, I think the one following that I'm guessing people either forgot to  mention the i but let's just, let's just write that out and kind of see where this moves  us. One half i times pi. Now, if you're confused about where that came from,  I think this is a good time to remind ourselves of Euler's formula and  what it's really saying. It's one half pi times i, where again, computationally,  this very literally means if we plug in pi over two for theta here,  which would be something like 1.57 or so. Let me see if I can, I don't think I'll be able to get it right on the head,  but something in the 1.57 range, if you were to play out this whole sum,  the claim of saying that e to the pi halves i equals i,  is that when you play all of this out and you add all of the terms together,  you're going to get to the top here. But usually this is kind of a complicated way to think about it. People don't want to pull up this whole polynomial and imagine the spiraling sum. I think it's helpful just in case you find yourself doubting the reality  of what we're talking about or the fact that it's something sensible. Almost always, anytime that people are thinking about complex exponentials,  instead they find themselves thinking something like e to the i times theta,  they just immediately know of, maybe not immediately,  but you come to immediately know of Euler's formula,  that it's telling you you walk a distance theta around the unit circle,  which is to say an angle of theta radians, and whatever point you're sitting  at on the complex plane, that's the output. So people who knew about this would say, hmm, i as a number is also sitting on  the unit circle, so I just have to walk an angle of 90 degrees pi halves radians. And from here we can actually move forward and get kind of a funny looking answer,  because that i will hop to the inside and we'll be looking at e to the pi halves times i  squared. i squared is negative one by definition. So this looks like e to the negative pi halves. That is a purely real number. You could just plug that into your calculator and it's actually around 0.2 or so. It's about a fifth, which is weird, uh, that you take an imaginary  number and raise it to an imaginary power and that gets you a real number. Um, maybe it feels a little bit weird that e and pi have shown up,  not that much if we're thinking in terms of Euler's formula and all of that,  but I kind of want to go deeper on this one, right? I think it's one thing to plug in some numbers and see what pops out. And there's a couple great videos who have talked  about i to the i from some of my favorite channels. Stand Up Math with Matt Parker, he talked about i to the i, did a beautiful job. Black Pin Red Pin did another i to the i video, truly great. One thing that I try to, you know, I try to do is add something  into the mix if I'm talking about a topic that others already have. And in this case, I think one of the most interesting questions you can ask before  we jump in, I mean, there's lots of interesting things about this expression i to the i,  but if we're seeking intuition, thinking about how i is a 90 degree rotation, right,  that's the way that it acts when we're multiplying things on the complex plane. We think of it very intuitively as the thing that upon  multiplication turns stuff 90 degrees, or pi halves radians. So when you look at this expression that i to the power i equals e to  the negative pi halves, it begs the question, in what sense do two 90  degree rotations combine to make this real number,  this very specific real number of e to the negative pi halves around 0.2079, on and on? And it's like those games that sometimes you play with arithmetic where someone says,  oh, I'll give you the numbers 1, 3, 4, and 6, see if you can combine them  in some way with addition, multiplication, division, to get some other specific number,  like 24, in that case is a particularly fun puzzle. In this case, it's kind of like that style of puzzle on steroids. How do we take the idea of a 90 degree rotation and combine it with itself twice in  some mathematical sense such that we get out this number e to the negative pi halves? Where's that intuition coming from? And the first step, I would say, is to remind ourselves of the intuition  for why it is that Euler's formula works, why it is that I can take an  expression like e to the pi halves i and say that that's the same thing as i. You know, I just showed what it means in a very, um, computational sense,  what the claim is with this spiraling sum, but that tells us nothing about why,  why it would be the case that this is how things behave. Now I've at this point made, you know, quite a number of videos on variants of this,  but I think the quickest one is to think of it dynamically somehow. So if we take an expression like e to the i times t and we're thinking of that  as describing a dynamic, you're going to have a position that changes over time,  then what I'll do is I'm going to start drawing that with a blue vector,  and we know as an initial condition that when we raise e to the zero, that's at one. So where we are at time t equals zero is equal to one,  but let's say that's all we know, right? We haven't been told about Euler's formula, or how we should  be thinking about it with circles or anything like that. That's just where we're starting. Well, one thing we might know is that e to the x is its own derivative. So if we're thinking of dynamics here, we might ask about the velocity of our position  taking its derivative, and because e to the x is its own derivative, this is quite nice. The outer expression, is going to stay the same,  and then the inner expression as we're applying the chain rule is just i times t,  so we multiply the whole outer thing by i. And this gives us a literal way to read the equation in terms of dynamics, right? What we're saying is take whatever your position vector is,  if you rotate that 90 degrees, you apply this action of i,  that's going to give you the velocity vector. So wherever you're standing, draw a vector from zero, the origin, up to where you are,  rotate that vector 90 degrees, that gives you your velocity,  and that's enough to tell you how to move, assuming you know where you're starting. And of course we have to draw this out in the complex plane,  the fact that we've rotated 90 degrees already brings us there.  And I could draw out a bunch of different potential position vectors, you know,  suggestively maybe putting them on a circle and saying really imagine yourself  sitting at any one of those and following the rule for this dynamic.  And what it would tell you is, okay, I've got to sit there, rotate my vector 90 degrees,  that describes my velocity. And it doesn't necessarily have to be any one of the points on that circle,  any point in the plane, if you're following this dynamic,  you say rotate that vector 90 degrees, which if we're drawing a vector field,  we often scale down, and it's all well and good. And here you could phrase this question without even talking about exponentials or  complex numbers or anything like that, and in fact I'm going to go back to the quiz  just to really emphasize that Euler's formula and what it's claiming and then how  we apply it to expressions like i to the power i, it's very,  it's really intuitive as soon as we're putting some dynamics into it,  and we can ask questions removed from the idea of exponentials that actually have  the same substance in their answers. So here I want you to imagine starting a walk from the point 1,0 on the coordinate plane,  in such a way that at all moments your velocity vector is a 90 degree counterclockwise  rotation of the vector drawn from 0,0, the origin, up to where you are. After pi halves units of time, where will you be on the plane? Okay, so kind of think about that, think about that  dynamic and where you'll end up after a little bit of time. While you answer, let me see if we have any questions  that have popped in from the audience. No questions at the moment, at least that I see, so if ever you do want to ask,  go to Twitter, use the hashtag lockdownmath, those will be forwarded to me and then  sometimes they'll be on the screen that I can pull up here,  and that always makes for a fun time. For example, it seems like now we actually have one,  which is how about other solutions to the expression x equals i, such as 5 pi halves? Oh, I'm so glad you asked, I'm so very glad you asked,  we will certainly be talking about that. And if you just hold on for like one little moment,  that's exactly what we're going to get to, so I'll keep that on file for us to  pull up in a little moment. But right now while we're just trying to get intuition around the first,  you know, there will be multiple answers. The first answer we saw was e to the negative pi halves. Let's consider this lake question. So it seems like most of you correctly said that  this would get you at the coordinates 0,1. It's essentially walking you a quarter of the way around. I said lake question. I'm sort of picturing in my head as a big circular lake that you're going for  a walk around, because when you have this rule for dynamics where your position  vector rotated by 90 degrees gives you your velocity vector, that is circular motion,  because the tangent line to a circle is always perpendicular to its radius. So this rule of motion corresponds with walking around a circle,  and that's kind of the intuition for Euler's formula. Right? That you keep increasing that value of t, and this dynamical rule,  if e to the i t is going to behave according to the derivatives that we  expect of a function like e to the t, necessarily walks you around a circle. So in particular, when we're wondering how long does it take to get to i,  you would basically say just wait for an amount of time equal to,  well, whatever the angle to get up there is, pi halves. Okay, so in this case we're thinking pi halves. Let me see if I can get it exactly on the dot. Okay, 1.57. We're thinking of pi halves as kind of an amount of  time for these dynamics to get you on the number i. And that gives us the first half of our intuition if we want to go back to our formula,  and we're asking in what sense do two 90 degree rotations combine  to make e to the negative pi halves? Once we're thinking of our dynamics here as each one of your velocity vectors  as a 90 degree rotation of your position, this base i,  the way that we're kind of thinking about it reading it off as something with  meaning rather than just a number, is that as a point on the plane,  it's where you get after traveling for pi halves units of time according to the  dynamics of this expression, according to the idea that your velocity is always  a 90 degree rotation of your position. Okay, so that's awfully nice. And in fact, there's already sort of two different i's at play here,  which, or I guess there's three different i's at play. We have this base, which is describing the 90 degrees that we walk around the circle. We have the i that's sitting here, which is describing  the rule of rotating your velocity vector 90 degrees. But now we're going to introduce another i, which  essentially has this effect of changing what your dynamics are. Because as we go from e to the i times t, and instead we, you know,  raise things to another power of i, which I'll just write with a little caret i,  if we take e to the i t and we alter what that expression is by raising it to the i,  what we get is e to the negative t. Okay, so we have e to the negative t. And if we try to interpret that with the same sort of dynamics that we  had above in terms of a velocity and a position,  what that's telling us is that the derivative of our new dynamic e to the  negative t is equal to, well now the constant sitting in front of t is negative one,  so our chain rule will have it be negative one times itself, times e to the negative t. So whatever your position is, now your velocity is negative one times itself. So the effect of raising to another power i, it's kind of like we took the dynamics,  we looked at every velocity vector and we said rotate another 90 degrees,  so that in this context it would actually be in the beginning a  velocity vector pointing backwards with one unit. So if you're starting off at the number one, your  initial velocity is to walk straight toward zero. And as you walk even lower, if you were sitting at one half,  then you would still be walking towards zero, but now your velocity  vector would be negative one times where you are, which is negative one half. And what this means for the actual motion that this would imply,  you might kind of imagine it, I haven't animated this nicely yet or anything,  but if you look at this whole vector field and you ask each one of those vectors,  take wherever you are and rotate another 90 degrees, counterclockwise,  they would all be pointed in towards the origin. So if you were to have a little dot move in such a way that its velocity  always matches whatever vector it's sitting on top of,  what you would end up with is something where with each time step it kind of  takes a step towards zero and it just with each of your time steps is walking  towards zero and each step has a size that gets smaller and smaller as you  actually approach zero. And of course in practice, this would be a bunch of  infinitesimal steps rather than very concrete sizing. You might be very exact about it if you wanted and say what we're looking at  is scaling down by some number just less than one and we're doing this n  different times and then we're gonna multiply that by however much time we're waiting. And you take this as a limiting expression. That's just what we talked about in the compound interest lecture if you're curious  and it's kind of the standard way to talk about e to powers as this sort of limit. You could also have that t living on the inside here instead if you wanted. But now if we think about our original point i, our base, what that meant,  it was saying look at our dynamics and it's the point you get to when you wait pi halves  units of time. So the effect of raising to the i changes our dynamics in such a way that  instead of walking around a circle we're doing this kind of exponential decay. We're moving towards zero at a slowing and slowing rate and the place that you end  up after pi halves units of time will be e to the negative pi halves around 0.2079. So, you know, that's a little bit of intuition for in what sense do  two 90 degree rotations combine to get you this very specific value. One of them changes your dynamics and the original  one came from the idea of walking pi halves radians. So I think that's kind of satisfying in its own way because  otherwise when you look at the expression i to the i equals e to the negative pi halves,  it's like what does any of this mean? This doesn't correspond to any, you know, thing that might see in the real world. But thinking through the intuitions actually have you thinking  through things like what are the dynamics of circular motion? What are the dynamics for exponential decay? Things that come up in the real world all the time. But there is a potentially more pressing question  which was raised and let's see if it's still up there. Well, whoever asked it a little bit earlier, what  about other solutions to e to the x equals i? I think that's that's actually spot on and in fact,  let me let me ask other people to contribute some solutions here. So let's let's go to our quiz. Let me go to question number three, which is going to be very similar to  a question that was already seen, which is to write a value of x other than  the one we just saw x equals pi halves times i so that e to the x equals i. And feel free to be as creative as you want to try to  get an answer that other people haven't written, right? Um just to really emphasize that there are actually quite a  few different options here and then in a moment we'll talk  about why there are quite a few options if it's not already clear. But I'll give you a moment to think of which of the many possible values of  x you could choose is the one that you want to put your fingerprint on that  you want to be contributing to the live stats page that we're seeing right now. I'll give you a little moment. So, and as you're answering that we've got a question coming in  that says wouldn't it be more accurate to say that i to the power  i is i different 90 degree rotations, not two 90 degree rotations. After all it's multiplying by i that's the rotation. So if we stretch the meaning of words too thin, aren't we multiplying by i i times? I mean, I think the most honest answer here is just no not at all. No offense meant but that's just not what exponentiation actually  means as soon as we're extending to the idea of complex numbers. I get the intent you kind of want to stretch the meaning of taking i to the i. It's as if you're multiplying by itself i different times. But I cannot think of a way that that actually like satisfactorily makes sense in my mind. What I do think makes some sense is to try to think of the function i to the x. Say what properties do we want this function to have? And in the context of counting numbers, you know,  if n and k are just things like 3 and 5, we know that it should  satisfy this idea of multiplying the outputs correspond to adding the inputs. So we want to say if this is any kind of function, and I, you know,  I've said this in many different forms in many different places,  we want it to satisfy the property that when you add the inputs you multiply the outputs. That to me is kind of what exponentiation is more so than  trying to stretch the idea of repeated multiplication. So, it like, I mean, correct me if I'm wrong, if you can definitely,  if you can find some way where if you read this off in a stretching language context  saying we're taking a 90 degree rotation and applying that i different times,  that's not nonsense and that somehow like intuitively gets you to the answer e to the  negative pi halves, I'm all ears. But I think the healthier relationship to have is to say we have this central property  for exponentiation, which definitely holds in the context of repeated multiplication. But to extend beyond the places where repeated multiplication makes any sense,  because it just it just doesn't make sense when we're talking about something that's  not a counting number like i, or other crazy things that we exponentiate in math like  matrices. Focus on the property more so than what some people think of as  the origins of that property or the original intuition behind it. And an interesting question will be, you know,  is there just one such function that feels reasonable to write for this? Because, you know, if we're going to write it as i to the x not only should it  satisfy this, it should also satisfy, you know, when we plug in the number one we get i,  presumably i to the power one, however we're thinking of this function should be i. Is there just one such function or are there multiple such functions? That's what the quiz question is starting to get at and we've  got lots of different answers, which always makes me happy. So let's see some of the variety that people have thrown in here. So we've got five pi i halves. Great, that absolutely is another value that we could plug in for x here. And just to spell out that a little bit more visually,  if we were to look back at our circle here where we've at the moment walked for an amount  of time equal to pi halves, which is 1.57, what if instead we took another full turn and  we go another pi halves to get us to pi, which you know, we might kind of record,  that's where the e to the pi i value is. We walk another pi halves, we walk another pi halves,  which at this point we would have gone a full circle getting us back to one,  and then we walk for five pi halves, which numerically is about 7.85. Yeah, that absolutely is another number that gets us on top of i. And if we were to go through the whole rigmarole of re-expressing i  to the power i by first writing e to the five pi halves i to the power i,  those i's multiply to become negative and we'd be looking at e to the  negative five pi halves, which is a very different number, right? We can actually calculate this. I'm not sure off the top of my head, but let's take a look at Desmos maybe. Go over here. Let's ask it. What is e to the negative five pi halves? 0.000388. Okay, 000388. Much smaller number. 0.000388. Which begs the question of okay i to the i, what are you? Right? Are you about a fifth like we saw before around 0.2? Or are you this much smaller number? And in terms of our intuition, it's basically a  question of how we're interpreting that base i, right? Are we thinking of it as you wait about 1.57 units of time and then you  translate your dynamics into something that looks like decay rather than  spinning and see where you decay to after that amount of time, which is 0.2. Or do you wait even longer for about 7.85 units of time, which is five pi halves? And see what happens when you decay for that long,  which gets you to a much smaller number. But that's not the only answer that we could enter, right? We have other people coming in here with negative three halves times i pi. Which, you know, in terms of a unit circle, we could think of as saying,  hey if I want to get to i, rather than walking 90 degrees,  pi halves radians that way, what if I walk 270 degrees the other way? Three pi halves radians, which maybe I'll think of as negative  because the convention is usually that counterclockwise is positive. That absolutely is another way to express it. And that would get us a different answer. If we had e to the negative three pi halves i,  all to the power i, we go through the same game. Now the i squared cancels with the negative that's already there,  and we have a positive three pi halves. And numerically this gets us an even different looking answer from what we had before,  which if we go over and we say hey, what is e to the three pi,  not three o, three pi halves 111.31. Very different kind of number than what we saw before. 111 point, what was it? 111.31. Great. 111.31 or so. And again in terms of the intuition, what you might be asking there is,  suppose we have this rotating dynamic, but we move backwards in time. We see how long ago in time would I have to be,  such that if I played things forward from there, I would land on the number one,  my initial condition. And you have to go back in time three pi halves units. And then if you were to translate to the decay dynamics,  which is what raising to the i is doing in this context,  you say if I'm starting at the number one, but I want to move backwards in time  and say where should I have started if I want to decay down such that I end up at  the number one after three pi halves units of time? the answer is evidently starting at around a hundred  and eleven for that kind of exponential decay And you can see where this is going, where there's actually infinitely many different  values that we could plug in for x if we're thinking of e to the x as being i. And people have entered a lot more here. Excuse me, throwing my pen onto the ground as one does. Classic for third place. Nine pi halves, great choice. 1729 pi halves, y'all are my favorite. Lots and lots of different options, infinitely many different values,  which feels a little disconcerting at first, right? Because we look at an expression that seems like,  you know, there's just going to be some computation. I just plug that into my calculator and see what pops out. And we've got multiple different values for it. So what's going on here, right? What's going on? And I think this really cuts to the idea of how we think about exponentials in general,  right? But before that I do want to emphasize that this isn't the only time in math  where we come across a kind of ambiguity for how to interpret something, right? Because if I say something like, what is the square root of 25? You know, I think a lot of us say, well, it's five. But if we are saying, you know, what should the square root be? It should be some number x such that when you square it you get 25. Well, there's two different answers to that. Who's to say that our conventions should be that the square root function is positive,  gives us a positive number rather than negative five. So we have one expression that seems like it wants to have multiple different values,  right? And this could actually happen in another context where instead of square roots,  what if I was asking for the fourth root of something like 16? Usually we would think of this as positive number two, right? Two is a number such that when you multiply by itself four times you get 16. Seems like a decent answer to a fourth root. But if we're thinking of this as answering the question,  what number to the fourth equals 16? There is another answer to this. We could also say negative two. That's a number that when you multiply by itself four times you get 16. But there's another answer. You could say two times i. That seems valid, but there's another answer. You could think negative two times i. All four of these numbers satisfy that property. So who's to say that the fourth root of 16 should be two? And the answer ends up being, well, we adopt a convention. When there's multiple options like this, when you have a multi-valued function,  we often just choose one of those values to be what we mean when we want to  treat it as a function, as something with a single input and a single output. In fancier lingo, this comes up all the time when we're dealing with complex numbers,  the idea of something as an operation kind of wanting to have multiple values. You'll sometimes hear the phrase branch, where you choose a branch of  the square root function, which is to say you choose a certain convention. In real numbers, it's nice and easy sometimes  because you say just choose the positive one. But there's no notion of which complex numbers are like the  positive complex numbers when we want to take square roots. Just to give one example, let's say we wanted to take the square root of i. And we want to know what should that be? Because there's multiple different answers. You know, we think of i again as this 90 degree rotation. And if we were thinking of it as a 90 degree rotation,  it feels like the square root should be, you know, something sitting at a 45 degree angle. Maybe that's the square root of i, which we could write  out very explicitly as root 2 over 2, root 2 over 2 i. That's just using trigonometry. But if we were thinking of i instead as being a negative 270 degree rotation,  it feels like half of that, doing half of that operation,  should actually get us on the other side. Maybe the number sitting down here should be the square root of i. And that's actually just the negative of what we saw before. Negative root 2 over 2 minus root 2 over 2 times i. Now in the context of real valued functions, we can say, yeah,  just choose the square root to be whatever the positive answer is. But which of these do you consider the positive answer? You know, maybe it feels like we should consider this  upper one because its coordinates have positive numbers. But however you try to define positive in a nice way here that's going to be consistent,  you know, for example, two positive numbers should always multiply to make a positive  number, you're not really going to be able to do it the way that you can for real numbers. And in fact, this phenomenon here where we're taking roots is  actually the same as the phenomenon we were just looking at when  we were talking about multiple values for i raised to the power of i. Because forget i raised to the power of i, let me ask what might  look like a much simpler question of taking 2 to the power one half. Okay, what's 2 to the one half? Yeah, I think you say, well, we know what this is,  we kind of define it to be the square root of 2, all is well and good. But what if I said let's approach this the same way  that we were approaching our i to the i expression? I want to first express things as e to the something, right,  and then I'm going to raise that to the one half by multiplying the one half  into the exponent. And I say, well, okay, I can, I guess I can do that. e to the what is equal to 2? Well, that's the natural log of 2. It's a constant which is around 0.69 or so. If we raise e to that power, we'll get 2. So we could be thinking of this as e to the natural log of 2 times one half. And if you wanted to, if you were thinking of e to the x, you know,  this might be kind of overkill in the context of real numbers,  but if you were thinking of e to the x as shorthand for this x function,  you could plug in the value 0.69 times one half, which I guess would be around 0.345ish,  something like that. You plug in that very concrete value into your polynomial,  see what it outputs, and it will output around 1.415. So that's a nice real number. Square root of 2, what you would expect. But if we do the same thing we were just doing with i and  acknowledging that there's actually multiple different answers  when we want to write something as e to a power, we could also write this. This might seem funny, but we could write it as e to the natural log of 2 plus 2 pi i. That whole thing raised to the one half. Right? After all, this value will come to equal 2. You could break it down as it's e to the natural log of 2 multiplied by e to the 2 pi i. This one just has the effect of rotating things 360 degrees. So it's just going to equal 1, so we're looking at 2 times 1. Great, that feels like a valid substitution. And yet when we play the same game of taking this and raising it to a power and  treating that by multiplying the power into the exponent, look at what happens. We have e to the natural log of 2 times one half plus Well, what's 2 pi i times one half? Well, that will be pi times i. Now this first part, e to the natural log of 2 times one half,  that will end up being the familiar square root of 2. That's all well and good. But we're going to be multiplying that by e to the pi i. Right? And quite famously e to the pi i is negative 1. So in this case, it seems to be suggesting that if we are solving this expression  2 to the one half by playing around with the different answers we could plug in for  something like e to the x equaling one half, what we end up with is another answer. What we might traditionally write as this negative square root of 2. And here, I mean it's a little funny for it to have multiple values  to look at 2 to the one half and say that's not equaling one thing,  but based on choices we make it could equal multiple different things. But the two things that it could seem quite reasonable. If there's going to be anything that 2 to the one half is,  it seems like it should either be the positive square root that we're familiar with or  the negative variant of that. That doesn't actually seem like such a problem. And in fact, we could we could play this game even further,  where let me ask you for even more creative answers to this expression. Because maybe we can find other funny powers of something like 2 to the power x as  we start plugging in various different values of x based on what substitution we make. If we're abiding by the same rules that we were using in evaluating i to the power i. So this time the question asks or it specifies that one solution of  the equation e to the x equals 2 is the real number natural log of 2. Okay, that one we know it. It's not boring, but it's boring in comparison to what else we could do. Can you think of another one? Can you write some other answer to the question e to the x equals 2? And again, creativity is welcomed. So I will give you another little moment for that. All right, I will go ahead and lock in some answers here if that's all right with you. I'm not sure how much time it necessarily takes to do  the math entry depending on what device you're looking at. But don't be too stressed if it's before you got the chance to enter  the question that you want into the answer that you wanted to answer. So it looks like 131 of you have entered the variant  where we take ln of 2 and we add 2 pi i. And I guess I in writing this question mistakenly like marked one of the  answers as being correct when in fact there's quite a few different correct ones. So that's on me for the fact that I don't know if it looks to any of you like,  oh, it's red you got it wrong when you entered ln of 2 plus  42 i pi which is of course a great choice. But you could also have something like 4 pi i plus the natural log of 2 or 6 pi i. Or really any integer multiple of 2 pi i if you add that it doesn't affect e to the x. Because it just has the effect of multiplying by e  to the 2 pi i which is the effect of multiplying by 1. And again, this has kind of a funny consequence where it  seems to output kind of reasonable results when we do it. As another example, it looks like the second most common  entered expression there was that we might replace 2. So let's think we're thinking of 2 to the power of one fourth. Okay. There was a suggestion that we replace 2 with e to the natural log of 2 plus 4 pi i. Okay. Plus 4 pi i. And we raise all of that to the one fourth, right? Well if you were to play the same game you would get e to the natural  log of 2 times one fourth and we'd be multiplying by e to the pi i. Now the first part of that is going to be the usual positive fourth root of 2. The thing we mean when you plug in an expression like fourth root of 2 into a calculator,  a nice small positive number. But then this second part is negative 1. So it seems to be saying, you know, if we were to interpret 2 in this different way,  raising it to the one fourth, you know, it's not the usual answer  that we get but it's a reasonable answer. It's another number that when you raise it to the fourth power you get 2. And if we had done this with even different values, if instead we had been using 2 pi i,  you know, it's kind of fun to think about how that would have changed things. If instead of 4 pi i we had been adding 2 pi i,  well then over here we would have been looking at pi halves times i. And instead of multiplying by negative 1 we would have instead been multiplying by i. Which again is a valid answer. It seems like a reasonable output for something like 2 to the one fourth. So when you're looking at the fact that i to the power i seems to have multiple different  values for it, right, we have this funny phenomenon where we can plug in e to the 5 pi  halves i, negative 3 pi halves i, and we get what seem like wildly different answers. Something super small, something super big, all very different from the one fifth,  approximately one fifth answer that we found before up here. It's exactly the same phenomenon as when you're asking something like  what's 2 to the one fourth and acknowledging that there's actually  multiple different solutions to the expression x to the fourth equals 2. Four different solutions in fact. And what you're looking at is the fact that there's multiple different  solutions to the expression e to the x equals some kind of base,  whether that base is i, whether that base is 2, whatever it might be. And one way that we might think about this is that when  you're dealing with real numbers things are just lovely. Things are nice. There's one-to-one relationships. You've got positives. It's great. Where if we want to think about exponential functions,  let me just cover some of this stuff up. We have this nice back and forth where you can choose to express any  exponential as a base to x like 2 to the x or you could express that same  exponential as x of r times x which you know, that is the polynomial that  we refer to whenever implicitly refer to whenever we write something like e to the x. And there's a lovely back and forth because you can just take a natural  logarithm of b and it gives you one answer assuming that b is a positive number. And that's the same thing as saying that x of r is equal to b. So one way that I've talked about this earlier in the series is  that if you were looking at the family of all possible exponentials,  right, we could write them as x of r times x and change what r is. And this is exactly the same thing as writing e to the r  times x if that's something you're more comfortable with. So e to the r times x x of r times x those are the same thing. We could think about changing what that is. But on the other hand if you were to think about all possible exponentials as some base,  let me do base to the power of x and we're going to change what that base is. At first it feels like that's a different kind of expression to  manipulate but it's just another way of expressing the same family. Right, and a way that you might think about this for how do we think about what base  does it correspond to if we're thinking a little bit more abstractly as exp of r times x. And there's a reason I'm doing this because we're about to  apply this to complex numbers where it's going to look weirder. So follow through with me here. If instead of looking at that base, one thing I could do is say what is the  value of exp of r, right, which is basically this function of when we plug in one. So exp of r times one if you prefer to think of it that way. And that is being represented by our green line. nd what you could see is okay if I get R that Factor in front of X in my exponential  function exp of R X to be zero point six nine Which I know is around the natural log of  two What this means is that exp of one is about two. And so this corresponds with the function that  we would usually write as two to the power x. Right. Okay, and basically as I change around my r, you know,  I could try to change it to something so that it looks like three. So around 1.1 that exponential looks like three,  which we would usually write as three to the power x. I would like to argue that it's a little bit healthier to  think about varying this value r rather than varying the base. And the main reason is that as soon as we get to complex contexts and we're  thinking of exponentiation, you have this overloading that goes on where  if we change around what sits in front of the x, that's all well and good. I could have exp of R times X where maybe R is something like zero point six nine But I could shift that down by 2 pi i. And that doesn't change the base that it would correspond to. That would still correspond to two. Or it could shift it up by 2 pi i. That doesn't change the base that it corresponds to. Because in all of those cases when we plug in x equals one, we get the same thing. However, all of these for different values of x are distinct functions. This is why we saw multiple different values for i to the power i. Because i to the x is an ambiguous function in that context. It would be unambiguous if we decided which value of r such that what  we're representing is exp of r times x, which value of r do we choose? As soon as we choose one, it's an unambiguous function. But at that point it just feels like maybe what we want is to stop  thinking about things in terms of some base raised to the power x. Maybe as soon as we're in the context of complex numbers,  we should just write them all as exp of some constant times x. If for no other reason, it makes crystal clear how we actually plug in  numbers if we want to do a computation, or just to do math on top of it. We've got this nice infinite polynomial that we plug them into. And I'll make another case for you that this is maybe the the correct way to think about  exponentials, as soon as we're extending into other domains, things like complex numbers. And for that, let's just let's just back up. Go back. Oh doorbell, something's arrived. Go back to the original way that we extend the idea of  exponentiation and just think of like what is two to the x? Right. We know how to think about this for natural numbers,  you know something like two to the three, repeated multiplication. How is it that you're first taught to think about something like two to  the x for fractional amounts or for negative amounts and things like that? Well, you're usually taught that two to the one half should be something where you know  if I multiply it by itself and this follows the usual rules that exponentials do with  counting numbers where we're able to add things in that exponent,  I should get two to the one. So it should be some number that when I multiply it by itself, I get two. And you know at that point you have a choice. Maybe it's positive. Maybe it's negative. But if you always decide to make the positive choice,  you're going to be able to get a nice continuous function out of this. Same deal if we ask about negative numbers, what should two to the negative one be? Well, that should be something where when I multiply it by two to the one,  it gets me two to the zero. And that's kind of the justification for our convention  that negative exponents look like one half. But what's really going on here is we're saying whatever this is,  it should be some kind of function that satisfies this property f of a plus b equals  f of a times f of b. And moreover the fact that the base is two is basically  telling us that it's not just any such function. It's a function where when we plug in one we get two. And just as a little, you know, sanity check style question to  see if you're following along with some of the implications here. I want to ask you what is, I won't call it like a softball, but this is,  this isn't meant to be like an incredibly deep question necessarily. It's just more of a check if you're following along with the idea of  abstractly starting with properties of a function and then kind of  deducing ways that we might want to write it down based on those properties. If f of x satisfies this exponential property f of a plus b equals f of a times f of b  for all inputs, and it also satisfies f of one equals two, which of the following is true? Which is to say which of the following is necessarily  true no matter which such function you're starting with. And those of you who remember which lecture was it? It's whichever one we were talking about how to  interpret what Euler's formula is really saying. I asked a question of this style where I neglected a single condition,  you know, I didn't write down the fact that we want to make sure f of  x is non-zero everywhere and then that caused some amount of confutlement. Which is cool, get confutlement on screen that happens to all of us. But the the intent of it was to basically show that this abstract property of  something that turns addition into multiplication is uh is enough to basically make  you want to write the function as whatever it equals as one raised to some kind of power. This is the the spirit of the question. Um Now we've got a couple questions actually about power towers that  seem to have popped up here, which is great connected to last time. Um, let's let's hold off on the power tower question for just a moment,  so that we first get like a deeper feel of like what exponentiation should mean here. Um, because because we can be what I want to claim  is we can answer it in like multiple different ways. So if you give me just a moment, we'll talk about power towers. Uh, and then just as a number line can be represented in a logarithmic scale,  can the same be done for a complex plane? Maybe mapping the complex plane onto an infinite cylinder in the logarithmic sense. Yeah. Yeah, uh, in fact, there's a visualization that I'm going to get to  in just a moment here where we do something quite similar to that. Because what we'll do is play around with different exponential functions x of r times x,  but we're going to change that value of r which is going to be  represented by a little yellow dot. So we'll kind of talk through this. It's not going to map the whole plane, but just a couple  sample points from the real axis and the imaginary axis. But the idea is that as we move around what that constant is,  we're going to be able to kind of visualize the different things that um,  it does to the plane. And effectively, it's like it's turning the x-axis into a  logarithmic scale and then wrapping the imaginary axis along a circle. And then as soon as that value of r becomes imaginary, it swaps the role of those. Real numbers get put on the circle and imaginary  numbers get put on a logarithmic scaled positive axis. So great question. All three of which I guess are sort of jumping the gun ahead for where I want to go,  but nice to see that's where people are thinking. So on this one, let's go ahead and just grade it. The idea is that this property of f of a plus b ends up letting you  express a lot of different things purely in terms of what f of one is. And just to spell that out very explicitly, something like f of five is the  same thing as f of one plus one plus one plus one plus one,  which is the same thing as f of one multiplied by itself five times because  of this property. Which if f of one is two is the same as two to the power five. And then something like f of negative five, it should be the case  that when we multiply it by f of five, we get whatever f of zero is. And it's not immediately clear what f of zero is,  but we could say that f of one plus zero is equal to whatever f of one is  times what f of zero is. But f of one is equal to two, and so this is also equal to two. So we're saying two is equal to two times something. Well that something has to be a one. So in this context this guarantees that f of negative five is two to the negative five. It's one over two to the fifth. So we could explicitly write this as two to the negative five. Which is all to say, these two properties together make us really want to write  the function as two to the x, because any counting number that we put in,  it's going to satisfy, it's going to look like two multiplied by itself that number  of times. Any fractional number we put in, it's going to satisfy these properties that we wanted. And you might wonder, is that unique? And in the context of real valued functions, it actually would be. But in the context of complex valued functions,  there would be multiple such functions f that we could write for this. One of which is what we were looking at before,  where we could have a function defined to be exp of the natural log of two plus  two pi i all of that times x. Okay, forgive the sloppiness here. I just get excited writing about this. And this is actually a different function, as evidenced  by what happens if you plug in x equals one half. Right, we saw a little bit earlier how when you plug in one half,  what you get is the negative square root of two. And then if you plug in one fourth, you get not the fourth root of two,  but i times the fourth root of two. So it is a different function, but it still satisfies these properties,  and it kind of makes us want to write it as two to the x. And it makes it suggest that maybe two to the x is an ambiguous bit of notation,  and we should just write everything in terms of exp of r times something. But you might wonder, well, you know, maybe we're just not being  creative enough with all of the functions that satisfy this property. Maybe there's an ambiguity when we write exp of r times something,  and there's different values of r that could come into play. Um, but I'm just going to put down a little claim,  and then maybe give like a sketch of what the proof would look like if you want,  which is that let's say you have some complex function f,  and it satisfies the following properties. First, you're able to take a derivative of it. It's differentiable, which just keeps it from being some, uh, you know,  totally messy discontinuous thing that's like taking on some random values depending on,  you know, the span of whatever vector space over, I don't know,  fractional amounts you might want to think of in crazy ways. It's a nice function that's differentiable. It's not equal to zero everywhere. So the condition that sort of slipped my mind and I forget which lecture,  lecture four or something like that. And then it has this central property that it turns addition into multiplication. If you have such a function, I claim that there's a unique,  maybe I should really specify, there exists a unique complex number r so that  you could write f of x as basically being this exponential function of r  times that value x. Which is, you know, basically saying that if you have exp as a function,  this infinite polynomial with nice derivative properties and all of that,  if you have this you have every exponential that you want in a very like abstract  generic sense of the word exponential just based on a property that we could want from it. And the sketch of the proof would look something like this. If you want to first look at what is the derivative of this value,  which we're assuming exists everywhere, right? And you explicitly write out what the limit of that is. I'll just talk through it very quickly here for those who  want to like pause and think through the details, feel free to. The central property that we have lets us expand out the f of x plus h term. So we're thinking, you know, a change, slight change to  the output over the change to the input that caused it. That's what df dx unwraps to. And because we can factor that out, we can factor f of x out of the  expression entirely and the whole limit is expressed only in terms of h. Which if you think about what it means in the context of derivatives and the fact  that f of zero necessarily equals one, this whole limiting expression is just some  constant, but more specifically it's whatever the derivative of our function at zero is. So you have this funny thing where if you know its derivative  at zero that determines what its derivative is everywhere. And in the context of exponential functions this is hopefully quite familiar because all  that we're really saying is the derivative of an exponential function is proportional to  itself and that proportionality constant is equal to whatever the derivative at zero is. This is all very abstractly phrased and such, but the purpose of it is to  emphasize that it's not necessarily just functions that we already think of  as a to the power x, but it is a potentially much more broad class of functions  that just satisfy this abstract property of turning addition into multiplication. But if you have that, it actually guarantees that you also have a second derivative. And for that matter a third derivative and such because  the derivative function is just proportional to itself. So in order to take the nth derivative you just look at  that proportionality constant and raise it to the power n. And then from here you could do a Taylor series expansion and I might leave that as sort  of the advanced homework for those of you who are comfortable with Taylor series and that  idea especially if you want to intermix the idea of any differentiable function that's  differentiable in a sense of complex numbers, which is sort of a definitely college topic. You know, you could intermix the reasoning there as you want,  but fuzzy reasoning is allowed in the context of someone who only knows about Taylor  series and nothing else to take this idea and look at the Taylor expansion for f and kind  of justify the idea that there's a unique complex number such that our function f can  necessarily be written like this. And then the connection to normal exponentials is whenever you have such  a value r we do essentially what we do in the complex context of real  numbers is if you look at x of that function of that value r and write  that as a base it feels like you should be able to write that as b to the x. But the whole the whole point here of course is that when we play this game and  you're trying to interpret something like i to the x that's an ambiguous function  because there's lots of different values of r we could interpret that to mean  not just exp of pi halves i times x but we could also interpret it to mean exp  of five pi halves i times x and these are separate functions and there's an  infinite family of separate functions that feel like we should write them as i to the x. So the expression i to the i unless you've adopted a standard for what that's necessarily  going to mean when you say it has infinitely many outputs another way to think of that  is that the function i to the x with the notation we have is a little bit ambiguous. Now with all of that, let's let's just start visualizing  some of this because I think that's fun. And you know, you you tell me if this is if this is a helpful visual or a more  confusing visual but what we're going to do is look at this function exp of  r times x which is basically this is another way to write e to the power of x. In fact, I think I I think I rendered a different animation at some  point that specified that because I was planning on planning on doing that. So let me oh, yeah, there you are get back in my  file system get back to where you're supposed to be. Get on in there is it complaining because there's multiple different? It's going to be like there's a oh replace it shows up on the other screen. Wait, why is it? Yeah, okay replace place whatever you see there. And now we go back to oh there we go all of that all of that just so that I could have  nicely written out uh, if you're uncomfortable with thinking of it as exp of r times  x this infinite polynomial Just in the back of your head e to the r times x and we're  going to vary around r So i'm going to follow the points of the imaginary axis and  i'm going to follow the points of the real axis And uh, let's see what this does Well,  that's all kind of fast so let me think through it a little bit more slowly all of  the negative numbers Anything that's a negative real number is going to get squished  into the range between zero and one which should make sense e to the negative e to a  negative real number is something between zero and one and we're Specifically tracking  f of negative one which is going to show up around whatever one over e is around zero  point three seven f of one lands on e As expected that's what x of one is f of i Is  going to land one radian around the unit circle and it's kind of fun to follow along  the whole imaginary axis here How the imaginary axis gets uh wrapped around a circle? And what happens as we tweak this value of r that's determining not just that we're  talking about an exponential function But which exponential function there's a nice  one-to-one correspondence between all the exponential functions we might want and  values of r here It stretches things differently So when we put it up to two You know  it stretches out the real axis a lot more so that f of one ends up around where e  squared is a little Above seven f of negative one is much closer to zero f of i Is a  two radian rotation around the circle f of negative i is a negative two radian rotation  And of course we can get to our favorite formula that If that were pi that we had as  our scaling constant then the real axis gets stretched out quite a lot you know f of  one is sitting off at e to the pi which is very close to 20 plus pi which is always  fun and f of negative one extremely close to zero so It's really stretched out that  real axis and it's also stretched out things in the Unit circle direction so that  getting to f of i or f of negative i walks halfway around the circle So that's all  well and good now. How would we think about a function like? two to the x Which is what? We would also write as exp of Exp of the natural log of two times x So we  kind of move our yellow dot representing the value of r to around zero point  six nine still no imaginary part Just a real number zero point six nine or so. That's the natural log of two Well, you can see that f of one lands on two,  which is why we want to call this function two to the x f of one half actually,  sorry f of negative one lands right on one half f of i It's some walk around the unit  circle very specifically it's going to be 0.69 radians around the unit circle And now  we could have a little bit more fun and say what would happen if we were to Change this  to instead of being 0.69 instead of being the natural log of two make it i times the  natural log of two So that we're really thinking of something that might have an  exponential base to it This would be what we might think of as two times i Raised to a  power Well, if we move that yellow dot which is representing r off of the real axis and  onto the imaginary axis it swaps the roles of the Teal dots and all of the maroon dots  in this context which remember came from being the positive and imaginary axes And it  should make sense that it swaps their roles because what does it mean if we take the  input space and we multiply it? By i it means we're rotating that input space So everything that was the real number  axis turns into the imaginary axis and everything that was the imaginary axis Is  getting turned into the real axis So for us what that means is our new exponential  function where our value of r is now purely imaginary Takes all of the real numbers  and it just wraps them around a circle and it takes all the imaginary numbers And it's  putting them onto the real number line So in particular,  let's say we scale this thing up so that we're sitting at around pi halves times i Well,  what does that actually mean? That means it takes the real number one to the value i Which is the  sense in which we want to write this function as i to the power x Right. It just tempts us to write it not as this abstract looking thing X of r  times x where r is equal to pi halves i no No,  we just want to write it as i to the x even if that's a little ambiguous  What that really means is just that the function we're dealing with outputs  i at one and if it's an exponential function that Uh,  and we're asking what does it do to the value i? What is i to the power i? In this case, it shoves it to around uh, 0.2 around a fifth But there's many  different exponential functions that would have this property of putting f of  one onto the number i So if we were to scale it up even further,  I don't think I have it animated here But if we were to take that yellow dot  and raise it up until it got to five halves times pi i What you would see is  that the unit circle? Uh is rotated around on itself so that f of negative f of one would rotate around another  two pi radians and land where it is But it would stretch out the real axis a lot more  Which was the sense in which another output of i to the i is a much much smaller number. It was around. What was it? 0.0003 or so But we can also see what I think is quite fun. What happens if we consider Alternate expressions  that we want to interpret as two to the power x right? So when r is a purely real number the natural log of two kind of makes sense  that when you plug it in here The expression we get is what we want to write  as two to the power x But what if we start moving it in the imaginary direction? Okay And what i'll first do is i'll move it up by pi i units Now what's going on here? We have x of r times x and r is equal to this value,  which is the natural log of two plus pi times i What that means is that  when we plug in one? f of one is at negative two, so we want to write this function as negative two to the  power x right, and that's actually something that You know,  it's it's a little deceptively simple when we write a negative number to a power Negative  two To the power x it doesn't at first look like this necessarily it brings us into  the complex numbers in any way but of course when we plug in even a value like One half  Where we're kind of asking for a square root of negative two We we realize that we want  to write this as something like i times the square root of two But if you were to look  at this function negative two to the power x in the full complex domain that it's  dealing with What you're looking at is a function that takes the value of one to negative  two And if it does that what it does to the rest of the real number line is it kind of  spirals it outward? So we see that f of negative one sits at negative one half About where you would expect  if you were to follow to f of one half It would sit exactly on the imaginary line and  f of one half would be square root of two Well, my mouse is not where I want it to be. It would be around a square root of two times i and As you continue further on this is  showing you all of the real value powers of negative two to the x it necessarily spirals  around Um, but we could also move our value of r even higher and get it up to around  tau times i around 6.28 times i And in that context,  this is another function that we would want to write as something like two to the x  because For any whole number to whole number that you plug in for x it will look like  repeated multiplication And it even has kind of reasonable values for things like one  half where it spits out the negative square root instead of the positive square But  what it's actually doing is a transformation to the plane where it puts everything Uh  is the real number line ends up being a very tightly wound spiral That goes around and  it just spirals in such a way that f of one lands right on the number two so it is in  that sense that we could say, um two to the x is Is plausibly interpreted as a separate  exponential function from the one that we are traditionally used to so I think with  all of that I will um I will leave things for today and i'll just leave you with a  couple lingering questions to think about. Okay, so If you want to think of i to the i as being a multi-valued expression, right? You could you could say we adopt a convention Fancifully you'd say you choose a branch  of the natural logarithm function and maybe that locks you into this being e to the  negative pi halves But if you say this kind of wants to be infinitely many different  values like the various ones that we saw How many values does two to the one-third  want to be in the same sense where we are replacing two with various different uh  various different options for e to the x Such that e to the x equals two How many  different values does that want to be or how many values does two to the three-tenths  want to be? Phrased differently of all of the uh, let me say of all of the exponential functions  So f of x which satisfy oh have I written it down somewhere f of x that satisfies  All of these properties that i've written so if it satisfies all of these um and  if f of one is equal to two Right, how many different outputs are we going to get  when we plug in x equals three-tenths for the various options for what function? That is and how many outputs are we going to get? For two to the pi for the various functions that two to the x could represent If we're  thinking of two to the x as some kind of exponential function exponential in the sense  of these sort of abstract properties and if we uh yeah,  if we if we have a Class of different such functions and we want to plug in pi it makes  me laugh just because it's such a I don't know Kind of a funny answer that pops out As  you're trying to think about it. So those are the questions that i'll leave you with and I think this is you know,  my my My central question in approaching today's lecture was whether I wanted to be  um kind of describing like these abstract properties of exponential functions and it's  just cool to me that Starting from those abstract properties you get locked into the  idea of e to the rx or more You know, I think more honestly written exp of r times x  for different values of r That it locks you in that far but it doesn't lock you in as  far as having an unambiguous Notion of what two to the power x should be much less  something like i to the power x The risk in that of course is that sometimes people  don't love abstraction and sometimes it doesn't come off as approachable But if that's  the case, you know, you just let me know I think I think there's a whole interesting  circle of thoughts that surrounds all of this stuff to include power towers because  if you want to Actually talk about power towers like we were last time in the context  of complex numbers or even with negative bases You have to be thinking through things  like this so, um, it was a question that we had up on screen Uh, yeah,  what happens if we do this for i to the power i titration, you know,  let's just try this Let's just go ahead and try a power tower where we're raising i  to a given power and see what uh, what pops out of it so I wasn't planning on doing  this but we can We can always pull up python and essentially do what we were doing  last time so the way that this would work Is we were starting off with some base value  and then for some kind of range What were we doing? We were taking a and we're going to reassign it to be whatever The base  which in this case is i raised to the power of a should be Okay, cool. So we're going to do that and then we're going to print off the value of a and let's just  do this for Uh, yeah, it's a much bigger number like 200 uh So it seems like what happens  is There's there's potential for chaos with these things like sometimes it's not that  you've landed on a stable A stable value or it's not even that you've diverged it could  be that you're bouncing between a cycle of values or That you're like literally bouncing  in a way that's um, it's not periodic or anything and it's actually chaotic I I suspect  that doesn't happen for i but it's a thing to potentially look out for It looks like it  does kind of stabilize um, maybe there's Some little subjection to numerical error,  but we stay pretty consistently around something with a real part of 0.43 and 0.36 Now  what I would want to emphasize though is this expression So let's set a back to b equal  to 1 this expression of taking i to the power of a remember That's a little bit ambiguous. It depends on what choice of the function I we actually have so let me Let me  import NumPy so I have the exponential function Let me go For our big range like  we had before Rather than writing it as you know,  something that's like i to the power of x I'm going to write it as the exponential  function of a different constant right a different constant That i'm going to make  I want it to be five pi halves. So i'll do five pi halves times i so it's a complex number And it's got five pi  halves as the imaginary part So this is five pi halves times i and what am I doing? I'm exponentiating that So I want to multiply a onto the inside there. Okay, this is basically another way that you could interpret the expression i to the  x Thankfully you would say you've chosen a different branch of the natural log function  But it is another Function which we could iterate on itself and see what happens and  we might get a different result Ah very interesting, okay,  so we actually have a different result It looks like what ends up happening is it  bounces between two values? Oh, wow, is it period three? That's interesting period three implies chaos. So we've got seven point three five then zero then point nine nine So it looks like it  gets into the cycle of bouncing between three separate values even though um In theory  in both of those cases we were doing something that was i to the x iterated on itself  It has everything to do with what actual function you think i to the x is referring to  so in that sense The power tower question is ambiguous Usually you just choose it to be  the pi halves i variant but it's more fun to see that it can be multiple things All right. We have addition multiplication exponentiation titration. Can we think of something in between halfway between multiplication and exponentiation? oh, that's an uh, I mean Spirit of it because each one of them it comes  down to like a discrete step of you're repeating the previous operation  But oftentimes in math when you have something initially defined in  terms of repetition Like exponentiation you can extend it beyond that. I can't think of anything off the top of my head,  but that's an interesting question I don't know if that's been That's an extended notion. I mean you have things like fractional derivatives you have things like fractional  and complex exponents So it doesn't seem outlandish,  but i'm not familiar with one myself And then lastly do complex numbers to the  power of complex number values arise in physics and if yes How does one decide  which values are valid? so I can't think of if they necessary. Oh, sorry scene switching. I can't think of if they Come up in physics in like a direct  sense and this is probably just because i'm not a physicist. icist so I Would say like ask ask your neighborhood physicist and see see what they  have to say I mean clearly The point of teaching the lesson here is that the thoughts  that you have to go through to make sense out of it do build a stronger relationship  with exponentials things like it's not just more natural to represent them as e to the  rx Once you get to complex numbers you kind of have to represent them that way whereas  previously in like physics or other real-world contexts It's something that's just nice

================================================================================
VIDEO ID: D__UaR5MQao
TITLE: The DP-3T algorithm for contact tracing (with Nicky Case)
URL: https://www.youtube.com/watch?v=D__UaR5MQao
PUBLISHED: 2020-05-14T15:00:01Z
STATUS: SUCCESS
================================================================================
Not infected yet, infected and contagious but with no symptoms,  and infected, contagious and showing symptoms. If you have widespread testing, you can get people  to self-isolate as soon as they show symptoms. The problem is that the virus still spreads because of all the  contacts that happened while people are contagious but asymptomatic. However, if when someone shows symptoms and tests positive, you isolate not only them,  but everyone they've been in contact with, you're staying one step ahead of the virus. The old-school way to do this is with interviews, but that's slow,  it's inefficient, and frankly it's quite the intrusion on people's privacy. Another approach in the modern world would be to ask people who've  tested positive to forfeit all the geolocation information from their phones,  and then to track down the people who've been in those same spots. But now we're well into big brother territory,  so do we have to sacrifice privacy for health? Well, I'll just let Nicky's illustration speak for itself here. There are several clever algorithms that let you alert everybody  who's recently been in contact with someone who tests positive for COVID-19,  but without compromising the privacy of anybody involved. Side note here, I found this very surprising. I know it shouldn't have been, since I've gone through this dance many times  of thinking something's impossible only to see that cryptography makes it  actually possible, but I would not blame anybody at all for assuming that  downloading an app that can alert everybody you've been in contact with must  necessarily be tracking and revealing your location and a lot of other information. The code for these apps is entirely open, so you don't have to trust me or whoever  wrote the app or Nicky or anyone to believe it's doing what it really claims to be doing. Anyway, back to the post. Let's see how this works with the help of Alice and Bob. Alice gets a tracing app. Every five minutes her phone sends out some uniquely  pseudo-random gibberish to all the nearby devices using Bluetooth. Because these messages are pseudo-random, they don't use GPS and contain  no information about Alice's identity, not her location, not anything. It really is gibberish, but the key point is that this gibberish is unique. Now, while her phone sends out messages, it also listens for messages from nearby phones. For example, Bob's. Bob also has a privacy-first tracing app that's compatible with, or the same, as Alice's. If Alice and Bob stay close to each other for more than five minutes,  their phones will exchange respective strings of unique gibberish. Both of these phones remember all of the messages  that they said and heard over the last 14 days. Again, because the random messages contain no information,  Alice's privacy is protected from Bob and vice versa. The next day, Alice develops a dry cough and a fever. Alice gets tested. Alice has COVID-19. This is not a good day for Alice. But she won't suffer in vain. Alice tells her app to upload all of the random gibberish  messages that it's been sending out to a hospital database. And to do this, she uses a one-time passcode given to her by her doctor. This code is to prevent spam. The database then stores Alice's gibberish, and again,  the random messages give no information about Alice, where she was,  who she was with, what she was doing, or even how many people Alice met. It really is meaningless to the hospital. But it's not meaningless to Bob's phone. Bob's phone often checks this hospital list of random  messages that have come in from COVID-19 positive cases. Essentially, the hospital's database is saying to all the phones out there,  hey, we just got this new random gibberish. If you've seen that same random gibberish sometime in the last 14 days,  it means you've been in contact with someone who just tested positive for COVID-19. Once Bob's phone recognizes some of these numbers that are the gibberish snippets now  known to be associated with positive test cases, it can warn Bob to self quarantine. And so Bob cuts off the chain of transmissions. We're staying one step ahead of the virus. And that's it. That's how digital contact tracing apps can proactively  prevent the spread of COVID-19 while also protecting our rights. Thanks, Alice and Bob. Stay safe.

================================================================================
VIDEO ID: elQVZLLiod4
TITLE: The power tower puzzle | Ep. 8 Lockdown live math
URL: https://www.youtube.com/watch?v=elQVZLLiod4
PUBLISHED: 2020-05-12T19:59:48Z
STATUS: SUCCESS
================================================================================
ðŸŽµMusicðŸŽµ Presumably you can hear this. There's some construction happening in the house next door,  and for the last hour or maybe two hours or so,  it seems like this is the ground-smashing portion of whatever construction they're doing,  and just the whole house has been shaking, which you will be able to hear  if they continue. I think it's still going on now. So if you're curious, that's what the sound is. Now in one of the intro questions that you were just answering,  you are actually going to have your mind primed to think about what we're going to  talk about today. This question just made me laugh so much to write it and try to think it through. It's asking if x is the number that most people are going to enter into this box,  what is 2 to the x going to be? And it's just so mind-confuddling, because you think about, okay,  if a lot of people are entering 1, I should enter 2, but everyone would think about that,  so maybe I should enter 4, but everyone thinks about that,  so I should do 2 to the 4, or maybe 2 to the that, or maybe 2 to the that. And, you know, if it was a room full of perfect logicians, you'd blow up to infinity,  but people aren't logicians, and there is some objectively correct answer,  and we can take a look at what the objectively correct answer is in this context. And it would appear most, okay, the largest number of people entered 2,  which means anyone who entered 4 is absolutely correct. But in the game where you imagine thinking through, you know, the perfect logicians,  and you're taking 2 to the 2 to the 2 to the 2,  you're starting to think about the topic for today's video,  which is an operation that's not typically taught in school,  probably because it doesn't have the same level of applications as certain other ones,  but as you'll see, there's a couple puzzles that we can start to do with it that  absolutely bring out some very important problem-solving skills,  and ideas of just really thinking through what terms actually mean,  and whether or not operations that you're doing that seem to make sense when you  do it symbolically actually make sense when you think through what's really going on. So this operation is called tetration, and a way you might think about it is,  you know, we all learn about addition as one of the first things,  the way that we can add two numbers, and multiplication, as we first see it,  is repeated addition. A times B is A plus A plus A plus A, B different times. And if you say, well, what happens if we repeat multiplication,  you know, taking A times A times A times A, B different times,  we write it as A to the power B, and that's exponentiation. Now if you were to go one step further in this process and say,  what happens if we repeat exponentiation, this has a name, we call it tetration. Tetra comes from the Greek for four, because it's sort of the fourth  stage in this process of repeatedly applying the previous operation. And of course, in the context of things like multiplication,  we've extended the idea beyond just counting numbers. So here this only makes sense if B was a counting number,  but we do things like taking pi times E, or even complex values,  where you can take the square root of two times one plus i. So we've extended it beyond repeated addition, but that's sort of its origin,  that's the way that we often start thinking about it. Similarly, very famously, one thing we've been talking a fair about in this  series is extending exponentiation with the classic Euler's formula example. But for right now, we're just going to think of this  tetration in terms of repeating an integer number of times. Do you hear it? I swear, we were so dreading the idea that the ground-smashing  day would come during one of the streams, but here we are. Now this is actually ambiguous if we don't define our terms a little bit more clearly,  because exponentiation is not associative, meaning the order that we  do these operations and start collapsing it matters. Because if I was going from left to right, let's say I was writing this as two squared,  and then I'm going to think of squaring that, and then squaring the result,  that will get me a different number than if I think of going from the top to the bottom. If the first thing I evaluate is the two to the power two at the top,  and then I go to the next one, and we can think about why. Here if I'm collapsing from the bottom, that bottom part is four,  so then I square it, and I'll square that. Four squared is sixteen, so I square that, and I end up getting 256. But on the bottom, if I start by collapsing that top term, it becomes a four. And then if I think of collapsing the current top term,  that becomes two to the sixteen, and that's a much bigger number. That is 65,536. And in general, this process of repeatedly exponentiating,  going from the top to the bottom, explodes very quickly. And tetration in general refers to the top to the bottom part,  so we start evaluating at the top, and we work down. If you want to make that crystal clear, I think instead of drawing it as a power tower,  one thing that you could do is define the iterative process very exactly. You might say we have some value that we're going to start out at one,  and then each successive value is going to be two to the power of the previous thing. So a sub one would just be two. a sub two is going to be two to the power of whatever a sub one was,  which in this case is two squared. a sub three is going to be two to the power of whatever a sub two was,  which now is two to the two to the two. And there's no more ambiguity for what the order of operations should be,  because you see that it came from the a two term,  so we should first be evaluating what's in the top. And similarly, if you go on like this, and a sub n for any value n  is equal to two to the previous term, a sub n minus one,  when you unfold this expression and kind of go back in our recursive definition,  what you're going to get is a power tower of two n different times. Now another thing that's nice about writing it like this is we can become experimental. And as you all know, I love to encourage people to be very  playful when you come across a new operation like this. And a lot in this series, we've just been pulling up some Python to do that. So let's do that here. Let's take this iterative process and see what it actually looks like. So I will go over to my terminal, I will open up some Python,  I will set an initial value of a to be one, and then what I want to do is  take a look at two to the power of that, but I'm going to reassign that value into a. So this double asterisk, that's how we take powers in Python. And then in a lot of programming languages, a single equal sign,  it's not a question, it's not asking if they're equal, it's an operation. It's saying take whatever's sitting on that right side and shove it into the left value. So when we do this, it reassigns the value of a to be two to whatever it was before. This can be bizarre to people who haven't done programming because  it seems like you have an equation that you're solving for something. But in this case, the left-hand side is getting changed. It's an operation on it. So if I do that again, I take that same process of turning a into two to the power of  whatever it was before, and then I'll just print it out in the same line so we can  say it turns into four, that turns into 16, that is going to turn into,  you can try to make a prediction here, it will turn into two to the 16,  which we just saw was 65,536. If I take one more step, which would be a power tower of height five,  so just five twos stacked on top of each other, it totally explodes. It's just this monstrous number, which I think it's awfully  kind of Python to even do the work to find the number for us. I'm impressed with it. And if we wanted, we could say, okay, think of that number as a string,  what's the length of that string, and it's telling us the number of digits that are in it. So the number we have there is a 19,000-digit expression, just monstrously huge. And if we were to try one more iteration of this,  turning a into two to the power of that 19,000-digit monstrosity,  you would not be able to store the information required for that number. Any way that you were using matter to encode all the digits of whatever would come out,  if that was within the confines of something like the radius of the Earth,  you would absolutely create a black hole in any attempt to store that kind of information. So just a power tower of height six, and it's well beyond  what you can literally physically convey in any kind of way. So you might ask, how quickly does this thing blow up for other numbers, if it's not two? And one thing that I'm going to ask you, actually just in the live poll,  let's go ahead and pull it up, is to predict what's going to  happen here if instead of two we were dealing with 1.1. So if you go to the link that's in the description and up on the screen to answer  the live questions along with us, we are asked, let B equal 1.1,  so just a little above one, and consider an expression of the form B to the B to  the B to the B, this power tower, and its height is n,  meaning you'll see n different copies of B. How big does n have to be? How many times do you have to repeat this operation before  the value of the expression has more than ten digits? So with two, we had to get to a tower of size five before that happened. It jumped from being a five-digit number to a 19,000-digit number. So how many times would you have to do it for a value of B equals 1.1? And I'll give you a moment to answer that while we listen  to the soothing tones of construction maybe slowing down. And just to illustrate this process here, if we hop back over to Python,  and let me just pop on over here, get back into my terminal,  let's say I started A at a value of one. Let's just do this in a for loop. So for n in some kind of range like 50. I'm going to reassign A. What if instead of doing repeated exponentiation,  I was just repeatedly multiplying it by 1.1? So just repeated multiplication, which should be exponentiation. You can get a sense of how quickly that grows. And if we take a look here at the first 50 values, you know, it starts at 1.1,  it goes to 1.21, and at each stage it's actually growing just by a little bit,  by 10% with each jump, and you get classic exponential growth. So with 50 steps it took us up to 117. That's exponential growth. So you might wonder what is tetrational growth? What happens if we're repeatedly exponentiating this thing? And before I answer that, let me see what you think. What do you think is going to happen here if we repeatedly exponentiate this? Okay. So the correct answer is that it actually never grows past anything like that. And, ah, interesting, that's the third placed answer. So most of you thought that the height that you would need would be between 10 and 100. Doing it between 10 and 100 times, that would blow you up past 10 digits. The second most common answer was thinking it was between 1 and 10,  which would be very analogous to how 2 was growing. Third most common, and I'm wondering how many of those third most common people have  seen this process before, because it's very weird the idea that repeatedly multiplying  it by itself, that'll grow as much as you want,  but that somehow doing what feels like a much more powerful operation,  repeatedly exponentiating, that actually stays confined. And we can see this bear out in practice if we hop back over to our Python,  where now what I'm doing with each iteration, and I guess I should set a to b,  1 again, I'm going to repeatedly turn it into 1 to the power of itself. And what we get is a little bit of initial growth, but it quickly slows down,  and just within 20 iterations it actually stays fixed at this value. You can see that this digit isn't changing. And if you think through what's going on there, evidently when a is equal to that value,  and you take 1.1 to the power of that value, so 1.1 to the power of this thing,  that's 1.1117, ah, don't type it too many times, that actually stays fixed. You get the same value that you had before. So another way that we can phrase this is to say that the  equation 1.1 to the power x equals x, something where when  you plug it into the function you get itself, this has a solution. This didn't hold when we were doing it with 2. If we had 2 to the x equals x, if you try to think through different answers to this,  it's a funky equation to think about, but if you just try out some values  like 0 and 1 or anything in between, you'll find there's actually no answer here,  whereas evidently we just saw an answer in this case. And what that means for our iterative process,  if instead of 2 at the base it was 1.1 at the base,  you'd have this situation where the previous value, you raise 1.1 to that,  it just stays fixed. And now this starts raising a lot of interesting questions. First of all, where's the switch? What number between 1 and 2 is the point where it goes from staying finite to blowing up? And blowing up incredibly quickly at that. Remember with 2 it only took us 5 iterations before we had something that was,  you know, beyond what the computer could handle. And we could play around with this a little bit,  but I think another interesting product of the fact that this  can convert at all is we can start answering what look like very bizarre questions. Where I can say, imagine I have an unknown value x,  and I do not a power tower of some finite size, but of an infinite size. I'm going to keep going forever in the same way  that evidently I can do with a base of 1.1. Can I find a value of x where this converges? For example, to 4. This is the question posed in the thumbnail of the video. And what we just saw is that we could find a value that converges to 1.111782, on and on. That's evidently a value you can converge to, and the solution would be 1.1. But how do you go the other way around? How can we actually solve for the idea that we can find a value of x that equals 4? And there's a clever trick here that you might spot. And this comes up in certain problem solving kinds of math where you have this  infinite expression, and you say, hmm, there's some self-similarity I can leverage. There's a copy of the entire power tower inside itself. Because it's infinite, it's a genuine copy of itself. It's not, it doesn't have a height of 1 minus whatever the previous height was, Because the height is infinity. And under the assumption that the whole power tower equals 4,  I could replace that with a 4 and solve x to the fourth equals 4. Let's see, what would that be? If I take square roots, that's the same as saying x squared equals 2. So it looks like, interesting, x equals square root  of 2 gives me a power tower that should converge to 4. Kind of funky. The idea that anything converges at all is sort of weird, but the idea that, you know,  square root of 2 would go to a clean value, like an integer, that's kind of surprising. And let me actually ask you another question where I'm going to have you  apply the same tactic that we just did, leveraging that self-similarity  to solve another one of these situations, where you're looking for a power  tower with an unknown base and seeing when it equals a pre-specified value. So this time the question is going to ask us, if  we give it just a little moment to pull up here. Well, it's taking a little moment, which is fine. Ah, great. The question asks us, using the tactic just demonstrated, what I just did for 4,  solve the equation x to the x to the x on and on up to infinity equals 2. So I'll give you a moment to think that through. The ground smasher is back. Man, yesterday when we were doing it, we, uh, I wish I had the footage to show you. Maybe I can try to pull it up on my phone or something. But the things were shaking so much that just  a pile of circuit boards was actively shaking. Let me see if I can find this. It's super funny. Alright, this might not, this is probably the worst way to stream something,  is to take an overhead camera shot of a phone. But let me see if this works decently well. So I was trying to get a view of the construction. We move over and just the pile of circuit boards is just jittering like that. And that's what we have to deal with. So, hope you enjoy. Now on the quiz, it looks like just about everybody is converging around the same answer. And I'm going to assume you've landed on the correct answer,  which is in fact the square root of 2. Which is kind of a funny thing, because if we go and we do exactly the same  logic that we were doing for solving for 4, where we have this infinite  power tower and we're assuming that it equals 2 and we recognize the self-similarity,  we're like, ah yes, the power tower, copy of it in itself,  so that should mean x squared equals 2, that means x equals the square root of 2. Well hang on a second, this can't be right. Because on the one hand this seems to be suggesting that an  infinite power tower converges to 2 when the base is root 2. But on the other hand it converges to 4 when the base is root 2. It can't be both. We've got a very deterministic process up here for what it converges. So it's got to be just one of them, if any. Maybe the entire logic of the situation is false. So let's get empirical. Let's turn to our programming to see which one of these it actually ends up being. So I'll hop back over, I will reassign my variable a to be 1,  I'm going to make my little loop. Actually let's import math because I'm going to need a square root here. So I'm going to say for, I don't know, we'll just do 20 at a time. I'm going to take a, turn it into the square root of 2,  square root of 2 to the power of a, print out what it looks like. Guess I don't need that semicolon but it doesn't really matter. And it looks like for those first 20 iterations  it does kind of slow down as it approaches 2. And if I do another 20 iterations it's definitely slowing down as it gets to 2. Definitely, alright. And now it does something kind of bizarre where it seems  like it lands exactly on 2 but then it jumps up to 2.0004. Which if you think through what's going on here, at some point it equals 2. So we're saying a equals 2. And then we're taking the square root of 2 to the power of that. But square root of 2 to the power of 2 by definition should be 2. So that's going to be just some simple numerical error. I guess, however, the math square root library is implementing square roots. You know, there's always going to be a little bit of numerical error with floating points. So when we square it we don't exactly get 2 back. That's fine, not a problem. But it does seem to suggest that the correct answer to our question of  what happens when we have a power tower with root 2 is that it equals 2. Or that the sequence of numbers that this represents approaches 2. What's wrong with the other logic though? What's wrong with the logic that seemed to imply that it should equal 4? Well to answer that we should do two things. First is to represent this thing a little bit more visually,  a little bit graphically so we can try to understand what is going on with this  iterative process. And then from there understand which values will converge and which values will blow up. And by answering that we can get back in the direction of what's  wrong with the logic associated with having this thing approach 4. So for that let's take a look over at our good friend Desmos. So pop on over here, open up Chrome. Not look at that yet, that is 4 later. And we will just take a look at a graph here. So what I have is the line y equals x. I've got a function b to the power x and I've set b to be 2. So we're just looking at the graph of 2 to the x. And to think about the idea of repeatedly applying a function and  kind of taking the output and then plugging it back into the input. We can draw what's commonly known as a cobweb diagram. The way this will work is I have an initial value of 1 as the  input and then the next value is going to be whatever f of 1 is. I'm going to plug in 1 to the function. And what that means is I move vertically until I  hit the graph and in this case 2 to the 1 is just 2. So I'm going to hit it at a y value of 2. But from there what I want is the output that I just got,  that 2, to become an input to the function. But if outputs are represented on the y axis and inputs are on the x axis,  what I need is some point where the y value is the same as the x value. So if I walk horizontally until the y value is the same as the x value,  I'll get to a point where 2 is the x value. Where I can now think of that 2 as being the input. And to do that I walk until I hit the line y equals x. Because once I hit that I'm looking at 2 comma 2. So I can treat that 2 as an input by moving vertically until I hit the graph. You can see how that works. Meaning the next point in our iterative process is going to  be 2 to the power of what we just had, which is 2 squared or 4. And then I move over to the right, turning my output into an input,  looking for what point on the plane has an x value that's also equal to 4. Then once I hit that, I kind of think of bouncing off of this line,  y equals x, and moving vertically until I hit the graph again. And this time it's not until 16 that I hit the graph. And then I move to the right until x also equals 16. And then from there, I have to go quite a while,  quite a while moving vertically, but it will happen quite a while. And around 65,000 it intersects the graph again. And then it's going to move to the right until  we get to an x coordinate that's also 65,000. And from there, Desmos just totally gives up on trying to draw the next vertical line. Because as we saw, what it would have to get to is a height  where the number describing that height is a 19,000 digit number. So it just gives up on us there. But when we think in terms of these cobweb diagrams,  now if I start playing with what is that base, you can see what's going to happen. What is that base? The base is the ground-smashing activity. At some point, the graphs actually cross each other. So in particular, we were looking at 1.1 earlier, and that, yeah, they absolutely cross. But even up to around 1.41, which is around the square root of 2,  if you look at what happens with this process, we look at the output,  turn the output into an input, look at the new output, output into an input,  and bounce back and forth. We're bouncing towards the value where these graphs intersect each other. towards the value where b of x, b to the power x, excuse me, is equal to x. And in particular, if that base was the square root of 2,  and I say find a solution of square root of 2 to the power x equals x,  you know, it's not easy to think about how you solve this systematically,  but for this particular case, you would believe me if I told you that the  solution is x equals 2. You can just plug that in and solve it. So if we look at our graph, if b, actually let's go ahead and make it  precisely the square root of 2 rather than just an approximation here. So b is going to be the square root, square root of 2, no, of 2. The intersection point is exactly at 2, so you  see your iterative process approaching that. Okay, that's kind of interesting. This also shows us how we're going to need to think about it if we want to be,  if we want to understand where the switch happens between when  things converge and when things don't converge. Because what we want is knowing what value of b should I go to where things can escape,  there is no intersection point, to where things don't escape,  where there is an intersection point. And by the way, I've left the link to this particular Desmos graph in the description,  so if you want to hop down there and just play along, you're more than welcome to. One thing I should specify, the fact that they intersect,  that's actually not enough to ensure that this cobweb iterative process  necessarily converges. It's important that the graph of our function,  which in this case is b to the x, intersects at a slope that's less than 1. And we can think about why that's true. If I turn a new leaf, let's say I wasn't dealing with exponential  functions or curves like that, I was just dealing with any generic function. So look at the line y equals x, and let's say I have some function which,  you know, it squiggles along and it intersects it but with a slope greater than 1. Then when we do our iterative process, we'll have some output and we say  let's turn it into an input by walking horizontally until we hit y equals x. Look at the new output by walking vertically. Smash, smash, smash. Look at the new input, or turn that output into  an input by walking horizontally until we hit it. And then repeat that process. You can see that's what's happening because it intersected with a slope greater than 1,  we're actually walking away from the intersection point. So to make sure that it's not just a stable point,  it's not just a common point between the graphs,  but it's stable when you repeat this process. That slope does need to be less than 1. I have a whole video about another perspective on how to think about this kind of process. I think I gave it an absurd title, like what they won't teach you in calculus,  but if you want to see more examples of this and fun,  infinite iterated objects, that's a place that you can turn to. Now, in our case, it is the case that the slope is less than 1, so that works. Although, on the second intersection point, that's actually a slope greater than 1. So if I changed the iterative process where my first value wasn't 1,  but in this case if I made it 4, then my iterative process would actually run  away from the intersection point, like you can see,  and it will indeed blow up to infinity. So that's always fun. I'll change that back to a 1. You can take a look at my little note for being annoyed that you can't do four  loops of recursion in Desmos definitions, and you can see what we need to solve. One thing that's kind of fun here is at 1.45, which seems just above a point  where they actually intersect, you have this bouncing and bouncing that just  stays somewhat stable for such a long time before it eventually blows up. And imagine trying to think about this not graphically,  but if you were just playing around with it numerically. So if we had taken the same process we did before, where A starts out at 1,  we're going to do a bunch of iterative exponentiating,  but we're going to make it 1.45 instead. And let's give ourselves like 50 values for this one. The process eventually blows up. It gives us this overflow error. But the processes would be very confusing if you  didn't have any visual for what's going on. It starts at 1.45, it grows, it stays kind of not stable,  but it doesn't seem to be moving that much in the 2.71828 region. For some reason around there it just seems awfully slow moving. But as it starts to get a little bit bigger into the 3 region it stays there for a while. The 4 region there's two values. Then 6, and then 9, and then 39, and then it just blows up to 2 million after that. And then from there it's bigger than what the computer can handle. So that would be deeply confusing, except we have a nice understanding of what's going on. The graphs almost touch, but they don't quite. So somewhere between 1.44 and 1.45 is what we're looking for. And you might think of this now in terms of calculus,  where what we want is to know when the tangent of this graph is the same as  the line y equals x. When does the graph b to the x lie tangent to the line y equals x? And rather than me setting up the equations that we need to solve for that,  I'm going to have you do the same. I'm going to have you take a look at this condition of looking for a value of b. Well let's just read what the question asks us more specifically. We want a value of b such that the graph of y equals  b to the x sits tangent to the graph y equals x. Which of the following represents the pair of equations that we need to solve? Okay, so take a moment to think about this. Which of the following is the pair of equations that we need to solve? While you're thinking about that, I'll go ahead  and take a couple questions from the audience. We have... So immediately I wondered, repeat-detectration is pentation. Or is that even a useful idea? Yeah, there's this whole notation that talks about the idea of repeating these processes. It's called Knuth arrow notation. And you can kind of have as many as you want. So the way this works is that if I write something like a arrow b,  that's the same thing as a to the power b. But then a with two arrows is the repetition of that process. You know, b times. And, sorry, that's a two arrows and then a b. If I had three arrows, three arrows and then a b,  then what I'm repeating is the process of doing a double arrow. Which is really mind-warpingly big as you start to think about it for numbers. Even numbers like two and three. The idea of repeating this process some number of times is just crazy. And you could just keep going with more and more arrows. And if any of you have not learned about Gram's constant,  go over to that number file right now and see how Gram's constant is defined. Because it involves these sort of arrow operations and it's genuinely crazy. And it's one of the most mind-blowing moments you'll have in  your mathematical life the first time you see Gram's constant. So I would recommend. Alright, so next we have for 1.1 to the power x equals x,  Wolfram Alpha yields two real solutions. Ooh, excellent question. One of them is the one that we converge to. The other is around 38.29. Awesome. What's the deal with that second solution? We can take a look exactly in the graph that we have. So if we take b and we make it 1.1. Okay. It's what I was talking about how at the place where it intersects with a  slope greater than one, yeah, it's a fixed point for our iterative process. But it's not a stable fixed point. So up here is that 38 value that you were just referencing. And because it intersects at a slope that's bigger than one,  even if you were to seed the process with a value that's really near there,  it would run away from that value. So if you're seeding the process, if you're starting off at a value of a equals one,  this is the intersection point that it'll end up finding. That's an outstanding question. And third, are there practical use cases for such an operation as tetration? I've studied very scientific branch and have never come across this operator. I'm very curious. Okay, so that is a spot on question. So I will talk a little bit about a role with chaos and fractals at the end,  which is tenuous at best because it's saying it's related to other things which  themselves are useful. I can't personally think of a place where you're out in  the wild doing science and then boom, tetration pops up. I can think of a puzzle, like a sort of brainteaser type puzzle  where you would not at all think this operation comes up, but it does. Which, if we have time at the end, I think I might share with you. I would say the motivation for learning this kind of thing right now is,  pardon the scene switching chaos there, is just that the process for actually  solving the puzzles that are sitting in front of us,  understanding what was up with the repeated tower equaling four,  and understanding what we're about to find, and where is the switching point  between things converging and things not converging. Those are problem solving tactics that carry over into other  things you might do that involve more practical iterative processes. And iterative processes absolutely do come up all throughout science. I mean, chaos theory is like the big one there. So with all of that as the answering people's question side,  and I'll take more through Twitter as we go and probably do more of that at the end,  let's see how you've done on our problem. So we're looking for a system of equations here, and the correct answer,  which 1777 of you got, I think that's not quite French Revolution territory,  but American Revolution territory of you, we got b to the x equals x,  so we need them to intersect, and then moreover what we want is the slope to be the  same where they do intersect. And the derivative of b to the x is itself, but scaled by the natural log of b,  and we want that slope to equal one, because it's got to be the  same as the slope of the graph we're just looking at. And if ever you don't remember what the derivatives of your exponential functions are,  if you do remember that e to the x is its own derivative,  which if there's any one thing you remember in calculus with respect to e to the x,  it should be that e to the x is its own derivative. Note that we can write b as e to the natural log of b, so then all of that to the x,  so this is the same as expressing e to the natural log of b times x,  we talked about this I think last lecture, so then if you want to take the derivative of  this, take its derivative, on the one hand it should be the derivative of this,  which by the chain rule is that constant sitting in the exponent,  natural log of b times itself, e to the ln b times x. So what we're looking at is, okay it should be itself,  but scaled by something, and that something was the natural log of b. Now for our puzzle of understanding when is it that our graph is going to nicely lie  tangent to y equals x, let's solve this equation, this system of equations actually. Because we're looking for the value x where that solution happens,  we know that the curve b to the x equals x at that point,  and we know that its slope, the natural log of b times itself, is equal to one. Now to solve this, the first thing I might do is note that I  can simplify b to the x as being x, so I would apply that over here,  and I can write the natural log of b times x is equal to one. And what that gives me is that b is the same as one divided by x, all very nice,  no no no, it doesn't give me that, it gives me that the natural log of b is one over x. That is the same statement as saying e to the one over x is equal to b. Alright, now what does that buy us? Well it gives us an expression for b entirely in terms of x,  so I can go to this top part and I can get an equation that has nothing but x's in it. It'll be e to the one over x, all to the power x,  I'm just replacing the b with what we found it to be, and that is supposed to equal x. But on the other hand, e to the one over x to the power x simplifies  down to simply being e, and what we found is that x is equal to e. And by the way, so I was doing like a sort of a dry run of this lesson  last night where sometimes I'll put out like a link to a stream on Twitter  that's an unlisted link, and just say like as soon as a hundred of you  hop on here I'm deleting the tweet and we're just going to do a dry run. And when I was solving this, for some reason I was just confuddled for like ten minutes  where I got to this point and I'm like that can't be right,  because we're looking for a value that's between 1.44 and 1.45, so x can't be e,  that's way too big, that's like 2.718. So I went back and I was trying to think through like what have I done wrong,  what on earth has gone wrong here? It was mildly embarrassing because it took so long,  and then I ultimately realized no, you idiot, it's not that we're  looking for a value of x that's between 1.44 and 1.45,  that was the condition for b, for the base of our exponential when  we were playing around over here. So x is just wherever they intersect, so it's fine for that to be around e,  in fact that looks consistent that around where this point of tangency is,  is e, which incidentally is also the output because this is happening with  the line y equals x, so the point of tangency has coordinates e comma e, evidently. And what does that mean for the value of b itself once we solve? Well we have an exact expression for x, we have an expression for b in terms of x,  so this would seem to imply that b is e to the power of 1 divided by e,  which is such a delightfully bizarre answer, e to the power of 1 divided by e. And we can check with our calculator that that makes some sense,  so if we hop on over here and I say, hey Desmos, what is e to the 1 over e? Not 1 over 3, 1 over e. Yeah, checks out, it is between 1.44 and 1.45, which is exactly what we were looking for,  for the point when it goes from converging to exploding. Very satisfying, I think, finding that solution, that it's e to the 1 over e. As a challenge puzzle for you, if you want a little bit of homework today,  I want you to find a lower bound on where this converges. So we found the highest value that will make this converge,  but we can also start playing with values of b that are less than 1,  and if we do that, I'll just kind of get rid of our cobweb here,  if we do that there will be some value, I guess I should keep the cobwebbing,  where it's no longer going to zero in on some exact value,  and it instead becomes an unstable point. And the question for you is, when does that happen? When does it go from approaching the point where the two graphs  intersect to no longer approaching it because it's unstable? And if you want a hint, think about the fact that the slope,  in this case it's not a matter of when it's equal to 1,  it's a matter of when it's less than negative 1. And if you want another hint, it should be an  expression that also involves two e's inside of it. So, very fun puzzle if you want to get to it. And that will give you kind of a range of convergence for what values could we have  as the base in our titration such that the power tower actually converges to something. And one thing that's noteworthy here is that it goes from  converging to a value of e to just blowing up to infinity. It never converges to values between e and infinity,  which maybe runs against intuition because you would think that it  somehow smoothly blows up, that rather than going, oh it converges to 1,  it converges to 2, it converges to e, and then discontinuously jumping to infinity. But that is apparently the behavior. And it happens just because the graphs were once  tangent and then that's where they separate. They're kissing and then they stop kissing. And this answers for us what's going on in the case of the power tower with 4. So if you think back to the logic, where did we have it? Great. So if we have our power tower and I was saying solve for the value where this equals 4,  well this assumes that such a value even exists,  that this process will ever converge to be 4. But we just saw that it'll never converge to be anything that's bigger than e. So in particular the very first step where we make the substitution that's  leveraging the assumption that a solution even exists, that's invalid. And the reason that it worked for 2 is because  there does exist a value where this converges to 2. So when we make that initial substitution, that's a valid thing to do. And before we even solved it, you could have seen that there  exists a value where it converges to 2 by looking at the graphs. What you would look for, even if you didn't know it was going to be square root of 2,  what you would look for is when does this intersection point  between the graphs happen at a y value of 2? I guess it's also an x value of 2 because it's on the line y equals x. But what we care about is that the y value should be 2. And you would be able to empirically start seeing that hmm,  it's somewhere between 1.41 and 1.42. And you could binary search your way on down even a little bit further. So I think that's delightful. That you can take a look at this absolutely crazy singing process of a repeated  power tower, that it converges at any points at all, which is counterintuitive. And that we can actually make very substantive statements about when it converges,  thinking through iterative processes like this. And that's actually it for today. This is going to be a shorter lesson. That is the end of what I wanted to say about the power  tower puzzle and leaving you with that little bit of homework. So for the very end here, I just want to take a couple more questions from Twitter. If you ask them with the hashtag locked down math, they might get forwarded to me. And anything about tetration and this process is exactly what we should talk about. Great. So, he says, if there's a triangle of exponents, is there a square of tetration? What uses are there for the inverses of tetration? Well, I mean, in either case, we'd be dealing with three different variables. There's the idea of what's the base, what's the height, and then what's the output. So in either case, we'd just be having three of them. The four in tetration, like what makes it four,  is not the fact that there's three relevant numbers, you know, the base, the exponent,  and then whatever the output. And then some new fourth thing. It's that in this process of addition, multiplication, exponentiation,  it's kind of the fourth of our like repeating the process before. Next question from ML. Will you show us part of the fractal set of complex numbers x  for which the power tower x to the x to the x to the x converges? I'm so happy that you asked, ML. Yes, you might wonder what happens if instead of our base equaling two,  or instead of our base equaling square root of two, or 1.4,  or all the values we were just looking at, what if you have some complex number like  z that you're raising to a repeated power? Now there's a little bit of nuance there for what exactly  it means to raise complex values to other complex values. And I think I'm going to talk about that. Don't hold me to it. I think I'll talk about that in the next lecture. It's very similar to what we see with real values where you  can re-express it in terms of e, and then because we know how  to think about e with complex numbers, you'll be able to do it. But if you are willing to grant the fact that there does exist a way that you  can extend exponentiation to complex numbers, you could certainly repeat it. And when you repeat it, you can start asking about does this converge? And if you ask about when it converges, and if you go and you write a  shader or whatever your favorite kind of program is to color all the  pixels on the plane based on whether or not it converges, this is what you get. So what you're looking at right now, the axes aren't labeled,  but the real axis is running across the middle of the screen from around negative  4.5 up to I think 3. And then the imaginary axis that's going from I think like negative 2i up to 2i. So this horizontal part of blackness corresponds to all the values that  converge that we just found, where the upper bound was e to the 1 over e,  and the lower bound is what you can find for homework if you want. But the other values above that diverge, and the  coloring tells you how quickly they diverge. So yellow means that it explodes very quickly,  blue means that it explodes less quickly, and so on. And so evidently what happens is as you allow for complex numbers,  even if their real part is greater than e to the 1 over e,  that imaginary part can conspire in just such a way that it makes it converge,  and you get this totally intricate pattern, very analogous to the Mandelbrot set,  which is also defined in terms of a certain repeated operation. And what this indicates is there's actually a lot more intricacy than you  might expect associated with these power towers and this titration operation. And you get this a lot where repeated applications of something can yield chaos,  and that chaos is often pictorially reflected in the fact that a fractal emerges,  and it's kind of like the intricacy of the image is paralleled in the  difficulty of predicting what the outputs are going to be. And just to illustrate the fact that the outputs can be difficult to predict,  you want to know what an unsolved problem is, what no one in the world actually knows? Is if you can ever take a power tower with pis,  so pi to the power pi to the power pi to the power pi, you do that. At any point, is this ever equal to an integer? Almost certainly not, it would seem highly unlikely because it's  an irrational number and if you're thinking of it kind of probabilistically,  but it's not probabilistic, it's a deterministic process. In fact, we don't even know for a power tower of height 4 if there's just 4 pis here. You take pi to the power pi, pi to the power of that, pi to the power of that,  it ends up being a monstrous number, bigger than we can compute exactly. We don't have a way to prove whether or not this is an integer. And if you can prove that, you know, you will be contributing to the forefront of math. That's the level of what we actually don't know about these power towers,  which I think is kind of interesting. Can I share the brainteaser where the arrow operator shows up? Yeah, fantastic. Let me, I can draw it out for you. I think this came from an IMO. This is something that Po-Shan-Lo was sharing with me at one  point and I'm sure he has a talk about it somewhere that will  be more illustrative than what I can talk about on the fly here. But the way this will work is that we have 6 different cups  and each cup is going to start out with a single coin in it. And you have two different operations available to you. One of those operations is that you can remove the coin from one cup,  so we'll remove it from one cup, but then two more coins will drop into the cup  to its right. So there's a certain directionality to this. Two more will drop into the one to its right. So you can imagine from here we can then eliminate all three  coins and then there would be six that just magically drop in. Five, six, magically drop into the next cup beside it. And if that was the only ability that you had,  kind of a warm-up teaser is to understand that the maximum number of coins  you can have ends up being 63. If you just sort of keep doing this process of taking out coins,  doubling it, but shifted one over, you can get up to 63. Now if I introduce the second magical operation,  which is that I can eliminate one of the coins in a cup,  and instead of magically dropping two into the next one,  I swap the two that are sitting right after it. I swap their positions. That's the second power that you have, which seems less magical  because it doesn't require bringing about coins from the ether. I think the way that this was originally framed is,  is the maximum amount of money that you can have after doing  this process bigger or smaller than 2010 to the power 2010 to the power 2010? That was the question. When you have these two abilities and you start with six cups that each have one  coin in them, will it be bigger, the maximum amount of money that you can get if  you're clever enough, be bigger or smaller than that power tower of height three? And it's just, again, kind of absurd that that second operation would get you  anywhere near that level of number because this is, I mean, this is just so huge. It's way bigger than anything you'll find in physics. Unless you're doing statistical mechanics or something like that. So, yeah, excellent question. And with that, unless there's anything more that people want to ask and which also ends  up getting forwarded to me, I think I'm going to go ahead and call it a day on this one. And thank you for joining. I think I will ultimately probably have ten episodes in  this lockdown series is what I'm thinking at the moment. So if you want to join for the next two, those will be the last two. Oh, great. We have another question. When you solved x to the x to the x on and on equals two and got x squared equals two,  you ignored the negative square root of two. Awesome. Yeah. Yeah. A solution to x squared equals two. Can I explain why? Ah, yeah, that's absolutely outstanding. Let's so if we think about this graphically again,  where that helps us be a little bit more concrete when it comes to what's going  on with the iterative process. When I said B equal to around one point four one. OK, it seems like nothing's really happening around the negative square root of two. OK, so let's try to understand why that's happening. There's not even necessarily a an intersection at that point. So the reason we were taking square roots of two when we were  looking at our power tower operations, if we remind ourselves. We had the assumption that there even exists an answer. This whole thing. No, not with an x at the top. It just goes up to infinity equals two. We saw the reflection of itself. X squared equals two. Let's think about what this would mean. What do we mean to have a negative square root here? Well, I guess what you'd be assuming is that you you're taking negative powers. Now that I think about it. If we said x equal to the negative square root of two. Then you'd be raising it in the next process. You would take negative square root of two. You would raise it to a negative power. OK, so raising to a negative power. We're already in the realm of thinking about negative square root of two to the one over. No, negative one over square root of two to the square root of two. Why doesn't that end up popping up in the intersection or anything like that? Actually, the more I think about it, there might be a  very obvious answer to what's going on that I'm missing. Other than I mean, we can talk about. We can talk about the fact that negative numbers don't sit in the range of convergence. Like if you solve the homework problem, the assumption that  there exists an x that's negative that converges like this  would be false because you'll find that the the bound ends up. I think it ends up being e to the negative e. So in the same way that it failed, our logic failed in the case of four. Our logic fails if we just plug in square root of negative two. I'm kind of curious if that breaks down numerically. So if we do try this over in our python where let's again set equal to one. Let's find our for loop. We're now we're going to do the negative square root of two and repeat the process. Yeah, what do we get? We do get a stable point. Interesting. Negative square root of two. You look like you're a very stable point. You're not a stable point that's equal to two at all. What is that number? What's going on there? You know what? I'm not entirely positive. Now that now I have it now I have a decision to make it. Do I try to think about what exactly is going on on  screen live rather than just calling it into the stream? Or do I do I think about it and then like pin that to a comment at the end? Let's see. What's going on with our logic exactly? We're saying assume that there equals a value that converges to two. If there does it's going to satisfy this property. I mean because I guess what you can say is it's  like x equals plus or minus square root of two. You try them both. One of them equals one of them doesn't. End of story. I mean this happens a lot when you're doing something algebraic. You have a manipulation like this. You have multiple possibilities but you just kind of  plug them into check and one of them just doesn't work. But that's always very unsatisfying because what you want is some  sort of answer to why it looked like it was going to work but didn't. So in the case of a power tower that equals four you could very clearly see why it didn't. The assumption that it even converged was false. And I guess in this case our assumption would be if we had negative root two,  if we have a negative value, that what's sitting up here is still equal to two. I don't know. We saw that it doesn't. We can say when you're doing this you try them  both and if one of them doesn't that's all it is. But that just doesn't feel satisfying to me so I'll think about that a little bit. If anyone has deeper thoughts share them in the comments of course. I would love to hear what you have to say as sort of a  like what's going on with the square root of negative two. What does it converge to and why does it have any relation to this process which as  we already saw is a faulty line of reasoning and like a little bit shaky to just  replace what's inside your infinite power tower with the assumptions you've already made. Yeah I'll think on that. Excellent question and I think that's a great place to end it. Also I couldn't help but notice the Twitter handle for who was asking that because this  is someone who's created these super beautiful notes for all of the lockdown series so  far. Which I've been throwing in the video descriptions just because I'm like yeah this is,  boy do I wish my handwriting looked anything like that. So if anyone wants to check them out she's done a beautiful job. And with that I will actually call it an end to today's lesson. I'll see you at Friday at the same time for our  second to last in the lockdown math series.

================================================================================
VIDEO ID: 4PDoT7jtxmw
TITLE: What makes the natural log "natural"? | Ep. 7 Lockdown live math
URL: https://www.youtube.com/watch?v=4PDoT7jtxmw
PUBLISHED: 2020-05-08T20:22:12Z
STATUS: SUCCESS
================================================================================
Let's go ahead and open things up today with a question that  might seem like it's incredibly unrelated to the title of the video. So if you guys go to 3b1b.co. Live, link is in the description. You've all been there for some of the warm-up animations. I want you to just make an estimate for the following question. It looks like a couple of you have already started coming in with answers here. Consider the numbers between 1 trillion and a trillion plus a thousand. Okay, so this range of a thousand integers that's pretty high. Which of the following would you guess is closest  to the proportion of these numbers that are prime? So if you were to go through the painstaking process of, you know,  looking at all of those numbers between a trillion and a trillion plus a thousand,  considering which of them are prime, what do you guess is the relevant proportion there? So don't worry about getting it right or wrong. I'm mostly curious where people's intuitions are on this one. So while we don't necessarily have to do those painstaking calculations,  I have gone ahead and written up a simple program that can do that for us. So if we hop on over to Python, it's not exactly the most sophisticated  program for getting primes in the world, but it'll get the job done for us. So if I type something like get primes between 0 and 50, you know, we take a look. Okay, it's got 2, 3, 5, 7, all your favorite prime numbers between 0 and 50,  you're gonna find in there. But maybe you don't like that range. Maybe you want to look between a thousand and a thousand fifty. And there you go. There's the primes between a thousand and a thousand fifty. And there's fewer of them. In general, as you get bigger and bigger, the primes get sparser and sparser,  essentially because each one has more options for what it could factor into. You know, if you're just doing the guess and check on something like 143,  you just have to check all the numbers up to around its square root. Whereas if you're checking around a trillion, you have to check on the order of,  you know, something like a million numbers, all the primes up to a million,  whether or not they go into it. So you might think that when we, let's say we define the list where  we're going to get all of the primes, you know, get the primes between a trillion,  which is 10 to the 12th, and a trillion plus a thousand. This involves a lot of number crunching to actually find those primes. And you can see by the fact that, you know, the program I  wrote isn't going to be the most efficient thing in the world. It takes a little bit of time before it gets there. So we can look at that list in just a moment. But before I want to properly take a look at what everybody thinks. And we have a great split! Oh, I love questions that split up the audience like this. That's always fun. So what do you think? What do you think is the actual density of primes up there? Ooh, the correct answer is only third place. Usually in lockdown math, the correct answer is always at top. So this is exciting for me. It seems like most, or the largest number of people thought that D,  one out of 250, that there would only be four primes in that range. After that, it was people who thought only one in a thousand, that up there,  you know, primes are so rare they only come one in every thousand. The correct answer, the closest proportion here, would have been one in 25. So a lot more frequent than people might have thought. And what's interesting is actually if you ask this question to a mathematician,  they would be able to pretty quickly tell you what the correct answer is,  not because they're doing all that number crunching. And in fact, if you were to talk to a mathematician, they would look at this problem,  they would do a small little calculation in their head and they'd say,  the closest is one in 25, but really it's going to be closer to, you know,  one in every 27 or 28. That would be a bit more accurate. You might wonder how they do that, because if we look at the number  crunching that our computer had to do, it had to check all of the  potential factors for all of the numbers we were looking at,  and it does give us all of the primes between a trillion and a trillion plus a thousand. So as you can see, they're, they're sparser than they  are for just the numbers between zero and a thousand. But there's a meaningful number of them. You know, we've got one trillion seven hundred fifty one, one trillion seven eighty seven. The Boeing engineers are probably pleased that that's in there. And the actual length of that list is 37. So there's 37 primes in there. So the proportion out of the thousand is 0.37. Or the way we were phrasing it, it was one out of something,  so we might take the reciprocal of that and do a thousand divided by the number in there. And it's about one in every twenty-seven. But what the mathematician would do is they would say,  I know this very cute fact about prime numbers,  which is that the density of prime numbers near a given value,  like a trillion, is around the natural log. So I'm going to type math dot log here, which takes a natural logarithm of that number. And we can, you know, check if you want, what does the documentation tell us. It says this returns the logarithm of X to a given base. If the base is not specified, it returns the natural logarithm, which is log base e of X. And just as a reminder, if anyone needs a little reminding on what logarithms mean,  we talked about this all in the last lecture, so feel free to pop over. But when you have an expression like L in X, which is telling us the log with  base e of X equals Y, that is saying the same thing as e to the power Y equals X. It's asking the question e to the what equals X. So for example, the natural log of 10, it's around 2.3. And that's a kind of useful value to know if you want to make  conversions between exponentials written with e versus exponentials written with 10,  but the natural log of 10 is around 2.3. So that's saying the same thing as e to the 2.3 equals 10. Now the cutesy fact here is that prime numbers,  their density is actually kind of related to this natural logarithm. If we went over and we took the natural log of a trillion,  which was the number defining our range at the lower end of that range,  you'd see that it's 27. And that was about the ratio we were looking at before, right? A thousand divided by the length of our list of primes. I mean, that's quite close. And the fact that that happens at all is, I don't know,  I might not call that my favorite piece of math because I use that term a lot,  but it's definitely going to make the list of top five favorite pieces of math. That the log with base e has anything to do with prime numbers. So I want to show you another kind of cute fact associated with  the relationship between natural logs and primes,  because you might wonder why is it that we call this thing the natural logarithm? There's lots of logarithms, lots of different bases. What makes this one more natural? And I think the more often you see it show up in nature,  the more that name starts to kind of make sense. So I'm going to play a game that will seem truly strange for a moment. I'm going to take an infinite series, for example one that's,  you know, a favorite among a lot of people. If you take 1 over 1 plus 1 over 4 plus 1 over 9 plus 1 over 16,  and in general you're always taking 1 over n squared, and you add up all of those numbers. If you keep adding and adding them, they'll stay below a  certain bound and they'll actually approach a certain number. And it was this open question in Europe, it was posed in Basel by I think  one of the Bernoullis for a while, like what is the number that this equals? And eventually Euler, genius of the day, was able to prove that it  equals pi squared divided by 6, which is very beautiful,  the idea that pi is at all related to just adding up the reciprocals of squares. But it gets crazier than that. I'm going to play this weird game that's going to kick out terms  that don't look like prime numbers, keep the prime numbers,  and then also scale down ones that are sufficiently prime similar for us. I'll show you what I mean. So 1 is not at all a prime. We're not even going to include it. 2 is a prime, so I'm going to keep that 1 over 2 squared term. 3 is a prime, so I'm going to keep the 1 over 3 squared term. 4, it's not a prime. But I'm not going to kick it out because it is the power of a prime. So I'm going to say that 1 over 4 squared term can stay,  but because you're only the square of a prime, I'm going to scale you down by a half. It's kind of a way of saying you look sort of like a prime,  but because you're only a power of it, I'm scaling you down by that power. 5 is a prime, so we keep the fifth term. 6, not a prime, not a power of a prime. We don't like it at all. It gets kicked out. 7, we keep it, and you can sort of see where I'm going here,  but I'll write a couple more examples because it's such a bizarre way to  manipulate a series. You would think that this isn't going to get us anything nice at all. 8, it's a power of a prime, but because it's a cube,  I'm going to scale it down by a factor of 3. So I'm going to take one third of the eighth term. 9, it's the square of a prime, so I'll take one half of the ninth term. 10 gets kicked out, we ignore it entirely. 11 stays as is, and on and on. So each one of your terms looks like the power of a prime. 1 over pk, and because this series, we're squaring them all,  it's 1 over the power of that prime squared, but we scale it down by whatever  that power is. Now, because we've manipulated this in a pretty chaotic way, I mean,  the primes are distributed in a pretty random fashion,  you might think that this is completely uncomputable. It's just a crazy situation. And it's going to be smaller, you know, for sure it's going to be smaller than  the pi squared over 6, because we left out the 1, we left out a lot of composite numbers,  and prime powers bigger than, with a power bigger than 1, we scaled down. So it's definitely a smaller number. You might be able to guess where this is going based on the title of the video. What it ends up equaling is the natural log of what it was before, of pi squared over 6. And that's not just true for this particular sequence of sums of squares. There's a number of other formulas that get us something related to prime,  where we could, sorry, something related to pi, which is evidently related to primes,  in a way that's, um, I mean, you play the same game and you have this weird  fashion of taking logarithms, and not just any logarithm, the log base e. So just to talk through what I mean in this other context,  if you take 1 minus a third plus a fifth minus a seventh plus a ninth,  and kind of alternate back and forth between the odd numbers, you get pi divided by 4. I have a video all about this, Mathologer also has a video about it if you're curious. Very beautiful why it's true. But even stranger is when we play this game of keeping the primes and kicking out others. So 1 we're going to kick out. If we keep the third term, that's negative 3. Then the 5, we keep that. The 7, I guess it's a minus 1 seventh. The 9, we keep it but we scale it down, because it's the square of a prime. And in this case, because we're only looking at odd numbers,  it looks like we're keeping quite a few of them. We have to get bigger before we kick them out. So like 15, that gets kicked out. 17 is positive, it gets to stay as is. 19 gets to stay as is. 21 gets kicked out. 23 gets to stay. So a very bizarre thing. I mean now the pluses and minuses, they don't alternate nicely. It's like minus plus, minus plus, minus plus plus, minus minus. It's a, it almost seems like a random sequence. 25, we can scale that down because it's 5 squared. 1 over 25. And this doesn't equal pi fourths anymore, but  it does equal the natural logarithm of pi fourths. So evidently there's this relationship between taking logarithms with base e,  which is to say, answering the question e to the what equals a value,  and these sort of prime patterns. And it's quite beautiful when you think about it,  because if you look at like this entire sequence up here,  it's going to equal some number such that e to that number is related to pi. So you have this formula that's interrelating all of the prime numbers,  and their powers for that matter, excluding the composite,  so it's still a cool sequence, it's not just like all the integers. We're taking e, raising e to the power of that sum, and you get something related to pi. I mean, clearly better than Euler's formula. I think you'd have to agree. So, we might at the end of the lesson get to why that's true. It'll depend on how much time there is. But the next two facts I'll show you, we will definitely explain why they're true. So we're going to play a couple more games with series here. These ones are going to be a little bit simpler  facts to think about than the first two that I showed. But the relation with primes is just, oh man, if that doesn't make you love math,  I don't know what would. But if we played an alternating game that doesn't go through all the odd numbers,  but it goes through every number. So I'm going to take 1 minus a half plus a third minus a fourth, on and on. And you might visualize this with a number line, where I'm going between 0 and 1 here. When we take 1 minus a half, you're hopping backwards by a half. And then plus a third, you're hopping forward by a smaller amount. Minus a fourth, you hop backwards by a still smaller amount. Then plus a fifth, and then backwards might get you here,  and then forward might get you something like that. And you're alternating back and forth, and because each one is smaller than the last,  you can probably see that it has to zero in on some kind of value. And as a matter of fact, it does. It zeroes in on a value that's around 0.69 or so,  and more precisely, it comes in on the natural log of 2. The answer to the question, e to what is equal to 2. Kind of strange, don't you think? That something like e would show up with relation to  just odd numbers oscillating back and forth like this. And there's another relation that natural logarithms  have to a sequence that looks like this. You might ask, what happens if we don't alternate back and forth,  but we add them all together? What does that approach? Because in the same way that, you know, when we added all the squares,  the sum of the reciprocals of the squares, that approached a beautiful thing,  it was pi squared over 6, you might think an even more natural question to ask is,  don't square them at all. Take 1 plus a half plus a third plus a fourth, on and on, what does this approach? Now as it happens, it actually, it doesn't approach anything. No matter how small a number you choose, this  sequence is eventually going to get bigger than it. So I could say, keep adding terms and eventually you'll get bigger than 100. If you have some patience, keep adding terms and  eventually you'll get bigger than a million. And that's kind of surprising, because each one of these numbers is  getting smaller and smaller, so as you're making your additions,  you would think it's going to slow down, it won't get you past something like 100. But I can explain to you why this is going to happen, it's actually a very pretty proof. If I group my terms appropriately, so I'm going to group a third and a fourth together,  I'm going to group all the numbers between a fifth and an eighth,  all of the numbers between a ninth and a sixteenth,  all of the numbers between 1 over 17 and 1 over 32. So into these groups that grow in size by powers of 2,  what I can say is that a third plus a fourth, well both of those numbers are  bigger than a fourth. A third is bigger than a fourth, and, well a fourth isn't bigger,  but it's exactly equal to, but that does mean that their sum,  yeah their sum is definitely going to be bigger than 1 fourth times 1 fourth,  which is the same as taking 2 times a fourth. Similarly, this sum here, 1 fifth plus 1 sixth plus 1 seventh plus 1 eighth,  each one of those terms is bigger than an eighth. All four of those terms are bigger than 1 eighth. So the group of them together is bigger than 4 eighths. Similarly over here, all of the numbers between a ninth and a sixteenth,  all eight of those numbers are bigger than 1 and 16,  so the sum all together is bigger than 8 times 1 over 16. And you might see where I'm going with this, you know,  here I have 16 numbers that are all bigger than one in 30, excuse me,  bigger than one in 32, talking while writing, and of course all of these are just  equal to one half, so this two fourths is the same as a half,  four eighths is the same as a half, eight sixteenths, that's a half. So in other words, what I can do is group all of my terms so that the sum  instead looks like taking 1 plus a half plus a half plus a half on and on forever. And that you can see, okay, if I keep going sufficiently long, it is going to get bigger. And it also gives you a little instinct that this might actually be related  to logarithms, because the size of our groupings grow according to powers of 2. So if you were wondering, how long do I have to go before the sum gets bigger than 10,  you might have the instinct that, hmm, I'm going to have to add together, let's see,  I have 1 and then the rest of them are halves,  so I'm going to have to add together 18 different groups that each look like a half,  so I might have to get up to the point where the size of my group is like 2 to the 17th  or 2 to the 18th, something like that. And you would be spot on that it grows, well, it doesn't grow exponentially,  it grows logarithmically, because if you're asking how far do you need  to go in order to get to that point, it would be logarithmic. And as you might guess, it's actually the natural logarithm. So if I add up all of the terms to about 1 over n,  it ends up being approximately the natural log of n. And if you want to get even more accurate, it's the natural log of  n plus a certain constant, this is a constant we'll talk about later on in the lesson,  but just for an order of approximation, this gives you the idea that  you need to get up to around the natural log of n. So I'm going to go ahead and pull up the quiz and ask you another question,  just to see if you've been paying attention so far. So our question asks, which of the following is closest to the  smallest value of n for which the sum 1 plus a half plus a  third plus a fourth on a 9 you keep adding until you get 1 over n. How long do you have to go until that sum is bigger than a million? So remember, your first instinct here might have been that this entire  sum converges to something, in the same way that when you add the reciprocals of squares,  it converges to pi squared divided by 6, very beautiful. You might have thought that you keep going to this and it converges. In fact, what happens is it'll always get larger,  but you can be more quantitative than that, and you can ask,  how long does it take before this gets larger than a million? So I'll give you a little bit of time to think through what the answer to that will be,  and I will say, because we're kind of converting between E-related things and base  10-related things, if you wanted a little reminder,  I can pull up the fact that the natural log of 10 is around 2.3,  if you wanted to use that for estimation purposes. So just to see if you were paying attention to the result that I just described  of this thing growing like a natural logarithm, let's see how you answer. And I'll give another 20 seconds or so here. Alright, even if you're not necessarily finished,  I'll go ahead and see where people are on this one, lock in the answers,  and then explain where it comes from. So, the correct answer is that it's around 10 to the 400,000 or so,  which is a huge, huge number. The estimated number of atoms in the universe is around 10 to the 80th,  so it would be as if each atom in the universe had a universe inside of it,  that would get us to 10 to the 160, then each one of those had a universe inside it,  that only gets us to 10 to the 240. You'd have to keep iterating like that over and over, and it would even,  even that crazy idea, like mental thought for how you can get up to a big number,  would take forever to get you to something of the size 10 to the 400,000. Alright, now the way that you would think about  something like this is to take a look at what I just said. When we add up all these numbers up to the point 1 over n,  it's about the natural log of n. So what you're looking for is the value when the  natural log of n is approximately a million. That's how long you have to go before the sum gets bigger than a million. This is the same statement as saying that n is about e to the power of a million. Okay, but of all of our answers, we're expressed in terms of powers of 10,  so in order to make the conversion, I would think to myself, 10 to the what is equal to e? That way I'm going to be able to make a little substitution in here with the power of 10. Well, this is asking me what is the log base 10 of e? And from properties of logarithms, like what we learned last time,  this is the same as asking log base e of 10, but we're taking the reciprocal of that. Okay, and another way you could think about that is that e to the 1 over x equals 10. That these two expressions are the same, so we're looking for the natural log of 10,  but we take 1 over it. Now our estimation for the natural log of 10, if you happen to know, it's around 2.3. All you would really need to know for this one is that it's roughly 2,  or even that it's on the order of 1, because all the exponents in our options were  looking very different. So if you're asking what's 1 divided by 2.3, I mean very roughly, it's like a half. So we could think of n as being very, very roughly something that's like  10 to the 1 half to the 1 million, just to get us something kind of close. So that looks like it's 10 to the 500,000, and we know that that 1 half really  should be a little bit smaller, because we're taking 1 divided by 2.3,  not 1 divided by 2, so the number should be something a little smaller than 500,000. And indeed, of all the options here, there's one that's much closer to 10 to the  500,000 than anything else, so our very rough approximation would get us there. Alright, so that's pretty fun. Now, to start explaining where on earth some of these things are coming from,  like why is the natural log present in these circumstances,  I want to take a moment to start talking about E and the role that E  plays in math in a way that I think sometimes it can be a little bit misunderstood. So, just to start off, I'm going to pick a number from the audience, so in your own time,  feel free to go to 3b1b.co and enter whatever your favorite number is. But the thing I want to talk about to begin here is how... Ooh, lots of answers coming in. That's always fun. When you see a family of functions, okay, so let's say we see something that looks like... I'll pop on over here... Something that looks like e to the r times x for various different values of r. This is something you see all the time in engineering, in math, in physics. We describe a bunch of different exponentials with some kind of parameter,  like r sitting there. And we say depending on what r is, this can give us a shallower exponential growth,  something that grows exponentially but a little bit more slowly,  versus a steep exponential growth. Okay? Once you're writing things in terms of a family,  I think a lot of people have this instinct that these are all of the  functions that e produces, like e the number is producing this beautiful  family of functions. But it's important to realize this is the same statement as creating a family of  functions that just look like a to the x with various different bases,  where it could tweak what that value of a is and say, you know,  sometimes it looks like 2 to the power x, sometimes it looks like 3 to the power x,  or 4 to the power x. Tweaking that base gets us various different exponentials. That's actually playing the same game. For any one that you have here, like, you know, the function 3 to the x,  taking powers of 3, I can choose an r such that e to the r x equals that. And in fact, there's nothing special about e. I could have chosen as the base here something like pi. I could say look at the family of exponentials that look like pi to the r times x. It's not that pi is producing these numbers or  pi is related to this family in a particular way. It's a choice that we're making to write it that way. And almost always, the choice that we make in physics and engineering  and math all over the place to write families of exponentials is with e. So the right question to ask isn't what does e have to do with such a family,  but why is it the right choice? I'll give you another example of where this can come up. I mean, they're all over the place, things that look like exponential curves. But one that's very important for probability and statistics is the bell curve. So it's something that we almost always write in the form e to the negative x squared. And a way you might think about this, by the way, is if we take just e to the x,  we get this thing that grows and it kind of decays as you go to the left. And if we made it negative, it would decay as you go to the right. So whenever the input to e to the x is getting very negative, it decays. So to make it decay on both sides, you could take e to the negative x squared. And then it's decaying on both sides and you get this nice bell curve. And because of that square, it sort of smooths things out,  whereas if we had taken something like the absolute value of x but negated it,  okay, then it decays on both sides, but we get this awkward cusp. That doesn't explain why this very specific curve comes up in statistics. but if you ever kind of want to remember oh what was the what  was the formula for a bell curve again you can kind of think  through the fact that this should have roughly that shape. And quite often it comes with some kind of parameters, though. For example, I could put in something, maybe a value I'll call s in there,  that will determine how wide and skinny this bell curve is,  something like a standard deviation in the context of statistics. S wouldn't be that standard deviation. We would have to reciprocate it and square it and do some things. But the idea that when you tweak what's in that exponent, it changes the bell curve. That's the only point I want to make here. You can think, just looking at this, that somehow  bell curves are produced by the number e. But that's not exactly true, because I could also write a to the negative x squared,  and I get the same family of curves. As I tweak the value of a, I'm also changing what that width is,  so I could come up with other ways of describing the standard deviation of this  in terms of a. And it's the same family of curves. It's not just that they look similar. They are, in fact, the same thing. And this is not too hard to show algebraically. It almost makes it look a little bit more deceptively simple than it really is. So we've got a lot of answers for what people wanted to enter  as an example number to go with, so let's go ahead and see. It seems like the most popular answer, by a little margin above i, is 69,  which I assume is because if you take all of the natural numbers between 1 and 9,  and then you look at the divisors for each one of those, you look at the numbers,  you list all their divisors, and you add up the divisors, it adds up to 69. And adding up divisors like this is a very fun and common thing in number theory,  so I assume that's why people chose it. But the point here is that if you see some kind of function like,  let's see, how should I write it? 69 to the power x. I could also write that. I could write the same thing as e to the power of the natural log of 69. Okay, I've written that kind of sloppily. Let me do it again. e to the natural log of 69. That's the same thing as the number 69, right? Because it's saying e to the what equals 69, but then I've taken e to that,  so I should get 69 back. All of that to the power x. And by the rules of exponentials, this is the same thing as e to just some constant,  whatever the natural log of 69 is, times x. So I could replace that with a constant, which happens to be around 4.234,  as any mathematician will be able to tell you, well-known constant of nature,  the natural log of 69. And the point here is that this just looks like e to some constant times x. So you might wonder, why do we make this choice, right? Because it didn't have to be pi. I could write that same function, sorry, it didn't have to be e. I could write that same function sorry it didn't have to be e I could write  that same function as pi raised to a special power namely the log base pi Man, I'm writing quite sloppily here. Log base pi of 69 times x, that would be the same function. We could describe everything with a base of pi if we wanted to. And to just give one more example of where I think this, even though it's a,  like it's a simple conversion if you know logarithms,  that anything that looks like a to the x can be expressed as e to something times that,  I think it's clearly not very appreciated that you can make that conversion,  because any time that we talk about imaginary exponentials,  and I get that it's kind of a weird thing to talk about e to the i times t,  once someone learns, you know, and I've made a number of videos in this series about it,  Mathologer has videos, lots of people have videos about it,  the idea is that e to the imaginary constant times some value t walks you around  the unit circle, and in fact it walks you a distance of t radians. And the importance of this, the way that it comes up in, for example,  electrical engineering, is it gives you this oscillating pattern. As you scale up t, you have something that's oscillating,  and it gives a very nice way to describe sine waves and cosine waves and  signals that oscillate. And there's actually one electrical engineer that I used to know,  and he would always say, oh I love the number e. What I like about e is it's the number that spins. That's really what makes e special, I realized this. e is the number that spins. But the problem is that's not, that's not exactly true. It is true that e to the i t spins around, but that's not special to e. I could also take 2 to the i times t, and that  will also produce values that walk around a circle. And we can think through more exactly, 2 is the same thing as e to the natural log of 2,  so 2 to the i t is the same as e to the natural log of 2 times t,  all of that times the imaginary number i. Which basically means it's doing the same thing as e to the i t, it's just rescaling time. It's walking a little bit more slowly. And then similarly, if you were to take something like your  favorite number to the i times t, that would look like e to  the approximately 4.234 times t, all times the imaginary number. Which just means you're walking around at a different rate. So e is not the number that spins. The idea of complex exponents walking around a circle doesn't have to do with e per se,  it really just has to do with a lot of what we talked about I think in lectures 4 and 5. And I'll go over it again in just a moment here as a quick reminder. So the thing that's special about e, the reason that we always  choose to write things in this way, has to do with rates of change. That when you take the derivative of e to the power t, this is the same thing as itself. Which is to say if we were to graph this, you know maybe e to the t  represents an amount of money you have over time or something like that. And we were to look above a value of t, the slope of this graph,  the rate at which it's increasing, is actually equal to its own height. So the farther you are along the curve, meaning you have a greater height,  the steeper it is. So the more money you have, the faster it grows. This is the power of compound growth. But that's actually true of any exponential. What makes e special is that they're exactly the same,  it's not just that they grow in proportion with each other. So if we were to write a family of exponential curves as e to the r times t,  as opposed to writing it as a to the power t, and thinking of changing that value a,  the value in doing that is that taking the derivative by the chain rule,  we take the derivative of the inside, which looks like r,  and we multiply by the derivative of the outside, which is e to the rt. And if anybody here doesn't know calculus by the way,  we're about to start doing a fair amount of it,  I have a whole series on it that you can pop over and take a look at,  lots of other places on YouTube and such to give a quick primer. But if you're coming in and you're not familiar with calculus,  like just be warned that that's where we're about to start going. Because if you want to understand natural logarithms,  and by extension the number e, the importance that they have has  everything to do with rates of change and the inverse of that operation, as you'll see. So anyway, why would it be nice to express a function like this? Well what it's telling you, let's say this was something like the size of your investment. This is an expression saying how much money you have at a given point in time. If you want to know the rate of change of that, how much is it changing per unit time,  it's proportional to itself, and r gives you that proportionality constant. If r was 0.01, it's telling you that the rate  of growth is 10% of the size of the thing itself. So the choice that we make to write things this way is,  it's basically a way to make all the constants involved more readable. So if you're to look at these statistics associated with bell curves,  and the way that we actually tend to write things,  the pattern ends up looking something like 1 divided by s squared,  and sometimes that x instead of writing it as x. Strange parentheses. I might say x minus m for some value of m. Both of these terms end up having really nice readable meanings, where m,  this isn't specific to the e fact, but it's just a common thing you'll see,  m gives you the mean of the distribution, where this pile is,  and s gives you the standard deviation. And when we choose to write this family with e,  it's giving those constants readable meanings. And a similar thing happens with how we describe complex exponentials. When we choose to write the idea of walking around a circle with e,  it gives a very readable meaning to what this term t is. It's saying, what is the distance that you've walked along the unit circle? And you can actually understand this with derivatives pretty well, where if we say,  what is the derivative, what is the rate of change of some value that looks like e to  the i times t, by the chain rule, this is going to look like i times itself,  e to the i times t. Now what would that actually mean? That means that if you're sitting at some kind of number,  if this is your current value for e to the i times t,  the rate of change is i multiplied by that value,  which is a 90 degree rotation of this vector. Maybe I would draw it like this. This right here would give you your rate of change. So you might move that over and consider it a velocity vector. So this is kind of like your velocity vector, this is kind of like your position vector,  which I might write something like an s. So what this whole expression of e to the i times t is essentially saying is,  whatever this does, if it's somewhere in the complex plane, at every given point,  the rate of change of my vector is a 90 degree rotation of itself. And so that's why we're walking around the circle at a speed of one unit per second,  because the length of the position vector is one,  so the length of the velocity vector is one. And it's also why, if you were to look at two to the i t,  it walks around at a different rate. Because there, the constant is not just i, a 90 degree rotation,  it's i times natural log of two. i times something would mean that this, where are we,  this operation here is not just a 90 degree rotation,  it's a 90 degree rotation and a scaling. So your velocity vector would end up looking a little bit shorter,  and you'd be walking around the unit circle more slowly. So that's kind of the important thing to understand about e,  the fact that it's a choice that we're making to write families of exponentials this way,  but because it is its own derivative, that ends up making these things play much  more nicely. Now, this lets us take derivatives of anything else if you wanted. If you did describe your money's rate of growth with a to the t, to take its derivative,  you could first do a conversion, write the whole thing as e to the natural log of a  times t, and the reason you would is then when we're, I sort of squished my font here,  then when you're taking the derivative of that,  the derivative of the inside is the natural log of a,  and then that's multiplied by itself, e to the natural log of a times t,  which you could then spell out even further, convert it back into a to the t. so if you did describe all of your investments as a to the power t  which kind of feels more natural to a lot of people that oh you might  say rather than e to some investment rate times t just think of 1.05  to the t and that describes you know something like five percent growth If you were thinking of that growth in a continuous sense,  not year over year, what's the new percentage, but moment by moment,  what's the rate of growth, you would have to say the rate of growth  is the natural log of that base, which just feels a little bit more awkward. You could do it, but it would feel more awkward. Now, all of this leaves open the question of why? Why on earth is the derivative of e to the t equal to itself? It's this very nice property, so you might wonder where this thing comes from. And it really has everything to do with how you define the number e. And this can be a little bit frustrating, where in some contexts you'll see people say,  what is the number e? Well, it's the number defined such that this derivative equals itself. And then other contexts, you might find e defined in a different  way that is very conducive to whatever the circumstance there is. So you might wonder, okay, can we come at this a little bit more directly,  and try to understand derivatives of exponentials,  and see why the special value 2.718 would fit into it. And to do that, let me draw myself a new graph here. Let's say I have some kind of exponential. And if I want to understand the rate of change, the slope tangent to that point x,  the way we often think about it is think of two nearby points,  so another one that might be x plus a little constant times h. And then we're going to look at the slope between those  two points and consider what happens as h goes towards zero. So if this whole graph was a function a to the x,  if we wanted to give a very direct look at what might the derivative of this  expression be, we can make an attempt to calculate it ourselves without  depending on a pre-established fact handed down from on high that e to the t is,  or I guess in this case e to the x is its own derivative,  and then manipulate based on natural logs and such. So what does this look like if you try to come at it directly? Well what you would say is that the change in the height of the graph divided  by the change in the width, the sort of rise over run, dy dx,  looks like the difference in the outputs at those two values,  so the output at the high value, which is x plus h, minus the value at the low value,  a to the x, all of that divided by the step in the x direction, which is just of size h. And the fact that we are doing calculus here, that we have the little d's,  that is a signal to us that we don't just want this ratio for a particular value of h,  we want to consider what that ratio change in y,  change in x looks like as the change in x goes to zero. And here I'm writing that change in x as h, so  it's a limit as h goes to zero of this expression. And from here you can try to manipulate it a little bit and see what you might find. The first step, take advantage of the exponential  properties to write this as a to the x times a to the h. And what's nice about that is it lets us factor out an a to the x,  because it shows up both in the first term and the second,  so I could write this whole thing as a limit of a to the x outside of a to  the h minus one all over h. And this was the limit as h goes to zero. Well, x has nothing to do with the h here, so  we're allowed to pull out the a to the x term itself. As far as h is concerned, it's just some constant rescaling the thing,  and the limit of a constant times a thing is that constant times the limit of the thing. A times, or a to the x times the limit as h goes to zero of a to the h minus one over h. And at this point, we're a little bit stuck. We've found a very interesting fact, which is that any kind of exponential,  e or whatever you want, base pi to the x, two to the x, 69 to the x,  those have derivatives that are proportional to themselves,  but we want to understand this proportionality constant. And I could ask you to guess, just to see if you can get  a feel for it in the context of one particular example. So let's say that I'm choosing a base of something like two,  and I want to understand rates of change of two to the x. Our question asks us, the limit below, I guess it tells us,  it tells us a little bit about what it is. The limit below is a number between zero and one. So this is, we're looking at two to a small value  minus one divided by that same small value. Don't worry about calculating it exactly, I'm just kind of curious if you guessed. Enter some kind of guess for what this value is,  and then round it to two decimal places so that we can have some consistency. So we'll give you a moment to just think of what it might be,  but don't think too hard if you don't want to. It's totally okay to get this one wrong, we just want to see what people think. Looks like we've got a couple things coming in from the audience here,  which is always fun. So Robert points out that in French the notation reads,  logarithm l'imperillain, and is wondering why this word is used. I asked this on Twitter the other day, evidently it's in reference to a person,  I think John Napier, and so it's in reference to him. And then there was a truly terrible French pun about an exponential  and a logarithm walk into a bar and they order a beer and who pays? And the answer is that the exponential has to pay because la logarithm n'imperillain,  which anyone who speaks French will like groan and laugh at,  but that made me laugh a little bit. Do I have a personal vendetta against e? Yeah, yeah I do, I think it's an overrated constant. I think it's beautiful, but I think it's beautiful  in ways that aren't what people think they are. And I also think that, I'm going to talk about this in a moment, we should write,  we shouldn't write the exponential function as e to the x,  because when it's more general that doesn't make sense and I think it confuses people. We should just write it as what it is, which is a certain polynomial,  and just be honest up front rather than letting e,  like e has nothing to do with e to the pi i, that's a frustrating fact. It shouldn't be in there. Anyway, German here is normal for how you do maths  on a ruled paper instead of graph paper. I mean graph paper is definitely nicer, but I don't know,  this was the paper that I just had on hand. And in general if you want to make any comments or questions about the lesson,  you can do so on Twitter with the hashtag locked down math,  and those will be pulled up as we go. So it seems like we have strong consensus on our guess here,  which is people guessing that the correct answer to this limit is that it's around 0.69,  which I assume the reason everybody guessed that is because it's the correct answer,  that this limit does in fact approach around 0.69,  and we could play with Python if we wanted to see that experimentally. Python's kind of overkill here, you could do it with any calculator,  but if I raise 2 to some small power, I get some kind of number,  and if I subtract 1 from that, then I get a small number,  and if I divide it by the same small power, so here I have three zeros and a one,  it looks like we get around 0.6931. And if I made it a smaller value that I was doing,  it seems to stay pretty stable around there, it's around 0.69314. So congratulations to the majority of you who had the right guess here. And in fact it's no coincidence that that's what it is, because like I said earlier,  if you're taking the derivative, where have I written it? I've written it somewhere. Sloppily as I want to do, I've written that if you take the derivative of something  that looks like a to the t, the constant sitting in front is the natural log of a. So for something like 2, you would be looking at the natural log of 2,  which is in fact around 0.69. Now, all of that was dependent on the fact that e to the x is its own derivative, right? So there's one avenue that you could take here,  if you want to come up with a definition of e. What you could say, and this is totally valid,  is the number e is defined to be the constant such that this limit is 1. If that's the case, then e to the x is its own derivative, by definition, pretty much. And then from there, you will get the fact that anything else,  its derivative can be expressed in terms of the log base e of itself. That's one way that you could go. Another avenue that you could take is to say that when we write e to the x,  this is actually shorthand for a certain polynomial. I'm partial to this because I think this is an honest representation of the role  that it plays more generally, like when we start talking about complex numbers. It's weird to me that in high school I saw Euler's formula as the polar representation  for complex numbers before it was ever really explained that e to the x does not  refer to the repeated multiplication, that it's a shorthand for this long polynomial. You might give it another name, like exp, right? And then that's something that it makes sense to plug in complex numbers to. Traditionally, the way that you see this series in high school is you might go  through a calculus class where you learn about e to the x being its own derivative,  and then maybe at the end of a second calculus class,  the fact that it is its own derivative, in conjunction with a very wonderful topic  called Taylor series, right? So it being its own derivative and Taylor series proves that e to the  x must equal this long polynomial, which is absolutely the case, right? If you have a function that is its own derivative and at the value zero it equals one,  you will find that it has to equal this polynomial. An alternate approach that you could take if you wanted in setting the foundations is  to say, don't worry about Taylor series, start with this sequence as a primitive object,  and then something we talked about a couple lectures ago was,  because of a nice property that this function has,  which is basically that when you add the inputs,  basically this polynomial behaves like an exponential,  and you can prove that just from the polynomial itself without calculus or anything,  exp of a plus b equals exp of a times exp of b. And it's a very pleasing exercise to kind of work  out the expansion and see that that works. And the fact that that works, we talked about this a couple lectures ago,  implies that the whole sequence looks like whatever exp of one is raised to the x. So what you could say is the number e is defined to  be this particular sequence evaluated at x equals one. And if you go that direction, that's all well and good,  and it becomes a kind of substantive thing to talk about e to the x being  its own derivative. And it's one of the most pleasing exercises that you'll ever do,  because we can take a look at this, and if you know how to take derivatives of polynomial  terms, well let's just work it out actually, I'll turn over a new leaf so that it can be  nice and cleanly seen. It's really one of the most pleasing, I don't know,  times that you'll have in a calculus class. If you're just sitting, you're looking at this particular infinite polynomial,  and you're saying I wonder what the derivative of this happens to be. And all you need to know is the power rule for polynomial terms,  and you'll say that the derivative, let me take d dx,  well the derivative of a constant ends up being zero, the derivative of x is one,  the derivative of x squared over two, you know you might think of that two as kind of  hopping down in front and leaving one less than itself,  so it becomes two times x to the one, just x to the one over two, and those twos cancel,  so we're adding x. x cubed over three factorial, I might write this  out as x cubed over three times two times one. this ends up being three times x squared you know the exponential the exponent kind  of hopped down and left behind one minus itself over three times two times one the  threes cancel so we can see that that's actually the same as x squared over two factorial And in general, each one of our terms, as the exponent hops down,  it cancels out one of the things from the factorials below it,  and what we get is the exact same sequence but shifted, which is quite nice. And like I said, the traditional way that you see this series is that you're  using the fact that e to the x is its own derivative,  in conjunction with Taylor series to show that it must equal this,  but if you start with this as a primitive, and you say this is the thing that  defines a special function for which we use the shorthand, e to the x,  then it feels a little bit more contentful and quite fun to say that e to  the x ends up being its own derivative. And like we showed earlier, that then lets you take the derivative of all sorts of  other things, which in turn explains why we adopt the convention of writing all of  our exponentials as e to something times t, as opposed to writing them all as a to  something times t, even though those are equivalent and often weirdly hard to appreciate. So, with all of that said, we can turn ourselves back in the direction of natural  logarithms, because let's say I wanted to know the derivative of the natural log. you might wonder why i want to know that but if i have a bit you know a deeper  relationship with the natural log of x in terms not just of how it relates to  these series but in all facets of math maybe we can then start drawing connections And if you build up that relationship by knowing things like its derivative,  it actually helps you come back and understand things like  the alternating series we were looking at before. So, can we use the fact that e to the x is its own  derivative to figure out the slope of a natural log curve? Well, what that slope is asking us is to look at a given input x,  we consider a tiny step dx to the right, look at the corresponding step dy up,  and we want to understand the ratio, dy over dx. Now, at this point, which has some kind of output y,  what we can say is by definition, y is the natural log of x. Now, this is the same statement as saying e, have I written this right? y is natural, yeah, great. So, this is the same as saying e to the y is equal to x. Now, from there, I can understand the relationship between  tiny nudges to x and tiny nudges to y by taking derivatives. If I ask about some tiny nudge to the value x and the corresponding  tiny nudge to e to the y, well, what it means for e to the x,  or in this case, e to the y to be its own derivative,  is that the size of that tiny nudge is e to whatever the y value at that point is,  times dy. And we're saying that that equals dx. And what this lets us do then is express the slope that we want, dy over dx. If we just rearrange things, it looks like 1 divided by e to the y. So, what this is saying is that if we look at our graph, it's got some x coordinate,  some y coordinate, and I want to know what the slope is,  this change to y over change in x. I can't immediately express it in terms of x, maybe,  but I do know whatever this value of y is, if I take e to the power of that and then  reciprocate, that gives me the slope. But of course, what it means to be on our graph is that y is the natural log of x,  which is the same as saying e to the y equals x,  so this whole thing is the same as taking 1 divided by x. So if I want to know that slope, I can say, what is your x coordinate,  take 1 divided by that, and that gets me the slope of the natural log. Which is, we've just gone through a process called implicit differentiation. If you're not inclined to believe that this manipulation is legitimate,  that we can just move around the dx's and dy's like that,  I have a whole video about implicit differentiation in the calculus series  that you can take a look at. But the point for us is that we have a very nice fact,  that the derivative of ln of x looks like 1 divided by x. And that's quite nice, and it kind of passes a gut check that ln of x gets  shallower and shallower as you go on, which means the slope gets smaller and smaller. And the graph of 1 over x, you know, what does that look like? Well, at the input, let's say we have the input 1 somewhere like here, it'll be at 1. At the input 2, it'll be sitting at a half. At the input 3, it'll be sitting at a third. And in general, it gets lower and lower and closer to 0. So the idea that this would describe the slope of that, you know,  something that gets lower and lower closer to 0,  seems to pass a little bit of a sanity check. Now, the relevance that this is going to have to us  will involve the inverse operation to differentiation. So instead of talking about what is the slope of the natural log curve,  what I might do is ask about the area under this particular curve. Let's say I take the area up to... my stomach was just rumbling, I don't know if that's audible on the microphone. Clearly, gotta eat lunch before these things. So let's say I want to understand the area up to n of something like this. kay what that what that involves is taking the integral  between one and our value n of one divided by x by dx Now this actually looks quite similar in spirit,  the idea of adding up a bunch of things that look like 1 over x,  to what we were looking at earlier. How much earlier? I guess over here. Where we were adding up 1 plus a half plus a third plus a fourth, on and on. And already it gives a little bit of an intuitive instinct for  why something like this sum would be related to natural logs. Because we now know that in calculus land, natural logs  are intimately related to the idea of 1 divided by x. But I want you to think of this spelled out a little bit more exactly,  and so we'll pop on over to our quiz one more time. Second to last question for today. and the question asks us all right we're gonna let s be the  sum from n equals one up to capital n of one divided by n ok That's s. And then we're going to let i be an analogous integral,  where we're integrating dx over x between 1 and n. And it asks you to compare s and i. kay i'll give you s and i okay i'll give you a moment to think about that s Interestingly, we don't have a ton of consensus around this one. So there's only three options, and we've got a nice split. And as you guys know, this is actually one of my favorite things when  we do any of these lockdown live quizzes, is when it's not everyone  hopping on to one particular thing, but we have a division among folks. And I think that's great. i'm curious i'm curious actually what the uh what the answer is going to be here And in fact, even if it's not been enough time to thoroughly think through,  I'm going to go ahead and grade it, just so that we can see what it happens to be. and a lot of these the spirit of it is that you kind of hazard a guess so feel  no shame if you entered an answer and then it's not what turns out to be correct s So in this case, the sum does in fact end up being bigger than the integral. nd the and it looks like uh 900 of you got that correct which is awesome an And then following that was people thinking that it was less. And then to those in B thinking that they were identical, you know,  that's a reasonable thought, because they're such similar expressions. But there's a picture that really makes the answer kind of shine out to us here,  which is, if I look at the curve 1 over x, which is what this white curve is,  it's 1 over x, and then I'm going to consider a bunch of bars,  each of whose area corresponds to 1 over n for some value of n. So for example, for the value 1, this bar has a width of 1, and then the height is 1,  and that means that right above the input 1 on its upper left corner,  it's hitting the graph. Now for the next term, if I want 1 over 2, that means it's going to  hit the graph above the input 2, since the graph is defined to be 1 over x,  so its upper left corner hits that, and then the area of this bar  whose height is 1 half is, well, 1 half, because its width is 1. Similarly, this bar has an area of 1 third, this bar has an area of 1 fourth,  and so what you have is a sequence of rectangles whose total area is going  to be similar to the area under the curve, definitely similar,  but you can tell that it's going to be bigger, because some of the area is leaking out. In this context, we've got a lot of area leaking out from the first bar,  a little bit less leaking out from the second, and on and on,  but as you go, because the graph flattens out,  it becomes quite a good approximation once you account for the area  that's leaked out there. Now something kind of bizarre is happening here,  where usually we think of these rectangles as being something like a Riemann  sum that defines integration, where we say, oh,  we don't know what the area under a curve is, but we like areas of rectangles,  so we use the rectangles to approximate the curve. Here, we're going to do something that's backwards to that. If we know calculus, we do know the area under the curve. It's very nice. It involves the antiderivative of 1 over x, like we'll show in a moment. What we don't know is the sum of the areas of the rectangles. That was the sum that we were looking at earlier and trying to understand. So here we're going backwards and using the area under a curve to  approximate the area of a bunch of rectangles, which I think is fun. It shows that calculus has this back and forth. It's not just geometry informing understanding of curves,  but it's an understanding of curves informing an understanding of geometry and number  theory and things of that sort. So what this means for us is that if we take a look back at our paper and we look at  my much more sloppily drawn graph than the beautiful exact illustrations can give us,  if we want to understand that area, taking this integral,  the task is to do an inverse derivative, to ask what function has a derivative that  equals the inside here. If that's something you haven't learned about, again, calculus series. Take a look at the fundamental theorem of calculus video,  or even the first video in that series I think shows a little of  an instinct for why you have this relationship between slopes and areas. But what it means for us is that we take the inverse derivative,  which we now know is the natural log, the thing whose derivative is  1 over x is the natural log, and we evaluate it at the bounds, at n and 1. And this notation where I kind of put brackets around it and then a number  in the upper right corner and lower right corner means I take that expression  evaluated at the top minus that expression evaluated at the bottom. And that, well, natural log of 1, what is that? e to the what equals 1? Well, it's 0. Pretty much anything to the 0 will equal 1. So this term goes away entirely, and what we're left with is the natural log of n. And what this means for us is if we were using our rectangles to approximate the sum,  or using the integral to approximate those rectangles,  it's saying that 1 over 1 plus 1 over 2 plus 1 over 3, on and on,  up to a given bound is about equal to the natural log of n. And more specifically, if you were to account for how much area is leaking out here,  that area actually does converge. As n tends towards infinity, the area that's leaked out approaches a certain constant,  and it's called Euler's constant, or the Euler-Macheroni constant,  and it happens to be around 0.577. So in the same way that pi and e are constants of nature,  this is another constant of nature, also bearing Euler's name. And what it describes is the deviation between this sum,  often called the harmonic sum, and the natural log of x, a thing that is related to e. So Euler has really got his fingerprints all over the situation,  at least as far as naming is concerned in our little expression here. So that's quite nice. That's quite fun. But that only answers one of the mysteries that we had earlier. Because if you remember, I opened this whole thing up by talking not just  about this series that grows like the natural log, we also alternated it. We went 1 minus a half plus a third minus a fourth,  and the claim is that that was the natural log of 2. So let's see if we can try to understand why that's true. And I might actually postpone explaining the even more bizarre fact that this  interrelates with primes in a certain way, depending on how long I want this particular  stream to go. But at least finish off by understanding the alternating series,  because it's extremely satisfying. So to do that, let me just rewrite what our series looks like. And this is one of those things where, as I go through the answer,  it has a feeling of magic. And sometimes not in a great way. You might find yourself looking at how we go about this and asking,  how on earth would anyone ever come up with that? And maybe after we plop it all down, we can try to introspect and think about the  reasonable ways that someone would come up with the following line of reasoning. But it is not unique to this situation, it's kind  of a useful set of tricks to be familiar with. And there's a couple general principles in there. The first general principle is that if we have a hard question,  in this case figuring out what this sum approaches,  bizarrely it can become easier if we make it more general. You might think that making things more general would make it harder,  because you have to answer a more powerful fact. But math does this bizarre thing, where sometimes by trying to make it more general,  you actually make the problem more tractable. Which is quite cool, actually, because what it means is when a mathematician  is motivated only by making their own life easier,  it has the strange effect of making their results applicable to a wider  variety of circumstances. So the way I'm going to generalize this, again,  it might look kind of bizarre and unmotivated, but run with me for a second,  is rather than thinking of a single value, I'm going to put an x in here and  consider this a function where I'm taking x over 1 minus x squared over 2 plus  x cubed over 3, on and on and on. And I want to know, in general, what does this approach for various values of x,  and then I just have to plug in the value x equals 1. Now, like I said, that might make it seem harder, infinitely harder. Previously we just had to know one value, now  you're asking me to compute infinitely many values? But if you know calculus, you might recognize that the exponents of  your polynomial terms might just play nicely with the denominators here. And in particular, if we were to take the derivative of this series,  it behaves quite nicely. The derivative of x is 1, the derivative of x squared over 2,  well that 2 hops down and cancels out the denominator, so it becomes negative x. Similarly, that 3 hops down and cancels the denominator, so it becomes x squared. And while you might not know why we're taking a derivative of something here,  and how that would be helpful for actually evaluating the ultimate sum that  we care about, it is an interesting fact, and it's something that is playful and fun,  that we've somehow simplified the expression by taking its derivative. And the simplification is actually quite important,  because there's a well-known fact within math that you can take a  series where each term is the product of the last with a constant kind of product. So here, as we go from one term to the next, we're always multiplying by negative x,  so to go from negative x to x squared, you multiply by negative x,  and then similarly x squared to negative x cubed, you're multiplying by negative x. And when that's the case, the series as a whole is going to approach 1 divided by,  or wherever you start, but here we started at 1,  so the thing you started at divided by 1 minus the thing that you're constantly  multiplying by, which is negative x. So to give another example of where this comes up,  is if we were to take something like 1 plus 1 half plus 1 fourth,  where each time in our sequence we are multiplying the last term by 1 half,  this will equal 1 divided by 1 minus the thing we were multiplying by, which was 1 half. And 1 divided by 1 minus 1 half ends up being the same as 2. And that actually kind of feels intuitive, that if we take 1 plus 1 half plus 1 fourth  plus 1 eighth, you could even draw out a picture,  where let's say I've got a rectangle whose side length is 1, and 1 here,  I can say the 1 represents this area, and then half represents this area,  and then a fourth represents this area, and an eighth represents that area,  and kind of keep playing this game, and eventually it'll fill an area of 2. Now the more general version of that is this geometric sum,  which someone who's done a lot of problem solving in math is able to recognize kind  of quickly, which is why they might enjoy this series much more than they would  enjoy the one above it. So this whole thing ends up looking like 1 divided by 1 plus x. Great. But what this suggests is that if we somehow take an antiderivative,  if we somehow integrate this, we might have an alternate expression for what the  initial sequence was. So from here, I'm going to go ahead and pose a quiz,  and part of this quiz is seeing who in the audience is comfortable with calculus,  and again if you're not, calculus series, go and check it out. But what we have here is the question, what is the  integral from 0 up to 1 of 1 divided by 1 plus x, dx? I want you to evaluate that integral, and I'll give you a little moment for this one. So, let's see. And you know, tell you what, while answers are rolling in, before locking it in,  I'm going to go ahead and just start describing the answer here. So, if you want to know the integral from 0 up to 1 of 1 divided by 1 plus x, dx,  well we know that the antiderivative of 1 over x is the natural log of x,  so it's going to be the natural log of that inside divided by the derivative of  the inside. That's kind of the inverse chain rule, or something you can get with u-substitution. But the derivative of the inside is just 1, so you can check yourself that if  you take the derivative of this, you get 1 over the inside, 1 over 1 plus x,  but then the chain rule just has you multiplying by 1, so it stays the same. So then we evaluate this at the bounds, 1 and 0,  and what this ends up getting us is the natural log at the top,  which is 1 plus 1, minus the natural log of 1 plus x at the bottom, which was 1 plus 0. The natural log of 1 plus 1 is of course ln of 2,  and then we're subtracting off the natural log of 1, which is 0. So, the proper answer here comes out to be the natural log of 2. And it looks like 1600 of you have correctly answered that,  so well done, well done indeed. And if you wanted to kind of visualize this in your head or get some sort of gut  instinct on which of those answers seemed loosely correct,  even if you didn't know how to calculate it immediately,  the graph of 1 over 1 plus x is going to look just like the graph of 1 over x,  but shifted to the left, so it's actually going to pass through the input 0, 1,  and then we're looking for the area under here. So you know that it's going to be an area somewhere between 0 and 1,  probably filling up more than a half of it, and the natural log of 2 is around 0.69,  so that actually seems about right. But what's quite cool here is that if we say that the,  well I can just write it out again here, if I say I want to integrate  this bottom expression from 0 up to 1, which is the same as integrating  1 over 1 plus x from 0 up to 1, I know that that should be the value 2, ln of 2. Okay? but on the other hand if I picture taking my anti-derivative and getting this  whole sequence here and evaluating it between 0 and 1 what I'm doing is I'm  plugging in the number 1 which gets me my alternating sequence then I'm subtracting  off the value of 0 which when I plug it in just gets 0 so evaluating this at 0  and 1 is the same thing as integrating the bottom expression from 0 to 1 which  is the same thing as integrating 1 over 1 plus x from 0 to 1 which is the same  thing as natural log of 2 and hence that whole top thing ends up being the natural  log of 2 Very clever! Just such a sneaky sequence of manipulations that, like I said,  if you just see it plopped down, almost as intimidating because you wonder,  how on earth do you go from seeing this sequence up here to thinking about, ah yes,  if I generalize it with lots of powers of x and then take the derivatives of those  and then use a geometric series sum and then integrate that using natural log, yes,  then it'll all become obvious. And I think the answer is that that's probably  not what the problem solving process looks like. Instead, you build up a familiarity with a lot of these things,  like derivatives of polynomial terms, and then you build up  familiarity with other things, like derivatives of natural logs. And the more familiarity you have with a lot of different pieces of math,  then sometimes when you see one particular pattern,  you're able to draw in your mind a connection to things that make you look like a genius. I think Euler did this all the time. If you look at some of the great discoveries of Euler,  they just come really out of nowhere. I mean the very opening thing that I talked about,  I guess it wasn't the very opening, but early on, where are we? I seem to have... The sum of the reciprocals of squares, which, somewhere in my notebook here,  we were just looking at the pages. Maybe I tore it out. Oh, yeah, there we are. Things can become a little bit of a mess over here. but if we look at this uh this long somewhere we're taking one over one  squared one over two squared and equals pi squared over six the way that  Euler found this um I mean it involves this very strange thing where you  start looking at an infinite product associated with sine of pi times x And if you think of it as starting with this sum and then dreaming up out of your head  an infinite product associated with sine of pi times x,  or it might have been cotangent of pi times x or something like that,  it really does seem like it came out of nowhere. but in general I think you build up these bits of familiarity with different pieces  and then once you see something like Euler seeing that basel problem sum or someone  seeing this alternating harmonic sum you're able to use those connections to kind of  make yourself look smarter than you actually are which is fun and if nothing else it  helps motivate the idea of just being playful with your calculus and being playful  with your math purely for the motivation of exposing yourself to more patterns and more

================================================================================
VIDEO ID: cEvgcoyZvB4
TITLE: Logarithm Fundamentals | Ep. 6 Lockdown live math
URL: https://www.youtube.com/watch?v=cEvgcoyZvB4
PUBLISHED: 2020-05-05T20:36:51Z
STATUS: SUCCESS
================================================================================
... you you you you you you you you you you you you you you you you you you you you you you  you you you it ends up looking like this, you know,  classic exponential curve that curves upward and I can sometimes make it hard to see  where it's going or what the overall pattern is so a common trick is to say instead of  looking at this y axis that increases linearly as in here I'm going from 5k to 10k,  10k to 15k, 15k to 20k each step is additive, we're adding 5000 instead use a y axis  where each step is multiplicative so you're going from 10 to 100, 100 to 1000,  1000 to 10, 10,000 all of these are increases by multiplying by 10 and what you can say  is the y axis is now plotting not the total number of cases but the logarithm of the  total number of cases and this actually makes it kind of easier to see on a plot if you  wanted to project out what that trend would do and, you know,  it's a little bit of a naive model to say oh it's going to grow exactly exponentially but  in the early phases of something like this that is what it is so I kind of fast forward  in the animation I made for that video and what's interesting is if back then I think I  posted it on March 6th if you just found a line of best fit and you stretched it out and  you said when is that line going to cross a million which because the y axis is growing  with multiplicative steps each time that you step up you're multiplying by 10 so even if  it might seem like the 20,000 cases or so that it was back then is very far from a  million you know when you understand logarithmic scales it actually didn't seem that far  it was only 30 days away if you naively just drew out that line and in fact fast forward  to around April 5th which is when that would have predicted we hit a million cases  outside China that's pretty much the day that it happened I think plus or minus a day but  I don't remember exactly but it was right in that neighborhood because I remember  thinking wow it was kind of a naive model for the video to even use and it's shocking  that it matched so exactly thankfully since then the growth has stopped being exponential  so if you look at it on a logarithmic plot instead of going up in a straight line it  starts to taper off but point being any time that you're coming across something in  nature or even in a man-made construct where what's natural to think about are  multiplicative increases logarithms come in to help you so let's go ahead and think about  what these actually are how are they defined and actually there was a question asked on  Twitter right before we started that I think hits this very perfectly so Max 182 asks us  additions inverse is subtraction multiplications inverse is division but I never truly  understood if exponentiations inverse was nth rooting or logarithms if either one could  be you know if either one could really be called that way can they that is such a  fantastic question Max and I think it comes down to the fact that with addition and  multiplication you're not I'll just draw it out for you actually this is going to be  easiest if we have some kind of exponential relationship let's say 10 to the power 3 is  equal to 1000 there's three different numbers at play here we're showing a relationship  between the 10, the 3 and the 1000 and aside from writing it with an exponent there's two  other ways we could write that same relationship we could also say that the cube root of  1000 is equal to 10 this is asking 1000 what number raised to the third is equal to 1000  that's sort of what the cube root is asking and another way that you could phrase the  exact same thing is to say the log base 10 of 1000 is equal to 3 okay three different  notations the same exact relationship a while ago I made this video about an alternate  possible notation that would center in the idea that you think of this relationship  between the three numbers with a triangle where you'd have our 10 sitting down here the  power sitting at the top 10 to the third and the thing they equal sitting to the lower  right and whenever you want to talk about a function or an operation between two of these  numbers you indicate which one of them you're leaving out so to write 10 cubed we would  include the 10 on the lower left the 3 on the upper right and then we leave out that  bottom one so this is indicating that we're taking a power 10 cubed for that radical what  you would say is we know what's on the bottom right something to some power equals 1000  we even know what the power is something cubed equals that 1000 but the thing we don't  know is on the bottom left that is the sense in which radicals are an opposite of  exponentiation where if the thing you don't know instead of being on that bottom right is  on the bottom left but what logarithms are it's an inverse in another sense because what  it's saying is in this triangle relationship we know the base,  it's 10 we know the power that it should be 1000 but the thing we don't know is what's in  that exponent so to answer your question maybe even more briefly we could say that 10 to  the x the inverse of that the inverse is the log base 10 you know,  of y of some other variable whereas if you're taking x to the 10th some unknown raised to  a power the inverse of that is going to be the 10th root of some other value and on the  triangle it's basically asking which of the things do we consider to be a variable so are  you considering that lower right to be a variable quantity are you considering that top  to be a variable quantity and what is the unknown but I really liked this idea of making  explicit how we have three totally different notations for the same exact fact one of  them you're using relative positions of the numbers one of them we introduce a new symbol  this radical and one of them we introduce a new word,  log so these three syntactically different ways to communicate the same idea seemed wrong  and so I made this video about an alternate possible notation and while I don't  necessarily think that oh we should teach logarithms with this triangle because  convention is what it is so it's better to start getting people used to the usual  expression what I do like about it and starting off with it is when you see and think  about this triangle it's really emphasizing that what the log wants to be is that  exponent every time that you see log of some value you should think in your mind okay  whatever this number is it really wants to be an exponent it wants to be an exponent and  we'll see more of what that means as we go on okay so every time you see a log it wants  to be an exponent this value three and more specifically it should be an exponent sitting  on top of whatever that base is now in terms of convention for the first part of this  video I'm just going to be using log without a base written on it to be the shorthand for  log base 10 because log base 10 will be the most intuitive thing out there you should  know that often in math the convention instead is that log without anything might mean  log base e there's also another notation for that ln for natural log we're going to talk  all about the natural log next time so don't worry too much about that right now and  there's also yet another convention often if you're in a computer science setting log  without any added sugar to indicate what it is defaults to meaning log base 2 so this can  sometimes be a source of confusion but it basically depends on what discipline you're in  in math, not moth, math people really like a base of e we'll see why next lecture in,  I don't know, I'll say engineering but really it's anything where you want good intuition  with our normal base 10 number system log means log base 10 and if you're curious often  in computer science settings log base 2 comes up all the time so like I said,  in the back of your mind if you're trying to think of some of these properties just  resting on the idea that log counts the number of zeros at the end of a number that can  get you a really far way so we're going to start going through a couple of these  properties and I want to do this just with a set of practiced examples so we'll  transition away from the poll and this time to the first proper question and the question  asks you which of the following is true a. the log of 1000 times x is equal to 3 times the log of x and  remember we're using the convention that it's base 10 log b. log of 1000 times x equals log of x cubed c. log of 1000 times x equals 3 plus the log of x d. log of 1000 times x equals 3 to the power of log of x and e. none of the above and remember like I said earlier we should fully expect that all of  those people at the beginning who said they understand logs well they're going to be  answering immediately, they're going to be answering correctly but if you're someone who  doesn't, don't let that intimidate you when you're looking at a problem like this one  what I would encourage you to do is just plug in various powers of 10 and think in terms  of the idea that the log function counts the number of zeros so I'll give you a little  moment to think about that great ok so I'll go ahead and grade it and as always if that's  faster than what you're comfortable with know that it's only because I want to proceed  forward with the lesson so in this case the correct answer comes out to be log of 1000  times x is the same as taking 3 plus the log of x and now let's think about that for a  moment and like I said when you're just getting started with them I think the best thing  to do is just be comfortable plugging in various numbers and the best numbers to plug in  are the ones that are already powers of 10 so if you're asking something like log of 1000  times x well I don't know, let's just plug in something for x log of 1000 times 100 ok,  well we know how many zeros are going to be in the final answer here well 1000 times 100  is 100,000 we already intuitively have this idea that when we multiply 2 powers of 10  we're just taking the zeros, the 3 zeros from that 1000 the 2 zeros from that 100 and  we're putting them next to each other so it should be 5 total zeros but if you really  reflect not just on how did the number turn out but why did it turn out that way it was  the 3 zeros from that 1000 plus the 2 zeros from that 100 which we could also write by  saying the number of zeros in 1000 plus the number of zeros in 100 so this idea that a  logarithm of the product of two things is the sum of the logarithms of those two things  in the context of powers of 10 that's just communicating what's already a super intuitive  idea for a lot of us if you take 2 powers of 10 and you multiply them you just take all  of their zeros and kind of cram them onto each other so the way I've written things out  here is actually indicative of a slightly more general fact which is going to be our very  first property of logarithms which is that if we take the log of A times B it equals the  log of A plus the log of B now anytime you see one of these logarithm rules if you find  yourself squinting your eyes or you're a little bit confused by how to remember it just  plug in examples I'm being redundant, I'm saying this a lot but it's because I think it's  very easy to forget once you're swamped in the algebra itself and you're sitting on some  kind of test and it's just got a lot of symbols to remind yourself you are okay to just  plug in some numbers that's a fine thing to do and often it's a great way to yield  intuition so in this case, saying log of A times B and breaking it apart we could just  think, oh, that log of 100 times 1000 which is 5,  there's 5 zeros in it and it breaks up in terms of the number of zeros in each given part  great, wonderful so carrying that intuition further,  let's try another practice problem and again, if you know it, great,  you'll be able to answer it fine but maybe think,  not just what is the answer but how would I explain this answer to someone or how would  I try to get a student to come to this answer on their own without me having to tell them  what the answer is so there's two potential audience members there's those who are  interested in the lesson itself and then those who are interested in the meta lesson so  our question asks, again, which of the following is true A,  log of x to the n is equal to n times log of x B,  log of x to the n is equal to log of x to the power n C,  log of x to the n is equal to n plus log of x or D,  log of x to the n is equal to log of n times log of x or none of the above so again,  take a moment to answer as people do answer, we'll start to see them roll in and if you  are struggling to think of where to even start just plug in some powers of 10 and see  what intuition you might get from it you alright,  so it looks like just about everybody is landing on one particular answer hopefully it's  the right answer, like I said, all to be expected so let's go ahead and see if our  majority ended up correct and they did so the correct answer here is A,  which it looks like 4000 of you got congratulations,  telling us that log of x to the power n is equal to n times log of x so again,  let's say that you're trying to teach this to someone or if you're trying to come to  grips with what it means yourself I think a fine place to start is plugging something in  and in this case, for log of x to the power n let's just try it with 100 to the power 3  and you could try it with other ones to see if the patterns you're doing actually work  but if you're thinking it through not in terms of simply seeing what the answer is but  trying to think of why the answer turned out that way sometimes one example will do  because 100 cubed, we can think of that as taking well,  that's 3 copies of 100 I'm taking 3 copies of 100 and when I multiply all that out and I  think of log as counting the number of zeros we say, oh,  it's going to be some number that just has 6 zeros on it that's what it means to take 100  times 100 times 100 I can just think of grouping all of those zeros together to get a  million so this number is going to be 6 but if we think actually why was it 6 not just  that's the number of zeros inside the million where that 6 came from is that we had 3  copies of that 100 and each of those 100 had 2 different zeros so that way it's a more  general way you can think about it where if instead of taking 100 cubed we were looking  at 1000 cubed or 1000 to the n or x to the power n you can think that it's whatever that  value of n was the number of copies we were multiplying in times the number of,  well let's see, it's not x times the number of zeros that were in whatever we substituted  for x which in this case was 100 so if instead I had taken something like log of 10,000  to the power n this would be the same as taking n copies of that 10,000 counting the  number of zeros in each one of them which is 4 so it would be n times 4 and of course the  general property that most of you correctly answered is that you have this lovely little  effect where when you see the log of something raised to a power that little power hops  down in front of it and you just have log of what was on the inside now one of the maybe  most important implications of that I don't know if you'd call it an implication or if  you'd call it a restatement of the definition if I'm taking log,  and I'll just re-emphasize it's base 10 of 10 to the power n we can kind of think of that  little n as hopping down in front and it becomes n times the log base 10 of 10 which is  of course 1 this expression you can think of as either counting the number of zeros at  the end or more generally it's asking 10 to the what equals 10 and the answer is simply  1 which is very reassuring because another way that you could go back and just read this  original expression is saying 10 to the what equals 10 to the n oh well the answer is n  now with every given logarithm property that we have so in this case we just found one,  log of x to the power n involves that n hopping in front there's always going to be a  mirror image exponential property and that's another way that we can help to get  ourselves a little bit of intuition for these so let me just cover up some of the future  properties we're going to get to here try to hide where we're going what we just found,  raising something to the n that hops in front this corresponds to the exponential  property that if I take 10 to the x and raise that whole thing to the power n that's the  same as taking 10 to the n times x and this gets us to another intuition that you might  have for logarithms which is they kind of, they're like exponentiation turned inside out  and here's what I mean by that the thing sitting on the inside of the log,  if I'm taking log of a you should be thinking of that as the whole outer expression for  something that's exponential in this case the a, the thing on the inside,  corresponds to 10 to the x the output of the function whereas the entire thing itself,  the log of a corresponds to what's on the inside over here just what's the exponent of  the 10 so wherever you see a log expression here,  you should be thinking that plays the role of an exponent on the right side and every  time you see an exponential the entire 10 to the x expression,  the whole outer component on the right side that corresponds to something that's sitting  on the inside of one of the logs and we saw this above,  right the idea that when we're multiplying on the inside,  that's adding on the outside well if logs kind of turn exponentials inside out that's  telling us that multiplying on the outside, multiplying the outputs of the function is  the same as adding on the inside because each of these logs,  like log a and log b is playing the role of the x and the y in the expression on the  right okay, so with that, let's keep playing let's just do a couple more of these and see  how many of these properties that we can build up an intuition for so this last one,  very nice, thinking of exponents hopping down the next one is something that might look  a little bit weird to those who are not necessarily familiar with logarithms but again,  plug in some numbers to gain some intuition for it and we'll give it a little bit more,  a moment to pull up which of the following is true? log base a of b is negative log base b of a log base a of b is 1 divided by log base b  of a log base a of b is 1 minus log base b of a log base b of a is log base a of 1  divided by b or none of the above so it's asking what happens when we swap the base with  what's sitting inside of the logarithm and I'll just give you a minute or two to answer  that so let's do a couple more okay, so it seems like answers have kind of stabilized  out there so let's go ahead and grade things and in this case,  the correct answer of the choices we have comes out to be b that the log base a of b  involves taking 1 divided by the log base b of a again,  let's think this through both in terms of an example and then in terms of a more proofy,  systematic reason why it should be true so if we're swapping our bases let's just start  off with our good old friend log base 10 and let's plug in a nice power of 10 like 1000  counting the number of zeros, we get 3 so let's try swapping the bases and see what this  should mean log base 1000 of 10 okay, well what is this asking? maybe you think of drawing the little triangle saying something like  we know 1000 to something is equal to 10 1000 to the what equals 10? well, if 10 cubed is 1000 that is the same thing as saying 10 is equal to 1000 raised  to the 1 third doing the inverse here involves the multiplicative inverse of the  exponent and the way that pans out is that it looks like 1 divided by 3 and that 3  corresponds to the log base 10 of 1000 it's 1 divided by the log base 10 of 1000 so  more generally, you might guess based on this single example that when we swap the  base with what's on the inside it corresponds to taking 1 divided by what's on the  outside there and again, you can think this through in terms of looking at the  corresponding exponential rule now what happened to my lovely little log and exponentials? wonderful so, again let's hide where some of the things some of the other properties  that we'll get to here and I'll keep it in the same order I had it before here I was  thinking that having it pre-written could keep me a little bit cleaner than usual but  maybe it just involves playing this weird game of paper cutting shuffling around so what  we just found, log base b of a if you swap those,  it's the same as dividing by 1 what this corresponds to,  off an exponential land is if you take b to some power and say that that equals a that's  the same statement as saying that a to the inverse of that power equals b again,  it's kind of helpful to take a moment and think of the logarithms as turning things  inside out the expression log base b of a is playing the role of that x and the  expression log base a of b is playing the role of whatever sits on top of the a and then  symmetrically, the whole expression b to the power x is playing the role of the inside  on the left, it plays the role of the a and the whole expression,  a to the power of something plays the role of what's sitting inside the log base a there  so you can see just by plugging in some examples and by corresponding it to the  exponential rules we can already think through three different logarithm rules which if  they were just handed down as pieces of algebra to be memorized you know,  you could memorize them but it's very easy for them to kind of slip out of your head  and it's also very easy to get frustrated by the task at hand but you might want to  remind yourself that the reason we care about these sorts of things is understanding  the rules of logarithms helps us do math in contexts where it's like a virus growing  where from one day to the next, from one step to the next,  things tend to grow multiplicatively understanding the rules of logarithms helps you to  get a better feel for that kind of stuff so before we do a nice real world example of  what that can look like let me just do one more quiz question in this vein to ask about  properties of logarithms one last one before we transition to a little bit of a real  world example get rid of what we had here and now, which of the following is true? log of a plus b is the same as log of a plus log of b log of a plus b is equal  to log of a times log of b log of a plus b is equal to one divided by log of  a plus log of b or log of a plus b is equal to one divided by log of a times  log of b or none of the above ah, and now we don't have as much consensus, do we? very interesting we've got a horse race between two so I will give you a moment  to think this through while people are answering actually I have a little question  for the audience so you know I was just talking about how we might think in terms  of multiplicative growth and that doesn't just have to be powers of 10 we could  also do something like powers of 3 or if you're going from 1 to 3 to 9 to 27 to  81 all of these we could say that the log base 3 of these numbers just grows in  nice little steps so log base 3 of 1, 3 to the what equals 1? the answer is 0 In general the log of 1 no matter the base will be 0. Log base 3 of 3, 3 to the what equals 3 is 1 Similarly log  base 3 of 9 is 2 You might wonder what my question is,  but it'll help to draw all of these out and For my own pleasure here. Let me just write out one more log base 3 of 81 is 4. Now I've heard that ostensibly if you ask a child's let's say  around like 5 or 6 years old What number is halfway between 1 and 9? Okay, you say what number is halfway? Their instincts for how to answer are Logarithmic whereas our instincts tend to be more  linear So we often think 1 and 9 you've got a bunch of evenly spaced numbers between  them 2, 3, 4, 5, 6, 7, 8 And if you go right halfway in between you'll land on 5 But  if you're thinking in terms of multiplicative growth where to get from 1 to 9 It's not  a matter of adding a bunch of things But you're growing by a certain amount you grow  by a factor of 3 then you grow by another factor of 3 supposedly a kid's natural instinct  lines up with saying 3 and supposedly this also lines up with If you have anthropologists  studying societies that haven't developed Counting systems and writing in the same way  that modern societies have they'll answer 3 for this So my question for the audience  if any of you watching right now have access to a small child Let's say in the range  of 5 years old See if you can go ask them What number is halfway between 1 and 9 and  if you can let us know on Twitter what the What the child says what their actual answer  is? Because I I don't know why I'm just a little bit  skeptical of whether that Actually pans out in practice. I understand this is not a super scientific way to do it asking people watching a  YouTube live stream to Survey their own children and then tweet the answer but for my  own sake it would be interesting to see some kind of validation there Back to our  question. This is the first one that doesn't seem to have a huge Consensus in one direction,  but let's go ahead and grade it to see what the answer turns out to be Great okay,  so 2400 of you correctly answered that it's none of the above okay that log of a plus  B doesn't satisfy any of these nice properties And in general unless we're going to be  working with Certain kinds of approximations especially when the natural log comes into  play we might talk about this next time Adding the inputs of a logarithm is actually  a very weird sensation It's a very weird thing to do and to get a sense of that weirdness  plug in some powers of 10 If I ask you log of a plus B What you might start thinking  is okay? Let me just plug in some examples like 10,000 and 100 and I asked myself if I  do this zero counting function of what's in that input how many zeros are in it? But it's weird because when we add 10,100 well,  we're no longer at a clean power of 10 and okay That's fine. You know often you're taking logarithms of things that aren't clean  powers of 10 but it becomes very strange to ask how you express this  in terms of log of 100 which was 2 and log of 10,000 Which was 4? because if you look at log of 10,100 it's asking 10 to the what is equal to 10,100  you might say, I don't know, it's going to be a little above 4 because it's kind of  close to 10,000 so the best you might guess here is oh this is going to be something That's kind of like The log of 10,000, but that just feels like a coincidence based on  the two numbers that we happen to put in There's not a nice systematic reason coming  there, so maybe you guess oh if the numbers A and B are very different It's kind of close  to Whatever the maximum of them is But it's very bizarre and most importantly for the  sake of the quiz If you just look at the options that it's giving you if you try this out  with any particular numbers You'll find that none of those actually work So all is good  sometimes you get something that looks like it's going to be a nice property But it  doesn't end up being a nice property, and I also think that's important rather than just  finding yourself Only working with the various You know log of A times B or log of X to  the power N these things that have a nice rule Sometimes you're out in the mathematical  wild you're working on some problem You have a logarithm expression And it's adding  things in the input and you want to be able to Have familiarity with the fact that that's  kind of weird that you're not going to be able to simplify But if you you know if you  hadn't thought about that before you might wonder Oh is there just some formula that I  haven't seen before So with all of that let me go ahead and take a couple questions from  the audience Before we transition to a different sort of example So it looks like Uma  Sherma asks Can can the base be zero? That's an interesting question okay? Can the base of a logarithm be zero? Well in terms of our triangle we might think of that as saying You know zero to  some kind of power X is equal to some other value Y Right this is something that  we could write either by saying zero to the X equals Y Or we could write the  same thing by saying log base zero of Y Is equal to X zero to the what equals X? Now the issue here is that zero to anything ends up being zero right so? If we're just going to be thinking of log base zero of Y for any other input Y. You know you want to input something like one or two or pi Anything you might  want you're asking the question zero to the what is equal to one or two or pi? Or whatever number you might have there, and there's just not going  to be an answer so at best You could try to say oh yes log of zero. It's a perfectly valid function It's only defined on the input zero,  but even then you'd have trouble Trying to finagle what you  want there because saying zero to the what equals zero. It's like anything anything applies to it So your arm is going to be twisted  behind your back However you want to make that work and it corresponds to  the fact that the exponential function with base zero Is entirely zero it  doesn't it doesn't map numbers in a nice one-to-one fashion on to each other? So that's a great question can you have a log base zero now back to  the idea of where these things come up in the real world One one  example I kind of like is the Richter scale for earthquakes so the  Richter scale Gives us a quantification for how strong an earthquake is okay? And it can be anything from very small numbers up to very large  numbers like I think the largest earthquake ever measured And this  is just a chart that comes from Wikipedia was a nine point five okay? And to appreciate just how insane that is it's worth looking at the relationship  between What these numbers mean and then something like the equivalent amount of  TNT some sort of measure of how much energy there is in it And then what we can  try to do here is see if we can get an expression for the Richter scale number in  terms of the amount of energy and Why logarithms would be a natural way to describe this? So the key to focus on is as we're taking steps forward how much do things increase? So for example if we go from two Well in this case it doesn't show us where  three is so maybe we think of Taking a step from two up to four which is kind  of like taking two steps What does that do in terms of the amount of energy? Well it looks like it takes us from one metric ton of TNT Which is I guess a  large bomb from World War two and it takes us up to a kiloton a thousand times  as much Okay Which is a small a small atom bomb so just two steps on the Richter  scale Going from an earthquake of magnitude two to an earthquake of magnitude  four takes us from large bomb from World War two Up to the nuclear age, right? so that is noteworthy and The first clean step that we get is going from four  to five at least in terms of what this chart is nicely showing us And evidently  a single step up from four to five Corresponds to going from one kiloton to  32 kilotons And that was evidently the size of the city destroying bomb that  land on Nagasaki So this is maybe one thing that can be counterintuitive about  logarithmic scales if you're just hearing in the news the difference between  oh there Was an earthquake that was a 4.0 versus an earthquake that was a 5.0. It's easy to think yeah four and five Those are pretty similar numbers But evidently  in terms of TNT amounts that corresponds to multiplying by 32 to get from one to the  next And going from two to four was evidently multiplying by about a thousand okay,  and the only reason that's bigger is because here our chart wasn't showing what three  was so we were taking two steps and You can verify for yourself that if you take a  step of 32, and then you multiply by another 32 That's actually pretty close to a  thousand So the idea that additive steps on the Richter number correspond to  multiplicative steps in the TNT Seems to suggest that something logarithmic is at play  here, and it's a little interesting to just keep going here and say How how much does  this grow partly? Because of the the world phenomena. It's describing. Yes, not a huge surprise that as we take another step It's  multiplying by about 32 again But raining that in to our intuitions. That's the difference between 32 kilotons a small atom bomb And then one megaton  which we might think of as not small atom bomb Nagasaki atom bomb Which I guess  is 32 of the Nagasaki atom bombs For one megaton that is evidently the magnitude  of the double string flat earthquake in Nevada, USA 1994 I didn't know what that was. Thanks Wikipedia in terms of frequencies by the way I Also looked these up  evidently ones that are less than two those happen all the time There's like  8,000 of those per day, but as soon as we're in the realm of atom bombs things  like 3.5 and 4 Those evidently also happen quite frequently somewhere on the earth. There's around 134 of those happening somewhere every day who knew But as we get even  more intense into this 5 and 6 range which you know we're well above the atom bomb scale  now we're only merely at around 2 per day and You know I'm sure that a geologist could  come in and explain why we all shouldn't be super worried about the fact that there's  two atom bomb equivalent Disruptions to the Earth's crust happening every day,  but presumably it's particularly rare for those to be concentrated on some Some spot like  a city where what lots of people live Now just verifying that I thought that each step  involves a growth of 32 Let's look at what the step from 6 up to 7 looks like and here  It's giving us lots more examples in between maybe giving the illusion that that's a  bigger step than it actually is and indeed That's the difference between 1 megaton and  32 megatons, so that's multiplying by 32 One of the things I found most interesting on  this chart by the way was Look at how far we have to go before we get to the largest  nuclear weapon that's ever actually been Tested This was height of the Cold War the Tsar  bomb That was 50 megatons, and I believe they actually had original plans to have a 100  megaton bomb but talked themselves down from that 50 megatons we're talking start off at  that 32 kilotons of the Nagasaki bomb Multiply by 32 to get a megaton multiply by another  32 Right so we're talking about a thousand times the strength of the World War two ending  explosion And you're still not at the 50 megatons of what humanity is capable of And that  is evidently you know the Java earthquake of Indonesia so 7.0 is not just a little bit  bigger than 6.0. It's a lot bigger and The point here of course is just that when you have a scale giving  you multiplicative increases It's worth appreciating that what look like small steps  Can actually be huge steps in terms of the energy implied or the absolute values implied  here So it I mean when we're thinking about the fact that there was ever a 9.5 That  actually seems absurd given that it's only in the 7.0 range that we're talking about  the largest thermonuclear weapon ever put out And this is indicative of one area where  logarithms tend to come about it's When humans want to create a scale for something  that accounts for a hugely wide variance in how big things can be So in the case of  size of earthquakes you can have things from what happens Just all the time around the  earth the size of a large hand grenade And you want that to be on your scale and  something to think about ranging all the way up to you know the largest disruption that  we've Seen in human history right and in order to have that in a way that you're not  just Writing a whole bunch of different digits in your numbers for one case and a whole  bunch of different a smaller number of digits For your number in another case It's nice  to take logarithms And then just put that on a single scale that basically puts squishes  those numbers between 0 and 10 You see something very similar going on with the decibel  scale for music that one actually Works a little bit differently where every time you  take a step up of 10 decibels that corresponds to multi multiplying by 10 So rather  than a step of 1 multiplying by 10 It's a step of 10 that multiplies by 10 so that kind  of makes the math of it a little bit screwy But the idea is the same that if you're  listening to a sound that's 50 decibels for 60 decibels It's a lot quieter in terms of  the energy being transmitted and going from you know What would it be 60 to 70 or 70  to 80? Those steps you know from 60 up to 80 that involves multiplying the amount of energy per  square area By a factor of 100 so every time you see a logarithmic scale Know in your  mind that that means whatever it's referring to under the hood grows by a huge amount  This is again why we saw a lot of logarithmic scales used to describe the coronavirus  outbreak so How might you describe a relationship like this where every time you grow the  Richter scale number by 1 you're multiplying by 32 Well,  we could think in terms of a log with base 32. I Could say if I take the log of I'm just gonna call our the number for the Richter scale. I might think of this as log base 32 and That's going to correspond to No, no,  no, I'm doing this wrong That's not the thing that's logged We take the log  base 32 of the big number of the the TNT number something that was like You  know one Gigaton or one megaton It's one million Tons The log base 32 that  should correspond to the Richter scale number But there might be some kind of offset. So we might say that there's some kind of Constant s that  we're adding to this Richter scale number and this expression  is exactly the same Excuse me for going off the bottom there. This expression is exactly the same as saying 32 to the power of some offset times our  Richter scale number, which is the same as taking you know 32 to that offset which  itself is just some big constant times 32 to the Richter scale number so you might  think of this as just being some constant Times 32 to the power of the number you see  So this way of writing it really emphasizes the exponential growth of it that if this  is what corresponds to the TNT amount that you see as You increase that R step by step  you're multiplying by 32 But another way of communicating the exact same fact is to  take the log base 32 of whatever that amount is Alright now the next thing I want to  talk about is how we don't always have to Worry about how to compute logs of different  bases and it's a little weird here that we were talking about log base 32 I referenced  earlier how mathematicians really like to have a log with base e computer scientists  really like to have a log with base 2 and it turns out for Computational purposes or  for also thinking about how these things grow if you have one Log if you're able to  compute one type of log whether that's base 10 base 2 base e you can compute pretty  much anything else That you want Okay now to get our intuitions in that direction,  let's turn back to our quiz and go to the next question and I believe that this question  is the most I don't know. This is this is a halfway reasonable question. This should be nice This is just going to get us prepared to translate from base 2  contexts to base 10 contexts and it's also a good intuition for understanding powers  of 2 to have in general The relationship that it has with powers of 10 because it's  this lovely kind of coincidence of nature that these two sort of Well,  you'll see what I mean. they play nicely with each other so our question asks,  given the fact that 2 to the 10th is 1024, 1024 which is approximately 1000, okay,  so you can if you're being a little bit loose with your numbers and you're just making  approximations 2 to the 10th, basically 1000, which of the following is closest to being  true? log base 2 of 10 is approximately 0.3 log base 2 of 10 is approximately, sorry,  log base 10 of 2 is approximately 0.3 log base 2 of 10 is approximately 1 third or log  base 10 of 2 is approximately 1 third okay, which of these is closest to being true based  on the fact that 2 to the 10th is essentially 1000?  I'll give you a little moment for that log base 2 of 10 is approximately 0.3 interesting  that we've got kind of a split on this one so I'm wondering if they're going to be  numerically pretty similar or if they're going to be conceptually similar or if there's  even a difference between those two so since answers keep rolling in,  I'm going to give this a little bit more time so anyone at home watching,  hopefully you already have a pencil and paper out to be noodling through these yourself,  that is the spirit of the lectures that we're doing if you don't,  now is the time to take out a pencil and paper and see if you can think this one through  and write it out some of the problems that we're going to build to here definitely will  require pencil and paper so now is as good a time as any and if you're watching this in  the future, even if you can't participate in the live poll I really do think it's a lot of fun to kind of throw your own hat into the mix even  if it's not going to contribute to one of the numbers that you see growing on the  screen I'll give you a little bit more time here as the answers seem to continue  rolling in so now is the time to take out your pencil and paper and write it out so  now is the time to write your own paper and write it out so now is the time to write  your own paper and write it out so now is the time to write your own paper and write  it out so now is the time to write your own paper and write it out so now is the time  to write your own paper And then I'm ready to move on to the google Okay,  so I'll go ahead and grade it now and let's see how people did on this one.  So the correct answer is B, Which is that the log base 10 of 2 is around 1 third so that's good They're very  numerically similar right that It's either 0.3 or around 1 third which is 0.3 3 3 3  repeating But the question was asking which one is closest to being true,  and let's see how we can think about this so It points out that you have a power of 2  which is 1024 awfully close to a power of 10 about 10 cubed and the question is how we  can leverage this to understand something like Log base 2 of 10 or log base 10 of 2 as  we saw earlier those are just the reciprocals of each other So what does this mean if  log base 2 of 10 is equal to X? That's the same thing as saying 2 to the X is equal to 10 right. It's asking us 2 to the what equals 10 So what we have here is an  expression 10 cubed is approximately equal to 2 to the 10th so what I  might write out is we know that 2 to the 10th Instead of writing it as a 10. I'm going to write that 10 as 2 to the X Where X is the  number such that 2 to the X is approximate is equal to 10? So if that cubed is the same as 2 to the 10th This is I'll just write out  the full details the same as saying 2 to the 3 X is equal to 2 to the 10th  and Exponentiation is a nice one-to-one function,  so it's okay to just Say whatever is going on in the input if the outputs  are the same the inputs must also be the same You can't do that with every  function people seem to think you can do that with any function But you just  can't and what that means is that? X is about X is about 10 thirds, okay which Ah Great so log base 2 of 10 is about 10  thirds, so if we looked at our answers though That's not actually any of the options. We've got various things asking log base 2 of 10 being around 0.3 or 1 third so it  looks like instead we should try to re-express this as log base 10 of 2 and Well enough  what we saw earlier is that log base 2 of 10 we could also say log base 10 of 2 is Just  1 over that amount 1 over X and you can see this pretty easily by writing 2 is equal  to 10 to the 1 over X if we're asking 10 to the what equals 2 the answer is 1 over what  we just got there, so Log base 10 of 2 is 1 divided by this amount Which is 3 tenths? Which is 0.3 great So this is kind of a nice constant to think  about because there's this wonderful pattern that happens when  we're looking at powers of 2 so if I ask What is the log base 2 of? 1,000 Like we just saw it's approximately the case that 2 to the power 10 Is equal  to a thousand and because we're doing things at logs I'm just going to be writing  it in that way a log 2 of a thousand is approximately 10 Similarly log base 2 of  a million Well, let's see if we have to multiply 2 by itself about 10 times to  get to a thousand we should have to multiply it by itself around 20 times to get  up to a million and Indeed log base 2 of a million is approximately 20 It's a  little bit smaller, but this is kind of a nice approximation to have in your mind  And then similarly you'll see why I'm writing out this as a pattern in just a  moment if we wanted to go up to a billion Saying how many times do I have to  multiply 2 by itself to get to a billion This is about 30 And any computer scientist  out there who's thought about you know just how much as a kilobyte or a megabyte  or a gigabyte? they'll be familiar with the idea that powers of 2 are nice and close to  these powers of 10. Or more specifically, powers of 1000.  Now what I want to do is just write all of the same things with log base 10,  not approximately equal to, this is actually equal to 3.  Log base 10 of 1000 is equal to 3. Log base 10, well you tell me,  what's log base 10 of a million? It's equal to 3 Log base 10 well you tell me what's log base 10 of a million It's  counting the number of zeros it ends up being about 6 and log base 10 of a billion  Counting the number of zeros it ends up being 9 Now the reason I wanted to write all of  this out is to just emphasize an interesting pattern here Which is we're just growing  by these increments right as we go from a thousand to a million to a billion with log  base 2 We're stepping up by steps of 10 But when we're playing the same game with 10  we're stepping up by these increments of 3 So there's this nice relationship and in fact  for all of them to go from log base 2 to log base 10 It seems like we're just multiplying  by 0.3. So 10 times 0.3 is 3 20 we scale down by that same amount 30 we  scale down by that same amount Okay now this is an intuition  worth remembering if you have Your numbers described with one base. It's basically the same as describing them with another base,  but there's some rescaling constant Okay, and then the next question is going to  start getting us at that direction But it's going to be framed in a way that just  looks like a whole pile of algebra And again, I will encourage you to plug in  numbers if you want to to gain a little intuition for it So as our third to last  question, this will be a long lecture We have which of the following is true and  then just a whole pile of Various possible ways to combine log base C of B times  log base C of A Does that equal log base B log base B of A and rather than me  reading them out to you? I'll just let you look through them plug in some numbers I'll give you I'll  give you a meaningful time on this one because it's not it's not obvious  unless you're already familiar with logarithms and It's worth thinking through  a little bit You We have an outstanding question from the audience Which is  does the bar length of the pole use some kind of log function and healthily? It looks like Ben Eater has gone ahead and directly answered in the form of the code  involved where the chart max is mapped up is the raising 2 to the power of a Ceiling  of a log base 2 of the maximum attempt count which I think is to say unraveling If  you're looking at the maximum number I'm not I'm not great at Vanna whiting this thing  if you look at the maximum number in our poll It's asking what's the log base 2 of that? so as it crosses different powers of 2 then that rescales it and Yes,  yes is the answer what a fantastically apropos question Thank You Karen All right,  so answers are still rolling in and I think like I said I just want to give you  some more time to think this through because it's looks like a big pile of algebra  plug in some numbers to see what seems to work well and See which answer fits You  You You Okay, so even if you are still thinking about it I'm gonna go ahead and  grade it here and then start talking about Why it's true and then also why we should  care why this is an operation that actually tells us something so the correct answer  which it looks like around 1700 of you got congratulations is Log base C of B times  log base B of A is equal to log base C of A great Now that's just a big ol pile of things. Why would that be true? How do we think about it? Now phase one, like I said, we might plug in an example,  but let's try to actually think about why the example holds. So let me Pull out we've got this as one more of the log rules This is just  repeating the end what the correct answer turned out to be where we've got an  expression for Log base C of B log base B of A and this ends up being log base  C of A It's gotten rid of the B's which is kind of interesting so Some examples  you might plug in here would be things like let's use a different color. Let's use green Instead of C. I'm gonna go ahead and plug in 10 Log base 10 of 100 which is kind of asking  how many times does 10 go into a 100 in a multiplicative sense how many times  do I multiply 10 by itself to get to 100 where the answer is 2 and then log of  100 of Let's plug in another power of 10 It'll be nice if it's also a power of  100 So I'll do a million So This one is asking 10 to 100 to the what equals a  million How many times do I multiply a hundred by itself to get to a million? How many times does a hundred go into a million? Phrasing the same thing 10 different ways now the claim is that this is  the same thing as taking log base 10 of a million That if I ask how many  times does 10 go into 100 and how many times does 100 go into a million? Multiplying those should give me the answer to how many times 10 goes into a million  now just checking the numbers this certainly works 10 goes into a hundred two times  100 goes into a million three times in a multiplicative sense in that a hundred  cubed is equal to a million and Indeed how many times does 10 go into a million? well six Now we could think of this property in terms of the corresponding  exponent rule which is going to look a little bit stranger But it's actually  just saying the entirely the same thing So here we're if we have a base of C  and a base of B And we're trying to relate those to each other the whole statement  is equal to saying that um suppose that B to the X is equal to a Got some number B. You raise it to some number X and equals a suppose  It's also the case that C to the Y equals B. Those two together are the same as saying C to the XY equals a Now that's kind  of a mouthful to say out loud But if you plug in some numbers to translate what  all of that is really saying in the context of the example we just did Saying  if you can write a hundred is ten squared and if you can write a million as a  hundred cubed Well that lets you write a million in terms of a power of ten Okay,  so sort of asking this question How many times does one number go into another? but letting you layer it on top of each other. Now if we rearrange that expression,  we get what is probably the second most important of all of our log rules.  The most important is this top one, that when you multiply the inputs,  you add the outputs. But the second most important,  which is known as the change of base formula, lets us write that if you want the log base  b of some value a, then for whatever c you want,  it doesn't actually matter what log you have in your pocket. If you use that other log,  and you take the log c of a, divided by the log c of b, that gives you log base b of a.  So just as an example here, what this would look like,  is let's say I wanted to be able to compute log base 100 of things. I just really want to.  It's not a button on my calculator, but I would love to be able to do it.  And I want to do it with an input like a million.  Well even if I don't have the log base 100 button on my calculator,  what I can do is say I'll use the log base 10 button and evaluate what's on the inside  here, which at least positionally it's kind of above the 100.  It has a higher altitude as we write it. So this can line up with the notation a little  bit, that it sits on the numerator. And on the bottom,  I use the log base 10 button that's in my calculator on the base, on the 100.  And then I can evaluate both of those and it'll give me the answer.  In this case it gets you 6 divided by 2, which will be 3.  And if we really just think through what this is saying,  I know I've said it many different times, but it's a convoluted enough way to write  things, but an intuitive enough fact that I think just coming at it from a bunch of  different angles can be important. Because like I said,  this is probably the second most important log rule.  We're asking how many times does 100 go into a million? In a multiplicative sense,  how many times do I multiply by itself? But division is asking that same question in an additive  sense if I say how many times does the log of 100 go into the? Log of a million that's what division means it's saying how many  times do I add this bottom number to itself to get to the top? But anything additive in the logarithm realm is the same as anything multiplicative  in terms of what's inside the parentheses So both of the left-handed side and  the right-hand side are just saying how many times does 100 go into a million? but going about that in different ways. So this is extremely nice because it  actually lets us compute things. Next time we're going to talk all about the  natural logarithm, which is log base e, often written ln. And turns out,  this is much easier to compute. There's nice math behind it such that if you want  to come up with an algorithm that your calculator can use,  it's actually a lot easier to think of log base e of numbers.  So any time that you need to, go to some kind of calculator. I don't know let's say we popped over to something like Desmos Always happy to have  as a friend, and you wanted to compute log base 10 of Some number you know let's say  we're doing log base 10 of 57 and it looks like that's you know it should make sense. It's between 1 and 2 because 57 was between 10 and 100 What's going on under the hood? How is it actually figuring this out? It's going to use somewhere in there a change of base formula Which is going  to be that the natural log of 57 divided by the natural log of 10 is the same  thing These are two different ways of writing it so if you know one logarithm. You know all of the logarithms okay, and Well,  let's just use that fact to answer one more of our quiz questions And this will be the  second to last quiz question, so thank you all for sticking it through I think we will be  I Think you'll be pleased by the last question because the last question will actually be  like a fun Problem-solving puzzle II thing and it'll involve a lot of what we've used up  to this point kind of a culminating thing So before that though just to make sure that  we've got the instincts of Change of base down. What do we have? Use the approximation that log base 2 of 10 is around 10 thirds so  using that approximation Which of the following is approximately true? Log base 2 of X is about 10 thirds of log base 10 of X Log base 2 of X is log  base 10 of 10 thirds of X log base 2 of X is log base 10 of X to the power 10  thirds or Log base 2 of X is 10 thirds times the log base 10 of X and finally  none of the above So I'll give you a moment to think about that you might want  to think to the chart that we were drawing earlier and thinking about log base  2 and log base 10 as we're looking at powers of 1000 and how each of those  grows that can leverage some of The intuition but I'll let you think about it. Stop talking You While answers are rolling in it looks like a number of  people have been asking on Twitter about Basically how complex numbers play  into this so you know we've got Jamil asking What if the base is imaginary? We've got Kalkan asking, what about complex bases?  Wouldn't z to the x is walking around the spiral? Wouldn't it hit every complex number?  Well, it won't hit every complex number. But your instinct that it's hitting multiple  things is pretty spot on. Doesn't make sense to talk about logs with imaginary numbers  by Nitya. So to all of these questions, It's actually a very Nuanced question the short answer is yes  complex logarithms absolutely exist But each one of them has  multiple different outputs so a good a good analogy here is how? If we have the square root function if I ask something like the square root of  5 You know we have the convention that you always do the positive amount,  but that doesn't quite feel honest It feels like the right answer is to specify  that there's two different outputs for the square root function two solutions  to x squared equals 25 And this is actually true in complex numbers as well  one of the things we talked about in a complex number lecture Was that you can  take the square root of I and you actually get root 2 over 2 plus root 2 over 2 I? But that there's two solutions you can do plus or minus this value and so you could  say that the square root function Isn't a function,  but it's a multi-valued function It always has two different outputs now something  funky happens when we have exponents at play So if you're just like someone who  hasn't seen this stuff don't worry. We talked about it in previous lectures I'm obviously jumping around on the  complexity level a lot here where if in lecture 5 I'm talking about Like  Euler's formula with complex numbers and compound interest and like how that  plays into physics and then lecture 6 We're back to the basics of logarithms. I acknowledge that might be a little bit jarring to potential audience members,  but just continuing on with the answer if you note that e to the 2 pi times you know some  number times I This basically walks you around a circle so that the output will Walk  around a circle and just keep repeating as n goes from 0 up to 1 It'll walk around one  cycle and end up back where you started as n goes from 1 to 2 You'll end up back where  you started so for example e to the 0 sits here e to the I pi Is at negative 1 but e to  the 2 pi I is? also at 1 same with Excuse me same with e to the 4 pi I that also Equals 1  so in general if you wanted to ask something like what is the log base e of 1? You know on the one hand we want to say the log of Log base anything of 1 should  be 0 because anything to the power 0 equals that 1 But if we're letting complex  numbers into the mix you would have to honestly say well 2 pi I is another pretty  good answer to this question because e to the 2 pi I also equals 1 and Same with  4 pi I and you could even go in the negative direction and in general n times pi  Times 2 times I kind of wrote that in a weird order for any integer in Feels like  a valid answer to this question So there's a couple ways that you can deal with  that in math and before we get back to our usual lesson Just on logarithm rules. This is interesting enough. I kind of want to pull it up Let's see what if we have complex logarithm  uh Great Wikipedia always to our aid probably it'll have a nice like  visual of some kind for us look such fancy color diagrams What I want okay. This is what I want wonderful. Let's zoom out a little bit Great, so there's this notion of what's called a Riemann  surface That's basically trying to capture the idea that you have a function with  multiple outputs and intuitively Maybe you can understand what it's getting at where  the input would be something on the XY plane and the output There's just many different  outputs sitting there so when you have a complex logarithm you have to account for that,  but it's used It's actually a very useful idea To do but it takes a lot more nuance than  than you might expect So with all of that hopefully that helped At least partially answer  some of people's questions same same by the way with Logarithms with based negative  numbers because if you're asking like negative 1 to the X and really noodling on what  that means it's It gets you into the realm of Complex numbers,  so you have to deal with the same multiple output idea now answers are rolling in more  slowly so this seems like a fine time to grade things and the answer turns out to be  You rescale it if you want to go from log base 2 of something to log base 10 of something  It involves rescaling and one way you could think about this is with the change of base  formula, so let's say we have Let's get rid of our e stuff Let's say you have Log base  2 of X, but we want to write it in terms of log base 10 We can write that as log base  10 of X Divided by log base 10 of 2 saying how many times does 2 go into X in a  multiplicative sense is The same as saying how many times does the log of 2 go into the  log of X in an additive sense, okay? And Well, what is 1 divided by the log base 10 of 2? so we're going to keep our log base 10 of X out here and From what we found earlier  We found that log base 10 of 2 was approximately 3 tenths was approximately 0.3. So when we divide by it that should get us 10 thirds Okay,  and this lines up with what we were looking at a little bit earlier with powers of 1000. Let's see. where was it? Where was it? Great. So when we're converting from log base 10 of something up to log base 2,  you know here we were thinking of multiplying the top by 0.3 to get to the bottom.  But you could also think of multiplying by 10 thirds to get to the top.  Anytime you have log base 10 of some number you just rescale it and you have log  base 2 of that number. And the rescaling constant comes from the log base 2 of 10.  Or vice versa, log base 10 of 2. So that's change of base.  Like I said it's very important. It lets you put everything into a nice universal  language. And that should be all of the hint that you need for the last question  which is a challenge question on this one. So if anyone's been watching and they've been like I know logarithms. I've got this completely down Let me pull up the last question which  came up on let's see It's not the AMC, but it's whatever the predecessor  to the AMC was I believe So it's you know, it's gonna involve a little  cleverness and manipulation We've got this long Sequence of fractions. Okay, you take 1 divided by the log base 2 of a hundred factorial And remember  100 factorial is a hundred times 99 times 98 on the way all the way down to 1 so  1 divided by the log base 2 of that plus 1 divided by the log base 3 of 100  factorial Plus 1 divided by log base 4 of 100 factorial on and on and on up until  1 divided by the log base 100 of 100 factorial So this looks rather intimidating, right? Certainly adding fractions is never fun adding 100 fractions seems even worse Dealing  with a bunch of logs of different bases seems like a pain and the factorial is playing  into this So I'm just gonna give you you know, given that this is the wind down time. I'm gonna give you Two or three minutes to start thinking about this and if you don't  get it, it's totally fine We're gonna walk through what the answer is,  but I'm just gonna let people think about this final challenge question before we call  it a day You You You You You So I'm gonna give you a little bit more time on this one  because it's definitely It's definitely fun to work out and I think if you know how to  start then great But if you don't know how to start just letting yourself kind of work  with a couple of the different rules that we've worked out before Change of base it  comes into play if you'd like to use that And just kind of keep manipulating and if it  feels like you're getting something that's a little too messy see if you come at it from  a different angle and Because answers are rolling in a little bit more slowly now What  I'm going to do is just start to describe the explanation here and then come back to  grade it in just a moment here. So the expression that we have Looks like I just started writing it out while you guys  were working on it one divided by log base two of a hundred factorial Plus one divided  by log base three of a hundred factorial and before you even start the fact that the  thing on the inside of The log involves a big product of stuff should actually feel  good because logs like to take in things that look like products because of the most  important property that we have which Is the idea that it turns products into addition? Okay, so right away, you know that you're probably going to use that second  thing You notice is that it's uncomfortable to have all of these different  bases log base 2 of something log base 3 of something log base 100 of  something so Translating it all into the common language should be helpful. How does change of base work? Well asking how many times does to go into a hundred factorial is the same as asking? How many times does the log of to divide into the log of a hundred factorial? It doesn't even matter what logarithm you use this log could be base 10 base e base  2 doesn't matter this change of base formula Still holds now what that means for  our expression is instead of taking one divided by log base 2 of 100 factorial I  could write that as log of 2 Divided by so let me draw a little dividing line between  what I'm doing here log of 2 divided by log of 100 factorial Okay, and then similarly? log of 3 divided by log of 100 factorial so all I'm doing here is taking The reciprocal  so instead of taking log of 100 factorial over log of 2 I have inverted it log of 2 over  100 factorial because that's what this reciprocal is doing so with that as the beginning  I'm gonna go ahead and just grade this lock in the answers and See how see how everyone's  doing So it looks like awesome around 1796 we always we always draw a little bit north of  Ramanujan's number around 1800 of you Answered that it's one which is correct  congratulations 70 of you answered 100 which we can maybe see where where that our error  would have come from Those of you that answered zero that's interesting it would imply  that somehow you have cancellation at play Because these are all positive numbers so  thinking one of them was negative So you could probably gut check against the idea that  it would be zero 41 of you want me to come up with a number fun numerical fact about 69,  but I won't 28 of you said 2 and I think yeah,  I think that's I Think the the difference between 1 and 100 maybe would be interesting to  try to analyze, but if we go back to our answer I Realize it may be a little bit  confusing how I've heard this this isn't this is not a big fraction this was just a  dividing line between Not true ironically trying not to confuse my fractions with each  other so rewriting our expression up on the top here as we add all of these things and we  can continue up until log of 100 all divided by log of 100 factorial The key is that now  all of the denominators are the same so we can add the numerators No more plus sign is  just going to equal something that top is going to look like log of 2 Plus log of 3 plus  on and on up to log of 100 all divided by the log of 100 factorial and it seems like the  only little contention among those answering the question is whether this should simplify  to be 1 or should it simplify to be a hundred and Really the way we can think about this  is to just break down that bottom part in terms of what a factorial means I'll go ahead  and do this on the bottom part since I didn't manage my paper real estate very  effectively here the log of 100 times 99 times 98 on and on times 2 times 1 is the same  as adding all of them and You can probably see this mostly cancels out with the top the  only question you might have though Is that in the factorial can we keep multiplying down  until we get that one? Which doesn't really make a difference, but before you think  about it too much you might wonder Hang on you know on the bottom. I'm multiplying everything and I'm adding this log of 1,  but on the top from what we found before I never saw that log of 1,  does that make any difference? And the answer is no,  because log of 1 is saying 10 to the power of what equals 1, and the answer is 0.  So in fact, taking the log of 100 factorial is the same as adding the logs of all the  numbers from 2 up to 100 and it simplifies down to 1. So to those of you who got it,  congratulations. To those of you who feel like you maybe have better intuitions for  change of base formulas for the fact that logarithms turn multiplication into addition,  that's my hope. In the next time, with this as a foundation of logarithms that can be  pointed back to, what I would love to talk about is what's known as the natural  logarithm, log base e. And try to give an instinct for why that's something that we care  about. Why is it that mathematicians just seem to really love the number e sitting in  the base of their logarithms? What does that buy for them? Why does it show up in nature? So that will happen on Friday at the  same time as this lecture, and I look forward to seeing everyone there.

================================================================================
VIDEO ID: IAEASE5GjdI
TITLE: Imaginary interest rates | Ep. 5 Lockdown live math
URL: https://www.youtube.com/watch?v=IAEASE5GjdI
PUBLISHED: 2020-05-01T20:11:37Z
STATUS: SUCCESS
================================================================================
Welcome back to Lockdown Math, where we try to answer some of the important  questions in life, some of the deeper things that are relevant, push your life forward. Like for example, what if you have a bank that offers  you an interest rate of the square root of negative one? A negative, not even a negative interest rate,  we thought that was weird enough, an imaginary interest rate. Should you take it? Now I almost guarantee, however interesting you think this question is,  it's going to be more interesting than that. I think there's going to be some people who find it totally nonsensical,  right, which is reasonable. What on earth would it mean for your money to grow by the square root of negative one? And I think there's also some people who think they know where this lesson is going,  but wherever you sit, I almost guarantee this is going to be more interesting than you  think. And to start things off, let me bring back our poll that we were doing,  you know, during the warm-up animations, and I just want to get a sense  for what your instinct is on this apparently nonsensical question. Okay, so obviously there's no right or wrong answer here,  it's something that we're going to answer by the end,  but I'm genuinely curious what you viewing right now think. If a bank offers you an annual interest rate of the square root of negative one,  do you take it? So if you want to participate either in this poll or any of  the live quizzing that we do throughout, obviously 3b1b.co  slash live is where you can go, link in the description as well. And while you're answering this, I just want to mention that even if this is  kind of a nonsensical question for money, one of the things I'd like to show  by the end is that thinking through the details of this question is shockingly  relevant to physics, okay, and to understanding simple harmonic motion. So even if it feels like nonsense, if you're willing to engage with the  weird storyline for a bit, there is a satisfying real-world endpoint for that. The other thing I want to mention is a brief plug for a video by Mathologer. If you guys don't know Mathologer, you're certainly in for a treat. But he did this one called E to the Pi I for Dummies,  and in general the channel is just full of gems. But this video in particular contains a lot of the things that  I want to talk about today, and it's just so beautifully done. It's extremely well presented, extremely approachable. Burkhard who presents it is extremely lovable,  so could not recommend that and other things highly enough. Good thing to watch maybe right after this, or even if you're  watching this in the future, you know, to watch right before this. So looking back at our poll, fascinating! We've got a very even split between the yeses and the nos. I wouldn't have guessed that, actually, and I'm curious if by the end of this,  once we see what the implications would be, how many of you would stand by your answers. So let me just, let me just see what this distribution is, because I am curious to know. Alright, so it looks like 1,600 and 1,700 of you said yes,  you would take the imaginary interest rate. And then 1,645 of you said no. Alright, we'll see if you stand by that by the end,  and we'll really understand the implications of imaginary interest. Now before that, let's ask a question that is a little bit more real world,  because I think we should spend the first, I don't know,  half hour of the lesson or so on actual normal compound interest, right? The kind of interest that we would all usually think of. Make sure we can build up some of the math of that,  and then once we have the math of that, see how we can tweak it to answer our,  well, frankly silly question. Okay, so as our first, I don't even want to call it a real question,  it's still meant as an opinion poll. Don't necessarily think you have to do the computation. What I want to gauge is what your gut reaction to this question is, okay? so there is a correct answer, but just answer what you, what you think it might be. So the question asks, two banks offer different interest rates on your savings. Bank A will increase your savings by 12% every year, okay? Pretty good bank. Bank B will increase your savings by 1% every month. Again, I wish my bank worked like this. With each of these banks, you set up an account with $100,  and after one year, which of the following is true? So you have more money with bank A by more than $1,  so the difference between what you have in A and B is greater than $1. You have more money in bank A but by less than $1. You have the same amount in each, more in bank B but by less than $1,  or more in bank B by more than $1. Okay, so it seems like we have pretty strong consensus. I don't know if I would call that strong consensus actually. There's a clear winner, but there's definitely a lot of contention behind it. And in general, by the way, while these answers are rolling in,  I'll sometimes be pulling up questions from the audience, which you can ask via Twitter. So the link is in the description for, you know,  where you can go to ask these sorts of questions. And it looks like someone with the profile of Yoda asks, What a poetically written tweet,  which seems pretty fitting for someone with a profile of Yoda in there. I mean, it's a subjective question. Personally, I do think the most beautiful things  are the ones that have unexpected connections. And I don't know if that's like a natural thing that humans  just love to see things that seemed unrelated come together. Humor seems to have this root, like a really good joke kind of takes you by surprise.  But when it's when there's some kind of logical connection,  it's not just surprise for its own sake. And as the lesson goes on, if you have questions relevant to what we're talking about,  ask them there and we'll pull them up on screen. So, like I said, there's technically a right answer to this question,  but I don't really want it to be treated as right or wrong. The reason I'm asking this one is to get kind of  an opinion poll to know where people are starting. So I'm going to go ahead and lock in the answers and see where people are. Interesting! This might be the first time in lockdown math history that the  plurality has not gotten what turns out to be the correct answer. So most of you said you would have more money  with bank B and it would be by more than a dollar. The second most common answer was to say you'd have more money  with bank B by less than a dollar, which turns out to be correct. We're going to walk through that in a moment. After that, more with bank A. And I think the ones that I most empathize with,  if I look back at what maybe an initial response to questions like this would be,  if you haven't thought about interest, is everyone who said C. You know, it's not obvious that 12% over a year  is going to be any different than 1% per month. r month. Like one percent per month, That should add up to 12% over the year. And I think it's worth just thinking through exactly why that's not the case. So, how do we think about this kind of problem? I've gone ahead and pulled up a Desmos graph for us to play around with. So we'll get rid of Burckardt's beautiful face and we'll head on over to Desmos. And the way I have things configured, it's going to be showing us  the graph of what happens to your money, in this case in bank A. So over the first year, at any point that you check in,  it's just got that $100 and it's not until the end of the year that it jumps up to $112. And the way you might think about that is by saying, okay,  let's take our $100, at the end of the year we add 12% of that $100. And sensibly enough, you get 112. And a nice way to think about this, which seems simple and it seems kind of innocuous,  but this turns out to be a powerful idea. We'll talk about more why I might want to emphasize that  this is more of a significant move than you might think. The fact that the rate of change is proportional to the  thing that's changing means we can factor out this $100. And we can just say, oh, that step that we take, we're multiplying it by a constant. In this case, that constant would be 1.12. So as you go from this step to the second year, at the end of that second year,  your account balance doesn't jump by just $12,  because it's also earning interest on the 12 extra dollars that you got that last year. So it jumps up to $125. It's a multiplicative amount. And this becomes particularly noticeable as we zoom out and see what would happen  over the course of many years with such a fantastic interest rate in your bank. It's not just growing like a straight line, it grows with this exponential curve. And in fact, if you look at 10 years in, it looks  like the Y coordinate of that is around 310. So you let your money sit in that savings account with 12% interest for 10 years,  and you'd end up with three times as much money. Pretty interesting. So now when we start thinking about having the interest accrue,  not just at the end of the year, but at various chunks on the way in,  let me just ask you another question. I think this is a fun way to start things off,  is rather than having me go through the logic, have you guys think through the details. So before we jump to the case of doing a step every month,  let's just say there was two steps halfway through the year. So what does the question ask us? It says a bank offers to increase the money in your  savings account by 6% at the end of every six months. Which of the following represents how much money will be in  your account if you put in $100 and then you wait for one year? So there's two different six month periods that have passed. Which of the following expressions shows how much you're going to have? All right, so I'm going to give you a moment to think through the details of this. Give you a little pause and ponder music maybe. Okay, as always, I'm probably going to grade this faster than is a reasonable  amount of time for someone who really wants to think through the details of things. So never feel like you're being rushed. Sometimes it's just that I want to move forward with the lesson. And it seems like answers are rolling in a little bit more slowly now. So I'm going to go ahead and lock this in, but as always,  feel free to pause and just think things through more yourself if you want. We're going to explain it in a moment. So the correct expression, which looks like 3,000 of you got,  is that it should be $100 times 1 plus 0.6 squared. Alright? Now let's think through why that might be the case. So if we head back over to our Desmos expression that we were working with,  if instead of increasing by 12 percent, we're saying increase by 6 percent,  when you factor it out, it looks like multiplying by 1.06. And then there's two ways you can think about this. If you're already comfortable with the idea that increasing by 6%  is multiplying by this constant, you say, oh, we just square that. And if you want to think through the details for why that's true,  if that's not something you're entirely comfortable with, you can say,  let's repeat the process. So this gets us 106 after that first six month period. Okay, we've got 106, then we're going to add 6%,  0.06 times that 106, and that's going to get us the final amount. But this we can factor, because the 106 shows up in two places. Because the rate of growth is proportional to itself,  it lets us factor this out as 106 times 1.06. And then you might realize, oh wait, I'm just  multiplying by the same constant that I did before. So I might as well have just gone and put that constant up there. And because it's the same constant, I might as well have simply written that as a square. So what that means is if you take these steps of percent increases many,  many different times, what it looks like is taking a number that's  a little above 1 and then raising it to some kind of power. So to our original question, asking about bank B, which, what did it say? It was going to be a 1% increase to your savings every month. The way you might think about that is by saying we multiply by 1.01,  okay, by 1 plus that 1%, and then we do it after 12 months. Okay, so instead of the, instead of the $112 that you would have had from bank A, woo hoo! It looks like compounding more frequently got us an extra 68 cents in our account. So, wonderful, right? In our graph, if we wanted to see what that would look like, again,  there's some machinery under here that I'll show in a moment,  but if I just crank up this number n to 12, that's basically asking how many times  per year do I compound this interest? Do I make a little step increase based on what the annual interest rate is? So if the annual interest rate was 12 percent and you're making steps each one twelfth  of a month, of a munch, of a month, that means you increase by 1 percent each one of them. So what it looks like is a step function that's a lot more fine, okay? And we can see how at the end of the one year,  the y coordinate of our graph is that $112 with the extra 68 cents. Not quite a dollar more, but it is more. And again, as we zoom out, you can see that it fits this nice exponential curve,  the power of compound growth. And if you're curious, you know, previously after 10 years,  we would have had 310 dollars, I think it was,  which we can verify for ourselves if I take that 100 dollars times  1 plus 0.12 to the tenth. Alright, this says $310. When we compound every month instead, and we wait for 120 months,  it looks like we've squeezed out an extra 20 bucks. So, not bad. The important part here though, is the idea that the frequency with  which you compound actually changes the amount, which is interesting. And this is the original circle of thoughts that Bernoulli was thinking about  that leads to the origins of the constant e that we all now know and love. Maybe the second most famous constant only next to pi. So let's write out some of what we're doing here, but with some formulas,  and then see what we can start learning with respect to those formulas. And this is going to help us understand the bizarre question of an  interest rate of negative, not even negative, I keep saying interest rate of negative 1,  interest rate of square root of negative 1. Nobody should let the Fed watch this video, I think it might introduce some shaky ideas. Alright, so the way we might think about this is let's say you start  off with some amount of money, okay, and then we're going to let it  accrue some interest over some long amount of time, that I'm going to call t. And the idea is that we're chopping this amount of time into a bunch of little pieces,  okay, and with each one of these steps we're going to increase our money. There's going to be some kind of change to m, a delta m. And each of these steps, let's say it's got a length of delta t. So maybe delta t is a 12th of a year, or maybe it's 1 365th of a year,  it depends on how finely we cut it. And just as another variable to throw down here,  let's keep track of how many steps there are along the way,  if we were to count them all up. And the total number would be the total amount of time  divided by the size of the time steps that we're taking, okay? So what interest rates do is they say that the amount your money  changes is going to equal that interest rate, r,  and you might think of r as being something like the 0.12 from our example. And then later on we're going to play around with making it imaginary. But you're going to multiply it by the size of your time step, okay,  which you might think of as being something like 1.12 if we were compounding monthly. Because simply by compounding monthly it doesn't mean you get to grow by 12% every month,  it means you grow by 1.12 of what the annual rate was every month. And then what makes compound growth so powerful,  it's also proportional to the amount of money you had. You know, if you had $100 it grows by a certain amount,  if you had $1000 in there it grows by 10 times as much. The more you have, the more it grows. Okay, so that in our example you might think of as being something like $100. Alright, so what's the magic of this? It looks innocuous at first, but it means that our  money changes by going to m plus r delta t times m. And because m shows up in both of these terms, it lets us factor things out,  so that m factors out and we have 1 plus r delta t. And because this is the same constant that we're going to multiply for each  one of these little time steps, all you're doing is multiplying by this constant. We can write an expression for how much money you're going to have after time t. What it's going to look like is the amount of money you had to start off  with at time t equals 0 multiplied by this expression, 1 plus r delta t. And I'll change this in a moment, but I'll keep writing it as r delta t. But we multiply it by itself n times, where n is the number of steps that we have in here. Okay, but there's a lot of different variables at play here,  so I want to start consolidating them. And instead of writing delta t, I'm going to go ahead  and express delta t as the total time divided by n. We look at the number of chunks we've cut our period into,  and we take the total amount of time and divide by that. So what our expression will look like is the amount of money we  started with times 1 plus r times the total time divided by n. So this t divided by n is playing the role of delta t. And we raise that to the nth power. Now this is actually a very interesting expression, no pun intended,  because we want to know how does the size of n influence things. If I crank up n a lot, meaning we're chopping our interval into very fine  increments and compounding very frequently, what does that mean for our interest? And you might, if you were a pure mathematician,  try to abstract away all the ideas of the money here, the specific interest rate,  and just say what we're interested in is this function of x that looks like  1 plus 1 over n. Or maybe I'll say 1 plus x over n. So we want to be able to plug in some value for r t. And we'll raise that to the power n. But you're not just curious about this for any particular n. What you want to know is what happens as you crank up the value of n. And the expression that mathematicians write for this, we write lim for limit,  and then we write n with an arrow to infinity,  saying I want to crank up that n and see what happens to this particular value. Now it's not obvious, I think, what happens to it,  and playing with my toy again, I just want to do another half-opinion poll,  half-real question about this one to see what your instinct is. So let's say, pull up the question here, what happens to the value 100  times 1 plus 0.12 over n to the power n as the value of n approaches infinity? And in the back of your mind, you can think this isn't just a purely mathematical  expression, it has a very real meaning in the context of compound interest. What we're basically saying is if you have that 12% interest rate,  and you want to wait one year, but you chop up that year into n different pieces,  maybe n is 12 if you compound every month, maybe n is 365 if you compound every day,  or maybe you want to compound every microsecond or every picosecond. The question is, how much money can you get at the  end of the year simply by compounding more frequently? If you'll remember, when we went from yearly to monthly, that gave us an extra 68 cents. So the question asks, basically, how high can this go? And now we have a very wide split, which is wonderful. I'm going to give you guys a couple more moments to think about this. And I don't want you to calculate it necessarily,  the spirit of this question is to see what your initial thought is,  kind of intuitively based on the numbers. So even though technically there's a right answer to this one,  so I'll highlight it green, there's no right or wrong here. The spirit of it is for me to know where people are. I'll give you just a little bit of time on this. And while I do, let's take a question from the audience. Considering that imaginary unit is defined in terms of operations on the real numbers,  is there an analogous definition of quaternions in terms of operations on complex numbers? Okay, so a bit of an advanced question. I don't expect most people watching the series to necessarily know what quaternions are. But it's a number system that instead of including two dimensions,  like the complex numbers, involves four dimensions. The short answer to the question, I think this is okay to say, the short answer is no. When we get the complex numbers it's because we  have an expression that we don't have a solution to. You want to know the square root of negative one. A solution to x squared equals negative one. And by introducing a solution, you extend your number system. Quaternions don't come about like that. For any polynomial, once you have the complex numbers,  you get all the solutions that you could ever want from that. So it's not going to be there's a problem that you wanted solved  in the sense of a solution to a polynomial and you extend it. But where it does come from is the idea, at least historically,  is the idea of wanting to describe motion in three dimensions. And complex numbers can describe things like rotation in two dimensions,  but they don't have enough degrees of freedom to describe rotations in three dimensions. So in that sense it was a concrete problem they couldn't solve. But the construct that you do to add on top of  it doesn't look like a solution to a polynomial. Kind of a more advanced question than the spirit of the lessons necessarily,  but obviously I love to just engage with wherever you are, whoever is watching this. So back to our question. I'll go ahead and grade it. And again, technically there's a right answer, but don't view this as right or wrong. It looks like 1670 of you correctly noted that this value would rise above 112,  but never above 113. So maybe taking the instincts from the fact that when we went from yearly to  monthly we only got 68 cents and saying you can't get much better than that. The next biggest answer, interesting, was people who said it would rise above 114,  but stay below some finite bound. Okay, so having that instinct that it would stay finite,  but that it was going to get bigger than anything listed here. And I think the most thought-provoking answer here is E. The thought that maybe it should blow up to infinity. I mean, we're letting n get as big as we want. It doesn't just have to be down to the picosecond, it could be down to a plank length. It could be down to the tiniest, the biggest number that you could think of,  so that our time steps are as tiny as you can think. It's not at all obvious that this thing would remain bounded. So we can play around with this a little bit if we want to. This won't be a proof that it remains bounded,  but maybe it can give us a little bit of an instinct in that direction. If I take 1 plus 0.12 over n, and I raise this to the power n,  and I say what happens as we increase n? And 100, that's not big enough. I want to let myself increase it to some huge number, you know, 100 million. So the value I want you to watch is sitting right here, okay? And remember that represents how much money you'll have  if you compound your 12% interest much more frequently. Even as I'm cranking it up around 100 million, this value really stays stable around 1.12. Here, let's multiply it by the $100 to make it more intuitive. Around the $112.74, about 75 cents, it stays really  stable around that even as I'm increasing by a lot. That's not a proof. For all we know, as you venture into the realm of huge, huge numbers,  10 to the 300th, or grams constant, or whatever big number you want,  maybe this thing would slowly crawl up and eventually get unbounded. But it's an interesting fact that it doesn't. Now, in terms of the math behind this, we can do an interesting manipulation. Because we have this expression that is a little funky to think about, right? We've got 1 plus x over n that you might think of as a partial interest rate,  and we're raising it to the n. I can do a little substitution and say, what if I define the value m to be n divided by x? And the reason for doing that would be so that I can write that inside without an x in it. So x divided by n will be the same as 1 divided by m. And now I'll be raising that to the power, well not n,  well no, the power n, but I want to write it in terms of m. So it'll look like m times x. And based on how exponents work, I can think of that just as  the quantity 1 plus 1 over m to the power n all raised to the x. And I'm curious about what happens here as I crank the value of m towards infinity. And Bernoulli was also interested in what happens  as we crank this value of m up towards infinity. And empirically, what you'll find is if you just play around with this,  and if we go over and take out the evidence that we were dealing with a real world  problem, with things like that $100 starting value, or that 12% interest rate,  and we just have clean constants like 1 for each of them,  it looks like this value ends up to being around 2.71828. And no matter how big you make n, it seems to never really get much different than that. Again, not a proof, but very suggestive that this  is maybe a fundamental constant of nature. And so this is the original definition of e, this is  the original way that people were thinking about it. As we pop over here, and we say instead of writing this whole limit expression,  I'll use a different color, say in principle, this is going to approach some kind of  constant. Let's call this constant e that empirically has a value around 2.71828. And then we can write our whole thing as e to the x. So for example, if we wanted to know what happens in our interest example,  when we started out with $0, not $0, started out with m of 0,  which might be something like $100, what we do is we just focus on that rt term,  we say we know that as we crank up n, this is going to approach some special constant  raised to the power of rt. And maybe this we would aptly describe as continuously compounded growth,  if we take that time step and we let it approach 0. And this was actually before Newton and Leibniz, this was before calculus existed. There was this idea of trying to take these discrete steps of increasing  and make it approach 0 to get something a little bit more continuous. So I think that's quite cool. And one thing that you might notice here is we've got this large expression  for basically a function of x that we now tend to write as e to the x. If you watched the last lecture, you would have remembered that I said  the way things have come about in math now, whenever we see e to the x,  we actually think of it as a shorthand for a certain polynomial. And the polynomial, I was calling it exp, which follows convention,  looks like 1 plus x plus x squared over 2 plus x cubed over 6,  and all of the terms look like x to the k divided by k factorial for some whole number k. And I said this is what e to the x is a shorthand for, this is how you think about it,  especially when there's weird inputs, things like an imaginary interest rate. And you might wonder, what on earth does this  polynomial have to do with this limiting expression? And as a super extra credit challenge question for those of you who are really  into algebra and who are very comfortable with binomial expansion,  if you know what those terms mean, if you take this expression for some large  value of n and you expand it, you just expand it and you kind of simplify your  terms and then you make approximations based on what's true when n is very large,  what you would find is that the polynomial this expands to looks a lot like this  polynomial here. And in fact, as this value of n gets bigger and bigger and approaches infinity,  this polynomial will get closer and closer to this one. It's a challenging question, so I wouldn't expect everyone to necessarily be  able to just bang it out, but if you want to it's a very elucidating exercise. And there's also a lot of delicacy in rigorously proving the fact that  what this approaches will also approach this, or that both of them even stay finite,  and they don't blow up when you, you know, add more and more terms to the sum,  or when you crank up n higher and higher. There's a lot of delicacy there, but you can probably  get to a point where there's an intuitive connection. And the reason that in math we tend to work with this polynomial instead of that limit,  it's basically easier for computations and easier for theory. But the value of this other expression is that it ties us back to the idea of compound  interest and the idea of taking a quantity that changes a little bit based on its own  size. You can kind of readily read this as saying we're going to multiply  by a certain constant that's a little above one many, many times. And if you'll remember, the reason we're doing that is when the way that  you change is proportional to yourself, that lets you factor things such  that you're just multiplying by something a little bigger than one. And when you do this approaching continuity, when you do it in a way where that time step  is getting smaller and smaller, this is when we start writing e to the power of something. What it's suggesting is that you have this compound interest expression,  but we're letting that n tend towards infinity. We're letting the time step go as small as we want. So, with all of that said, we can start having fun. We can start thinking about our original question of an imaginary interest rate. So how on earth is this going to work? First of all, let's just say from the get-go that if we try plugging in r to  this expression where we're raising a constant e to a power, it makes no sense. If r is equal to the square root of negative one. You cannot multiply a constant by itself the square root of negative one times. So that doesn't make sense. But what does is if we go to this original expression,  the origins of e, and try to imagine plugging in something like i to that. We know how to divide i by n, that's fine. We know how to add it to one, that's fine. We know how to take a complex number and multiply it by itself. All of the operations there are quite fine. Now let's draw it out to think about what it would look like. And the other thing I want to emphasize is I know this seems like utter nonsense. We're talking about imaginary numbers in the context of interest rates. But in a couple minutes, I really do hope to make this relevant to physics and  hope to make you see that this is not a totally nonsensical circle of thoughts. So, I've got my axes here. This is going to be my real,  this is my real money. And this will be all of my imaginary money. What it means if your interest rate is i, is that the change to the money looks like  i times whatever the time step is, delta t, times whatever the money is to begin with. Now, in, I believe it was lecture 3, we talked all about complex numbers,  and one of the fundamental facts was that when you multiply i by something,  it has the effect of a 90 degree rotation. And we talked about this in terms of looking at the coordinates and  realizing that you just swap the coordinates and make 1 negative 1. So this connection between the square root of 1 property and the  very mechanistic idea of taking a vector and rotating it 90 degrees. Now what this means for us is that the change to your money is going to  be a little arrow that, you know, it's not increasing the money,  you're not growing, you're not decreasing the money, it's not a negative interest rate,  it's moving somehow perpendicular to where the money already is. So after a little step in time, you end up with a little bit of imaginary money. So you have what you had originally and you can play Monopoly. And now from that point, when you do another time step, it does the same thing. It takes the vector that you've newly landed on and it rotates it 90 degrees,  okay, and then you take a little step based on that. And then again, you take a little step based on that. Where at each point you're looking at what is your money number that has some real part  and some imaginary part, you rotate it 90 degrees and you add a little step on that. And now the question is what happens to this? This is the original question. The bank offers you this interest rate, what's it going to do? The correct answer, I think, is that you need to ask the bank for more  information because how frequently you compound it is going to make a difference. So to illustrate this, let's say you compounded it annually,  meaning at the end of every year you take a big step that's based on this interest  rate multiple. So for every dollar that you have, if you started out just putting  your real money into the bank, at the end of the year you would add i times that amount,  which is a 90 degree rotation of your money. Again, I know this is utter nonsense, but follow along with me. One, it's fun, and two, it leads to real physics. So where does that get you? Well, it gets you $1 plus i dollars. So if you had a hundred dollars in the bank, you end up  with a hundred real dollars and a hundred imaginary dollars. But then, after the next year, you take another step,  where it takes that new money vector, rotates it 90 degrees,  and adds that to where you are. So after two years, you come back to your bank and you say, how's my money doing? And they say, good news, sir, there's twice as much of it. You say, that's fantastic, it's only been two years. And they say, bad news, it's all imaginary. So, very good for your Monopoly game, not great for life logistics. But it gets worse. As you wait more time, and you add another 90 degree rotation of where you currently are,  you're going to step into the negative real territory. So at this point, now you have negative 200 real dollars,  but you still have that 200 imaginary dollars. So, good for your Monopoly game, devastating now for your actual life. But it gets worse. As we take another step, four years later, after you've invested your hard-earned money,  you've not even invested, you weren't even putting it at risk,  it was just a savings account. And where do you end up? For every dollar you put in, you would now have negative four dollars. So you come to the bank and they say, well, you owe  us $400 for the $100 that you put in four years ago. And just as you're about to get outraged at them, they say, sir, we encourage you to wait. We really do think this is going to work out for you. If you just let your money sit, do its work, and  in the long run this will work out for you. And they're not entirely wrong, because if you keep playing this game of  rotating 90 degrees and then adding that vector, after a total of eight years,  where you're going to end up is at 16 times your original amount. Not too bad. So if you're willing to put up with a lot of stress going in,  changing your monopoly game, changing your real life,  and you were willing to just hold for eight total years, you would have 16 times as much. So that's pretty good, I would say. We might call this the venture capitalist approach, where you put in your money,  you can't see it for a long time, and most of the time it's completely imaginary. But every now and then you get a giant multiple at the end. Now before you excitedly do this, though, let's say  that your bank doesn't compound it annually, right? And they say, ah, actually we compound your interest continuously. Meaning that our time steps are not delta t of one year,  but it's delta t getting smaller and smaller. Well what that means is that each one of your steps that's  perpendicular to where you are is really just a tiny little step. And I'm showing with the arrows here what happens if you wait eight total years. So you take a tiny step that's perpendicular to where you are,  another tiny step that's perpendicular to where you are, and you keep going. But as that time step gets smaller and smaller, smaller and smaller and smaller,  to the point where it's genuinely continuously compounding interest,  what it means is that you're simply walking around a circle. So if you were writing this out as an expression, you know,  it might seem halfway reasonable to look at the fact that we  were using e to the x as a shorthand for this limiting value here. And in the case of real numbers that makes total sense when we plug in a value for x. But what it means here is with our imaginary money,  we're writing it as e to the i, that was our interest rate, times the amount of time. Nonsense if we think about repeated multiplication,  but in the context of compounding interest, all it really means is that after  taking a bunch of steps that are perpendicular to your current position,  and we do that continuously, so those time steps are just infinitesimal,  it has you walking around a circle. So, the bank offers you this, do you take it? Well let's think it through. What happens when you put in $100 to your savings account? Well if you wait a total of pi halves years, which is the  distance along a quarter of a circle, a little over a year and a half,  you come back into your account and what do you see? Well, for each dollar you put in, you have an imaginary dollar. Not great. But you push through, you know, the banker told you that this will work out in the end,  so you say, okay, I'm gonna wait. I didn't need it for that year and a half, life wasn't going too terribly,  so I'm just gonna let my money still sit in that savings account for another year and  a half or so. And you wait a total of pi years, around 3.14 years. You come back, and now it really doesn't look good. Now, you've got negative one dollar for each dollar that you originally put in. And just like before, you're infuriated at the bank, not as much as you were,  because it hasn't gone out to be negative four, but it's still negative,  and that's not fun. And the bank says, hold on, hold on, sir, we think  this is actually gonna work out for you in the end. You say, okay, I've seen this work out for my friends who got 16 times their money,  so I'll just hold. And you do, you just don't touch the money in your savings account,  you wait another year and a half and you check. And now, not only is it entirely imaginary, it's negative. So you can't live your real life, and you also can't even play Monopoly well. So, 4.7 years is a real low during this whole experience. But if you're willing to stick it out, and wait a total of 6.28 years, 2 pi years,  you come back, and for all of your stress, you're back to where you started. You just have one dollar for every dollar that you put in originally. So, should you accept this interest rate from your bank? Depends on how much emotional turmoil you want,  but if it's continuously compounding, certainly not, I think is the appropriate answer. Now, is this at all useful? This is kind of fun, I think, to take an idea that started off only  relevant to real numbers, you know, a 12% interest rate,  or if you have negative interest rates, you can think of how that decays. And say, well, what if we did something else to it? What if each time step wasn't in the direction, but it was perpendicular to the direction? And the answer is that this is actually incredibly relevant to  anything that involves what's called simple harmonic motion in physics. And so a great example of this is a spring. Let's say we wanted to understand the motion of a spring. So let me pull this up here. I think I have an actual spring sitting somewhere here, if it didn't roll off my table. I had trouble finding any reasonable ones, so I tried to just extract one from my pen. Maybe not the greatest physics demo in the world, but I've got one. So the idea here is that if I pull the spring,  it's pushing me back in the other direction against how I pull it. And similarly, if I push on it, then it's pushing me in the other direction. It's trying to get back to that equilibrium point. And the way that it does this obeys, at least to a loose  approximation for a lot of springs, something called Hooke's law. So if I draw out a spring, and let's imagine that  there's some mass sitting at the end of it. Let's say that this is where it wants to be. This is the equilibrium position, kind of like how my spring is  sitting here before it just rolls away with no forces acting on the mass. But if you stretch it out, if I pull it, that same mass at the end,  this distance, what we might call the displacement of our mass,  ends up influencing how much force the spring is pulling back on. Because intuitively we know that the spring is pulling back with some kind of force. And what Hooke's law suggests is that it's a force proportional to that size of x. And we use k as a proportionality constant and negative  to emphasize that it's pointed in the opposite direction. So in this context, what we're saying is if we double the amount that we're pulling it,  it's going to pull us back with twice the force. If we triple it, it pulls us back with three times the force. As with any kind of physical models, this is only true to an approximation. You know, if we pull the spring such that we just distort it entirely,  this certainly won't apply. And often with anything that involves the simple harmonic motion we're about to describe,  it tends to only be true for small variations. And as you get larger variations, the model would have to change. But this is a pretty good one, and it's very general. It comes up in a lot of different circumstances. Now force is mass times acceleration. This is what force is. This is what Newton's second law tells us. It says, what is your mass? I'm telling you how much you're going to accelerate. Acceleration is how much your velocity changes,  velocity being how much the value of x changes. Now this is quite interesting, because what it means is that acceleration,  which is influencing the displacement, kind of in a second order way  via how it influences velocity, is itself influenced by the value of x. So I'm going to go ahead and ask you a quiz question here. It's basically to have us think about what velocity  and acceleration really mean in a context like this. So we'll pull up our quiz again. We are going to go to the final live question for this lesson. Which is a big one, but it's largely just stating what I just did. A mass on a spring is pulled a distance x away from an equilibrium point. If the spring obeys Hooke's law, the mass will experience a force of  f equals negative kx, x being that displacement, for some constant k. Keep in mind, by Newton's second law, f equals ma,  where m is the mass and a is the acceleration. Okay, if the mass starts out with a displacement of x naught and a velocity of v naught,  which of the following most clearly describes the value,  the changes of these values after a small change in time, delta t? Okay, so we're going to let time play out for a tiny step in time,  and it wants us to know which of these four options best describes what that change to  the x value is going to look like, delta x, and what the change to the velocity value  will look like, delta v. So I'll give you a little bit of time for this one. While you're thinking about that, we've got another question in about quaternions,  not entirely relevant to the lesson, but certainly a very interesting idea and question. So if you're enjoying this kind of side plot to the full lecture,  rotation in 2D requires one extra number, i. So why is it that it requires three extra numbers,  i, j, k, and not just two, i and j, for 3D rotation? Is there an equivalent way for rotation in four dimensions,  and how many extra numbers are required there? Okay, awesome question. So a way to think about this, in complex numbers or in two dimensions,  you only need one degree of freedom to describe rotation, okay,  you just need to describe the angle that you're rotating. And so you might say, oh, why do we need a 2D number system in  order to describe something that only has one degree of freedom? And the idea is that it's nice to live in a slightly bigger space so  that we can have a circle, something where you come back on itself,  and then we just constrain all of the rotating actions to that circle. So the way that complex numbers describe rotation is  entirely based on the numbers that sit on a circle. It's only one dimension's worth of numbers in some sense. Awesome. So for three-dimensional rotation, it's not just two extra degrees of freedom you have,  you actually have three degrees of freedom to describe any 3D rotation. You might think of it as saying, choose an axis for your rotation,  a latitude and longitude that you're going to poke a hole through the entire Earth. And then after you choose that latitude and longitude,  two degrees of freedom for your axis, you have another degree of freedom for  how much you rotate. So it's a total of three degrees of freedom to describe rotation in three dimensions. Now again, you could say, in principle, we should be able to do this with a  three-dimensional space, where somehow you associate the three degrees of freedom of 3D  space with the three degrees of freedom of your rotation,  which you kind of can with a thing called stereographic projection,  which is entirely what the video I did about quaternions was about. But, in the same way that to describe rotations,  it's nice to have a circle, something that lives one dimension higher. To describe 3D rotations, it's nice to have a hypersphere,  basically something that loops back on itself, but it has three degrees of freedom on it. Very weird for us to think about, but that's sort of the degrees of freedom argument. And then four dimensions, rotations would actually have ten degrees of freedom. There's not a number system for it, but if you're trying to  constrain your matrices and understand things like that,  which again, this is, if none of this makes sense to you, don't worry. It's not in the spirit of this particular lecture or the target audience for it. But it's an interesting topic. And if it's what you're chatting about on Twitter, I'm happy to chime in on that. So, yeah, thinking about degrees of freedom and the fact that it's nice to live one  dimension higher to have, basically have a more interesting surface than flat Euclidean  space. Okay, with that as our changing scenes abruptly from the side plot of quaternions,  we return back to our regular programming of physics and how  it's relevant to imaginary interest rates. Locking in our answers here, it looks like most of you correctly answered A. And what is A saying here? It's saying that the change to x is whatever your velocity was  times the small step in time, which that's what velocity is, right? It's saying how many meters per second. What is the change in distance per unit time? So you multiply it by the change in time. And then the only tricky part is knowing that the  velocity changes based on acceleration times delta t. And acceleration in this case, we can work out based on the various equations. Not sure if you can hear, but there's some sirens in the background. In general, whenever I'm recording, it's so annoying when there's background noise. So one of the nice things about live is that I just have no option. So background noise needs to be tolerated. Anyway, if we want to write a pure expression for the acceleration,  what it looks like is, just rearranging, negative k over m times x. Now for where we're going with this, it's going to be a little bit simpler. This is a classic mathematician thing to do. Ignore the like real numbers. And just assume that we're working with whatever units we need to,  such that k over m is equal to 1. And then what we can say is that the acceleration is negative x. And the reason I want to do that will hopefully become apparent in a moment. Now the way I want you to think about this spring  setup is going to look a little weird at first. I'm going to have you follow two different numbers,  which is basically the displacement of our mass sitting up here, what is x. But then you also want to know the velocity. So let's say it's not just up there holding still,  it was actually moving a little bit with some kind of velocity to the right. You need to understand those two numbers to follow the system as a whole. And I'm going to package those two numbers together  as a single point in two dimensional space. So let's say I had some position, or some state I should say,  that has a small displacement but then a large velocity. I'm going to think of that as simply being a point, or maybe I draw an arrow to it,  thinking of it as a point in two dimensional space, with coordinates x and v. All I'm doing is packaging them together as a single point. And then what we might write is that the change to our two coordinates,  the change to x, v, looks like, well, the way x changes is  based on your velocity times a little change in time. That's what velocity is. And the way velocity changes, same deal but with acceleration. But acceleration is negative x for this system. So it's going to be negative x times delta t. So we have a value that changes, and in fact the way that it changes  is going to be based on a little vector perpendicular to itself. Which is what happens when you swap the variables and you make one negative. And let me just talk through this, not in the context of writing them  down as two separate coordinates, but in the context of imaginary numbers. Which feels like a very weird thing to do, but just walk through with  me this process because it feels so elegant once you let it play out. I'm going to package this pair of numbers as a single complex number where the  real part is the position of the spring and the imaginary part is the velocity. Again, totally crazy thing to do. If that feels weird or you don't understand it, that's fine, it's not a natural thing. But if we play this out and we start walking through the math,  hopefully it starts to justify itself. Because what I can write is that the change to this state,  this complex number, is actually equal to negative i times itself. Times x plus i times v times delta t. Why? Well, let me expand this out. When I take that negative i, negative i times x is going to be negative x times i. Negative i times iv is going to be negative i squared times v. i squared is negative 1, so that's just going to end up being v. So it's that whole number times our delta t. What is this saying? It says the change to the real part corresponds to v,  the velocity, which is what we saw up here. The change to the first coordinate is based on v. And the change to the imaginary part is based on the negative of the real part. The change to your velocity, the acceleration,  what corresponds to force, is based on negative x. So this weird idea of Hooke's Law, where the force that the spring  is pulling on turns out to be in the same, against the direction of  displacement and proportional to displacement,  lends itself to a very strange but natural description of our system  with a complex number. And I could write this even more compactly by saying,  let's describe our whole state with a number z. The way that z changes is equal to negative i times itself times a small step in time. Geometrically, what that looks like is taking wherever you started,  multiplying it by negative i, which rotates at 90 degrees,  so this is a 90 degree angle, and then taking a little step. And then now you're at a new state, and you rotate that new state by 90 degrees,  scale it down by delta t, whatever your time step is, and you take another step. And you take another step. And you keep doing this, and just like what we saw earlier for compound  interest that was imaginary, what you end up doing is walking around a circle. Now this is maybe the worst attempt at a circle I've ever drawn. This should go out a little bit further, something like that. Ignore my dotted lines there. Now let's gut check to see if this intuitively  makes sense that that's what our spring would do. Because this vertical axis is the velocity. So what we're saying is if you start off with a high velocity and a low displacement,  so your spring, your mass is moving fast, but it's not that far away from the equilibrium  point, well yeah, x is going to increase, because that's what it means to be moving fast. So the x component, the real component here, is getting bigger and bigger. And in the meantime, the y component, the velocity is slowing down,  because the spring is pulling it back. So our y component is getting smaller and smaller,  until we reach a point where there's no velocity,  and it's as far out in the x component as it can go. So we've kind of swung out, and then it's as far out as it can go,  and then it's going to start turning around. The x component is going to start decreasing, and the velocity is negative. And in general, this is just going to walk around a circle in our complex plane,  where the use of a complex plane feels kind of bizarre here. But maybe intuitively, that's not that crazy a thought. Whatever piece of math is describing the physics of a spring that goes back and forth,  and critically I should specify this is a spring where we're not taking  into account friction, so it'll just oscillate back and forth forever,  that oscillation corresponds with circular motion. And we can see this maybe even more concretely if we write out the math of it. So what we just saw is that imaginary compound interest invites us to write the solution,  the place that we're going to be after an amount of time t,  as wherever we were in the beginning, times e to the power of that interest rate,  where in this case the interest rate is negative i. The thing influencing how you change, it's not in the direction of where you are,  it's 90 degrees to where you are, times the time. This is actually a reasonable way to write things,  and it mirrors how you might see things written in certain parts of actual physics. This e to the i t term shows up any time you have this kind of oscillation,  and the oscillation often corresponds to forces that are proportional to the displacement  itself. It all loops together, it's all connected. Now if you wanted to make this, I don't know, connect with the kind of graphs and  functions that we see elsewhere, you could write this using Euler's formula,  writing the expansion of the fact that e to an imaginary constant walks around a circle,  as your initial state times the cosine of t, and minus i times the sine of t. And what this is basically saying is if we were to independently graph  the displacements and the velocities, they would look like sine waves. Okay, so I'm just going to draw out a couple different plots here,  where on each one I'm going to let the x-axis represent time that we're moving forward,  and in one of them we're going to plot the displacement. Well let's say the displacement started off entirely at one and the velocity was zero. What it would look like would just be this cosine of t, excuse me,  cosine of t real component of our weird complex number description of things. But if that all feels weird, hopefully it feels more concrete when you  realize all that saying is that the position of the spring oscillates  back and forth in a nice little cosine wave, which matches physical intuition,  it kind of oscillates back and forth in this gentle smooth wave. And then similarly the velocity, let's say it started off at zero,  what our Euler's formula is telling us is that this will end up being a negative  sine wave. So it's going to start off at zero, but then it's going to go down,  basically because it started off, you know, as far as it could be,  and then it's going to point in the opposite direction,  bringing the mass back towards equilibrium. And then the velocity will reach some minimum and  then it'll come back up until the velocity is zero. This is when the spring goes all the way to the other end. And then the velocity will be positive for a while  and it'll keep oscillating back and forth like that. And I'm sure I haven't quite lined up the waves appropriately,  but the idea that each one of them is a sort of sinusoidal pattern,  and that they're out of sync with each other, hopefully lines up with some  physical reasoning. And I just think it's beautiful that what you can see is happening is it is  two different shadows of circular motion in an abstract mathematical idea,  of packaging the two components as a real and imaginary part of some number. Because this Hooke's law let us describe things at a 90 degree angle. And all of that is actually deeper than you might think it is. There's certain formalizations of classical Newtonian mechanics that  introduce complex numbers for pretty similar reasons to what's going on here. It's all a bit advanced, I won't necessarily go into it. But what I want to emphasize is that this original question we asked of  what happens if your bank offers you an imaginary interest rate isn't totally insane,  and in fact, at least it's insane for money, but it's not insane as an  abstract idea to pursue, and it corresponds to some very real things. So with that, I'm going to go ahead and take one final question from the audience,  and then say my goodbyes. So the last question we have for today. Can we get some hints or thoughts on the last challenge from the previous lecture,  particularly exp of x for matrices? Excellent. That was a hard question, by the way, the homework that I left at the end of last lecture. So remember, last lecture we were talking all about thinking of the exponential function  as this infinite polynomial, and hopefully today the fact that it came from our limiting  expression, I didn't show why, but we could call that homework number two for today. If you're really ambitious, it's showing that this expression that comes  from compound interest ends up expanding to be this polynomial,  which is what we mean anytime we refer to e to the x in math, at least in modern math. So I asked some questions on the homework that involved expanding this  out all around trying to understand the crucial equation that when you  add two numbers in the input, this is the same as multiplying two outputs. Okay. And then what we have on screen is asking about for matrices, what goes on here. So the thing that again, this is kind of advanced and maybe I feel a little  bit bad about that if I didn't properly emphasize it in giving the homework. The thing I want you to notice is when you go through parts one and two of  the homework where you're expanding it out, and especially in the case of  part two where you're expanding things out, to think critically about whether  the commutative property, x times y equals y times x, is needed or relevant. Because often when we expand out binomial terms, it assumes that this is true. And the reason that the math for expanding binomial terms looks like what it does,  the reason it works has everything to do with the fact that  order of multiplication doesn't matter. This is particularly relevant in part two where we're expanding this exp of x plus y. And when you do that, you're going to run into  these terms that look like x plus y to the power n. And then the parts of that are going to end up looking  like n choose k where this is the binomial constant. So that's a bit of prerequisite knowledge. If you don't have the prerequisite knowledge, don't feel intimidated by these problems. It just means that there's a little bit more to learn. The only reason that this expansion would work is if you have the commutative property. So it's very subtle. But what this means is that the whole line of argumentation to show  this property doesn't work if the things that you're plugging in don't  commute with each other, where x times y is not necessarily y times x. For complex numbers this is true, for real numbers this is true,  but for matrices that's actually not true. And this is one of the reasons, by the way, I actually  think writing e to the x for this is a bad convention. Because you have this bizarre situation where when you have matrices,  and this does come up, there's real math that's done where you are exponentiating  matrices, the notation inspires you to think, oh, I should be able to write this as,  you know, exponentiating a times exponentiating b should be exponentiating a plus b. But this is actually not true. This is not true in the case of matrices. We talked a little about quaternions today in the side plot,  it's not true in the case of quaternions. So this convention of writing it as e to the x is incredibly  confusing as soon as you start extending into the realms where it's most useful,  where you have this particularly powerful polynomial. And I'm just, I don't know, I think that is a fact worth emphasizing,  which is maybe why I wanted to sneak it into the homework, only later realizing that,  you know, if honestly my intention is to introduce people to the idea just at a  high level that this e to the x function is more than you think it is,  maybe jumping straight to the crazy idea of matrices and expecting them to notice  the nuance of commutativity being relevant to the n choose k formula for binomial  expansion. Like, actually there's kind of a lot of advanced  things that go in there if we're really dissecting it.

================================================================================
VIDEO ID: ZxYOEwM6Wbk
TITLE: What is Euler's formula actually saying? | Ep. 4 Lockdown live math
URL: https://www.youtube.com/watch?v=ZxYOEwM6Wbk
PUBLISHED: 2020-04-28T19:58:20Z
STATUS: SUCCESS
================================================================================
Welcome back to Lockdown Math! Today we are going to be talking about Euler's formula. And just to give you a little sense of where we're going to be  ending up with this lesson, I'm going to go ahead and show you  what we're aiming for at the end, which is a certain visualization. So, I don't expect you to necessarily understand this immediately,  but the point is that this is something we're going to walk towards. What we're going to analyze is an extension of the idea  of exponentials in a way that works in the complex plane. And the illustration that you're looking at is showing  very literally what the claim of Euler's formula is. Because what I want you to appreciate is what the actual statement says,  rather than letting it be shrouded in a certain mystery or a certain question of what the  conventions are. Now, needless to say, this is kind of a confusing thing. We've got this spiral of vectors, and if it's not entirely clear, don't worry about it. I just want to give you a little sense of where we're going to be going with this. But before any of that, let's take a step back and remember where were we. Back in the end of the last lesson, when we were talking about complex numbers,  one of the key types of complex numbers that we were looking  at were those that existed on the unit circle. So here I have a little complex plane drawn. We've got the real number line with the points 1 and negative 1 indicated. We've got the imaginary number line, i being the square root of negative 1. And if you remember, one of the main points that we emphasized last time is that  when you have a number who's sitting one unit away from the origin at some angle theta,  multiplying by this number has the effect of rotating things by that angle. This is incredibly important throughout physics,  throughout electrical engineering, all throughout math. You see these numbers everywhere. They describe wave mechanics, they're very important for polynomials. It's really hard to overstate how important numbers that sit on this unit circle are. Now one way that you could write them is with the real and imaginary parts. And based on lecture 2, if we know our trigonometry,  the x coordinate is going to be the cosine of that angle,  and the y coordinate, which is the imaginary part,  is going to be i times the sine of that angle. So you might think, all throughout physics, all throughout electrical engineering,  you see the expression cosine of theta plus i sine of theta. In fact, what you often see is another form of this. Almost always, you see this written down as e to the power i times theta. And this relationship is what's known as Euler's formula. Now e is a special constant of nature, and I always remember in high school,  it was never crystal clear to me exactly what it was. It was something that was just kind of handed down, okay, it's 2.71828, on and on. And we were just taking, you know, we were to take this as an analog of pi. It's an irrational number that evidently the universe finds significant. I had one calculus teacher who would tell us it was the Andrew Jackson number,  because the president, Andrew Jackson, served two terms. He was the seventh president, and he was elected in 1828. So, there you go. I don't know if Andrew Jackson appreciated this relationship that he had to Euler,  but it always helped me remember the number. Now, just to gauge sentiment, because I'm not entirely sure where the audience is,  I want to know what your current relationship with this particular formula is. So we're going to do a poll to start, and this poll is mostly going to be helpful to me. So, polling up some of the warm-up questions that we had, where evidently most of you,  if you were to choose one of Euler's formulas,  would have gone with the one that we're talking about today, which is great, you know,  appropriate given where we want to head. As a poll that's actually going to be helpful to me, let me ask you,  which of the following best describes your relationship with the formula  e to the power i theta equals cosine of theta plus i times the sine of theta? Okay? And the options here are that you've never seen it before, totally understandable,  that you've seen it but you're confused by it,  that you still don't understand it but you've grown used to it,  or that you understand it well. So, as you can see, answers are rolling in. Please participate! This is going to be way fun if more of you participate. You can go to 3b1b.co slash live, link is also in the description,  that forwards you to the place where you can answer this poll. And while answers are rolling in, I just want to remind us of a more famous variant of  this expression that you often see, which is basically what happens when you plug in pi. So, if we say e to the i times pi, now we're thinking of pi as an angle,  it's a number of radians, a distance around the unit circle,  you would plug in cosine of pi plus i times the sine of pi. Okay? And the way to think about that is to look at the unit circle and ask,  what if you walked around until you'd walked a total distance of pi? You know, if it's a lake with a radius 1 and you walk around the  boundary until you've gone a distance of pi, kind of by the definition of what pi is,  that takes you halfway around the circle. So the x component, cosine, is going to be negative 1, and then the y component,  sine, is actually 0, so there's no imaginary part, it's just negative 1. And this gets us, you know, what might be the most celebrity equation in all of math,  e to the i times pi is equal to negative 1. Okay? But it's baffling, genuinely baffling, because you've got this  idea of raising a constant, which is a little wishy-washy to start with,  what is e, but you're raising it to an imaginary power. And if you don't understand what that means, you're in good company,  I think very few people in the world actually do. Now turning back to our poll, where we've got a good number of responses,  and a pretty good spread too, I'm genuinely curious to know,  who am I talking to right now? Okay? Because it looks like we have a pretty even distribution among all camps. Alright, so the number one most common answer is c,  which is those who still don't understand it but they've grown used to it. This, I'm going to guess, includes people like math majors or  engineering majors or people who have gone into a technical field,  where it comes up a lot, so you have to grow used to it. This is also revealing the fact that even though these lectures are targeted  at high school students, that this channel has a certain base demographic to start with,  so sometimes those sitting in the audience, it's more like adults who have  walked in and are sitting in the back of the class. Very happy to see that d, I understand it well, is the second most common answer. I'm curious among those who answer d, if by the end of the lecture they would  say that what they understood about this is the same as what I'm going to teach. Because for example, I would make the claim that this  formula actually has nothing to do with the number e, okay? That the number e doesn't actually play a role  in what this formula is computationally saying. And I'd be curious if those who claim that they  understand it well would agree with that statement. After that we have those who've seen it but are confused by it,  and at the very end is the actual target demographic of those who've never seen it before. Oh, I don't know if it's fair to call that the target demographic  because I think sometimes you see it in an odd circumstance here or there,  but definitely those who answered a or b, you're my people. You're the ones that I want to talk to about this, okay? But let's say you see this, okay? You see this weird formula e to the pi i, or the  generalization e to the i times some angle. I think the healthy reaction to have to this, okay,  if you're just seeing this for the first time, the healthy question to ask is w t f, okay? What is the function at play and how is it defined, okay? What's the function? Because in this case the function is e to the x,  and we're plugging in certain imaginary inputs. And I think a lot of people think that that refers to taking a number e and multiplying  by itself some number of times, and that x describes how often you're multiplying by  itself. And that yeah, there's some notion of extending that to things  like one half or negative one, or any kind of real number,  but that it's based in this idea of repeated multiplication. Now the thing that makes this equation misleading is that that's not the function. That is not what e to the x is referring to. Let's emphasize that very heavily. This is not what e to the x means. This is not its convention. Instead, what has emerged in math is that we use  e to the x to be a shorthand for another function. A function which I'm going to give the name exp. This is how you often see it in literature. And it's defined to be a certain polynomial. It's one plus x plus x squared divided by two plus x cubed  divided by six plus x to the power four divided by twenty four. And in fact it's not a polynomial, it's an infinite polynomial. We add infinitely many terms, each of which look like x to the n divided by n factorial. The proper term for this is a series. In practice, if you're actually computing this,  because that denominator grows so quickly, you can chop off  the series pretty early to get an approximate value for what this actually is. Now right away, we can see that this is going to  work for lots of kinds of x that we could plug in. Anything where we know how to raise x to a power, just a whole number power,  multiply it by itself, and where we know how to divide by a factorial and add  those together, we can come up with a nice meaning for what this exp function means. But before we jump into things like complex numbers and throwing that in,  I think it would be very unsatisfying to do that if we didn't first draw the connection  to the number e. And the idea of repeated multiplication. Because on the surface, this infinite polynomial seems very different from  the idea of some special constant of nature e and raising it to a power. So let's build up a little familiarity. We're going to take, you know, a couple minutes to do this. And it's a very healthy exercise I think to become friends with  this function by starting to plug in a couple different values. One of the first you might plug in is the number 1. So that way we get 1 and then x is 1, so that's 1. x squared is still 1, so that's 1 half. And then 1 sixth. And then 1 twenty fourth. And in general, we're adding 1 divided by n factorial. In math we say that this is a series that converges in the  sense that as we add more and more terms, it approaches a  certain value and it gets closer and closer to some specific value. And that value ends up being around 2.71828, the Andrew Jackson number. But at this point, just think of it as it was going to be something. x of 1 was going to be something. This is what x of 1 happens to be. At the moment, there isn't necessarily anything special about that. But let's say you wanted to plug in other values. Just to get a little practice with what that would look like, if I wanted x of 2,  it would look like 1 plus 2 plus 2 squared over 2 plus 2 cubed over 6. And in principle, if you were on a desert island and you just needed to compute x of 2,  you could work this all out by hand if you were comfortable with long division. But of course, we live in the modern world. We have computers, we have programming. So I think to make this especially concrete, let's go ahead and actually implement  this function so that we can calculate a couple values and so that it's not a black box. It's not just a calculator that's been handed to us. We implement it so we know exactly what it's doing. So for that, let's go ahead and pull up a little Python. This is Desmos. We might look at that a little bit later. Right now, let's be a little bit more programmatic. Let's pull up some Python. Let's import some math because that's a sign you're always going to have some fun. Then I'm going to define the exp function that's going to take in some number x. And what I want is to return something that looks like 1 plus x plus x squared over 2,  where in Python this double, what do you call it, an asterisk,  this double asterisk sign is how we do exponentiation. And then x cubed over 6. And we kind of want to add that up a whole bunch. Of course, instead of typing all that out, we can use a little special  syntax where I'm going to say, I want you to return a sum of a bunch of terms. Each term is going to look like raising x to some power,  and it knows what x is because that's what was handed to it. x to some power divided by the factorial. Factorial of n. And that's built into this math package that we imported. And I'm just going to do this for values of n that start at 0. 0 factorial is defined to be 1, if you're curious. We could talk all about factorials of weird values at a later date,  but that's all you need to know here. And I'm just going to have it range up to 100 because 100 factorial is going to be huge. So that's going to be plenty big enough for a denominator to  be small enough that those later terms don't contribute a lot. So even if you don't know Python, I hope that this is a reasonably  clear way to turn the math into something that our computer can chew on,  and crunch through the numbers so that we don't have to. So for example, if we type x of 1, we get the Andrew Jackson number. 2.71828, on and on. And I could type in x of 2, and it looks like that's around 7.389. So maybe we even write that in our notes. We go over here and say, interesting, x of 2 was about 7.389. Okay. And if you spend a long time just kind of playing around with this, okay,  I think it's not obvious that you might find this,  but if you were just plugging in a couple values, x of 3, x of 4,  one important fact you might stumble across is that if I add two numbers in the input,  okay, so in this case I get 1096 when I plug in 7, which is 3 plus 4,  that actually ends up being the same as if I plug in x of 3 times x of 4. Okay. So adding the input corresponds to multiplying in the output. And 3 and 4 weren't special here, I could have done,  you know, 5.5 and 3.2, and that would have gotten me some value. And if instead I had added those together, okay, it gets the same value. That is not at all obvious, okay? So I think that would be a genuine discovery to have with respect to this function,  with this polynomial, if that was something that you found. And it's important enough that I want to write it down. Exp of a plus b is actually the same thing as exp of a times exp of b. Now if you just look at the polynomial, this is not clear. This is not something that, like, you look at it and say,  oh yes, of course, it couldn't have been any other way. At the end of today's lesson though, I'm going to give you guys some homework,  and yes, homework will make you learn better. And what we're going to do is go through a couple problems  that are going to have you show that this fact is true. That simply from the polynomial, and the fact that it includes these factorial terms,  excuse me, that's going to be enough to show this very special property. Now why am I calling it a very special property? Well, I want to ask you a certain question that will hopefully make this clear. And it really is important that you think this through yourself. Because I think if we, uh, if I just kind of tell you the implications here,  it's not going to sink in to the same extent as if you really noodle with it yourself. So I'm going to pull up another question, and I'm  going to give you some time to think on this one. What the question asks us is to suppose that we have  some function f of x that has this special property. We're adding two numbers in the input, f of a plus b,  gives the same result as multiplying in the output, f of a times f of b. And that this is true for any real number, a and b. Okay? Suppose you have some function that satisfies this property, who cares how it's defined? Whether it's through this polynomial, through other means. Which of the following is true? One of the options is that f of five is equal to f of one raised to the power five. Another is that f of one half is equal to the square root of f of one. And the other is f of negative one equals one divided by f of one. Now very important, I'm not asking does there exist  some function f where these three things will be true. I'm asking which of these necessarily has to be true only from that property. So you shouldn't be able to contrive some sort  of adversarial function that doesn't satisfy it. And then you have various options for which collection of these three things is true. I'm going to give you some time to think about  this because I really do think it's important. So I'm going to turn up our pause and ponder music to get us in the mood. And take a desperately needed drink of water. While you're noodling on that, I'm going to go  ahead and take a question from the audience. Where it looks like Serft asks, what do you think is more  interesting to someone who is a newcomer to higher level math? Special case theorems like e to the i pi or more general cases like e to the i x. Oh that is such a great question. By the way, anyone who wants to ask questions go  to Twitter and just use the hashtag lockdown math. Those will be forwarded to me. I think the best way to learn is to have specific examples and really let yourself  understand the patterns represented by those specific examples and then generalize them. For the specific one that you have here, I think if you just see e to the i pi,  that doesn't really count as a good specific example that explains the generality. It's more that you're plugging in one particular number into a formula. So in this case e to the i x, as you'll see, it has everything  to do with circular motion and between this lecture and the next one,  we're going to talk about why that relation might be there. So the form of having specific examples that aids your understanding wouldn't be,  you know, a number like e to the i pi. It would be building a relationship with circular motions and other  circumstances like studying physics where you have a tetherball with  some kind of centripetal force and it's orbiting or like orbital mechanics. Anything where you're really understanding the nature of circular motion,  that actually prepares you for understanding e to the i x as a generality a little  bit better. So with all of that, answers are still rolling in and I don't want you to feel rushed. So I'm going to give a little bit more time here actually. Because remember, you need to really be sure that if you're saying  that something like 2 or 3 or 1 is included in your answer that  any function with this special property necessarily follows that. Oh, let's see if we can grade it when the top answer is the year. So 2017, that's a little bit in the past. 2013, we're losing the top answer. Interesting, people are changing their mind. It's like we're going back in time. So it looks like a couple people are, oh now we're in the future, 2023. Yeah, so we're actually seeing people think about it and thinking,  hang on, you know, is it the case that option 3 here is necessarily true? And they're really being critical about that. So that's a good sign. If you want to keep thinking about it, please do. But for the sake of continuing with the lesson,  I'm going to go ahead and lock things in here and see how people ended up answering. So it looks like 2030 of you, the decade in the future,  believe that all three of these are necessarily true. So, second most common answer was B, they only believe that the first one is true. And then after that, people who either included number 2 or number 3. And the correct answer is that all of them are. And it's very interesting to walk through why. I do think it's very elucidating. So let's go ahead and do this. The first one, which it seems like a majority of you believe,  is that if we plug in something like 5 to a function with this special property,  that it'll be the same as taking f of 1 raised to the fifth. Now the reason is that we could also write 5 as 1 plus 1 plus 1 plus 1 plus 1. And this property of addition in the input becoming multiplication in the output  means that's the same thing as writing x of 1 multiplied by itself 5 times. Okay? It lets you rewrite the whole thing in terms of x of 1, which I'm going to say 5 times. This is the same as taking x of 1 raised to the power 5. And here when I'm writing exponentials, anytime you see a natural number or a  whole number, it can literally mean multiplying by itself that number of times. That's not the same as the fact that e to the x is a shorthand for this crazy polynomial. So that can sometimes get a little confusing, the exponent is playing two different roles. And we might give x of 1 a special name, a shorthand. Let's just call it e for short. That's not why we call this number e, by the way. It's also not because this is what Euler's name starts with. It's just because whenever Euler was using this, the first time in a particular book,  he was partial to vowels and the vowel a had already been used. So e was just his arbitrary letter. Okay, so simply by virtue of this property, we can  see that x of 5 has to be written in terms of x of 1. Now a little bit trickier was the question about plugging in 1 half. Okay? And the key to solving this, it's a little bit tricky,  is to think about what happens when we multiply that by itself. Exp of one half times exp of one half, because of this property,  has to satisfy, or I should say has to equal exp of one half plus exp of one half. Which is of course x of 1, which let's say we're using the shorthand and we call it e. So what does that mean? x of 1 half has to be a number such that multiplying it by itself equals e. Well that's what we mean when we write square roots. Okay? And the last one was talking about negative inputs. So just as an example, if we inputted something like negative 1. So the key here is to ask about multiplying it by the value when you plug in 1. By this rule, that addition in the input turns into multiplication in the output,  that has to be the same as exp of 0. Now what is exp of 0? Ooh, you know what I'm realizing. Hmm. I think I might have actually made the, entered a wrong answer there. Because in our case, in our case exp of 0 actually does come out to be the number 1. Okay, so if we plug in 0 for x, then all of these,  you add them together, the only term that matters is 1. So exp of negative 1 times exp of 1 is equal to exp of 0, which is 1. So this is true in the case of exp. I, I can't actually think to myself right now if that's necessarily true. You know, if we look at our question, where it's saying all  we know about f is that f of a plus b is f of a times f of b. If that necessarily implies that f of 0 is going to be 1. And I, I don't think it does. I think we could construct a function. Yeah, because we could just scale e to the x by some other amount. Okay, yeah, so actually what's graded here is not entirely correct. The correct answer would be only 1 and 2. I think. Someone correct me on Twitter if I'm wrong about that. But, very interesting. So if we go back to our paper, let's see. In the case of exp, this, this value at 0 would be 1. What does that imply? Well, if we call exp of 1 e, that means we're asking  what is the number which when you multiply by e equals 1. And it would be 1 divided by e. But yeah, for the general case, we need the added  condition that when you plug in 0 you do get 1. Now the point of all of this, right, the reason that I'm saying this,  is to emphasize why it's reasonable that we use the shorthand. That when we say exp of x, for real numbers x,  why it would be very reasonable to write this as e to the power x. Because basically this special property means that because  you can use the number 1 to access pretty much all the real  numbers by adding it to itself or dividing as needed or negating. And then if you have certain continuity restrictions that  will let you extend from rational numbers to all the reals. But that's a technical point, you don't need to fuss over for what we're doing right now. It lets you basically express everything that this polynomial  can output in terms of what it outputs at the number 1. So you might read e to the x as just, whatever this polynomial is at the input 1,  we can start exponentiating in terms of that. So that's the connection, right, we could, we could if we wanted define  the number e to simply be where is this polynomial at the number 1. And then all of this would follow. But I really want to emphasize that only makes sense for real numbers. Because as soon as we start introducing things like complex numbers,  you can't just add 1 to itself or subtract and divide and get the number i. And in math you often do even crazier things where  you plug in things like matrices into this polynomial. Which seems weird, but you know, you can take a matrix and square it,  you can divide it by 2, you can add all of those together. And that's actually a very useful thing. It's very useful for a field called differential equations,  which in turn is useful for physics. In quantum mechanics you often plug in these things called operators,  which are kind of like the mature older brother of matrices. And all of that looks totally nonsensical if we're  talking about a constant raised to some kind of power. But what you have to understand is that it's being plugged into this polynomial. So I understand why we have the convention of writing this as e to the x. It makes sense for real numbers. But I think that's actually a bad convention as soon as we start extending it. And I think that causes a lot of undue confusion. So with all of that said, let's finally have some fun and plug in some complex values. And before we do that, just as kind of a warm up,  I want to make sure that we're comfortable with powers of i. Because that's what's going to be important here. So let's pull up our quiz and let's go ahead and ask one more question. And then I'll take a question from the audience too while you guys think about this. Remember that i is defined to be a value that satisfies i squared equals negative one. So that's defined. For which values of n does i to the power n equal negative i? So the spirit of this question is to have people thinking deeply about powers of i. And I wanted it to be a question that's not totally obvious. So one that you do have to put a little mental energy into. So let's go ahead and take a question from the audience while I take a drink of water. F of x equals zero doesn't work with f of negative one equals one over f of one. Yeah, f of x equals zero. Oh, interesting. Yeah, okay. So they're saying that if f of x ever outputs zero. Actually, I'm not entirely sure what Sam is saying. F of x equals zero doesn't work with f of negative one equals one over f of one. So I guess that fact that f of negative one is one over  f of one doesn't imply that the output will ever be zero. So I could ask for some clarification, but I think that might  be getting at the general point of the mistake of the question. Which was to assume, to extend the idea of exp a little bit too much. Where the fact that exp of zero equals one gives us this other property. And then Crispin Simmons says three is included because f of x plus zero. Oh, okay. Yeah, okay. Great. Great. Yeah, someone thought this through a little bit more deeply  than I can while live and on camera and under some pressure. F of x plus zero is the same as f of x times f of zero, which implies f of x equals one. Awesome. Crispin, you saved me. You saved me on this one. That's a beautiful way of thinking about it. Yeah, all of these questions where you have like a  property of a function and you're supposed to deduce facts. They can be very subtle. And so in this case, okay, the question was graded correctly. The property simply that addition in the input becomes multiplication in the output is  enough to imply f of zero equals one, which in turn locks in the value for f of negative  one. Oh, it's so pleasing. One little property can just lock in basic, not the whole real number line  because it didn't assume continuity, but it locks in pretty much any value you want. Awesome. Excellent questions. I love live stuff. Even if I make errors, it does feel a little more interactive than the usual videos. So let's see how we're doing on the quiz. Looks like we've still got some answers rolling in. We're trying to understand which powers of i are equal to negative i. And the options include multiples of three or multiples of three  as long as they're positive, or integers one below a multiple of  four or those where you're restricted to them just being positive. And I'm going to go ahead and grade this question. And as always, if you feel like you weren't done by the time I'm locking it in,  know that that's just for the sake of letting the lesson progress forward. If you wanted to pause and think about it further yourself,  especially if you're watching this later, that would be totally in the spirit  of these lessons. Okay. So the majority, or the plurality, I guess, of you answered that  it's all integers one below a multiple of four, which is correct. And the second most common answer was basically the same but restricted to positives. Great. So let's think through what powers of i actually look like,  because this is going to be the only thing we really need to plug in complex values  into this exp function. And the way this can work, if I pull out my infinite supply of unit circles,  is to remember that multiplication in the complex plane includes a rotation component. And because i has a magnitude of one, there's only rotation. So multiplying by i has the effect of rotating 90 degrees. If you multiply by i twice, okay, i squared, you end up 180 degrees around. Reassuring, it's supposed to have a square of negative one,  and this geometry lines up with that fact. If we multiply by itself three times to get i cubed,  it ends up being a vector pointing straight down. Multiplying by itself a fourth time, 90 degrees, takes us back to one. So i to the fourth is one, and then after that they all start repeating. So basically all you need to know is where is  that exponent with respect to powers of four. If it's a power of four, you're at one. If it's one above a power of four, you're at i. Now the trickiness of the question was to also include the nuance  of whether this is only for positive powers or negative powers. But what a negative power means, if we write something like i to the negative one,  that's defined to be one over i, the number such that when you multiply by it,  you get one. And you can see that that's actually the same as i cubed. This is the same as i cubed because that's a number where when we multiply it by i,  we get one. Negative one, that's also one below a multiple of four. And in general, anything that's one below all the  negative multiples of four will also satisfy this property. So it's a little tricky question, but it's just because I wanted you to think deeply  about this idea that powers of i, of whole numbers,  just have us ticking forward by 90 degrees. And finally, we can have our fun. We can take our crazy exp function, and we could plug it  into Python if we wanted to and see how things play there. But first, let me go ahead and visualize it for you. So I'm going to, uh, let's see, that circle is already suggestively drawn,  but I don't want that to be there. I just want you to think about this polynomial where I'm going to plug in i scaled  by some kind of constant, which very suggestively I'm going to give the name theta. And then what that means is taking one plus i times theta plus i theta squared over two,  on and on. And just as an example, let's crank theta on up until it equals one. And let's try to think pretty deeply about what this actually means computationally. The first term is one, which we might draw with this green vector on the bottom,  pointed one unit to the right. The next term is going to be i times one, so just i. It's pointed straight up with magnitude one. Now think about what the next term is. It's going to be i squared, or i theta squared, but theta is one,  so it's i squared, which is negative one over two. So that's why this next vector is pointed to the left, and it has length one half. Okay? Then after that, i cubed is pointed straight down, and we divide it by six. So now we just have an itty bitty vector that is of magnitude one sixth,  and then they just get smaller from there. The next one is pointed to the right, but it has magnitude one over twenty four,  and they just shrink a whole bunch. And so we get something. It's clear that this is a computation that makes sense to do. It's not clear how we would know where it ends up. That feels like it's going to require real math to have some kind of theory behind it. We could be computational, and pull up Python,  and remember that it actually has built-in support for complex numbers. If I write something like complex of two three,  it gives me a complex number with real part two and imaginary part three,  and what's cool is that it already knows the rules for multiplication. So I could multiply this by other things, it knows how to take their product, very cool. Now given that our definition of this exponential function, if you'll remember,  was only ever in terms of raising something to a power and scaling it by a factorial,  and then adding all those terms up, well it should make sense to plug in something  like complex zero one, which is how we write i in Python, and see what it pops out. And indeed, it crunches through the numbers, and it gets for us  something whose real part is evidently around point five four, who knew? And whose imaginary part is around point eight four,  and in terms of our visual, you know, that checks out. It looks like the real part is a little above point five,  so point five four, I believe that. And the imaginary part is, it claimed what, point eight four? Yeah, that seems about right. So at this point, we can actually think, what is the claim of Euler's formula? What is it telling us about the behavior here? And my hope is that Euler's formula might have started off mysterious,  but mysterious in a bad way, okay? Because when you initially see this expression,  e to the i theta is equal to cosine theta plus i sine theta, telling you that,  oh, I guess imaginary exponents get us on the unit circle,  it doesn't leave you wondering about a real pattern,  it leaves you wondering what the convention is, right? It leaves you wondering, WTF. However, right now what we can see is what this is saying is if I plug in i times theta,  evidently that's the same as walking around a unit circle. Now that feels very substantive, there's a lot of content to be had in that expression,  because if we go to our visual, what it's telling us is that if I,  if I crank up this value of theta, the place that the sum of vectors  converges always sits on a circle that's one of radius one. That's not obvious. If you just look at this expression and you think through what it's saying  very literally, that is definitely not something that just pops right out of it. But it becomes a lot more beautiful, in my opinion,  because you're no longer asking questions of convention,  you're asking questions of the universe, of actual patterns. So just to take the most famous input that there is,  plugging in pi around 3.14, let's think about what this is actually saying. It's saying, okay, the first term is one, so we've  got our vector pointed one unit to the right. The next term is i times pi. Okay, so that's going to be a vector that's pointed up because of  the i with a length of pi around 3.14, which it looks like it is. The next one is going to be i squared times pi squared over two. So that i squared means that it's negative, okay, it's pointing to the left. And I guess the magnitude is pi squared over two. We could do a quick gut check if we wanted and just ask ourselves,  you know, what is pi squared? It's around 9.8, same as the gravity on Earth in terms of meters per second squared,  which is always fun. And dividing that by two, it looks like it's 4.93. Okay, does that check out? Yeah, I buy it that the length of this vector is just less than five, so 4.93. And then the next one, because of the i cubed,  is pointed down and the magnitude is pi cubed over six. Evidently that's around the magnitude of pi cubed over six. And so far the vectors have been getting bigger,  but it's at this point they start turning around because basically each time on the,  for each new term, the numerator gets an extra pi thrown in. But the denominator now gets an extra four thrown in. Like going from six to 24, you're multiplying by a four. And then it's going to get an extra five and then a six. So the denominator is going to start growing much more than the numerator,  which is why the vectors shrink and shrink and start to converge to a point. So the i in there is what's letting these vectors all turn  90 degrees each time and give us this very pretty spiral sum. And the claim of Euler's formula is this very fascinating fact,  that evidently when the vectors are rotating according to powers of i,  and when their lengths are changing according to powers of pi divided by n factorial,  they all conspire in just the right way, that they land at the point negative one. That's interesting. Still mysterious, but mysterious in a good way. And it's making an even stronger claim, which is that any other  angle that we might put in, it puts us on a unit circle at that angle. Now this is especially mysterious when we consider the fact that as we let this value  just continue increasing, it's not even clear that the function would be periodic, right? Because as theta increases, more and more of the vectors become relevant,  because it takes longer and longer for the denominator of our terms to win out,  and yet they stay very nicely constrained onto the unit circle. I think that's interesting. So just to do a last little concept check here,  I'm going to ask you one final question to basically see if you've been paying attention,  see if the claims made stand to reason. So getting rid of our powers of i, the last question  is a wind-down question of sorts for the evening. Which of the following values is closest to e to the 3i? So as usual, this is the link you can go to. Which of the following values is closest to e to the 3i? Now as you're answering, let me just remind you that the main takeaway  I want you to have from this lesson is that the way that you read  this is not to think about a constant e raised to an imaginary power. Because that doesn't really make sense when we're  thinking of powers as repeated multiplication. However, what does... Let's see... Seems like we have some controversy over the last question. We'll address that in a moment. But what you should think about here is the fact that e  to the x is shorthand for this general polynomial, okay? And this general polynomial, it turns out to be very  relevant in things like calculus in a future lecture. I'd like to start talking about why this idea of  x to the n over n factorial and adding them up. Why is that useful? Why would anyone care? Why would it give rotation? But if you know that that's how to read it, hopefully this isn't a nonsense question. And it's not one that just asks you to blindly believe convention. It kind of asks you to blindly believe a claim about the fact that this follows a circle,  but we'll address that in the next lecture. And I think that's enough time to go ahead and grade this. And the correct answer is b, which around 3800 of you nicely got. Well done, well done indeed. And it's around negative 0.99 plus 0.14i. So the expectation isn't that you're a machine who can calculate that in your head. It's instead the idea that if we go over to our visual,  where we're plugging in values of theta, and you ask what happens when you plug in 3,  that the claim of Euler's formula is that we walk three units around a unit circle. Knowing that pi units takes us all the way around,  three units should take us so that the real part is really quite close to negative 1,  and the imaginary part is something positive. And of the options you were given, those were the only ones in there. Now the very last thing that I would like to emphasize here is that  nothing about this actual expression has to do with the number E. Has to do with the number 2.71828, on and on. If we were to go to the computation taking place,  if I plug in something like exp of a complex number whose real part is 0  and whose imaginary part is pi, which at first it might look like it's  outputting something other than negative 1, but it's saying the real part is negative 1,  and then some numerical error because, partly because of how we defined it,  you know, only doing so many terms, and partly because computers can't do  infinite precision. The imaginary part, it might look like it's saying 3.45,  but really it's saying times 10 to the negative 16th, that's what that means. So it's basically 0. If you wanted to see this we could maybe import numpy and do something like round it. So I can round this thing to, I don't know, 8 decimal places,  and we see that, okay, it's basically negative 1. So this is the function that we wrote, showing us that e to the pi i is negative 1. But what I'd like to emphasize is that nowhere  in that function did we include the value 2.718. In fact, nowhere in the computer's memory during the execution  of this computation would it encounter the value 2.718. I would submit to you that that value is not relevant to the equation  e to the pi i equals negative 1, which is kind of funny, right? Let's at least write out what the relationship is, because, you know,  I'm not going to say there's no connection between e and pi, there is one,  but I think when you write the very famous celebrity equation e to the pi i  equals negative 1, it heavily overstates the connection that there is between  this e and that pi. What's really going on is that we have this function exp that we've defined,  and that when you plug in real values, okay, when you plug in real numbers,  for the reasons we talked about earlier, it makes sense to write exp of x  in terms of whatever its value at 1 happens to be, exp of 1 raised to the x. And that we often call that value exp of 1 e, okay? This is a property of the function. Another fact about this is that when we plug in imaginary numbers,  the claim of Euler's formula, which I haven't shown why it's true,  but the claim that it's making is that it's periodic, basically. That it walks around a circle, and it's periodic with a period of 2 pi i. Basically when you increase that input by 2 pi i, you get back to where you started,  and even more specifically that you do so by walking along a circle. So it's saying that each of these constants is a child of the function exp of x, right? But the way that they're related kind of happens along different dimensions. That I think is the healthy way to understand this formula. Now in the next lecture, we are going to be talking  about why this thing walks around in circles. And that necessarily involves a little bit of calculus,  so we're going to get a little bit of calculus into the mix here, but as minimal as I can. And before then, I want to leave you with some homework. Because if you remember, the core property that related this  strange polynomial with factorials to the number e was that  addition in the input is the same as multiplication in the output. So before next time, I won't grade this, this is just,  you know, to do on your own time in your own way. Question number 1, I want you to show that when you fully expand exp of x times exp of y,  and you know, you might have written down for yourself what this function is,  it's all those factorial things. Show that when you expand that out, each term has the form x to the k times y  to the m divided by k factorial m factorial for certain whole numbers k and m. And remember, 0 factorial is defined to be 1. Question number 2, show that when you expand exp of x plus y,  so addition in the input, each term is going to look like 1 over  n factorial times n choose k times x to the k times y to the n minus k. If you're not familiar with this term n choose k,  take a look at the binomial formula, I'm sure there's plenty of  excellent videos on YouTube about it, I'll leave links in the description as I find them. But show that that's true. Question 3, compare the two results that you just found to explain this key property. The thing that relates this function to some special  constant and the idea of raising it to powers. And then if you're up for the bonus question, this is kind of the,  this is for all of the extra credit in the world, justify,  see if you can say, will this result still be true if x and y are complex numbers? And will it still be true if they're matrices? That actually I think is a very important exercise to go  through to understand when this is true for what kinds of inputs. Because like I said, as you get deeper and deeper into math,  this exp function remains very relevant and you start plugging in things that seem  wilder and wilder. It's useful, it is genuinely useful, and it's important  to know what properties carry over and which ones don't. Now, I was talking a little about this lecture with a friend beforehand,  and I mentioned the spirit of the lockdown math series being like high school classes. And you know, he looks at me quizzically and he's like,  is this, is that a high school topic? And the honest answer is I don't know. What I can say is that it is the case that in high school,  we came across the formula e to the i theta. I think the first time that I ever saw it, it was in,  you know, learning about complex numbers. It was just taught as the polar representation of complex numbers to emphasize this idea  that when you multiply two things, you multiply their magnitudes and you add their angles. But it was just this strange thing handed from on high. The usual way that we teach a relationship between e to the x in  this polynomial comes from a piece of calculus called Taylor series. And you start with the function e to the x, always defined in a little  bit of a wishy-washy way, depending on the course that you're taking. And then you show that it's connected to this polynomial. But I think there's no reason we can't go the other way around. And I actually wish that I had seen this. I wish that I had known from the beginning that through math,  especially through deeper math, that this is what the expression e to the x  actually means. So with that, I'm going to call an end to the proper lecture and just  take a couple more questions from the audience to finish things off. Maintain the interactivity that is the spirit of our lectures. All right. Great, great. We have more discussion. I love this. Crispin's proof is wrong. The constant function f of x equals zero. Ah, wonderful. Excellent counter example. I think this was maybe niggling in the back of my mind. It's like, I don't think this is unique. Great. So you have the case of a function that is constantly equal to zero. And I think whoever was asking a question earlier that I didn't quite understand,  I think this must be what you were getting at. And I didn't. I just wasn't reading it properly. But yeah, that would be a function where f of zero is not necessarily one. Beautiful. All right. So that question that I said was wrong and then I said it wasn't wrong,  it actually was wrong. So thank you very much, Eric Moss. And to everyone who can think more clearly about things than I can while live on camera. And then another person points out exactly the same thing. I love this. This is just like a real class. I'm up here. I get to make mistakes. You're down there. You get to correct them. And I think it makes it better for everyone watching. There's a legitimate discussion to be had. What's relevant in the case of the exp function is just that it's not constantly zero. That it does, in fact, equal one at the input x equals zero. But I love this discussion. And I think I can imagine no better place to end things than right there. So as always, thank you for joining. I hope this helped provide a little bit of a different perspective than what you usually  see in other classes on what's a very popular topic on the Internet,  at least as math goes. And next time we're going to talk about why it's true, where the circle would come from. I hope to see you then.
844
00:50:54,660 --> 00:50:39,160
.

================================================================================
VIDEO ID: 5PcpBw5Hbwo
TITLE: Complex number fundamentals | Ep. 3 Lockdown live math
URL: https://www.youtube.com/watch?v=5PcpBw5Hbwo
PUBLISHED: 2020-04-24T20:31:26Z
STATUS: SUCCESS
================================================================================
Today we are going to talk about one of my absolute all-time favorite pieces of math. It's incredibly fundamental to engineering, to mathematics itself,  to quantum mechanics, but it's something that has a terrible, terrible name. We call them complex numbers. And worse than that, the things that bring about  complex numbers we call imaginary numbers. And before we get into any of it, what I want to do is start with kind of a poll,  just to poll the audience on seeing what you guys can consider to be, well, real. What do you consider to exist when it comes to numbers? So we've already been doing a couple polls in the warm-up animations,  but as a serious poll of sorts, one that's actually going to help me see where  you're coming from before we begin the lesson here,  I just want to ask you a very simple question. Okay, so let's go ahead and pull it up here. Pull it on up. And, oh, for whatever reason it seems like we're having trouble polling this one up. Okay, there we go. Took a little delay there. Among the values 2, square root of 2, square root of negative 1, and infinity,  which would you personally consider to really exist,  whatever really existing means to you? So in theory, if you guys go to 3b1b.co slash live, you should be able to answer this,  and then the statistics based on your answers are going to start populating the screen. We won't know what those answers refer to. At the moment, all we know is that, you know, someone who has a lead,  another one that's pretty close behind it, and as your answers come in and  as the servers kind of digest them, we'll start to see some of the stats here. If you go to that page, by the way, 3b1b.co slash live, which redirects to itempool.com,  what you're going to find is at the very top, you can ask a question on Twitter,  and all that's going to do is basically open up a tweet that's going to have the hashtag  in it, lockdown math, and that's the way that we're going to be doing questions to this. Instead of a live chat, anytime you have a question or a comment that you want to,  you know, insert into the lesson and let that be part of the discussion,  it's going to be pulled up here, and it looks like we already have one. This is from Yash Dave, who asks, if you could rename the complex numbers and the  so-called imaginary numbers to something more intuitive,  to a name that conveyed the fact that they have numerous applications in the real world,  what would you name them? I couldn't be happier that you asked, Yash. So I have one friend who seems very passionate about  the fact that we should call them sneaky numbers. Personally, I'm very fond of trying to connote spinning and rotation,  and this is one of the things we'll talk about in today's lesson,  is the fact that what we call complex numbers, what we call imaginary numbers,  some of the main uses that they have come from very elegant descriptions of  how to rotate stuff, and I hope you'll kind of see what I mean as we proceed with that. So on our poll, asking you guys which numbers you consider to really exist,  which is of course a subjective question, there's no right or wrong answer here,  I am genuinely curious, actually, how this breaks down,  because it's not at all a strong consensus in one direction. It seems like we've got three top contenders, and then three that are  falling pretty evenly behind that, so let's go ahead and take a look. What do you consider to really exist when it comes to numbers? Now, I can imagine which ones might be the top two,  but I'm very curious about the fact that there's three all kind of coinciding with each  other there, and it looks like I'm getting a little bit of a delay before the reveal,  so there's kind of this nice dramatic pause. I'll tell you, for me personally, I feel like it's very silly to  answer anything that's either that's not all of them or none of them. I can maybe understand if someone wants to treat infinity as something different,  because it's ill-defined. There's lots of different things that that might mean,  but insofar as numbers exist at all, if you consider what a number is to be a real thing,  then it would... oh man, I can't believe that we're stalling out on this one.  We had fixed it by live stream too, but I guess there's going to be an  oscillation between when it works and when it doesn't. So, for me, I think that the question is, well, man,  I can't believe that we're stalling out on this one. t has a kind of reality in our minds, and things like the square root of two,  which you can't express as a fraction, or things like the  square root of negative one that don't show u But for me personally, basically, anytime that you have a numerical  construct that's helpful in the real world, you know, I consider that real. What I'd like to do for you today, basically, is show you the sense in  which imaginary numbers are useful, the complex numbers are useful, an d from there maybe try to imbue them with a little more reality.  I won't assume that you know what they are yet, it's meant to be a basic primer,  but let's just dive right in, okay? The end, by the way, the very end here,  I want to talk about two different trigonometric functions, and And things like the square root of 2, which you can't express as a fraction,  or things like the square root of negative 1 that don't show up among real normal  numbers, you know, even if they might seem a little bit different, oh,  this is such a shame. ing that we're going to build to, two identities from trigonometry,  and I understand that maybe, oh, these complicated identities from trigonometry  is not going to be the best way to lure some people into understanding,  oh yeah, complex numbers, they're really useful, you're really going to love th em. But I do think it's interesting that you can have a fact tha What I'd like to do for you today, basically, is show you the sense  in which imaginary numbers are useful, the complex numbers are useful,  and from there maybe try to imbue them with a little more reality. I won't assume that you know what they are yet,  it's meant to be a basic primer, but let's just dive right in. ou can have facts that are pretty hard to remember.  I remember when I was in school and we learned these addition formulas,  that if you want to know the cosine of the sum of two different angles, you know,  it's this kind of long thing in te And I understand that maybe, oh, these complicated identities from trigonometry  is not going to be the best way to lure some people into understanding, oh yeah,  complex numbers, they're really useful, you're really going to love them. But I do think it's interesting that you can have a fact that has  nothing to do with complex numbers or the square root of negative one,  it's just trigonometry, it's everything we were talking about last time. And you can have facts that are pretty hard to remember. I remember when I was in school and we learned these addition formulas,  that if you want to know the cosine of the sum of two different angles, you know,  it's this kind of long thing in terms of cosines and sines of the original two angles. y who's going into serious math, they'll tell you that complex numbers are as  real a part of their work and their life as real numbers are.  But the starting point looks very strange, okay? When you start introducing this,  the very first thing you do is to say, assume that there's some number i so that  i squared is equal to negative 1. And I think to a lot of students  there's maybe one of two possible reactions that you can have here. It's something that's very error-prone if you're just trying to memorize it as it is. However, if you come at it with complex numbers, this is not only much less error-prone,  it has a very beautiful meaning and it just falls right out. So even if you don't necessarily believe in the reality of the square root of negative  one, you at the very least have to admit that it's interesting that it can make other  pieces of math useful, that other pieces of math a little bit more understandable too. d says, oh no no it exists, we've defined it so that that's the case.  I think the other reaction someone can have is, hang on a second, you can do that? If you talk to anybody who's in engineering, anybody who's going into serious math,  they'll tell you that complex numbers are as real a part of  their work and their life as real numbers are. But the starting point looks very strange, okay? do when you start talking about complex numbers is to say,  there's not just such a number i, but we're going to give it a home.  Instead of the real number line, which you know all of these numbers we know when we  square them, you can't get a negative, wha t we do is say i lives in a different dimension. i lives perpendicularly,  there's one above and then there's one below, negative i, and you can have negati ve 2i, you scale it however you want. Essentially it's proposing that  numbers be two-dimensional and that i has a very specific home,  one unit perpendicular, uh, perpendicularly above the real number line. Any time I square a number, even if it's negative,  if I take negative five for example and I square it,  well a negative times a negative is a positive, so I get 25. Any number that you square, if it's positive, well that just stays positive. So it seems like no matter what, when I'm squaring numbers I always get a positive number. I'm never going to get anything negative. and then you move in that perpendicular direction into the extension of our number s ystem, which again, you're kind of asking the students to take a lot on faith here  that you're okay to do that, that you're allowed to just pretend that the numbers I think the other reaction someone can have is, hang on a second, you can do that? When you have a problem that you can't solve you can just say,  oh I've defined things so that we now magically have a solution. Okay, next time I'm having trouble with my homework and I don't know what the answer  to x is, I will be like, let x be the value defined to be the answer to this question. So if you're uncomfortable with this, you're definitely not alone. In fact, Rene Descartes coined the term imaginary for these numbers as a derogatory. It was meant to make fun of the fact that obviously there  is no such answer and it shouldn't be taken as serious math. And then we stuck with that as a convention and we still call them imaginary numbers,  which is genuinely absurd. like there's a, there's a back and forth between answers f and d,  so f is all of them, saying that all of these should be considered real.  And interesting, d is the one that says you The second weird thing that you do when you start talking about complex numbers  is to say, there's not just a number i, but we're going to give it a home. Instead of the real number line, which you know,  all of these numbers we know when we square them, you can't get a negative,  what we do is say i lives in a different dimension. i lives perpendicularly. There's one above and then there's one below, negative i, and you can have negative 2i. You scale it however you want. Essentially it's proposing that numbers be two-dimensional and that i has a very  specific home, one unit perpendicular perpendicularly above the real number line. And okay, if we want to extend our number system, I get it,  maybe it's useful to put some kind of number up there, but why i, right? Why not say infinity is the number that sits one unit above zero,  or one divided by zero, or any other problem that you couldn't  solve before and you make up an answer to, why should that live there? What on earth does the idea of a point one unit above the real number  line in a separate dimension have to do with squaring to negative one? So I hope to answer this for you. At the very beginning, let's just talk about how if you're adding numbers that  are two-dimensional like this, the rules are pretty straightforward and it operates  essentially the same as vectors for any of you who might be familiar with vectors. So I guess I can pull it up on the, just on the piece of paper,  and you can follow along at home, see what the addition might be.  It turns out to be relatively straightforward. If you're moving four units to the And then I'm going to take a second number and it's helpful to draw them as vectors,  kind of an arrow from the number zero, and this one is going  to end up at negative two plus two i. So what I'm saying is you take the real number negative two and then you move in  that perpendicular direction into the extension of our number system,  which again you're kind of asking the students to take a lot on faith here that  you're okay to do that, that you're allowed to just pretend that the numbers extend  in this direction. can get you something like it. But the rules end up being very different  from that in the number system. You can't really do algebra.  You can't do things like assume that if two numbers multiply to make zero,  then one of them h as to be zero. But complex numbers are going to  end up behaving much like the real numbers, s Now assuming that our question system has not broken down,  I should be able to do this as a proper poll and let me go ahead,  I guess we can first check the previous poll, okay things seem to be working so we  can take a little step back in the lesson so I'm just genuinely curious,  I want to know how you guys answered on this one. It looks like there's a there's a back and forth between answers f and d,  so f is all of them saying that all of these should be considered real,  and interesting d is the one that says you should consider two square root of two and  negative one but not infinity, so there's a good contingent of you out there who would  just reject infinity as being considered real but are very comfortable with the square  root of negative one, that's awesome, and then after that it looks like c,  people who reject the square root of negative one, fascinating,  I actually would have thought that none of them would have come higher than that,  none of them is much lower at a, okay so it looks like we've got a cohort of people who  are comfortable with negative one, a large cohort are uncomfortable with infinity,  that's a topic for another day, don't worry about it,  and then a number of people who are kind of in that middle ground of maybe not being  super comfortable with the idea that negative one might be real,  let's see if we can convince you of the difference of that. So what we've done here is we've taken three, two and then we convert it to negative two,  three. Something which maybe in our original system you know looks  like this negative two and then three. Before I've taught you how to add them, make a guess at how it might work,  and I hope that it feels pretty straightforward,  addition is actually the least interesting part of this, but it is,  it's a good thing to know when you're learning about complex numbers,  it's definitely one of those operations that you are going to need to know. Unfortunately, and you can tell by the fact that I'm stalling and what I'm saying here,  it looks like the question is still not loading completely correctly,  so I'm going to have a stern word with Cam and Ider behind the scenes  who have otherwise built such a beautiful, beautiful interface that's  helpful for this kind of back and forth between you guys and me. nice gut check here is to say what happens when we do that twice what  if we do that same very mechanistic operation again twice and I'm  going to go and take this I swap the two coordinates we get a negative  b but then that first one becomes negative. So that was another 90 degree rotation. Well what's happened here is we've just made both of the coordinates  negative and that's reassuring because if I take some point sitting at a b an It turns out to be relatively straightforward. h is just taking both of the coordinates and making them negative negative a  negative b okay so that's reassuring this operation that does a 90 degree  rotation actually behaves like you would expect it to. Now why am I asking you this?  Well I'm being told that supposedly I'm allowed to ask you questions again so I 'm going to have you do your very first complex product.  Oh look a lot of people did submit answers very good.  Great let's let's grade the complex addition actually let's l et's see if it is as straightforward a process as I was hoping it was and see  how much explanation is demanded. Okay so it looks like a majority of you did  get the correct answer which is 2 plus 3i. Very good very good.  52 of you answered simply 2 which would have been the real part of the answer  so maybe just the fact that there's some vertical component and you need to  still add those vertical components or maybe those of you who answer 2 reject the reality of  imaginary numbers so you just don't even acknowledge that vertical component. Addition doesn't really have anything complicated going on, which is great. s just making that's just swapping up whether you're taking 4 minus 2 or 2 minus 4 so that's completely understandable. We've got 2 plus 3 which is maybe just dropping Well where everything becomes interesting is when  you try to multiply these numbers together. So with vectors, there's not really any notion of multiplying  them to get two vectors back, at least when we're in the 2d plane. that we ask questions and just say hey kamineter can't you make the live questions  work a little bit better for us? Okay I think we're finally there. Everybody ready?  Aha! Wonderful! Very simple question I want you to take the number i and I want you to multiply it by 3 plus 2i and even though I haven't really talked about You can't do things like assume that if two numbers multiply to make zero,  then one of them has to be zero, but complex numbers are going to end up behaving  much like the real numbers, so rules from algebra can carry over,  but to understand what that rotation rule is, oh no I'm giving things away,  what that multiplication rule is, I just want to ask you a simple question,  which is basically suppose I have the point three two, okay,  we're not even going to think of it as a complex number per se,  if I just have some sort of coordinate grid and I go to the point with x coordinate  three and y coordinate two, what is the 90 degree rotation of this? If I rotate it 90 degrees and let's say counterclockwise,  counter, counter, jeez, writing is difficult, counterclockwise. Okay, now what's lovely about this is we can basically  just turn our paper to figure it out. ons as you do it rather than sitting in passively watching this is genuinely  delightful to me. Okay this is this isn't necessarily a question I was  expecting to divide the audience necessarily so unsurprisingly it looks like  we have a very strong majority in one direction hopefully in the correct  direction but if not that would that would heavily inform where the lesson should So what we've done here is we've taken three two and then we convert it to  negative two three, something which maybe in our original system, you know,  looks like this, negative two and then three, that's going to be the 90 degree rotation. it looks like the majority of you answered negative two plus three i  which is absolutely correct absolutely correct so there's two ways to  think about this okay one of them is to walk forward with the algebra and just do it a little bit mechanistically okay so if we pull ourselves up our sheet if  we take i times three plus two i three plus two i it just distributes i times three  is going to be three i i times two i is going to be two times i squared by definition  i squared is negative one which means that our final answer is going to look like nega That's a 90 degree rotation. like I said it looks like a majority of you correctly did that product now it's one  thing to just walk through it mechanistically it's another to step back and say what  just happened geometrically right because what we just talked through was the fa ct that if you want to rotate numbers 90 degrees the rule  is to swap the two coordinates and then multiply that first one by negative two well look at what's happened here we've got three  and two those coordinates have been swapped two is now the real part  three is the imaginary part but that two got multiplied by a negative  one because i has this defining feature of squaring to become negative on e so that should give you some indication that okay multiplying  by i has this action of rotating things by 90 degrees maybe tha Well what's happened here is we've just made both of the coordinates negative  and that's reassuring because if I take some point sitting at a b and then I  rotate it 90 degrees, so this will be my initial 90 degree rotation,  and then another 90 degrees that's the same as a 180 degree roto- oh no I've  done that wrong. have a number that behaves this way it gives you a computational mechanism for all  of the other types of rotations that you might want to do that might not necessarily  be 90 degrees and to show you why this works i'm going to go ahead and pull up an  animation so let's say we have any number z and in this case z is going to be let's see where do i have it z is going to be at two uh plus i great and let's  say i want to understand what is multiplying by z due to every other  possible complex number well we can go one by one the very first So that's reassuring this operation that does a 90 degree  rotation actually behaves like you would expect it to. ask what is z times one where does it take the number one well z times one is going to be Well I'm being told that supposedly I'm allowed to ask you questions again,  so I'm going to have you do your very first complex product. tch that arrow up to the point where z is great a kind of  trivial fact even though it's trivial i'm actually going to take a moment to write that down just so that we can oh no no no that's for that's for  later that is randy don't you guys worry about him he'll be coming in in just a  moment so i just want to write down three crucial facts that are getting an influence  rotation three facts i'll call it three facts about multiplication the first two Okay so it looks like a majority of you did get the correct answer which is 2 plus 3i,  very good, very good. 52 of you answered simply 2 which would have been the real part of the answer so  maybe just the fact that there's some vertical component and you need to still  add those vertical components or maybe those of you who answered 2 reject the  reality of imaginary numbers so you just don't even acknowledge that vertical component. hatever the 90 degree rotation point for z itself is okay so  two down infinitely many to go okay we know what it does to  one we know what it does to i let's see if we can understand what z does to any other possible number well it turns out those two is really  all we need to work with if we have the distributive property so the third  fact that's going to look kind of innocuous is let's say i take this z  and i multiply it by c plus d times i where c and d are just any two  numbers okay well this is going to distribute so z times c i'm actually going to write that a little differently i'm going to write it as c times z plus z times  di which again i'm going to write in kind of a funny order and write that as d times  z i now the idea here is well we know where z is we also know where z times i is s o if we're just scaling them up by some other constants that  completely constrains where we need to go so let me go ahead and wr ite this down with an example okay let's say that we go back here and i want to know  what multiplying by z does to anything i want to tell i want to convince you that it Stal, stal, words, words. n a way that keeps these lines parallel it keeps them evenly spaced keeps them  perpendicular to each other it applies this very constrained rule to the whole plane  and really just think through any one particular point for this let's say that we  have two times negative i okay so you move two units in the positive right direction  and then negative one unit in the vertical direction well after the product where  that's going to land has to be two times wherever z lands plus negative one times  wherever i la nds okay and we see that right it's two times this  yellow vector and it'll be negative one times the gree n vector so here even before you actually work out the product we could just read off Aha wonderful. Very simple question. which says what is two plus i times two minus i and if you have notes  right now if you have a pencil and paper which i encourage you to always  come to class with i want you to try working it out do the first inside  outside last distribution property just to see mechanistically what number en ds up popping out from this and then we'll try to see how that squares with the  geometric intuition so while you're doing that while you're working that out  hopefully on pencil and paper it looks like we've got a question from the audience  which is is i the same as i and j the vectors in physics great question actually That's the only special thing you need to know about that. Other than that just treat it like it's a normal  number okay and then proceed forward with the product. Wonderful okay so it looks like we've got quite a  few of you coming in to answer which is always lovely. Super exciting for me by the way just how many people are enthusiastic  about coming and like getting back to the fundamentals of math in this  lockdown and just you know we're gonna sit back for an hour and we're gonna  learn about complex numbers and we're actually gonna participate we're  actually gonna answer questions as you do rather than sitting and passively watching. This is genuinely delightful to me.

================================================================================
VIDEO ID: yBw67Fb31Cs
TITLE: Trigonometry fundamentals | Ep. 2 Lockdown live math
URL: https://www.youtube.com/watch?v=yBw67Fb31Cs
PUBLISHED: 2020-04-21T20:51:44Z
STATUS: SUCCESS
================================================================================
My end goal for this lecture and the following lecture is to draw  for you a connection between trigonometry and complex numbers. And I really do think when you understand that connection between the two,  it strengthens your understanding of both of them. So for this lecture, we're just going to go back to the basics on some  of the trigonometric functions, how to think about them, what they mean. And to dive into it, what I want to first do is imagine that you don't actually  know any trigonometry yet, but show how just playing around with a graphing  calculator can lead you to come to some pretty non-trivial facts about trig. So for example, let's say you've never heard of the cosine function. But then one day, you know, it comes up, you hear someone talking about physics,  and they mention a sinusoidal wave and the cosine function and things like that. So you go to a graphing calculator, something like Desmos,  and you just poke it in and say, okay, what does this thing look like? Now before seeing its definition, you can understand, oh, yeah,  I can see how this might be relevant to waves and wave type dynamics that people  might want to study. It's got kind of a cycling phenomenon to it, so maybe anytime people  are studying something associated with cycling,  you could play around with the graph and do all the things that you can  with any normal function. If I tweak the input, it kind of squishes it, right? So as I put a bigger constant in front of that input X,  it squishes things, gives it a higher frequency. Okay, that's all well and good. You could stretch it out in the Y direction by messing with the output. Now what I want to do though is point out something very interesting  about the cosine graph that is something you might want to take note of. So what I'm going to do is square it, and I don't want to show you what it looks like yet. I want you to predict what it's going to look like when we take cosine of X squared, okay? And in particular, I'm just going to have you focus in on the region from 0 up to 2 pi. So again, if you're just playing around, what you would notice is  cosine is clearly related to pi and probably circles in some way. So it takes a dip down to pi, down to negative 1 at pi,  excuse me, and then it comes right back up to 1 at the input 2 pi. So what I want you to do is predict what it looks like when we take cosine of X squared. And let's actually do this as one of our fun live question dynamics, okay? So getting rid of our Randy, which was a very informative thing for me,  let's dump into our very first genuinely mathematical quiz question. What does it say here? What will the graph of f of X equals cosine of X squared look like? Okay, and it looks like A as an option has these sort of valleys where in all of  these it might be a little small to read, but the range is going from 0 to about 2 pi. So in A it hits 1 and then it goes down and hits 1 again at  the input pi and kind of goes down with these flat valleys. B has a similar behavior for when it hits 1 and 0, but it's a little spikier. So it's kind of bouncing right off that x-axis. C looks just like a sinusoidal wave. Okay, it looks like the same kind of wave, but it's all positive and it's,  it goes from 1 down to 0, then up to 1 in the span of pi. And then D kind of gets scrunched together in the x-direction  and starts going more rapidly as you move farther to the right. Okay, so it looks like we've got a lot of answers coming in. A fair bit of consensus towards the top, but it's not,  definitely not a unanimous decision on this one where people are going. So it seems like there's one most popular answer and then two  that kind of tie closely for the silver and the bronze medals. So I'm going to give you just a couple more seconds here if you want to change  your mind or if you want to go to 3b1b.co slash live and answer this as we're going. The link is also in the description if you just want to clink it there. Clink. Click it there. And, alright, I think that's probably enough time. Let's go ahead and grade this. What do you think it will be? Alright, it looks like a majority of you went with C,  which is the one that looks like a sinusoidal wave. The second most common one was A, which has a similar shape,  but it's kind of more flattened out on the bottom. Third most common was B, and then the last most common was D. And I think that's pretty good instincts because A, B, and C,  which were the top three choices there, if we go back and look at our actual cosine  graph itself, what you'll notice is that at the input 0 it's 1, so when you square that,  1 squared should stay 1. Similarly, negative 1 when you square that, that should come up to 1 as well. And then positive 1 at the end of its cycle, again that's 1. So the idea that no matter what you're going to get something that dips down to 0,  then up to 1, down to 0, and up to 1 should make sense. But the specific shape is what we don't know. Turns out, as you just saw, the answer is C. So if we go over here and reveal, it looks just like a little cosine wave. Which is weird, if you think about it, because what we're doing when we square something  is affecting the output, it's affecting stuff happening in the y-direction, right? But to get another cosine wave that's oscillating more quickly,  it's not at all clear that that's what would happen. And using this, even before you know what the cosine of x means,  if you're just playing around being kind of childlike with your graphing calculator,  you can discover a pretty non-trivial fact about trigonometric functions. And then as we start defining them and getting into them,  you will appreciate just how non-trivial it is, because it really is not obvious. So for this, I want to take us to a second question. Okay, and I look at this graph hard, okay, and remember  that it looks like a scaled-down version of the cosine graph. And what I'm going to want you to do is basically come up with an identity based on that,  okay? So question number two, what does it say? Working from the assumption that the graph of cosine of x squared looks like a  scaled-down version of the graph of cosine of x, which of the following equations is true? Okay, now because this might take a little moment for you guys to work out,  pencil and paper, highly encourage you to actively work it out. I'm just going to give you maybe 30 to 60 seconds to start penciling through,  noodling it out, and let's introduce a little bit of pause and ponder  music just to put us in the problem-solving mood, I think. So which one of these reflects the fact the cosine  of x squared is kind of a scaled version of itself? So it looks like we still have a fair bit of answers rolling in,  and I don't want you to feel rushed, so I'm going to give you time to figure it out for  yourself if you want to. While you're answering this, it looks like we've  got ourselves a question that's rolled in, okay? So Diego Mathemagician, love the name, asks, what is the new music? Great question. So the guy who usually composes the music for the channel,  his name is Vince, Vince Rubenetti. I told him that we were doing these streams, and I mentioned I wanted kind of a jeopardy. Here, I'll turn it down so that I can talk over it. Vince, your music is great, but I want to talk about it a little bit more. I wanted just a jeopardy type theme, but mixed with the usual three blue and brown vibe,  so a little clock ticking, and I think it really puts you in the problem-solving mood. Now that is probably enough to noodle this one out,  so I'm going to go ahead and grade this. And I'm guessing the majority have gotten it correct. Okay, great job. So to the 3,165 of you that answered B, which is that it's one half cosine of 2x plus 1,  congratulations, you're absolutely correct. But let's think about how you might do that in a step-by-step way,  and this is one of those things that, again, if you're just  noodling around on a graphing calculator, you can come to. So what I might do is take, here, I'll just go ahead and write a new cosine function,  okay? And then I'm going to start manipulating it. So cosine of x, we won't look at the original. The first thing you'd notice is, okay, we want to make it entirely positive  because that's what the other one is, so maybe I'm going to shift it up by one, okay? And that makes it all positive. But now it's twice as high as the other graph we're looking at,  so if we want to make it equal, we might chop it in half. But it still cycles once every 2 pi, right? You have to go from 0 all the way up to 2 pi before this blue graph that  we're looking at goes through the cycle from 1 down to 0 now, back up to 1. So the last step is going to be to squish it in the x direction. And sometimes people find this very counterintuitive that you scale up that input,  that you multiply it by 2 in order to squish it. But what's really going on, if you think it through,  is we want to say instead of taking 2 pi to go through your full cycle,  I want you to go through that cycle as x ranges from 0 to pi. So if we make that input 2x, then the thing being plugged  into cosine will go from 0 to 2 pi as x goes from 0 up to pi. And what you'll look at is the graphs are right on top of each other, right? Which is very cool, right on top of each other,  and that means you've discovered a pretty non-trivial fact about trigonometry. And it's worth writing down because it's one of those  things that comes up later in a very hard to memorize way. I always had a little bit of trouble actually remembering what this thing is. So, writing down what you just found, cosine of x squared, okay,  is equal to 1 plus cosine of 2x, which is basically saying increase its frequency. So we're going to double its frequency and then add 1 to it. So it's going to shift above that y-axis, and then we're going to divide that by 2, okay? So this is a fact that we're going to turn back to at the very end of the lecture,  and as you start to get an appreciation for what the cosine means,  it becomes clearer and clearer just how non-obvious this is. And in particular, the one thing I want you to take note of is the weird  fact that we've got this function that when you square it, it's not equal to,  but it's somewhat related to the idea of scaling up that input. Now if you were clever, there is another function that behaves very similarly to this,  where when you square it, it's the same as doing something to its input. And this actually takes us to our next question. So let's go ahead and move past from this one, okay,  and I'm going to ask you something that seems very unrelated to trigonometry,  and it'll take us until the next lecture to realize just how related it is. What does our question say? Which of the following functions satisfies f of 2x is equal to f of x squared? So when you plug in 2x, it should be the same as f of x squared. Option A, square root of 1 minus x squared, option B,  log of x, option C, x squared, and option D, 2 to the x. Okay, so I'm going to give you a couple minutes, a little bit to answer that. We won't take too long on this one. Oh, it looks like I accidentally graded it right away. Okay, well, sorry for everyone who felt a little bit rushed there, my finger slipped. Well, in either case, it's now been revealed that the answer is D, 2 to the x. Okay, and we can see this again if we go and just  play around a little bit in our Desmos graphs. So what we might do is pop over here and let me plug in 2 to the x. Look at what that graph looks like. So let's not look at our cosines anymore, 2 to the x. And indeed, if I take this whole thing and I square it. On the one hand, squaring usually does a kind of stretching motion in the y direction. But what's neat about this shape is that it's exactly the same as taking 2 to the 2x. And if you know anything about exponents, this kind of makes  sense because that 2 up here can get distributed into that x. But what this means is that exponents have this funny property that when you square them,  it's a lot like scaling the input. And of course, the reason I bring that up is that you're  looking at something very similar when it comes to cosine. Just before, just by playing around with graphs, before you even know what they mean,  you can have this tiny little instinct in your head that says, maybe,  just maybe, cosine is somehow related to exponents. It's not at all obvious how it is, but it absolutely is. And that's one of the things that I'd like to  get to by the end of the end of the second lecture. We won't get to the end of there today. So with all of that, I think it's high time that we  actually talk about what sine and cosine actually are. I don't want to come in assuming that you necessarily know that already,  so let's have a little moment to go back to the basics. I think one of the best summaries of trigonometry that I ever heard,  and this was on Reddit, but I cannot for the life of me find it,  or remember who originally said this, is you think that it's about triangles,  but really it's about circles. And this is absolutely true. I think between the time when I very first learned about trigonometry and now,  I think my mind shifted from fundamentally thinking of a triangular-based definition,  which we'll talk about in a moment, to circles. And let me just show you what I mean with respect to the circles,  because that's the one that explains how it comes up in physics,  and often how to get intuitions about where the values will be. So instead of our Desmos graph, I'm going to go  ahead and pull up a couple animations here. So in this one, I'll explain what sine of theta is, where theta is the input,  and it's going to be a measure of how far you've walked around a circle. So I want you to imagine that you've started on the  rightmost side of a circle that has a radius of one, okay? And then as you walk around at a constant rate, as a function of how far you've walked,  we're going to graph your height, which is to say your y-axis on this grid. Maybe you'd think of it as the distance between you and the x-axis. And as you do that, you get this wave that oscillates. And it kind of makes sense how it's just going to oscillate on and on,  no matter how far you walk. Which is why, when we go back over to the Desmos graph,  and you think of something like cosine of x, not the squared version,  let's just do the plain vanilla cosine x, you know,  it goes on forever continuing to cycle like this. And I guess here I'm explaining sine of x, but it works the same way. If instead I type sine of x, we get a similar looking shape. The only difference is that it starts at zero. And we can take a look to explain why here, because if by definition,  if it's giving your y-coordinate when you start off to the right,  it starts at zero before slowly increasing. Okay? Now by contrast, cosine, it's defined very similarly,  but it's giving you the x-coordinate as you walk around that circle. So the distance to the vertical line. And in that context, it starts off at one, and then as you walk around the circle,  your distance from that y-axis, your x-coordinate, is going to get lower. It ultimately gets down to negative one before it starts increasing again. Okay? So this is how you might think of sine and cosine with respect to circles. The input is a kind of, it's a kind of distance around a unit circle,  but you could think of that as an angle, And we're going to talk in a moment about the difference between degrees and radians. But when you're thinking about walking around the circle, if it has a radius of one,  you can think of that input as being the literal distance that you walk. So as an example, notice what happens when we get to the distance pi. Okay? pi gives you the semi-circumference of one of these circles. If it's got a radius of one, then the distance that it takes to get halfway around is pi,  which is why at that input pi, you see the output go to negative one. At half of that, if you turn to 90 degree angle,  which means walking around a distance of pi halves,  that's why cosine is zero at that point. So now I'm going to ask you another question where we're going to consider  the input in terms of this idea of a distance around the unit circle. And I'm just going to have you guess at some of the values for sine and cosine. So we'll go ahead and pull up our quiz again. And this time, let's get it up on here. What does our question say? Without looking it up or using a calculator, which of the following is true? And it's reminding us that that input 3 is going to be considered in radians,  which is to say the distance around the unit circle,  if you're just walking along at the arc length. Option A, the sine of 3 is around 0.14 and the cosine of 3 is around 0.99. B, the sine of 3 is around 0.14 and the cosine of 3 is around negative 0.99. C, sine of 3 is around 0.99, cosine of 3 is around 0.14. And D, sine of 3 is around negative 0.99 and cosine of 3 is around 0.14. Okay, so just to give you a little moment to think that through. it seems like there's not a hundred percent consensus  on this question and answers are still rolling in. So I'm going to go ahead and give you a little bit of pause and ponder music. I'll let you just think about it. I don't want you to feel rushed here. Okay, so I think this is probably a pretty good time to start grading things. So the correct answer is B. And it looks like the majority of you got the correct answer,  which is to say that sine is 0.14 and cosine is negative 0.99. Now the specific numbers here don't matter. What's actually relevant is just kind of whether it's positive or  negative and whether it's very close to 1 or if it's closer to 0. So if we think through what this might mean in the context of our graphs here,  the cosine, which remember is measuring the x-coordinate of  your little dot as you walk around the circle. What is that going to be when you input 3? Well, what does it mean to walk 3 units around the circle? Well, like I just mentioned, walking pi units around the circle gets you halfway around. This is really the way to think about pi is you've got a unit circle,  it takes you halfway around. So to walk 3 units is going to be something a little bit shy of that. Okay, and if you notice, there's very little change in  the x direction as you're at that left side of the circle. So when it approaches 1, it gets really close  to 1 and then it doesn't really change that much. So maybe it shouldn't be too surprising that our cosine of 3 turned out to be around 0.99. What's relevant is that it's negative, right? It's very close to negative one.  So it's close to negative 0.99. Now on the other hand, if we were doing this with sine,  which same game, but it's measuring your y-coordinate, When you walk almost halfway around, which is to say almost pi radians,  well, there's still a little bit of height left. And importantly, it's positive because you're still above that x-axis. So when we turn back to our question, the only thing differentiating our answers was that  some of them would switch whether sine or cosine was the one that's close to negative 1. And the others would just switch the sine, s-i-g-n, whether it's positive or negative. So congratulations to the 3,152 of you who got that one correct. So that's loosely how you might think about sine and  cosine if we're coming at it from the direction of circles. But this is very different from how it's usually taught if we're doing things like  in a typical high school class where you start off thinking about right triangles. One is not better, they're just very different and worth understanding the connection. So the classic thing when it comes to trig functions is a little  statement that everyone has ringing through their head called SOH CAH TOA. And what you're supposed to remember from this is if we have a right triangle,  so let me go ahead and draw a right triangle. So we know one of the angles is 90 degrees. And if you know another one of the angles, theta,  then consider one of the sides to be the hypotenuse. And then you ask what of the other two legs is adjacent to that angle,  and we label it a for adjacent, and which of them is opposite. So then SOH CAH TOA, if that's a phrase that you remember running through your head,  tells you that the sine of this angle, this is the definition of sine for some kind of  angle that we input, is for such a right triangle, it's the opposite over the hypotenuse. That's what this is telling us, opposite over hypotenuse. Similarly, the cosine of that angle is going to equal the adjacent over the hypotenuse. So that would be adjacent over hypotenuse. And then the tangent of that angle is going to be the opposite over the adjacent. So that opposite side O over the adjacent side. So that is the classic thing to remember if students come out of a trig class,  if they know one thing, they typically know SOH CAH TOA. And to give us an example of how you might apply this,  I'm going to go ahead and pull up another question here for you,  which is going to ask us about a leaning tower, a leaning tower of Pisa. Clearing out the last one, let's read what our new question has to say. Suppose that a tower is 100 meters high. After several years, the tower starts to lean. So instead of making a 90 degree angle with the ground, it makes an 80 degree angle. When the sun is directly overhead, what is the  length of the shadow cast by this leaning tower? Okay, the length of the shadow cast by this leaning tower. I would highly encourage you to try drawing this out yourself. I'm absolutely going to draw it for you in a moment,  but it's more fun if you're engaged and if you have a pencil and paper to noodle it out. You could also try to imagine it in your head if you want. But for me, at least, I always think much more clearly once I have pencil and paper,  no matter how much I think I can think things through in my head. So let's give you a little pause and ponder time on this one. Looks like we have some very strong consensus on this one, which is very reassuring. And I guess one thing that should maybe go without saying,  especially given that I've turned the super chat or the live chat into the very  aggressive slow mode. This is most fun if you don't know what the majority of people are already thinking. The whole idea of the statistics is right now you can see there's a bandwagon. There's 2600 people who are voting for one of the answers who think that's it,  but we don't know what one of those answers is. So if you have the answer, try not to just blurted out in the live chat. That's kind of the equivalent of a student in a classroom where when the teacher asks  something, rather than raising their hand to ask it or submitting it quietly,  just shouting. I get it. You're excited. You really want to do it. But in this case, it's a little bit more fun if we have the slow reveal. All right, so that's probably enough time for people to have rolled their answers in. Now let's go ahead and see what they see what the majority has submitted. And the correct answer is B, which is 100 times the cosine of 80. And it looks like the second most common answer was A, which is 100 times the sine of 80. So it looks like you guys correctly knew that you were  multiplying it by one of these trigonometric functions,  but there might have just been a little swap up for which one was which. So let's think this through. Okay, let's go back to our paper. And our question had us imagine a tower which is 100 meters tall. And specifically, it said it was 100 meters tall and then it started tilting. So we can think of the length of the towers 100 meters. That's not necessarily how far its new top is off of the ground. And then it has us imagine that there's the sun directly overhead. Okay, so it's going to be casting a shadow perpendicular to the ground. That's what gives us our nice right triangle. And it further specified that the angle here was 80 degrees. Okay, so the thing we want to know is this side here, the length of the shadow,  which if we look at our SOHCAHTOA, that's the adjacent side. So we might write for ourselves cosine of this angle, which is 80 degrees,  is equal to that adjacent side, the thing that we want to know. I'll just call it x, or maybe I'll call it s for shadow,  try to give our variables readable meanings, divided by the hypotenuse, which is 100. So that means that the shadow, once we rearrange, is 100 times the cosine of 80 degrees. Now already this feels very different from the thought of trigonometry via circles. Like I said, you start to think about it in terms of triangles, later it comes to circles. One of the main differences here is that we're dealing with a different unit, right? Here I was saying degrees, and that's very natural when we're in the context of triangles. We could also talk about angles in terms of radians,  like I'll say in a moment, but when humans assign numbers and  numerical systems to things, we really like whole numbers between 0 and 100. We just love that. Instead of thinking of proportions, we think in terms of percentages,  which is the same thing, but it just turns it to whole numbers between 0 and 100. When we think about like sound with decibels, which scales a whole bunch  and it's got this crazy exponential pattern to it,  we logarithmically change it and we have this very awkward system that's  really twisting the math behind its back, so that we can think of whole  numbers between 0 and 100. Same deal with what's going on with degrees, but mathematicians don't really like that. They don't really like to think in terms of degrees, because it's so unnatural. Instead, they want some sort of natural unit, something where you imagine if you  talk to an alien civilization about math, they would have the same conventions. So how does any of this connect to the unit circle and the idea of the  distance around that unit circle that we were walking, like we saw earlier? Well, let me just pull up a pre-printed unit circle,  because trust me, you don't want to see me try to draw a circle. What's neat here is we can, for each of these triangles,  imagine rescaling it so that that hypotenuse is really 1,  because all we care about are ratios of lengths of sides. So we might as well say, okay, let's scale this so that the hypotenuse is 1,  meaning we divide everything by h. And what that's going to get us is the opposite  side is now o over h, whatever that was, and then the adjacent side is a over h,  meaning that the y, or the vertical component here, is sine of theta,  where theta was our angle down here. Okay. And then that bottom part is cosine of theta.  Okay. And if we want to think about all possible right triangles who have a hypotenuse of 1,  what you might think of is taking a unit circle,  because that's saying every point is a distance of 1 away,  so think of that line as the hypotenuse of a triangle. If you have a triangle with a bigger angle, it shows up there. If you have a triangle with a smaller angle, it shows up there. And it's as if you take all possible right triangles and you fix them so that their  points are all in common, and such that their hypotenuses are all 1, you scale them down,  and the other tip of the triangle is going to trace out a unit circle like this,  and each one of these points for the corresponding angle is going to have coordinates,  cosine of theta as the x-coordinate, and then sine of theta for the y-coordinate. And I'm just writing it vertically so I can fit it all on here. Now typically, like I said, mathematicians like to think in terms of radians,  which is really a way of saying if we know that the radius of our circle is 1,  what is the distance that you've walked along the outside here? So for example, if you were to say 180 degrees, excuse me, degrees,  which is walking halfway around the circle, that's the same as pi radians. And if you were to take something like 60 degrees, okay,  which would maybe end up, oh, I don't know, around here, that might be 60 degrees. Well, that's a third of that. You're walking a third of the half turn around the circle. Everyone who's an enthusiast about tau is sort of yelling right now because it  would make the conventions easier, but pi is the standard, so we're working with it. It's pi, thirds, radians. Okay? So from this point forward, and really for a lot of your math career,  I would encourage you to, every time you want to think in terms of degrees,  where that makes the angle intuitive, try to translate it to radians,  because that's going to be the more natural way to understand it. And the farther you get down the road when it comes to how sine and  cosine play into calculus, how you actually find values of them,  almost all of the time it's easier to think of that input in terms of radians. So I think it's high time I ask you a couple questions about these,  and you might wonder, you know, how do we actually compute some of the values, right? How to compute. And the honest answer is that it's hard. If there was an easy answer to say, oh, well, this is the formula that shows  you what sine of theta is, we wouldn't have given sine of theta a fancy name. We would just always work in terms of that formula,  and we would call it the circle y coordinate formula, and it might get a name,  but it wouldn't be a special function. It wouldn't have a special button on your calculator,  because effectively what you have to do is, before you know fancy techniques  associated with calculus, or associated with even fancier things like  what's known as the Kordak algorithm, you just have to have a handful of  values that you do know that come from geometric settings where there's enough symmetry. So for example, let's say I try to draw an equilateral triangle. An equilateral triangle will be nice and symmetric,  and we're going to be able to leverage that symmetry to figure out a concrete  value of sine and cosine. This looks roughly equilateral, wouldn't you say? And let's say each of those side lengths is one because,  you know, if we get to choose our side lengths, why not one? Because remember, sine and cosine have everything to do with just ratios. So on an equilateral triangle, this angle here is a third of the total. The total is 180 degrees, so you might think of this as 60 degrees. But like I said earlier, I would encourage you to try to get in  the habit of thinking of that instead of 60 degrees, say, okay,  the full angle is pi, so a third of that is going to be pi thirds. And then similarly, this one up here is half that angle. Here's where we're leveraging that symmetry to some extent. That one is 30 degrees, which in terms of radians is now a sixth of a half turn. All the tau enthusiasts get very mad at this point. But again, hey, it's the convention. This is the thing that you should come out of a trig class  knowing in your head how to think in terms of radians measured in pi,  because that's how we often write it down in tests and such. So that one will be pi sixths. So one thing I might ask you now is if you can leverage the symmetry of the setup,  the fact that equilateral triangles are going to be very nice and that  the right triangle coming about from it is very nice,  to answer something like a very concrete calculation, what is the sine of pi sixths? OK, what do you think it is? And in fact, let's do this as another live question,  which, as you can see, I'm like a kid in a candy shop. I'm just very enthusiastic with my new toy. So let's go ahead and use it. Pull up another question here. And what does our question ask? What is the sine of pi sixths, of course? So again, if you want, if you're just joining now, you can hop over to 3b1b.co. Live. You can answer that. I imagine the best way to do this if you're doing it live is you might be answering  on your phone, watching on another screen, or if you want to switch between tabs. That's also good. Now, while those answers are rolling in, let's take  a look to see if we have anything from the audience. And we do. When you do maths problems, do you use pen or pencil? For sure I use pencil. One, I'm very error prone, so I'm going to make mistakes all the time. The only reason I'm writing in pen now is because it shows up better on the camera. And let me just tell you, with every stroke that I write,  I'm deeply terrified that there's about to be an error, because I know there will be. So if that terror doesn't show in the shaking of my hands,  then you'll start to notice it from this point forward. Back to our question, though. It looks like we've got pretty strong consensus now,  around 2,091 people agreeing on one of the answers,  and then a pretty even split among the other ones. Oh, no, no, I guess the length of the bar is a little,  whoever worked on the scaling, maybe a little bit misleading. It looks like one of the answers is much less popular than the other two. But I guess it's considering them to start from somewhere like that. Maybe we should have some axes on there indicating that. So there's one very unpopular answer, and then one very popular answer. So let's go ahead and see what that turns out to be. Correct answer is one half. Congratulations to the 2800, no, no, 2915 of you coming  into the last minute there to pull in a correct answer. Okay, so why is that the case? Why is that necessarily going to be one half? Well, remember, sine of pi six, we're asking SOHCAHTOA. So kind of remembering your head, sine is opposite over adjacent,  opposite over hypotenuse, excuse me. So with respect to this smaller angle, maybe I'll change colors. With respect to this smaller angle, the opposite side is this segment here. And because of the symmetry of our triangle, that's going to be one half. Because each side length of the equilateral triangle is one,  so half of it should be one half. And divided by the hypotenuse, but by definition the hypotenuse was one here. So one half divided by one, it's just the same as one half. Now, slightly trickier is if I'd asked you the cosine of pi six. And let's do this one again as a live quiz, but maybe a little bit more quickly this time. I'm going to hop over, get to our next question, and as you might expect,  the next question is going to ask you to find the cosine of pi divided by six. There we go. And your options are A, one half, B, square root of two divided by two, C,  square root of three divided by two, or D, square root of five divided by two. If you can, I would highly encourage you to be keeping your own notes, right? So if you wanted to kind of check back on your own piece of paper,  you could take a look through it as you're working out these questions. But for right now, I'm just going to give you maybe 20 seconds  or so to kind of noodle through it, think of what it might be. Get a little pause and ponder music going. Okay. Once again, it looks like we have some pretty strong consensus  from about the same number of people that we had before. So let's go ahead and grade the answers. And the correct one is C, square root of three divided by two. So congratulations to the 3183 of you who knew  that it was square root of three divided by two. Now, how do you figure something like that out? Well, the trick is basically if you have one of these right triangles,  if you know one of their sides, then you know both of them. So let me draw a little copy for ourselves here. We know that the hypotenuse is one, one of the side lengths is one half,  and the only thing that's missing if we're thinking the cosine of 30 degrees is this  adjacent side. So because we were doing it with the angle up there, adjacent side is here. Now the Pythagorean theorem tells us that that adjacent value squared  plus the other leg length squared is going to equal one squared. A hypotenuse squared, which means that value is equal to the square root of one minus,  well what's one half squared? It's one fourth. Which means it is the square root of one minus a fourth is three fourths. So we can go ahead and take the square root of  that bottom and just leave the radical in the top. And what we get is the square root of three all divided by two. Now this is a value that anybody coming out of a trig class becomes very familiar with. They're like, okay, if the answer isn't one half,  it's going to be square root of three over two. Or root two over two also comes up in another circumstance. But this is one of those that kind of becomes burned in your memory. Square root of three divided by two. And one very important fact that's come about here that's worth highlighting is that,  hmm, how does the Pythagorean theorem play into our trigonometry? Because if we have a right triangle whose hypotenuse is one,  and we know that one of the side lengths, let me switch to thinking with respect to  this lower left angle again. If one of the side lengths is cosine of theta, and one of them is sine of theta,  well the Pythagorean theorem tells us that cosine of x squared plus  sine of x squared is always equal to one squared. Okay? Now this is a very important identity. It basically tells you if you know cosine, you know sine. If you know sine, you know cosine. And it also is giving you a little reminder that  it's all really about the Pythagorean theorem. In fact, this is equivalent to the Pythagorean theorem. Because if you think of how cosine and sine are defined,  it's just defined in terms of the leg lengths of a right triangle,  and then everything scaled down as needed. Now there's one very silly convention with how we write these things. So we've already started to make friends with the cosine of x squared function,  and the fact that it's a little more interesting than you might think at first sight. But you never see it written down as open parenthesis  cosine of x closed parenthesis squared. Because people don't want to write too many parenthesis,  instead they write cosine squared of x plus sine squared of x. It's all very nice. How lovely. We don't have to write too many symbols. What a wonderful convention. Except for the fact that literally every other time in math you see  something written as f squared of x, what that means is not f of x squared. That's almost never what it means. Instead, what it's supposed to mean for most of math is taking a  function and applying it to itself, like layering it over itself. That's what that 2 usually refers to. Sometimes later on it refers to the second derivative,  especially if it has some parenthesis around it. But the idea is that it's very different from the convention in trigonometry. Trigonometry is just flying by its own rules and saying, yeah, yeah,  we've got our own conventions for what it means when you put a little 2 up there. I understand some students will be confused, but I'm trigonometry. I don't care. I'm moving forward with my conventions. And that's fine. You get used to it. This is the standard way that you'll end up seeing it. What I was writing earlier when we were thinking about the cosine squared function,  which again is very interesting, you would almost always see it written as cos squared  of x. Now, very interesting is that this is not just a consequence of the  Pythagorean theorem that gives us a relation between our trig functions. At the end of the lecture, I want to show you how you can use  trig functions to prove the Pythagorean theorem in a sneaky way. And it's pretty sneaky. Like it's not one of the common proofs that you'll see that's associated with,  you know, rearranging triangles or anything like that. But it is very visually satisfying. So that's something that we'll get to by the end of the lecture. But in the meantime, I want to think through a  couple more of our of our trig function questions. OK, so we kind of come back up here. We just found cosine of pi six, which is square root of three over two. But let's answer it for a couple more complicated ones. So far, I'm dealing only with angles that were between zero and 90 degrees,  or I should say between zero and pi halves. But let's try a question that's a little bit different from that. And what if I instead said cosine of negative two pi over three? OK, now that's one that is hard to think of in terms of triangles,  because what does it mean to have a negative angle? So this is a good reminder that cosine and sine,  even if you think they're about triangles, are really about circles. And remember, if you walk all the way around the circle, and if it has a radius of one,  walking all the way around the circle is going to take you a distance of two pi. So if you want to think about two pi thirds, what you might start by doing is  chopping the triangle into thirds and then using that to help guide the intuitions. But again, I kind of want to do this as a live quiz. So let's go ahead and pull up the next question. And have you guys answer this for me. What do you think the cosine of two pi divided by three? Let's go ahead and pull it up. Cosine of negative two pi divided by three. So again, if you're keeping notes, that can be very helpful. You reference your notes now. But just to make sure that you have enough time to think this through,  I'm going to go ahead and give you a little bit more of that pause and ponder music. It looks like one of you figured out how to submit an  answer that is not one of the four multiple choices. So other than that, we've got a very strong lead with 1152 of you,  as I say this, agreeing on one of the answers. And then second place by about a factor of four is going to sit on another one. I'm curious about actually what what all the answer distribution here is. I'm very curious about. Oh, now we have a sixth. OK, so two of you have now gone outside the realm of the  typical multiple choice universe and have entered your own things. Two of you sit there and say, I don't want one of your choices. I figured out my own answer and you just didn't put it in your form. So I'm going to figure out a way to submit it differently. If only you could do that on the SAT. What is the answer? A through E. Sir, I think the answer is J. 1729. We got Ramanujan's constant. Oh, if I pause it now, though, it's not going to stay there for a brief, glorious moment. We had a wonderful number. Maybe I can pause it around the year, though, because it's 1999. 2031. OK, well, I've paused it in the future. So the correct answer in this context is negative one half. OK. And it looks like the second most common answer was D,  which is negative root three over two. OK, so that's very good because often it's kind of this back and forth  between whether you think it's a half or whether you think it's root three over two,  because it's sort of the difference between things that feel like 30  degree angles and things that feel like 60 degree angles. So let's take a look back at our drawing and see how we might think about this. So, like I said, negative two pi divided by three. That's taking us a negative distance over here. And this is why cosine will be a negative number,  because the x coordinate is pointing in the negative direction. And if you want to think of this in terms of triangles,  I might draw this triangle here and ask, what is this angle? OK, we know that it's 90 degrees plus something or pi  halves plus something and negative two pi over thirds. If we wanted to think in terms of degrees, if that's something we're more comfortable  with, that's negative 360 divided by three degrees, which is negative 120 degrees. So if it takes 120 degrees to get around here,  then that minus the 90 degree angle between the x and y axis gives us 30 degrees. OK, so then the question is, what is the cosine of this value? What is the x coordinate there? With your 30, 60, 90 triangles, it's just kind of a nice thing to remember  that the shorter side is one half and the longer side is root three over two. And if you forget why, it's exactly the diagram that we  just drew before associated with equilateral triangles. Because if you imagine taking the equilateral triangle and chopping it in half,  then the shorter side has length one half and then the longer  side comes from the Pythagorean theorem. So congratulations to those of you who correctly found that. Now, I want to bring back that identity that you guys found at the very beginning,  associated with cosine squared and cosine of two thetas,  and show how that extends our capability for making some of these computations and  figuring out certain values. So let's remind ourselves what that actually was. I'm going to go back here and I'm going to pull up again the Desmos graph. And remember how what we said is that cosine squared,  which looks like this little scaled down version of cosine,  oscillating more quickly, is the same as cosine of two x, that quicker oscillation. But we had to kind of shift it and rescale it to make them equal. So now we're going to use that fact that you can discover just by playing around  with graphs to make a computation that otherwise would be pretty tricky to make. And I think that when you're able to make concrete computations,  it's often a reflection of the fact that you have a deeper conceptual understanding  of what's going on. So even if it's always going to be your calculator computing this,  you're not sitting here working out cosine values by hand,  the fact that you can is an illustrate that you understand that cosine  function a little bit better. So over on our paper, let me write down again what that identity was. Let's go back to black. Good old friendly black. Cosine squared of x, using the dumb dumb convention, is one plus cosine of two x. So it's kind of oscillating more quickly, all divided by two. OK, so now I'm going to ask you a trickier question,  which is going to be what is the cosine of pi twelfths? And for those of you keeping track, pi twelfths is the same as 15 degrees. So if we were doing this with a unit circle, what you might think is,  OK, a 30 degree angle. It's looking like this. That's 30 degrees. I'm now going to be taking half of that. Half of that. And I want to know the cosine of this value, which  is going to be the x coordinate of that value. And right away, you can probably make a guess that it's very close to one,  right, because it's a small angle. And the small angle means that we haven't walked that far around a circle,  so we haven't gotten that far away from one, especially given the fact that  as you start to walk, almost all of your velocity is in the up and down direction. All right, so cosine of pi twelfths, 15 degrees. You know what's about to happen. You know that this is a live quiz dynamic. So let's pull it up. All right. What is the cosine of pi divided by 12? OK, lots of answers rolling in. Very fun, very exciting. Again, if you just happen to be tuning in now,  you haven't been following along before, go to 3b1b.co slash live. Your answers will become part of what you're seeing on screen. It affects the overall distribution. This one, unlike what we had before, much less overall consensus. And it definitely seems to be taking a bit more time. So I'm going to just stop talking and give you some some pause and ponder moments here,  because this one is tricky. This one takes time to think through. So. Now it looks like there's a total of five of you who  have extended beyond the realm of usual multiple choice. By the way, as you guys are entering answers here,  let me just say a huge thanks to Ben Eater and Cam Christensen. They're the ones who actually worked on the item  pool website that is making all of this possible. Eater, many of you might recognize from his own YouTube channel,  named Ben Eater about computer engineering. If you haven't checked it out, you absolutely should. And then item pool is a pretty cool thing that will  be unfolding over the next coming months and year. So you might want to keep your eye on that. It looks like some more consensus is starting to form. So I'm going to go ahead and grade this question. All right, it looks like I'm getting a phone call. Awesome. So the correct answer is B, which is square root of it's a very complicated thing, right? Square root of one plus the square root of three over two divided by two. So congratulations to the two to two nine of you who two to two for two to four three. Two thousand two hundred forty three of you. How are the answers still changing? How are the answers still changing? Going to have to talk to Cam and Eater about that. My hands are not on this. Who got that correct? Now it looks like the second most common answer was A, which is of a very similar form. There's just a minus sign in there. So it's probably the case that while doing the arithmetic, something got flipped. We're going to walk through it in a moment so you can see. And a special congratulations to the two of you  who figured out how to submit an at sign on this. Oh, the three of you who submitted an at sign. That's not the correct answer, but well done. Well done, four of you. Very nice. All right. So clearly this is a complicated answer, but where does it come from? Well, if we look at our identity here, the key is that  it's relating two times an angle to the angle itself. So if we just plug this in for 15 degrees or for pi twelfth,  what we would get is that the cosine squared of pi twelfth. OK, if we enter that as X is equal to one plus the cosine of two times that value,  which is pi six. Pi six. All divided by two. Now, the cosine of pi six. s, we know, right? That's the same as our 30 degree angle here. Again, when you have a 30, 60, 90 triangle, the shorter side of that,  which is going to be the sign in this context, the shorter side is one half. And then the longer side is square root of three over two,  assuming that the hypotenuse is one, which in the context of the unit circle,  we always do assume. So that means that we now have one plus the square root of three over two. That's what the cosine of pi six was all divided by two, which means our final answer. When we just want to say cosine of pi twelfth,  no squared about it is going to be the square root of this value. OK, very interesting. So this is showing us that cosine and sine can get complicated. We've got a handful of values like pi six and pi thirds where we can figure them out. We can have even more, I won't call them trivial values,  but easier to compute values like cosine of pi,  where you would look at your unit circle and say, oh, pi. That means I've walked halfway around. So my x coordinate is negative one. But outside of just a handful of values like that, they're very hard to compute by hand. and in the olden days, the only way that people could compute them by hand,  before something like the existence of calculus, would be measuring it, right? You like draw out with a protractor and you try to carefully see  what the coordinates are or layering on usage of identities like  this over and over in ways that you can get approximate values like this. And just to check ourselves, we can actually go and plug this into a calculator  if we wanted to, something like Desmos and just see, one,  how big the value is and kind of confirm for ourselves that they turn out to be the same. So if we pop over here and I just type something like. Cosine of pi over 12. Point nine six five. OK, so like I said, very close to one, and that's kind of what we would expect. And the answer we just got was the square root of one plus the square root of three. Got to make sure I do the divided by two correctly. By two. Right. That looks correct. But then all of that was divided by two. All that stuff on the inside was divided by two. And indeed, they're the same value. So even just something like pi 12, we end up getting a very convoluted image. Now, like I said, this is a reflection of the fact that our cosine identity that we found  at the very beginning, just by playing through with graphs, it's definitely not obvious. And what we'll find next time is that this is actually a shadow of  the fact that trigonometric functions are related to complex numbers. And the idea of doubling the angle here corresponding to multiplying by something twice,  not at all a coincidence. I think it's very fun. I'm excited to show you guys all about that. Now, what I wanted to do just to finish things off here, though,  was to show two things that are not commonly shown about the unit circle. OK, so we see where sine and cosine are, but there might be a couple of questions. Where is tan? OK, where in our picture do we see tangent of theta? And then also, where is cosine of x or cosine of theta  squared or with the dumb convention, cosine squared of theta? So pulling up another one of my infinite supply of unit circles here. Actually, you know what? This one's not going to have enough y axis, so I'm going to do something  that I really shouldn't do, which is to try to use a compass live on camera. I'm sort of terrible at using compasses because it always slips out for me. We're just going to do this. I'm so nervous that this is going to somehow slip out. Oh, yeah, that actually didn't turn out too badly. Hopefully the pencil shows up OK on screen. The reason I'm doing this is the tangent is going to demand that we think outside of  the box, that we think outside of the circle in order to geometrically interpret it. You could just ask about the opposite divided by the adjacent,  which is where that SOHCAHTOA TOA comes from. But what I really want is a single length in our diagram that corresponds to  the tangent so we can kind of get that nice geometric intuitive feel for it. And the idea is we take that radius, which is one,  and if we think of the fact that tangent of theta, SOHCAHTOA,  is supposed to be the opposite over the adjacent,  I want a triangle where that adjacent is equal to one. OK, so a right triangle such that this one is the adjacent side to our angle theta. Well, in order to do that, let's just draw a right  angled perpendicular line off of our radial line. And some of you might know that if you draw a perpendicular line  to the radius of a circle, it actually lies tangent to the circle. So you see tangent, this is where the word comes from. Then what we have is a triangle where the adjacent side to  theta is one and then the opposite side is this length here. So that length there is the tangent of theta. And so right now you can kind of intuitively understand that as theta is very small,  when the opposite over adjacent is very close to zero,  because that opposite is close to zero and the adjacent is close to one. Well, indeed, this length also is getting very close to zero. And then you can also think through what happens as that angle approaches 90 degrees. This is something I actually illustrated once before in a previous video,  a lesser known video entitled Tattoos on Math. That, fun fact, includes someone who is behind the scenes as we say all of this right now. But the idea is that when you draw that tangent line,  tangent is this length that I just pointed out to you. And in that context, you could also think about cotangent. There's this whole other triad of trigonometric functions that aren't worth teaching,  but are kind of historical quirks. That's actually what that whole video was about. But from here, you can just play around with moving the angle theta  and seeing what that does to this tangent value, to that tangent length. And using that intuition, actually, I want you to place a guess  on what the graph of tangent of theta is going to look like. So once again, let's go over to our live question dynamic. Again, congratulations to those of you who got the last one right. And as our final question before the end of this particular stream,  which is a rather tall question, so it might actually pop up over,  over below the values we have available here. The final question, I just want you to guess what  the tangent of theta looks like when we graph it. And it should be pulled up now. And oh, there we go. It is rather tall, though. Okay. All right So let me go ahead and pull up a separate image  for you here so that you can see all of the options. Let's pop over here and take a look. Great. So again, if you go to 3b1b.co slash live, where the link is in the description,  you can submit your answers to this. Basically, which one of these graphs shows you the tangent of theta? Unfortunately, we're going to have to kind of switch back and forth to see the statistics. It looks like there's pretty strong consensus in one direction,  but I'm going to give you I'm going to give you a little bit more time to think about  it if you want to. Don't feel rushed. Don't feel like you have to jump right into it. I want a little ambient pause and ponder music while we're at it. I'm mildly addicted to it. All right. So while you're answering. So as we can see, some people are clearly messing with the website and having fun,  or there's a bug in the website to answer various other things. Other fun thing going on. It seems like we've got a couple comments in the in the Json associated with the answers. So to the person who decided to skip over my very draconian limits on the live  chat dynamic and instead entered in Json comment through the answer forum forum. I really enjoyed this class. Thank you. I appreciate that. And I appreciate your your hacky instincts. You're going to go far in life, my friend. You're going to go very, very far. So let's go ahead and grade this question here. It looks like we have very strong consensus, hopefully around the correct answer. And the correct answer is a again, maybe a little bit hard  to see on our on our indication of the question over here. But a is the graph that looks like this. And what you'll notice is it starts at zero. And then as you approach pi halves, it blows up to infinity. OK, now, in terms of the animations and the geometric interpretation of tangent,  that should actually make sense, because if we go back to what we were  looking at as the angle blows up, the angle doesn't blow up. The angle does a very modest thing of simply going to pi halves a fine number. But the tangent of that angle is going to just get bigger and bigger. And ultimately, it's it's not defined. It's the same as dividing by zero once you get to pi halves. And then after that, if you play the same game,  it's going to be it's going to be considered a negative value,  which basically comes down to the fact that the opposite and adjacent sides of our  triangle are going to be considered to have separate signs. So the very last thing that I want to talk about, like I said,  is the question of where does cosine squared of theta show up in our image? Because this is the very thing that we opened with is trying to understand cosine squared. And you might think, oh, if we can see that in our image somewhere,  maybe it really reveals why it looks like a miniature version of the cosine wave. Now, one of the naive things, not naive, but one of the first things you might  try to do is pull up the original cosine animation that we had or something like  it and say, oh, well, I'm going to take that cosine length and literally square it. I'm just going to draw the square based on that. And if I were to do this, where I'm going to plot the length of that horizontal line  and I'm also going to plot the area of that square, it's a little bit complicated. It certainly shows us what we already saw before,  which is that the square of that value looks like another cosine wave. But this is something where just by staring at the image,  it actually doesn't yield much insight. I think oftentimes in geometry or math, when you simply  write down the definition of things, the answer pops out. This is a sign that again, it's not trivial. It's very unclear why the way that that square,  that literal square would oscillate is going to be related to cosine,  much less cosine of two theta. So it's going to come from somewhere else inside our image. And for that, let me go ahead and draw a much bigger triangle for ourselves. Let's say we've got one of these guys that was living inside the unit circle. This, by the way, I think is the most exciting part of the lecture. So if there was just one thing that you were going to stick around for,  I would say that this is the thing that you should. Because it gives a very sneaky proof of the Pythagorean theorem. It might feel like a circular argument at first, but I assure you that it's not. And I also assure you that the word circular was not meant as a pun there. So remember, if that's our angle theta, then one of our side lengths is sine theta.  And that's the angle theta. And that's the angle theta. And that's the angle theta.  Then one of our side lengths is sine of theta. And the other one is cosine of theta. Let me ask you, if I draw, well, okay, so, you know,  the example we had earlier was this leaning tower thing where  we kind of imagined casting a shadow from a leaning tower onto the ground. This is sort of going to flip it on its head and say, well,  this angle theta between them, who's to say who's the tower and who's the ground? What if I wanted to have a light source over here and  I wanted to cast a shadow from the ground onto the tower? A nice perpendicular line in this direction. That way my angle theta is going to do double duty for me. It's describing the angle between these two lines,  but in one context, this ground line was the adjacent side. It was the short side. But now, if I ask you a question like, what is this side length? The shadow that the ground lays down on the tower,  if that's not more confusing than I want it to be, what are we going to get? Well, in terms of this smaller right triangle that we've just created,  by definition, the cosine of that angle is going to be the adjacent side,  the thing we want to know, maybe I'll call it s for shadow again. I'm going to write down what it equals. It's going to be the adjacent side divided by the hypotenuse. But for this little triangle, the hypotenuse is cosine. So it's divided by the cosine of theta, which means cosine squared of theta,  dumb convention, is equal to the answer that we want. Let me just write it down in a different color to really emphasize. Cosine squared of theta. And let me emphasize, this is not using the Pythagorean theorem in any way. This is not having the cosine squared arrive because we were assuming  that this sits on a circle where x squared plus y squared equals one. We're just using the definition of cosine twice  to cast one shadow and then to cast another. Now, you can probably see where this is going, do the same thing for the sine of theta. So another place where theta shows up in our diagram is right here. And a way that you can see that is that this angle plus something must equal 90 degrees. But this other something plus r theta had to be the  remaining angles of the little right triangle that we had. Or you might think up here, I could just give it a different name. If I called this other angle alpha, then we know that alpha plus theta,  alpha plus theta plus 90 degrees, or pi halves,  if you want to get used to the better conventions, has to equal pi. It's got to equal 180 degrees. This is maybe confusing. Just think alpha plus theta plus pi halves. In the back of your mind, you can go to 90 degrees  if that's something you want for comfort. But that also implies that when we have a new right triangle sitting here,  this little angle here has got to be theta because it's alpha plus 90 plus something,  so that something's got to be theta. Now, the reason I have stated that so much is because we're going to  play our same shadow casting game to figure out what this side length is. Now, with respect to that, we have sine of theta of this theta  in particular is the opposite, the new shadow we don't know,  I'll call it s prime, is equal to s prime divided by the hypotenuse. Well, on this smaller right triangle, what was the long side has become the hypotenuse,  so that's sine of theta. Sine of theta. Which means sine squared of theta is our other shadow. This here is sine squared of theta. So that's kind of cool. The side length, which was by definition one, because we've always been  rescaling our triangles such that the hypotenuse is one,  can be broken down into one part that's cosine squared and another part  that's sine squared. And the way to break that down is to just draw a single line,  the perpendicular projection from our corner point onto that hypotenuse. So what that means is every time you see a unit circle out in the wild,  which I'm sure you do pretty regularly, and you draw the standard triangle  to understand sine and cosine, so that height is going to be sine,  the x coordinate is going to be cosine, and our hypotenuse is always one. So that hypotenuse is one, this is theta. And you ask yourself, where is cosine squared in this diagram? Where is sine squared? You can just draw a little perpendicular line here,  and the part on the bottom is cosine squared. So, cos squared of theta is this length, this length here. And what we'll do in a future lecture, actually,  I want to talk about geometry and geometry proofs, and in particular,  one that comes up all the time, I've used it in many past videos,  it's high time we just sit down and say, how would you prove it,  is the inscribed angle theorem. So, after showing you how complex numbers play into things next time,  I want to turn back to this particular diagram to give another very intuitive  understanding for the identity that you found simply by playing around with graphs  at the very beginning here, which, again, is a very non-trivial identity,  that the cosine squared of some value is one plus the cosine of two times that  value divided by two. The more standard way you see it, by the way, if you were to look this up in a textbook,  instead of writing this as x, this is commonly written as something like  alpha halves for some angle, and then 2x would be alpha. And the whole thing ends up looking like cosine of alpha divided by two  is equal to the square root of one plus cosine of alpha divided by two. I, for one, I have such trouble memorizing the trig identities,  and I always would just sort of re-derive them on the fly. And this is one where I think the easiest way to re-derive is to practice  kind of smooshing around graphs in your head, when you have the one key insight,  which is that squaring cosine gets you a smaller cosine graph. And the next time I'll show you how complex numbers help  you kind of re-derive a bunch of other identities on the fly. But this one in particular, I just always had trouble remembering. It's called the half-angle identity. And I just think it's delightful that before you even know any trigonometry,  simply hopping over to something like Desmos and being a little bit playful,  that, I mean, that lands you on a highly non-trivial fact. And once again, it's one that indicates that cosine is related to exponentials. That's not obvious, and hopefully next time we can start to get a glimpse of why. Thanks for sticking around this long. Thank you once again to Cam and Ben Eater, who have been making  the item pool magic behind the scenes to get us our live statistics. And I'll see you go at the very end. I had almost everything down until the very end. I will see you all on Friday.

================================================================================
VIDEO ID: MHXO86wKeDY
TITLE: The simpler quadratic formula | Ep. 1 Lockdown live math
URL: https://www.youtube.com/watch?v=MHXO86wKeDY
PUBLISHED: 2020-04-17T20:04:24Z
STATUS: SUCCESS
================================================================================
Hello and welcome to the very first episode of Lockdown Math. So in this first lecture, what I'm going to talk  with you guys about is the quadratic formula. And traditionally, I think the quadratic formula is  one of the most famously memorized things in high school. We almost all kind of have this song that sings in our head related to it. And yet, if you actually ask someone, how often do you  expect you're going to be using this in the real world? I mean, how many people are going to give an answer  that's greater than zero to that question? Now what I want to do is give you guys a lesson regarding the quadratic  formula that's a little bit different from the traditional approach. And the main thing I want to focus on is connecting it to other  common patterns in math that are useful for general problem solving. Now the tactic that I'm going to talk through,  it's not the usual completing the squares bit that some people will learn in high school. And when you learn that, you often think, okay, in principle,  I could re-derive the quadratic formula, but frankly, it's going to be a bit of a pain. What I will talk about is somewhat similar to  something that Po Shen-Lo put out a couple months ago. For those of you who don't know him, he has a YouTube channel,  but more than that, he's the coach of the USIMO team,  and he has a company called X-Py, does a lot of great math stuff. So he talked about kind of an alternate way that we could teach the quadratic formula. The way I'm going to talk about it is a little bit different from how he did,  but certainly very similar in spirit. Again, the upshot that I want you guys to come away with is the fact that you should  connect this to other common patterns in math so as to make yourself a better problem  solver. And that should be the main takeaway lesson for, you know, this particular topic. Now these lectures in general, I'm going to be shooting for something  roughly on the order of an hour for each one of them,  and the dynamic that I'm going for is one where there's questions that I'm  asking the audience, and then the audience interacts with it in a very,  well, in a very live way. Now the thing about live stuff though is sometimes  it doesn't go the way that you intended. So the general technology that we're going to have for this is going to involve  me pulling up some kind of question, like for example right here,  the question is asking kind of facetiously about your relationship with the  quadratic formula. And I even had this going over the intro animation for you guys. And then what you see is the statistics associated with what the answers,  you know, other people are entering are. And they'll kind of get overlaid, we see the bars. At the moment all you see are question marks. We don't know what the most common answer was,  but at some point I can choose to grade that and then we'll see. Except for the fact that it looks like there's quite a few of  you guys and it's giving our servers a little bit of trouble. So we have a couple people who are going to be working on that in the background. In the meantime I'll just be asking the questions that are pushing us through the lesson. For future streams this will hopefully be a much more dynamic situation  where as you answer we're kind of grading it and you see how it's going. For this particular one, who knows, some magic might happen halfway through. But there's a lot of excitement among you guys right now which is awesome and I love that. And let's see if we can translate that into some of the math itself. So one of the questions that I was going to ask is how  many times do you expect to use the quadratic formula? And when we were doing this a little bit earlier with a couple people,  for sure the most common answer was zero. Zero times is when I think I'll use the quadratic formula outside of school. And a funny story about that, I actually was once giving this talk at Pixar where I  brought it up as this example of something that we teach every student and it's unclear  why. They're not going to use it. And I should have known better than to say this to a bunch of  engineers at Pixar because one of them looked at me and he was like  oh I'll have you know I actually use the quadratic formula all the time. His name was Tim Babb and he very kindly sent over basically a storyboard for a video,  something I think he was pitching me on. And the basic idea he was talking through an image  that he created purely with computer graphics. I think this is totally beautiful. You would think that this is a photograph of some reflective  billiard balls but this is entirely computer graphics. And the tactics used behind this involve something called ray tracing. So the basic idea there is you sort of imagine a camera shooting out a bunch  of rays through each pixel of your screen and then depending on whether it hits  the sphere and how it hits the sphere that tells you how to color each pixel. Now part of that problem though is to know hey if I'm  shooting a ray in some direction will it hit a given sphere? And so what you might do is define a certain vector,  you might imagine an amount of time that the beam of light is moving,  and then you can come up with a graph for how close is that ray to the  sphere as a function of time. And in some cases if it passes through the sphere  you're going to have two solutions there. And once you work out the math it turns out this is a quadratic equation  so what you need is a systematic way to plug in these solutions to a  quadratic equation and it needs to be programmatic it needs to be some  kind of formula because you're doing this for every single pixel on the screen. You also need to be able to know is it just glancing  off of the sphere or does it not go through it at all? And again all of that comes down to solving a quadratic. And this particular engineer at Pixar he did a loose back of the envelope calculation  for me that suggested the movie Coco probably used the quadratic formula over a  trillion times just given how many lights there are for every single frame in that shot. So in some very real sense the quadratic formula is useful to  the point of being used a trillion times to produce a movie. Nevertheless I don't necessarily think that's representative of most  people's future and it could be the case that the reason we teach people  this formula is because maybe they happen to be that Pixar employee. You never know what's going to be useful. But I want to make the case again that we can connect  it to other patterns and problem solving bits in math. And the way that I'm going to go about this is to start in a place  that's frankly completely unrelated to quadratics and quadratic functions. I just want to talk about some mental math tricks. Because I think if you are thinking about arithmetic, something very basic,  something we do in elementary school, and you think about it deeply enough,  some of the patterns that you observe become relevant to stuff that you're doing later on. So for example let's say I ask you to factor the number 35. You know it's easy to see that five goes into it and goes into it seven times. Each of those is prime. Great! We know how to factor 35. Now factoring is kind of an annoying task the bigger the numbers get,  especially if there's no obvious small factors that go into it. Because if I asked you, hey let's factor 143, I mean how do you go about it? I think the way a lot of us think about it is we initially think,  okay, we know that two doesn't go into it because it's not even. Three, there's a nice divisibility check where you do one plus four plus three,  and that sum in this case is five plus three or eight is not divisible by three,  so that's out. Five we can see doesn't go into it. Seven, okay you have to think about that for a moment,  but you might see that seven goes into 140 evenly because that's 20 times seven. Okay so that's right out. And at this point you might be annoyed with whoever was asking you the question,  but if you go one step further you might see, okay 11. Actually 11 does go into it and it ends up being 11 times 13. I just love the fact that right now people probably have no idea what any of  this has to do with the quadratic formula, but I assure you, highly related. Because what if I asked you 3,599? And this particular example isn't randomly chosen by the way. I was reading this article about a Russian programmer in an interview that he had,  I think it was at Goldman Sachs, and he was describing kind of  the intensity of that interview environment. And in one of them he just walks in the door, hadn't even met the person,  and the person just shouts at him, factor 3,599. You know the programmer's like, uh, all right. And he actually was able to spit out the factors particularly quickly,  which is impressive given the fact that if we imagine going through  all of the different primes, you know, does two go into it? No. Does three go into it? No. Five? No. You're going to be sitting there for quite a while. So clearly something different was happening in his head, and the question is, what? Well one thing you might notice about the numbers that  I've chosen here is that 35 is awfully close to a square. It's actually just one less than six squared. And maybe it kind of makes sense that its factors are each kind of close to six. You know, five times seven, it's probably not going to equal six times six,  but the fact that they're of similar sizes should be intuitive,  and as it happens it's precisely one less. And something similar happens with the other example I chose. 143 is rather close to a square number, 144. In fact it's one less. And it's no coincidence that its two factors are  hovering right around the square root of that value. One of them is 12 minus 1, and the other one is 12 plus 1. So it kind of makes sense that the product will be something around 12 times 12. And so from this you might make a guess that, hey,  maybe any time that you have some number that's one less than a perfect square,  and this, you know, it's suspiciously close to a very round seeming number, 3600. Well, what is 3600? We recognize the 36 as being six squared and 100 is 10 squared, so that's 60 times 60. And maybe you think, okay, the guess, if it's going to follow the same pattern as  what we've seen above, is that this would be one less than 60 times one more than 60. But of course you don't just want a pattern match. Let's see if there's a nice reason that it's a true. You can work it out algebraically, which we will, but as you guys know I love animation,  so let's just see if there's a nice visual way to understand this particular property. And if we're going to think about this, the natural  place to turn is to think about squares. So let me just pull up an image of a square, and if we want to say,  can I factor a number which is one less than a square,  what I might have us imagine doing is taking the corner off of that square, okay? So let's say it's x by x, whatever x is, in this case it happens to be six,  but you want to think a little bit more abstractly than that. And I'm going to take that bottom right corner, get it out of here, we don't want it. The question of factoring is to say, can I rearrange  the quantity that remains into some kind of rectangle? And in this case if I take that bottom row, sloop it on up to the right,  what you can see is it forms a rectangle, one with a side length x plus one,  and another with a side length x minus one. So this general property holds quite well, and I think that's really cool, right? You see this visually, you see that it's this neat mental  arithmetic trick where any time you have some sort of square number minus one,  you can factor that as x plus one times x minus one. But of course we can go one step further than that if we really want to. It doesn't have to be one sitting there. If we go back to our diagram, what you might instead do is say,  hey, what if I chopped off a bigger corner of that square? What if I wasn't taking x squared minus one, I was taking x squared minus y squared? Well, I can rearrange what remains into a rectangle where  it's x plus y on one side and then x minus y on the other side. Now that's the geometric way that you can view it,  which I think gives a certain satisfaction. And when we view it in terms of numbers, it gives us a reminder of how powerful it is. And yet somehow when we do this algebraically, the magic is a little bit lost. It's definitely easier to see, and that demonstrates the power of algebra. But if I just said x plus y times x minus y, actually,  you know what, let me change the variable names there. I don't like x and y because those don't necessarily have the same meaning. What I might do is try to picture, you know, let's picture the original  two numbers that we had, something that's like 59 and 61 on a number line. And I want to think in terms of the midpoint m and then  the distance between m and each of the other numbers. So plus and minus d. In this case, d is just one, but in principle, it might be something more. So if I ask you multiply m minus d times m plus d,  you know, at this point, it's pretty straightforward algebra. The first term is m times m. We get m squared. Next, we have negative d times m. So that's minus d m. Next, we have m times plus d, m plus d. That's plus d and then negative d times d. So minus d squared. And indeed, what comes out is m squared minus d squared. And if you're anything like me, the first time you see this in an algebra class,  it's just one of a whole bunch of exercises that you're doing. You're like, yeah, okay, can expand this one way. I guess some terms cancel out nicely. But the more you think about this, the more intriguing it is,  because any two numbers we can express, you know, if I just take any numbers r and s,  I could write that down as some midpoint plus or minus a distance. And what this is telling us is to think about products is always the same as thinking  about a difference of squares, which is weird, because products can be very chaotic. If I just walk through the number line, and I don't know, we I say look at 101,  102, 103, and I just say, take a look at all the numbers on the number line. And I want you to systematically tell me, can each one of  them be broken down as a product of two smaller whole numbers? Well, we know that what that's asking is, what are the primes? Because only the primes can't be broken down like that. And yet, evidently, that's a very similar question to saying,  when can I walk through those numbers and say, hey,  am I able to express you as a difference of squares? Could I add a square number to you to get another square? That still feels hard. But that feels like a very different question to me. So I think if you were doing some arithmetic, and you had this in the back of your mind,  that's a good pattern. And that's a pattern that's going to come up later in life. For example, let's say later in life, you find  yourself wanting to understand quadratic functions. And so here, we're going to talk about the simpler version of the quadratic formula,  which is really just refactoring the original thing. but I hope you see it's much easier to actually solve a random  quadratic that's thrown at you if you're going by um if you're  going by the method that I want to show you right here. So what's the task? Anytime you have some function that looks like ax squared plus bx plus c,  okay, for any numbers a, b, and c. So maybe that's something like 3x squared minus 4x plus 5. And you want to know when that equals zero, what are the two roots? Now, this is actually equivalent to rescaling everything. And I think it's a good common pattern to rescaling,  where I'm going to divide everything by a. So I just want that first coefficient to be equal to a. Because that's way easier to work with. So I'm going to call that x squared plus b prime x plus c prime,  where b prime and c prime are just the rescaled versions there. And this is a different function. It is a different quadratic function, but the roots are going to be the same. And one way that you might see this is if you just graph them. So let's go over and pull up our best friend of Desmos, right? So let's say I have some kind of parabola. In this case, I've written it so that one of the  roots is going to be two and the other is four. And then g of x here is just the scaled version of the expanded version of that. It's exactly the same graph. But let's say I wanted to scale that up and down, right? So I might take this and then I will multiply it by some kind of constant. What do you guys want to call that constant? See, this is the thing. If I had the question framework working right now,  I could just ask you, what do you want the constant to be? And we would see the statistics come up with what people had. But instead, maybe I'll throw in a slider. And as I change that, the function changes. It is a different function, but the roots are still two and four. So solving for this rescaled version of the quadratic is the same. And that should kind of make sense because s times zero is always going to be zero. So it doesn't matter how much we scale it. So going back to what we're working with here,  the reason that I think it's much nicer to make sure that that leading  coefficient is a one is because if we're thinking of our quadratic in terms of its roots,  and I say, okay, you know, it's going to intersect the x-axis at r and s,  or maybe it does, maybe it doesn't, but let's just write one that does like this. Another way that I could express that particular  quadratic is as x minus r times x minus s. Because if I plug in r, it's clear that we're going to get zero. And if I plug in s, again, this term will also cancel out to zero. So if I expand this, whatever r and s are, they're the unknowns,  I should get the same thing as what we have up here. And this is generally useful. This is not just for the quadratic formula, but a very good relationship  to have with polynomials is to know how the roots correspond to the coefficients,  especially in a circumstance where that leading coefficient is one,  and the whole polynomial has been kind of normalized in that way. And in this case, if you just expand it out, what we'll get is x squared minus  r plus s times x, because we have this minus r times x and then x times minus s. And then the constant term will be negative r times negative s,  so that becomes a positive r times s. Okay, so what does this tell us? This tells us the first two of the three key facts that are needed to be  able to solve any quadratic without really needing to memorize all that much. So the first key fact is that this b value, I'll call it b prime,  just to remind ourselves that it's after you've scaled things down,  is the same as the negative sum of the two roots. Okay, and then similarly, c prime is going to be the product of those two roots,  which is kind of cool, because what we have right here is, you know,  it's a system that feels like it should have a solution. We have two equations and two unknowns, but it's  not obvious how we would go about solving it. And every now and then, I think classes will have a unit in factoring quadratics,  where they basically tell you to just guess and check. So in some very fortunate circumstances, if you have something like,  you know, x squared, let's see, minus 7x plus 12. They basically say, see if you can guess and find two  different numbers that add up to be 7 and that multiply to be 12. And if you just kind of sit back there and think, you're like,  okay, can I find any two numbers that add to 7 and multiply to 12? Well factoring 12, we get 3 and 4, and 3 and 4 do add to 7. So yeah, in that case, you just totally luck out. And you could write this as x minus 3 and x minus 4, because those are the two roots. And then you typically move on from that chapter and it's like,  well, in most cases, you won't be able to just guess and check. And in any case, what you're going to look for is a general formula anyway,  so hope you had fun with that. But it turns out there's actually a systematic way to take this puzzle of finding  two numbers that have a known sum and a known product and figure out what they are. And the key comes down to thinking in terms of not the two numbers themselves,  but the mean of those two numbers, and then the distance between that mean and each one  of them. And you can see where this is going. This is why we talked about difference of squares,  because the third key fact to come away with, or to come into it with,  I should maybe say, is that we could re-express that product as m minus d times m plus d. And you see where I'm going, right? That means that the product that we know looks like m squared minus d squared. So just to give an example here, it's often much more helpful to have numbers. Let's say that you were given a quadratic like x squared, I don't know,  let's do six, even numbers will make this easier for us, and then seven. And you were tasked with knowing when does this equal zero? So I haven't told you how to solve it yet, but these three key facts  are going to be enough to just basically walk yourself into the answer. Well, what is what is m, right? Because we're  going to ultimately express our roots r and s As m plus or minus d for some kind of midpoint. Well, that midpoint is the sum of the two numbers over two. That's how we define averages. And because we know the sum of the two numbers is negative b prime,  that's the same as negative b prime over two, which you can basically read off of the  equation as just negative one half times whatever's sitting right there,  which in this case will be negative three. Awesome, we know what m is. But look at the equation we have up here. We have an expression for c, the last coefficient, in terms of m,  which we now know, and d, which is the only thing we don't know left. So we could rearrange this, and so that was saying c prime is that,  we could say that d squared, the square of this kind of standard deviation  between our roots, is m squared minus c prime, the product of the two roots. But we know both of those values, we could just write that down over here. Maybe I'll change colors again, be a little flamboyant. d squared is equal to m squared, which in our example turns out to be nine,  minus c prime, which is that last coefficient, or seven. Seven. Handwriting is terrible, but I think you guys can work with me. You see why I usually animate stuff. So that means that's two. So look, when we said r and s is some midpoint plus or minus a distance,  that midpoint is negative three, plus or minus, well if d squared is two,  that means d is the square root of two. There you go. You could do that for any quadratic that I give you. You could just walk through that particular process. And let me just show you what it looks like in general,  so that you can maybe remember it as a formula if you wanted to. In general, for any quadratic, that midpoint is just the rescaled  version of b if the leading coefficient wasn't already one, divided by two. And then that distance, well what did we just do? We took the square root of the midpoint squared minus the product of the two. And when I'm sort of thinking into my head, I've been saying like m squared minus p,  just because p has a readable meaning. I think of it as the midpoint squared minus the product. But of course p in this context is just whatever  the last coefficient of our quadratic was. So over in this example, the product of the two coefficients was seven. So for me, what I think the simpler quadratic formula is,  if you're going to memorize anything, is to come away and say it's m plus or minus the  square root of m squared minus p. All you have to do is first find m, which is, you know,  just a factor times one of the coefficients you're looking at, and then find p,  which is also, if not already, a factor, a coefficient that you're looking at,  a rescaling of one of them. So this to me is way simpler than the traditional quadratic formula. And if you were to try to sing a song to yourself for it, the song is almost too short. It's no fun. You're just sitting there like m plus or minus square root of m squared minus p. That's it. No song. No song to be had. So let's do a couple practice problems, because I do think practice will make it easier. And for future streams, again, it'll ultimately be the case that I'm giving you  these questions, and then you'll be able to go to 3b1b.co.live and answer them. But because there's too many of you, we can't have any fun today. This is the equivalent of trying to run a class where you have, you know,  I don't know, 20 seats sitting out and you're going to do a normal lecture. And then there's just people banging at the doors and trying to cram themselves in,  and the fire marshal comes in and they're like, ah, you got to cut out the class. You can't have this the way that you hoped for. But it's cool that there's so many of you here enthusiastic to learn about math. So let's just do some examples. Okay. That'll kind of highlight what this process looks like. Let's say we had x squared plus 10x plus three. So in this case, it's nicely already rescaled for us. That's always lovely. So I often, I just like to draw the picture for myself,  whether or not the two roots turn out to be real or even positive. It's just nice to remind myself what we're looking for. We're looking for where the two roots are. And I know that a different way to think about  products is to think about a difference of squares. So I just kind of think in my head, okay, I'll be thinking of  that in terms of their mean and the kind of standard deviation. So I just write down for myself, what does that mean? Well, it's negative b prime over two. And if I forget that fact, if I forget that that's what the sum of the two roots is,  I could always just go through this little rigmarole again and say, okay,  if I systematically wanted it to be a quadratic with roots r and s,  this is what it would look like. This is how it would expand. So you can re-derive it on the fly. There's not too much memorization needed. In this context, that works out to be negative five. And by the way, if I do ever make any mistakes,  which I'm quite positive I will, go ahead and throw them in the  chat and those will be forwarded to me and I'll be able to correct myself there. So we know the midpoint. And then we just ask ourselves, what's the square of the distance? And based on difference of squares, that'll be that midpoint squared minus the product,  which in this context is negative five squared or 25 minus the product,  which is that last coefficient, minus three. So what are the roots r and s? Well, it's negative five plus or minus the square root of 25 minus three or 22. There you go. Another quadratic solved. Ain't no thing. Let's try another. Just because I do think it's kind of nice to get a little bit of practice here. And as I'm going, if you have a piece of paper and pencil, please follow along. If you can just kind of race ahead and do the same process before I do it, that's awesome. That is the best kind of learning experience. If you're watching this in the future, by the way,  as with any video, I highly encourage you to pause and ponder. I really think that's the best way to learn math. If you're looking at some kind of lecture in those crucial  moments where there's a question asked, pause,  see if you can do it yourself and then see what the answer turns out to be. I guarantee you'll learn more effectively that way. I don't know. What should we do? Let's do maybe three x squared. I think I wrote one down earlier, didn't I? Just as kind of a offhanded thing. What did I write? That wasn't there. Oh yeah, it was at the top. Let's do that one. Three x squared minus four x plus five. Why not? Three x squared minus four x plus five. All right. So in this case, step one, we've got to rescale things. The first one gives the coefficients a nice readable meaning. Minus four thirds x plus five thirds. Great. And now same process. I'm sort of thinking in my head of this particular  image where I want to know the midpoint and the distance. So I say that midpoint is negative of this second coefficient divided by two. So that will become positive four thirds. But then that four divided by two gives us a two. So that midpoint will be two thirds. And then the distance squared is m squared minus the product,  which in this case is five thirds. Okay. And m squared in this case is, let's see, two thirds squared minus five thirds. All right. So this one, you know, it gets a little messier. We've got to work out our fractions, but that's not too bad. Two thirds squared is going to be four ninths. Oh, I'm off screen a little. And then what is five thirds in terms of ninths? That's going to be fifteen ninths if I'm not wrong. So we end up getting a negative number, which is always fun. So here we have negative eleven ninths. Okay. So what that means is that our final answer, the roots of this polynomial are in s. The values that will make the polynomial zero are going to be  two thirds plus or minus the square root of negative eleven over d. Negative eleven over d. What am I saying? Negative eleven over nine. Okay. So that's fun. In this case, the square root is a negative. So that means we have complex roots. And there's actually a very fun way to think about the way that complex roots  play into this difference of squares perspective on the quadratic formula. Let me actually try it with a simpler example,  but it ends up relating to the Pythagorean theorem,  which I think is cool because the whole purpose of this is to try to  connect various patterns in math that come up a lot. Things that might be useful outside of this particular class that you're doing. So I actually have written down for myself an  example that will work out with nice numbers here. I mean nice-ish. X squared minus six x plus ten. Okay. So we go through the same rigmarole. We say m, the midpoint, is going to be negative b prime over two. So in that case, it works out to just be three because  we take the negative of this term and divide by two. d squared is going to be m squared. So three squared is nine minus the product, which in this case is ten. So nicely that's exactly negative one, which means that our two roots,  and I'm down to the y or on the page that I've been writing with here,  our two roots are three plus or minus i. Okay. So what that means for us is that the actual parabola here,  it doesn't look like something that crosses the x-axis. Instead it would be something that maybe sits above it. But it does have imaginary roots. So if we were to look at the input space, not just in terms of the real number line,  but let me draw it out. Let me go back to black. Black will be our complex plane color for this moment. We'll call this our imaginary axis, where numbers like i and negative i,  the square root of one, or maybe I should say square roots of one, it's got two of them. You interchange them, it's fine. And then we've got just the real numbers. One, two, three, four. So in this case, our two roots live at three plus i and three minus i. So this, I should be very clear, this is not an x-axis and a y-axis. This entire plane now is where the input lives, where x lives. If you were going to graph it, you'd get some kind of graph that's outside of the paper. And any of you who've watched the channel Welsh Labs, which if you haven't,  you absolutely should, might be bringing to mind right now an absolutely awesome  like artificial reality effect he does, where he sort of pulls out that graph. Highly worth watching, super great moment. But what's interesting about this is if we look at the magnitude of the roots, okay? Because I could ask you, what is the magnitude of that root? And it's a right triangle that we're looking at. We've switched from algebra to geometry now. And based on the Pythagorean theorem, it'll be the square root  of one of the lengths squared, which is in this case three squared,  plus the other length squared, which is one squared. So square root of three squared plus one squared, and that ends up being root 10. It is not a coincidence at all that the magnitude of our roots,  I guess sort of no pun intended, the magnitude of the roots of our  quadratic equation here are the square root of that constant coefficient. Because remember that constant coefficient is  telling us what is the product of the two roots. And if you know something about complex numbers,  you might know that if I have two complex numbers and I multiply them together,  the magnitude of the product is the same as the product of the magnitudes. So in this case, given that I'm going to have two separate roots who are symmetric,  you know, it's going to be three plus or minus some imaginary number,  each of them is going to have the same magnitude. The product of their magnitudes needs to be 10. We know that offhand. So you kind of know ahead of time that it should be magnitude of square root of 10. And the reason that this is happening is basically because when you do  difference of squares, something like m plus d times m minus d,  but that distance is an imaginary value, i, what you get is m squared minus  i times d squared. But because i squared is by definition negative one, you get a sum of squares. So even sums of squares, which come up in geometry,  Pythagorean theorem stuff, all of that, can be expressed as  a kind of difference of squares, which itself gives a kind of factoring. And this, this shows up in a lot of very, very beautiful math later down the road. One of my favorite videos that I've made actually is, oh, what did I title it? I think pi hiding in prime regularities, where  you're counting lattice points inside a circle. And the key insight associated with doing that is to realize that asking when  you can express something as the sum of two squares is a sort of factoring problem,  but it's factoring not where you're dealing with prime numbers on the real number line,  but primes in complex numbers, these things called Gaussian primes. So even simple, I shouldn't say simple stuff, but even stuff that comes up  in high school, like the quadratic formula, I think if you're learning it the right way,  it ends up connecting to all sorts of other delightful things. And remembering these patterns comes up, like I said. So just to re-emphasize, how did we get here? What three key facts do you need to be aware of with quadratics to  be able to kind of rediscover a kind of quadratic formula on the fly? The first one is how to read the coefficient sitting in front of x. And if we have a quadratic that looks like x squared plus b prime x plus c prime,  you can read that first coefficient as the negative sum of the roots. You don't know that already, you can rediscover it on the fly,  but that is actually worth coming away with. Similar with how you can read the other coefficient, it's the product of the roots. Then the only other thing you need to know is that we could  express that product of roots as a difference of squares with  respect to the mean and the kind of standard deviation of those roots. And you can just solve any quadratic that comes to you on the fly. The only thing that looks remotely like memorization is if you want  to jumpstart to the end and just say m plus or minus m squared minus p. Now to finish things off, I think it would be very satisfying  to remind ourselves that this is actually equivalent to the  traditional quadratic formula, something that looks much bigger. So let's go ahead and actually do that exercise. And again, if you can, pause and just work it out for yourself right now. So let's remind ourselves of how that goes. So we've got, what are we solving? Any kind of quadratic. Ax squared plus bx plus c. We want to say no matter what a, b, and c are,  give me a systematic way to find these roots. Again, maybe you're doing something beautiful like ray tracing. Let me pull up that image again. That was a really nice image. I just can't believe that this is something that a computer generated. I guess I should believe it because like Pixar movies are amazing. But evidently, if you know the kind of math that can lead you to create an image  like this one, that's the kind of thing that can get your job as an engineer at Pixar. And of course, what is that math? That math is exactly what we're doing right now. So let's work it out again. Ax squared plus bx plus c equals zero. This time, we're just going to write everything in terms of a, b, and c. No new variables coming up. So when we do the first step of rescaling, we say x squared  is equal to b divided by a times x plus c divided by a. We don't give it any new names. Now remember how our trick works. We sort of picture in our head, hey, imagine this quadratic has some roots. Let's call them r and s. And we're trying to find the midpoint and the standard deviation. And we can read off that that midpoint is the negative of the second term divided by two. So in this case, that's going to be negative b over 2a. Great. And then that standard deviation is going to be m squared minus the product of the roots,  which in this case looks like negative b over 2a squared minus,  and the product here is what that last term is, c divided by a, c over a. And remember, if you don't remember this idea that, oh,  that's what the distance is, just re-derive it for yourself on the fly. Just go and say, okay, I remember that the product p is just the product of my two roots,  which can be expressed as m minus d, m plus d. Oh, okay, that's something I can write as m squared minus d squared. Oh, okay, that's what gives me an expression for d squared in terms of m squared and p. Don't feel like you have to just come in and know it off the top of your head. But after you do it a couple times, it sticks in your memory. So that's m, that's d, and the quadratic formula is just telling us that the  roots are m plus and minus, that's standard deviation, which in this case looks like,  maybe I'll write it out on two lines because this will be a lot, negative b,  actually no, I'll write it on one line for this one, negative b plus or minus,  I'm jumping to the original quadratic formula, a little bit too hard ingrained,  we'll go back to two lines, negative b divided by 2a,  divided by 2a plus or minus the square root, oh, I wrote this incorrectly, oh,  someone should have corrected me. This is what d squared is equal to, d squared is this whole thing,  so d itself is the root of those. I'm sure lots of people were shouting that in the live chat,  I don't have it pulled up now, but to those of you who did, much appreciated. So what do we have here? Well, it's going to be the square of negative b over 2a minus c over a, minus c over a. Okay, now we just got to expand this thing, which is frankly not super fun,  but it'll connect it to the original quadratic formula to for us. So I can pull out this 2a squared, and I'm just going to write that as 1 over  4a times negative b squared, negative b, yeah, negative b squared,  and then I want to also pull out 1 over 4a, I want to be able to say that  the last term also looks like 1 over 4a times something,  and that something to make it equal to c over a would have to cancel out the 4,  it would have to cancel out an extra a, and then c, sorry,  because this is really 1 over 4a squared. Let's see, have I done this right? Yeah, because I pulled out the 2a, so that should be 4 times a squared,  so over here I have 4 times a squared. I want that to cancel to become c over a, which it looks like it does, so that's awesome. So you can go over here, negative b over 2a, plus or minus,  and if this feels tedious, that's kind of the point. The whole quadratic formula is more complicated than it needs to be,  because we were just solving any quadratic that was thrown at us without having  to do this, but this is what happens if you don't introduce any new variable names  on your way. It's like code that hasn't been refactored properly. Okay, so what can we do here? We can factor out the 1 over 4a squared, and because that's in a radical,  its square root will also be 1 over 2a, and then what sits inside is what remains,  the well familiar negative b squared minus 4a. Okay, and this this is starting to look like the traditional form,  because if we pull onto the numerator, negative b plus or minus square root of... why am I writing negative b squared? Yeah, so this is a negative b squared, same as positive b squared. What should sit on the inside here is b squared minus 4ac. You can see how scatterbrained I am when I'm just doing some arithmetic at times. It's okay. We all forget a variable or two here and there,  but maybe that's why I actually care so much about formulas having nice  readable meanings, because I think this is a very error-prone process for someone like me. If I'm just trying to work through with a bunch of symbols that I don't  necessarily know how to read them, I get to the end result,  and it's hard for me to say like, oh yeah, of course that's what the answer is. Whereas if I look at something like the simpler variant of the quadratic formula,  if I basically refactor it and I'm saying, okay,  does the midpoint equal negative b over 2? I can kind of fact check, yeah, that that makes sense,  especially if you know a little calculus. Those of you will be able to look at that quadratic formula  and understand how to find the maximal or minimal point. So that's a thing that gets reinforced with a better pattern later on in  your mathematical life, always a good sign that you're learning things well. I can ask myself if it makes sense that the distance looks like this. Again, that has a readable meaning. So when I'm looking at the simpler version of the quadratic formula,  we have m plus or minus a kind of square root of the variance,  a kind of standard deviation. So it's a refactoring. Now I titled this thing, this is the simpler version of the quadratic formula,  and I think someone could rightfully complain. Like, is this actually simpler? Because, you know, you've got a lot of steps, you've introduced new variables into it. Now, in addition to thinking of the three coefficients a, b, and c,  you're telling me I also have to think about like a new term m and a distance  between them. But for me, math is very much about trying to draw connections to other patterns,  and I think things are much better remembered if you have that web of  connections in your head rather than just isolated cases. And the whole lesson here, if we think about what's going on,  it's about representing the same information in different ways, right? Because what the quadratic formula is doing for us, it's saying,  can I go from my coefficients a, b, and c, and can I get to the roots r and s? And we know that there's a very easy way to go the other way around,  because we can expand something like x minus r and x minus s. And really, because that a can get scaled out,  it doesn't add any information to the system, there's really as much information  as two different constants in there. So one of these directions is easy, and one of these directions is hard. And this idea of information that can be expressed in separate ways and translation  one direction being easy, one direction hard, that comes up all the time in math. That's a very useful thing to think about. And another useful thing to think about is how sometimes going in that  harder direction will be better if you go through some intermediate step. In this case, rather than thinking of your pair of numbers on the  number line just as they are, doing your m plus or minus d trick,  because we know that that changes how you think about products. If you go through the intermediate step of expressing that same information  with a mean and a standard deviation, that can get you to the roots. And that's all this is, it's just talking about different information flow paths  that can help go between various ways to just express two numbers,  whether those two numbers are the coefficients of your quadratic,  or the roots of the quadratic, or the mean and standard deviation.  So if the lesson you come away with is one of thinking, oh wow,  sometimes there's a lot of different ways that I can represent my data,  and some of them lend themselves to certain kind of problem solving better than others,  well then that is the proper lesson to have with the quadratic equation. Okay, so I think with that I'm going to call it an end to lesson number one. Really want to thank everyone who showed up for this, definitely a ton of fun. Next time we're going to have the live quizzing dynamic where we're  going to get stats up on the screen, so it's going to be pretty cool. I think this is a very cool thing that two former co-workers of mine  put together from Khan Academy, but obviously this is the first time  that we're trying it, it's a little rough around the edges,  so in the end what it's going to look like is these bars that you're seeing live. Oh interesting, these are bigger numbers than they were before. Okay, clearly they're updating, they're updating. Oh this is exciting. Do I have actual access here? Oh it would be so fun to do this properly before we end. Oh my god, oh this is so great, I think we're, I think we can do it. Okay, are you ready for this guys? Okay, I'm grading the answers. Oh, oh wonderful, oh we can see what people answered. This is great, this is how I wanted to end the stream. While I was talking just in the background some magic was being done, this is wonderful. So it looks like the most common answer, what's our question here? What best describes your relationship with the quadratic formula? And the most common answer is C. I'm a big fan, you might say I'm rooting for it. So it looks like 1724 of you, five short of Ramanujan's constant, are addicted to puns. Let's do a couple more, this is going to be pretty fun. These were just like the joke warm-up questions before we got into the real lesson,  but I actually think this is the perfect way to end the whole lesson,  is to just kind of wind down with some of what were meant to be introductory jokes. Oh it's working, I love this so much. Oh and there's so many of you answering, this makes me so happy.  All right so what's our question here? If the quadratic formula had a patronus,  what would it be? Okay well it looks like around 800 of you think it will be something. By the way, I'm being told right now that if there's too many of you who access it,  we're for sure going to break the system, and I'm purposefully ignoring that  because I'm having fun with this and if it breaks that kind of tickles me. So I'm being told not to say this, but please go to 3b1b.co live and enter  questions to this, and then you know whenever things break that would be  a perfect time to end the stream because I just think that's hilarious. Okay so oh again 1791, oh I guess we blew past Ramanujan's constant. Maybe I can try to see if I can grade this at a point right where we're  going to lock in answers where the majority is 1729, I think that would be fun. Okay so it looks like a majority of people went with C. If the quadratic formula had a patronus, it would be an old man  hunched over a chessboard, which is the correct answer actually. You know this question was structured as a poll where there's  no correct or incorrect rating, but I don't think that's right. I think it should have been structured where C is the  objectively correct JK Rowling would agree style answer. All right let's do the the warm-up question number three here. Oh this is a fun one. Okay what does it say? What integer will most people enter into this box? Okay oh oh lots of answers coming in. Again I really want my friends to like struggle, I have bars all over my face. You know this actually seems apropos given that the whole title of this is locked  down math that it starts to look like I'm slowly being imprisoned by everyone's  answers and just getting locked down further and further into the quarantine situation. So this one actually now there is a, where do I talk? Help! Bars are attacking me,  okay there's an objectively correct answer because there is going to be  some number that most people enter. And it looks like 919 of you think  that it'll be one particular thing, but we've got a widespread, This is actually pretty fun. So again if you want to partake in this head on over to 3b1.co.live. I actually think the best way that you could do this. Oh what is the seven? Wow I would not have guessed that most people entered seven  and in a weird way like the plurality of you are definitionally  correct that seven was the most commonly entered expression. 69 being the second most common. I can make a guess for why that might be the case. Did you know that 69 is the first number where if you square  it and then you cube it those two values between them encounter  the numbers or the digits zero through nine once and only once. Yeah it's the first number with that property which I  assume is why that was the second most popular answer. But the very end which is actually apropos at this point we can pull  up another question which is going to be what I was going to open  the whole lesson with so you can kind of see how the plan went here. How many times do you expect to use the quadratic  formula in your real life outside of school? And in this case luckily I'm getting a little bit less you know locked down by the bars  trapping me in here because it seems like there's a little bit more consensus around  how many times people think they will need to use the quadratic formula in the real life. What I could do is a plot twist on this and say you know interpret this question  in light of the lesson rather than when will you literally use negative b plus or  minus square root of I always forget it square root of b squared minus 4ac over  2a 2a that whole thing to when are you going to use the principles of recognizing  that a product of numbers expressed as a difference of squares can help you solve  problems or we're going when are you going to use the principles of expressing  your data in terms of a mean and a standard deviation can help you solve problems. That I think would give you wildly different answers but at the moment  we've got a lot of you on the system and it's not breaking and I'm  so happy right now I just can't tell you how much this tickles me. So it looks like we've got a wide forming consensus you know for for my sake can we  can we just like keep going on this I would love to see if we can get that top bar  up to 1729 whatever it might be at the moment we can all guess what it might be but  let's see if you can go to 3b1b.co slash live wherever you're watching this I think  honestly the best dynamic that I could imagine is if you just pull up your phone  and you're watching this on a screen with the one hand and then you're using your  phone to to answer questions a lot of you are already watching it on your phone so  that wouldn't necessarily work but that is the dynamic I would I would most expect. Okay so I'm just going to wait until we get that  top bar up to be Ramanujan's constant of 1729.

================================================================================
VIDEO ID: ppWPuXsnf1Q
TITLE: Lockdown math announcement
URL: https://www.youtube.com/watch?v=ppWPuXsnf1Q
PUBLISHED: 2020-04-16T21:25:09Z
STATUS: SUCCESS
================================================================================
As many of you know, with the coronavirus outbreak still very much underway,  there's a huge number of students who are left to learn remotely from home,  whether that means doing distance classes over video conference or trying  to find resources like Khan Academy and Brilliant to learn online. So one thing that I wanted to do in the next coming weeks,  which is very different for me on this channel,  is to do some live-streamed lectures specifically targeted at high school students. With each lecture, I want to cover something that's a standard high school  topic that most high schoolers will be expected to learn,  but at the same time to have some kind of intriguing angle on it that's a  little bit different from what most people might have seen,  just so that if you aren't a high school student and you're someone like me,  there's still something interesting about it. For example, the very first lesson is going to be on a simpler version of the  quadratic formula, and while I was putting together this lesson,  I honestly felt a little bit mad that this isn't the way that I learned things  when I was in high school, so if you can get that same feeling,  I'm going to call that mission success. One thing I'm particularly excited about is a little piece of technology that two good  friends of mine, who I used to work at Khan Academy with, have been working on,  which I think should make the dynamic between the audience and the progression of the  lecture feel a little bit more tight than it usually does in some kind of live-stream  situation. I don't want to say anything more, I would just say, show up,  be prepared to answer some questions, and to ask questions too. My goal is for it to feel as much like a real class as possible. Most of the dynamic is just going to be you and me talking through problems on a  piece of paper, which, even though I love to visualize stuff and put out animations  and that's kind of what the whole channel is about, to be honest,  I think just working through things on paper feels more like what actual math is to me,  and what the process of finding new ideas and coming to terms with them yourself  looks like. The tentative plan right now is to do every Friday and Tuesday at noon Pacific time,  but if anything changes on that, you'll see the schedule on the banner of the channel. So tune in, I hope to see you there, and be prepared to do some math. Thanks for watching!

================================================================================
VIDEO ID: ZA4JkHKZM50
TITLE: Why â€œprobability of 0â€ does not mean â€œimpossibleâ€ | Probabilities of probabilities, part 2
URL: https://www.youtube.com/watch?v=ZA4JkHKZM50
PUBLISHED: 2020-04-12T15:41:30Z
STATUS: SUCCESS
================================================================================
Imagine you have a weighted coin, so the probability of flipping heads might not be 50-50 exactly. It could be 20%, or maybe 90%, or 0%, or 31.41592%. The point is that you just don't know. But imagine that you flip this coin 10 different times, and 7 of those times it comes up heads. Do you think that the underlying weight of this coin is such that each flip has a 70% chance of coming up heads? If I were to ask you, hey, what's the probability that the true probability of flipping heads is 0.7, what would you say? This is a pretty weird question, and for two reasons. First of all, it's asking about a probability of a probability, as in the value we don't know is itself some kind of long-run frequency for a random event, which frankly is hard to think about. But the more pressing weirdness comes from asking about probabilities in the setting of continuous values. Let's give this unknown probability of flipping heads some kind of name, like h. Keep in mind that h could be any real number from 0 up to 1, ranging from a coin that always flips tails up to one that always flips heads and everything in between. So if I ask, hey, what's the probability that h is precisely 0.7, as opposed to, say, 0.7000001, or any other nearby value, well, there's going to be a strong possibility for paradox if we're not careful. It feels like no matter how small the answer to this question, it just wouldn't be small enough. If every specific value within some range, all uncountably infinitely many of them, has a non-zero probability, well, even if that probability was minuscule, adding them all up to get the total probability of any one of these values will blow up to infinity. On the other hand though, if all of these probabilities are 0, aside from the fact that that now gives you no useful information about the coin, the total sum of those probabilities would be 0, when it should be 1. After all, this weight of the coin h is something, so the probability of it being any one of these values should add up to 1. So if these values can't all be non-zero, and they can't all be 0, what do you do? Where we're going with this, by the way, is that I'd like to talk about the very practical question of using data to create meaningful answers to these sorts of probabilities of probabilities questions. But for this video, let's take a moment to appreciate how to work with probabilities over continuous values, and resolve this apparent paradox. The key is not to focus on individual values, but ranges of values. For example, we might make these buckets to represent the probability that h is between, say, 0.8 and 0.85. Also, and this is more important than it might seem, rather than thinking of the height of each of these bars as representing the probability, think of the area of each one as representing that probability. Where exactly those areas come from is something that we'll answer later. For right now, just know that in principle, there's some answer to the probability of h sitting inside one of these ranges. Our task right now is to take the answers to these very coarse-grained questions, and to get a more exact understanding of the distribution at the level of each individual input. The natural thing to do would be consider finer and finer buckets. And when you do, the smaller probability of falling into any one of them is accounted for in the thinner width of each of these bars, while the heights are going to stay roughly the same. That's important, because it means that as you take this process to the limit, you approach some kind of smooth curve. So even though all of the individual probabilities of falling into any one particular bucket will approach zero, the overall shape of the distribution is preserved, and even refined in this limit. If, on the other hand, we had let the heights of the bars represent probabilities, everything would have gone to zero. So in the limit, we would have just had a flat line giving no information about the overall shape of the distribution. So, wonderful. Letting area represent probability helps solve this problem. But let me ask you, if the y-axis no longer represents probability, what exactly are the units here? Since probability sits in the area of these bars, or width times height, the height represents a kind of probability per unit in the x-direction, what's known in the business as a probability density. The other thing to keep in mind is that the total area of all these bars has to equal one at every level of the process. That's something that has to be true for any valid probability distribution. The idea of probability density is actually really clever when you step back to think about it. As you take things to the limit, even if there's all sorts of paradoxes associated with assigning a probability to each of these uncountably infinitely many values of h between 0 and 1, there's no problem if we associate a probability density to each one of them, giving what's known as a probability density function, or PDF for short. Anytime you see a PDF in the wild, the way to interpret it is that the probability of your random variable lying between two values equals the area under this curve between those values. So, for example, what's the probability of getting any one very specific number, like 0.7? Well, the area of an infinitely thin slice is 0, so it's 0. What's the probability of all of them put together? Well, the area under the full curve is 1. You see? Paradox sidestepped. And the way that it's been sidestepped is a bit subtle. In normal, finite settings, like rolling a die or drawing a card, the probability that a random value falls into a given collection of possibilities is simply the sum of the probabilities of being any one of them. This feels very intuitive. It's even true in a countably infinite context. But to deal with the continuum, the rules themselves have shifted. The probability of falling into a range of values is no longer the sum of the probabilities of each individual value. Instead, probabilities associated with ranges are the fundamental primitive objects, and the only sense in which it's meaningful to talk about an individual value here is to think of it as a range of width 0. If the idea of the rules changing between a finite setting and a continuous one feels unsettling, well, you'll be happy to know that mathematicians are way ahead of you. There's a field of math called measure theory, which helps to unite these two settings and make rigorous the idea of associating numbers like probabilities to various subsets of all possibilities in a way that combines and distributes nicely. For example, let's say you're in a setting where you have a random number that equals 0 with 50% probability, and the rest of the time it's some positive number according to a distribution that looks like half of a bell curve. This is an awkward middle ground between a finite context, where a single value has a non-zero probability, and a continuous one, where probabilities are found according to areas under the appropriate density function. This is the sort of thing that measure theory handles very smoothly. I mention this mainly for the especially curious viewer, and you can find more reading material in the description. It's a pretty common rule of thumb that if you find yourself using a sum in a discrete context, then use an integral in the continuous context, which is the tool from calculus that we use to find areas under curves. In fact, you could argue this video would be way shorter if I just said that at the front and called it good. For my part though, I always found it a little unsatisfying to do this blindly without thinking through what it really means. And in fact, if you really dig into the theoretical underpinnings of integrals, what you'd find is that in addition to the way that it's defined in a typical intro calculus class, there is a separate more powerful definition that's based on measure theory, this formal foundation of probability. If I look back to when I first learned probability, I definitely remember grappling with this weird idea that in continuous settings, like random variables that are real numbers or throwing a dart at a dartboard, you have a bunch of outcomes that are possible, and yet each one has a probability of zero, and somehow altogether they have a probability of one. Now one step of coming to terms with this is to realize that possibility is better tied to probability density than probability, but just swapping out sums of one for integrals of the others never quite scratched the itch for me. I remember that it only really clicked when I realized that the rules for combining probabilities of different sets were not quite what I thought they were, and there was simply a different axiom system underlying it all. But anyway, steering away from the theory somewhere back in the loose direction of application, look back to our original question about the coin with an unknown weight. What we've learned here is that the right question to ask is, what's the probability density function that describes this value h after seeing the outcomes of a few tosses? If you can find that PDF, you can use it to answer questions like, what's the probability that the true probability of flipping heads falls between 0.6 and 0.8? To find that PDF, join me in the next part.

================================================================================
VIDEO ID: gxAaO2rsdIs
TITLE: Simulating an epidemic
URL: https://www.youtube.com/watch?v=gxAaO2rsdIs
PUBLISHED: 2020-03-27T19:47:30Z
STATUS: SUCCESS
================================================================================
I want to share with you a few simulations that model how an epidemic spreads. There have recently been a few wonderful interactive articles in this vein,  including one in the Washington Post by Harry Stevens,  and then another by Kevin Simler over at Melting Asphalt. They are great, you can play with them, they're very informative,  I'll of course leave links in the description. After seeing those, I had a few more questions. Like if people stay away from each other, I get that that's going to slow down the spread. But what if despite mostly staying away from each other,  people still occasionally go to a central location, like a grocery store or a school? Also, what if you're able to identify and isolate the cases? And if you can, what if a few slip through, say  because they don't show symptoms so they aren't tested? How does travel between separate communities affect things? And what if people avoid contact with each other for a while,  but then they kind of get tired and stop? We'll explore these questions and more, but first  let's walk through how exactly these models will work. Each simulation represents what's called an SIR model,  meaning the population is broken up into three categories,  those who are susceptible to getting the disease, those who are infectious,  and then those who have recovered from the infection,  so people who are immune don't play into it. The way I've written these, for every unit of time that a susceptible  person spends within a certain infection radius of someone with the disease,  they'll have some probability of contracting it themselves,  so we're using physical proximity as a stand-in for things like shaking hands,  touching the same surface, kissing, sneezing on each other, all that good stuff. Then for each infectious person, after some amount of time they'll recover and no longer  be able to spread the disease, or if they die they won't be able to spread it anymore,  so as a more generic term, sometimes people consider the R in SIR to stand for removed. This should go without saying, but let me emphasize it at the start anyway. These are toy models, with a tiny population, inevitably falling  far short of the complexities in real people and larger populations. I am not an epidemiologist, so I would be very hesitant to  generalize any of the lessons here without deeper consideration. That said, I think it can be healthy to engage the little scientist inside all of us  and take the chance to be experimental and quantitative,  even if it's in a necessarily limited fashion,  especially if the alternative is to dwell on headlines and uncertainty. We'll start things simple and layer on more complexity gradually. In these first few runs that you're looking at,  everybody is simply meandering around the city in a kind of random walk,  and the infection follows the rules we've laid out. So it doesn't look great, after not too long almost everybody gets infected. As a sanity check, what would you expect to happen if I double this radius of infection? You might think of this as representing more total interactions between people,  or a more socially engaged society. It'll spread more quickly, of course, but how much? It's actually very drastic. Within a short time span, the majority of our  little population is infected simultaneously. As another sanity check, what would you expect if we go back to the  original infection radius, and then cut the probability of infection in half? Remember, the way this is running, for each day that a susceptible person is within  that radius of an infectious person, they have some probability of becoming infected. By default I've set it to 20%, but this is the number we're now going to cut in half. You might think of this as better hand washing,  better cough protection, and less face touching. As you might expect, it spreads out the curve. In fact it does this by quite a lot, which really illustrates how  changes to hygiene have very large effects on the rate of spreading. The first of several key takeaways here that I'd like you to tuck away in your  mind is just how sensitive this growth can be to each parameter in our control. It's not that hard to imagine changing your daily habits in a way that multiplies  the number of people you interact with, or that cuts your probability of catching  an infection in half, but the implications for the pace of the spread are huge. The goal is probably to reduce the total number of people who die,  which is some proportion of this removed category in the end. That proportion is not a constant, though. If you get to a point where the peak of the infection curve is too high,  meaning there's a time when many people are all sick at once,  that's the point when available healthcare resources are overwhelmed,  which for a bad disease will increase the mortality rate. Now I don't know where you're from, but in most towns people don't  actually spend their days drunkenly wandering around the city like this. Often there's a common destination, like a central market or a school. In our model, if we introduce some central spot like this that  people regularly visit and then return from, it'sâ€¦ well, just look. One of the main things I was curious about is how to mitigate this effect,  and that's something we'll examine in just a bit. Another feature we could include is to have a  few separate communities with transit between them. Every day, each person will have some probability of traveling to the center  of another community, and then going about their usual routine from there. All of that is our basic setup, so now the question  is what actions help to stop this spread? What is by far most effective is to identify and isolate whoever is infectious,  for example with good testing and quick responsiveness. In our simulations, once we hit some critical threshold of cases,  we're going to start sending people to a separate location one day after they have  the infection. This is of course a stand-in for whatever isolation would look like in the real world,  it doesn't have to literally be transporting all the sick people into one sad box. Unsurprisingly, this totally halts the epidemic in its tracks. But what if when you're infected you have a 20% chance of not getting quarantined,  say because you show no symptoms so you don't get tested,  and you go about your day as usual? We're going to illustrate these people that have  no symptoms using yellow circles instead of red. Obviously this will have a result somewhere between a total quarantine and doing nothing,  but where on the spectrum would you predict it'll be? The peak number of simultaneous cases is only a little bit higher,  but there is a very low long tail as it takes a much longer time to stamp out,  resulting in about twice as many total cases. This gets more interesting when we do it in a  setting with many communities and transit between them. Again, totally effective tracking in isolation stops the epidemic very quickly,  but what would you predict is going to happen if now 20% of  the infectious cases slip through that process? Again, I've set things to wait until a certain critical threshold of  cases is hit before our little dot society kicks into gear and takes action. As a side note, it's a little interesting that even when all the parameters are the same,  some runs take three times longer to reach this point than others. Before the law of large numbers kicks in, that pace of growth can have as much to do  with the roll of the dice as it does with anything intrinsic to the disease itself. This leaky quarantining effort definitely flattens out the curve,  but it is a much thicker tail and takes a much longer time to track down all the cases,  with over half the population getting infected this time. Now, what would you predict if it was only 50% of  the infectious cases that were isolated like this? If half the infectious people are getting quarantined,  it doesn't mean that half the total population will end up with the disease. Because there are so many agents still out there spreading it,  we end up with a situation that's only barely better than if nothing had been done at all. A second key takeaway here is that changes in how many people slip through the tests  can cause disproportionately large changes to the total number of people infected. If we look back to the fact that quickly containing cases so early is so effective,  it actually has an interesting corollary, which is that the most lethal  diseases are in some sense less dangerous globally. Remember that the rule of this quarantine simulation is to send infectious people to  a separate spot one day after they've been infected,  but if the disease kills its host after one day, the model looks identical,  it just has a much darker interpretation. It is terrible for those who get it, but it doesn't spread. It also means that the most dangerous viruses are the ones that kill some part of  the population in the first place, while laying unnoticed and spreadable among others. Or worse yet, if they remain unnoticed and spreadable  in everyone before eventually becoming lethal. One of the reasons that the SARS outbreak in 2002 was so well  contained is that just about everybody in this infectious population  was showing symptoms, so they were much easier to identify and isolate. A more optimistic corollary of these quarantine  simulations is how useful early treatment can be. If there exists an antiviral therapeutic that can move people out of this infectious  category quickly, it has the same effect on the model as isolating those cases. But let's say you don't have widespread testing or antiviral therapeutics. Well, let's introduce a new parameter here, which  is how much people try to avoid each other. Let's call it the social distance factor. In these animations, I'll apply it as a repulsive force between people,  and have them glow yellow when they feel just a little too close to their neighbor. This has the sad but kind of cute effect that when our little agents are  social distancing, they often end up trembling near the edge of their box. No isolation is perfect, though, so every now and then even those  repulsed by each other will jiggle close enough to get infected. The point is that those interactions are much rarer. Let's take a look at four separate runs here. In each one of them, after we hit 50 cases, I'll turn on social distancing. But in the top left, we'll turn it on for everybody. In the top right, we'll turn it on for 90% of the population. In the bottom left, for 70% of the population,  and in the bottom right, for only half the population. What would you predict is going to happen? As you might expect, when 100% of people avoid each other,  the disease quickly goes away, entirely. And in all four cases, the presence of some kind of  widespread social distancing definitely flattens out the curve. However, in terms of the ultimate number of cases,  the run with 70% and even the one with 90% end up with a little less than  half the population ultimately getting infected,  which is only a tiny bit better than the one with 50%. That case with 90% of people repelling each other certainly takes longer to get there,  but evidently a mere 10% of the population cheating adds enough instability  to our system to keep the fire slowly burning for a long time. Again, I'll emphasize that these are toy models,  and I leave it to the intelligence of the viewer to judge if the behavior  of these little dots accurately reflects what social distancing would mean  for you and your life. Someone fully sequestered in their home is not necessarily  affected by the random jiggling of their neighbor, but then again,  few of us genuinely live independently from everyone else. Insofar as these models aren't outlandish, the third key takeaway  is that social distancing absolutely works to flatten the curve,  but even small imperfections prolong the spread for a while. Now let's look at that setup with 12 communities and travel between them. By default I have it set so that every day each agent has a  2% chance of traveling to the center of a different community. Now let's try a run where once we hit 100 cases,  we cut down that travel rate by a factor of 4, to only half a percent. What would you predict is going to happen? The honest answer is that it depends. In some runs it doesn't make any difference, and the majority of every community gets it. Other times there are a couple communities that end up unscathed. In general, the earlier you turn on this effect, the more effective it is,  but the takeaway here is that reducing contact between communities  really has only a limited effect once those communities already have it,  and as solutions go it's certainly not robust on its own. As a side note, when we run these simulations with larger cities,  which has the effect that city centers act like concentrated urban hubs,  you can see how as soon as the infection hits one of these urban centers,  it very quickly hits all of them. And after that, it slowly spreads to the edges of each community. Let's take a moment to talk about how to quantify this spread. Consider one person with the disease, and then  count how many people they infect while they have it. The average for this count across everybody who's been  sick is known as the effective reproductive number, or R. A more commonly discussed number is R-naught, which is the value  of R in a fully susceptible population, like at the very beginning. This is known as the basic reproductive number. You may have noticed I have this little label on our simulations,  and the way it's being calculated is to look at each individual who's currently  infectious, count how many people they've infected so far,  estimate how many they're going to infect in total based on the duration of the illness,  and then average those numbers. For example, in our first default simulation with no added spices,  R is around 2.2 at the highest part of the growth phase,  before falling down as the population becomes saturated. By contrast, when we doubled the infection radius, R was as high as 8! This factor has a huge effect on the growth rate. It should kind of make sense that it jumped up as high as 8, though. When you double that radius, there's about 4 times as many people inside it to infect. When we chopped the infection rate in half, it hovered around the 1.3 to 1.7 range. While R is greater than 1, the infection is growing exponentially,  and it's at that point that it's known as an epidemic. When it holds steady around 1, that's when a disease is called endemic,  and less than 1 means it's on the decline. For comparison, R-naught for COVID-19 is estimated to be a little above 2,  which is also around what the mean estimate for R-naught was during the 1918 Spanish  flu pandemic. The seasonal flu by comparison is much lower, around 1.3. In the travel case, as soon as we turn on social distancing and shut down travel,  you can see R quickly drop down from 2. There's a little bit of a lag between the change we make to the model and  the value of this number, since it's calculated based on current infectious cases,  which might have existed prior to the method being put in place. Like I said at the start, one of the things I was most curious about is the  effect of some kind of shared central location, like a market or a school. When I introduce such a destination for our little dots, R0 jumps as high as 5.8. This might be a little unfair, since it puts everyone right in the same spot,  and given that we're using physical proximity as a stand-in for things  like shaking hands or kissing, we should maybe acknowledge that people  going to the same school or grocery store are not as likely to spread an infection as,  say, close friends or people living in the same house. To account for this, let's conservatively cut  the probability of infection per day in half. This does indeed cut R0 in half, but the effect of a central market remains dramatic. Now let's try a run where after some threshold is hit, we turn on social distancing,  but people still go to that central location the way they did before. You may notice that some of our little dots seem to have escaped their little cage,  which was not supposed to happen, but I'm going to make the conscious choice not to fix  that. It's like they all looked at the chaos inside and just went,  nope, I'm out, I don't want any part of that. Living in the Bay Area during a shelter-in-place order,  I can confirm that this is how some people react. Wandering dots aside, let me show you how this graph compares to the control case  where we did nothing, and how it compares to what would have happened if in addition  to repelling from each other, all the dots also stopped going to that central location. The peak of the infection curve is a little lower than the control,  but in terms of the total number of cases, keeping that central  location active really defeats the effects of otherwise social distancing. Now let me ask you to make a prediction. What do you think will be more effective? If on top of that social distancing effect, we decrease the frequency with  which people go to that central spot, maybe by a factor of 5,  or if we chop the probability of infection down by another factor of 2,  for example meaning people are super extra cautious about washing their hands  and not touching their face. The simulation on the left requires our dots to very heavily alter their daily routines,  whereas on the right our dots can mostly continue their usual habits,  but are much more conscious of hygiene. They're actually nearly identical, which surprised me,  given that one of them is a fivefold decrease and the other is twofold. I guess it goes to show that the effect of hygiene,  which is maybe easier said than done, really goes a long way. Of course, it doesn't have to be an either-or. Our goal with these experiments is to look at the effects of one change at a time. If you're curious, here's what it looks like when we apply social distancing,  we restrict the rate that people go to the central location,  and we also lower the infection rate all at once. This combination is, indeed, very effective. But I want to emphasize again how the most desirable case  is when you can consistently identify and isolate cases. Even in this central market simulation, which left unchecked gives a huge conflagration,  being able to do this effectively still halts the epidemic,  and our little dots don't even have to be repelled by each other or stop their trips  to the central spot. In real epidemiology, by the way, it gets way more sophisticated than this,  with tactics like contact tracing, where you not only identify and isolate known cases,  but you do the same for everyone who's been in contact with those cases. Given the time I'm posting this, I imagine there's some  expectation for it to be a PSA on social distancing. But to be honest, that's not really my own main takeaway. To be clear, when it's needed, like it is now, social distancing absolutely saves lives,  and as we saw earlier, when people cheat or when they continue to regularly meet at  a central spot, it has a disproportionate effect on the long-term number of cases. The uncomfortable truth, though, is that while the disease still exists,  as soon as people let up and they go back to their normal lives,  if nothing is in place to contain the cases, few though they might be,  you'll just get a second wave. After making all of these, what I came away with more than anything else was a deeper  appreciation for disease control done right, for the inordinate value of early widespread  testing and the ability to isolate cases, for therapeutics that treat these cases,  and most importantly, for how easy it is to underestimate all that value when times are  good. I'm writing this during a pandemic, when some viewers may be able to identify  a little too well with the trembling dots retreating to the edge of their box. But in the future, many people will be watching this during a pandemic that never was,  a time when a novel pathogen that could have spread widely if left  unchecked was instead swiftly found and contained. Those would-be pandemics never make it into the history books,  which is maybe why we don't value the heroes behind them the way we should. Living in a world with widespread travel and vibrant urban centers does make  fighting the spread of a disease an uphill battle, that's absolutely true. But that same level of connectedness means that ideas spread more quickly than ever,  ideas that can lead to systems and technologies that nip these outbreaks in the bud. It won't happen on its own, and it's clear that we sometimes make mistakes,  but I'm fundamentally optimistic about our ability to learn from those mistakes. As you might imagine, these videos require a lot of hours of effort. I don't do any ad reads at the end, and YouTube content related to the current  pandemic seems to be systematically demonetized,  so I just want to take this chance to say a particularly warm thank you to those  who support them directly on Patreon. It really does make a difference.

================================================================================
VIDEO ID: 8idr1WZ1A7Q
TITLE: Binomial distributions | Probabilities of probabilities, part 1
URL: https://www.youtube.com/watch?v=8idr1WZ1A7Q
PUBLISHED: 2020-03-15T18:28:16Z
STATUS: SUCCESS
================================================================================
You're buying a product online, and you see three different sellers. They're all offering that same product at essentially the same price. One of them has a 100% positive rating, but with only 10 reviews. Another has a 96% positive rating, with 50 total reviews. And yet another has a 93% positive rating, but with 200 total reviews. Which one should you buy from? I think we all have this instinct that the more data we see,  it gives us more confidence in a given rating. We're a little suspicious of seeing 100% ratings,  since more often than not they come from a tiny number of reviews,  which makes it feel more plausible that things could have gone another  way and given a lower rating. But how do you make that intuition quantitative? What's the rational way to reason about the trade-off here between the  confidence gained from more data versus the lower absolute percentage? This particular example is a slight modification from one that John Cook  gave in his excellent blog post, A Bayesian Review of Amazon Resellers. For you and me, it's a wonderful excuse to dig into  a few core topics in probability and statistics. And to really cover these topics properly, it takes time. So what I'm going to do is break this down into three videos,  where in this first one we'll set up a model for the situation,  and start by talking about the binomial distribution. The second is going to bring in ideas of Bayesian updating,  and how to work with probabilities over continuous values. And in the third, we'll look at something known as a beta distribution,  and pull up a little python to analyze the data we have,  and come to various different answers depending on what it is you want to optimize. Now, to throw you a bone before we dive into all the math,  let me just show you what one of the answers turns out to be,  since it's delightfully simple. When you see an online rating, something like this 10 out of 10,  you pretend that there were two more reviews, one that was positive and one  that's negative. In this case, that means you pretend that it's 11 out of 12, which would give 91.7%. This number is your probability of having a good experience with that seller. So in the case of 50 reviews, where you have 48 positive and 2 negative,  you pretend that it's 49 positive and 3 negative, which would give you 49 out of 52,  or 94.2%. That's your probability of having a good experience with the second seller. Playing the same game with our third seller who had 200 reviews,  you get 187 out of 202, or 92.6%. So according to this rule, it would mean your best bet is to go with seller number 2. This is something known as Laplace's rule of succession,  it dates back to the 18th century, To understand what assumptions are underlying this,  and how changing either those assumptions or your underlying goal can  change the choice you make, we really do need to go through all the math. So without further ado, let's dive in. Step 1, how exactly are we modeling the situation,  and what exactly is it that you want to optimize? One option is to think of each seller as producing random experiences that are either  positive or negative, and that each seller has some kind of constant underlying  probability of giving a good experience, what we're going to call the success rate,  or S for short. The whole challenge is that we don't know S. When you see that first rating of 100% with 10 reviews,  that doesn't mean the underlying success rate is 100%. It could very well be something like 95%. And just to illustrate, let me run a little simulation,  where I choose a random number between 0 and 1, and if it's less than 0.95,  I'll record it as a positive review, otherwise record it as a negative review. Now do this 10 times in a row, and then make 10 more, and 10 more,  and 10 more, and so on, to get a sense of what sequences of 10  reviews for a seller with this success rate, would tend to look like. Quite a few of those, around 60% actually, give 10 out of 10. So the data we see seems perfectly plausible if the seller's true success rate was 95%. Or maybe it's really 90%, or 99%. The whole challenge is that we just don't know. As to the goal, let's say you simply want to maximize your probability of  having a positive experience, despite not being sure of this success rate. So think about this here, we've got many different possible success rates for  each seller, any number from 0 up to 1, and we need to say something about how  likely each one of these success rates is, a kind of probability of probabilities. Unlike the more gamified examples like coin flips and die tosses and the  sort of things you see in an intro probability class,  where you go in assuming a long run frequency, like 1.5 or 1.6,  what we have here is uncertainty about the long run frequency itself,  which is a much more potent kind of doubt. I should also emphasize that this kind of setup is relevant to many many situations in  the real world where you need to make a judgment about a random process from limited data. For example, let's say that you're setting up a factory producing cars,  and in an initial test of 100 cars, two of them come out with some kind of problem. If you plan to spin things up to produce a million cars,  what are you willing to confidently say about how many total cars will have problems  that need addressing? It's not like the test guarantees that the true error rate is 2%,  but what exactly does it say? As your first challenge, let me ask you this. If you did magically know the true success rate for a given seller,  say it was 95%, how would you compute the probability of seeing 10  positive reviews and 0 negative reviews, or 48 and 2, or 186 and 14? In other words, what's the probability of seeing the data given an assumed success rate? A moment ago I showed you something like this with a simulation,  generating 10 random reviews, and with a little programming you could just do  that many times, building up a histogram to get some sense of what this distribution  looks like. Likewise, you could simulate sets of 50 reviews,  and get some sense for how probable it would be to see 48 positive and 2 negative. You see, this is the nice thing about probability. A little programming can almost always let you cheat a little  and see what the answer is ahead of time by simulating it. For example, after a few hundred thousand samples of 50 reviews,  assuming the success rate is 95%, it looks like about 26.1% of them would give us this  48 out of 50 review. Luckily, in this case, an exact formula is not bad at all. The probability of seeing exactly 48 out of 50 looks like this. This first term is pronounced 50 choose 48, and it represents the total  number of ways that you could take 50 slots and fill out 48 of them. For example, maybe you start with 48 good reviews and end with 2 bad reviews,  or maybe you start with 47 good reviews and then it goes bad good bad, and so on. In principle, if you were to enumerate every possible way of  filling 48 out of 50 slots like this, the total number of these patterns is 50 choose 48,  which in this case works out to be 1225. What do we multiply by this count? Well, it's the probability of any one of these patterns,  which is the probability of a single positive review raised to  the 48th times the probability of a single negative review squared. Crucial is that we assume each review is independent of the last,  so we can multiply all the probabilities together like this,  and with the numbers we have, when you evaluate it, it works out to be 0.261,  which matches what we just saw empirically with the simulation. You could also replace this 48 with some other value,  and compute the probability of seeing any other number of positive reviews,  again assuming a given success rate. What you're looking at right now, by the way, is known in the business as a  binomial distribution, one of the most fundamental distributions in probability. It comes up whenever you have something like a coin flip,  a random event that can go one of two ways, and you repeat it some number of times,  and what you want to know is the probability of getting various different totals. For our purposes, this formula gives us the probability of seeing the data given  an assumed success rate, which ultimately we want to somehow use to make judgments  about the opposite, the probability of a success rate given the fixed data we see. These are related, but definitely distinct. To get more in that direction, let's play around with this value of s  and see what happens as we change it to different numbers between 0 and 1. The binomial distribution that it produces kind of looks  like this pile that's centered around whatever s times 50 is. The value we care about, the probability of seeing 48 out of 50 reviews,  is represented by this highlighted 48th bar. Let's draw a second plot on the bottom, representing how that value depends on s. When s is equal to 0.96, that value is as high as it's ever going to get. And this should kind of make sense, because when you look at that review of 96%,  it should be most likely if the true underlying success rate was 96%. As s increases, it kind of peters out, going to 0 as s approaches 1,  since someone with a perfect success rate would never have those two negative reviews. Also, as you move to the left, it approaches 0 pretty quickly. By the time you get to s equals 0.8, getting 48 out of 50 reviews  by chance is exceedingly rare, it would happen 1 in 1000 times. This plot we have on the bottom is a great start to getting a more  quantitative description for which values of s feel more or less plausible. Written down as a formula, what I want you to remember is that as a function  of the success rate s, the curve looks like some constant times s to the  number of positive reviews times 1 minus s to the number of negative reviews. In principle, if we had more data, like 480 positive reviews and 20 negative reviews,  the resulting plot would still be centered around 0.96,  but it would be smaller and more concentrated. A good exercise right now would be to see if you could explain why that's the case. There is a lingering question, though, of what to actually do with these curves. I mean, our goal is to compute the probability that you  have a good experience with this seller, so what do you do? Naively, you might think that probability is 96%,  since that's where the peak of the graph is, which in a sense is the most  likely success rate. But think of the example with 10 out of 10 positives. In that case, the whole binomial formula simplifies to be s to the power 10. The probability of seeing 10 consecutive good reviews is  the probability of seeing one of them raised to the 10th. The closer the true success rate is to 1, the  higher the probability of seeing a 10 out of 10. Our plot on the bottom only ever increases as s approaches 1. But even if s equals 1 is the value that maximizes this probability,  surely you wouldn't feel comfortable saying that you personally  have a 100% probability of a good experience with this seller. Maybe you think that instead we should look for some kind of center  of mass of this graph, and that would absolutely be on the right track. First, though, we need to explain how to take this expression for the probability  of the data we're seeing given a value of s, and get the probability for a value of s,  the thing we actually don't know, given the data, the thing we actually know. And that requires us to talk about Bayes' rule, and also probability density functions. For those, I'll see you in part 2.

================================================================================
VIDEO ID: Kas0tIxDvrg
TITLE: Exponential growth and epidemics
URL: https://www.youtube.com/watch?v=Kas0tIxDvrg
PUBLISHED: 2020-03-08T16:58:19Z
STATUS: SUCCESS
================================================================================
The phrase exponential growth is familiar to most people,  and yet human intuition has a hard time really recognizing what it means sometimes. We can anchor on a sequence of small seeming numbers and then  become surprised when suddenly those numbers look big,  even if the overall trend follows an exponential perfectly consistently. This right here is the data for the recorded cases of COVID-19,  aka the coronavirus, at least at the time I'm writing this. Never one to waste an opportunity for a math lesson,  I thought this might be a good time for all of us to go back to the basics on what  exponential growth really is, where it comes from, what it implies,  and maybe most pressingly how to know when it's coming to an end. Exponential growth means that as you go from one day to the next,  it involves multiplying by some constant. In our data, the number of cases in each day tends to be a multiple  of about 1.15 to 1.25 of the number of cases the previous day. Viruses are a textbook example of this kind of growth,  because what causes new cases are the existing cases. If the number of cases on a given day is n, and we say that each individual  with the virus is exposed to, on average, e people on a given day,  and each one of those exposures has a probability p of becoming a new infection,  then the number of new cases on a given day is e times p times n. The fact that n itself is a factor in its own change is what really makes things go fast,  because if n gets big, it means the rate of growth itself is getting big. One way to think about this is that as you add the new cases to  get the next day's growth, you can factor out the n,  so it's just the same as multiplying by some constant that's bigger than 1. This is sometimes easier to see if we put the y-axis of our graph on a logarithmic scale,  which means that each step of a fixed distance corresponds to multiplying by  a certain factor, in this case each step is another power of 10. On this scale, exponential growth should look like a straight line. Looking at our data, it seems like it took 20 days to go from 100 to 1000,  and 13 days to go from that to 10,000, and if you do a simple linear  regression to find the best fit line, you can look at the slope of that  line to draw a conclusion like we tend to multiply by 10 every 16 days on average. This regression also lets us be a little more quantitative about exactly  how close the exponential fit really is, and to use the technical  statistical jargon here, the answer is that it's really freaking close. But it can be hard to digest exactly what that means if true. When you see one country with, say, 6000 cases and another with 60,  it's easy to think that the second is doing 100 times better, and hence fine. But if you're actually in a situation where numbers multiply by 10 every 16 days,  another way to view the same fact is that the second country is about a month behind the  first. This is of course rather worrying if you draw out the line. I'm recording this on March 6th, and if the present trend continues  it would mean hitting a million cases in 30 days, hitting 10 million in 47 days,  100 million in 64 days, and 1 billion in 81 days. Needless to say, though, you can't just draw out a line like this forever,  it clearly has to start slowing down at some point. But the crucial question is when. Is it like the SARS outbreak of 2002 which capped out around 8000 cases,  or the Spanish flu of 1918 which ultimately infected about 27% of the world's population? In general, with no context, just drawing a line through your data is not a great way to  make predictions, but remember, there's an actual reason to expect an exponential here. If the number of new cases each day is proportional to the number of existing cases,  it necessarily means each day you multiply by some constant,  so moving forward d days is the same as multiplying by that constant d times. The only way that stops is if either the number E or P goes down. It's inevitable that this will eventually happen. Even in the most perfectly pernicious model for a virus,  which would be where every day each person with the infection is exposed  to a random subset of the world's population, at some point most of the  people they're exposed to would already be sick, and so they couldn't become new cases. In our equation, that would mean that the probability of an exposure  becoming a new infection would have to include some kind of factor to  account for the probability that someone you're exposed to is already infected. For a random shuffling model like this, that could mean including a factor  like 1 minus the proportion of people in the world who are already infected. Including that factor, and then solving for how N grows,  you get what's known in the model. ss as a logistic curve, which is essentially indistinguishable from  an exponential at the beginning, but ultimately levels out once you're  approaching the total population size, which is what you would expect. True exponentials essentially never exist in the real world,  every one of them is the start of a logistic curve. This point right here, where that logistic curve goes from curving  upward to instead curving downward, is known as the inflection point. There, the number of new cases each day, represented by the slope of this curve,  stops increasing and stays roughly constant before it starts decreasing. One number that people often follow with epidemics is the growth factor,  which is defined as the ratio between the number of new cases  one day and the number of new cases the previous day. Just to be clear, if you were looking at all of the totals from one day to the next,  then tracking the changes between those totals,  the growth factor is a ratio between two successive changes. While you're on the exponential part, this factor stays consistently above one,  whereas as soon as your growth factor looks closer to one,  it's a sign that you've hit the inflection. This can make for another counterintuitive fact while following the data. Think about what it would feel like for the number of new cases one day  to be about 15% more than the number of new cases the previous day,  and contrast that with what it would feel like for it to be about the same. Just looking at the totals they result in, they don't really feel that different. But if the growth factor is one, it could mean you're at the  inflection point of a logistic, which would mean the total number  of cases is going to max out at about two times wherever you are now. But a growth factor bigger than one, subtle though that might seem,  means you're on the exponential part, which could imply there  are orders of magnitude of growth still waiting ahead of you. Now, while it's true that in the worst-case situation the saturation point  is around the total population, it's of course not at all true that people  with the virus are randomly shuffled around the world's population like this. People are clustered in local communities. However, if you run simulations where there's even a little bit of travel  between clusters like this, the growth is actually not that much different. What you end up with is a kind of fractal pattern,  where communities themselves function like individuals. Each one has some exposure to others, with some probability of spreading the infection,  so the same underlying and exponential-inducing laws apply. Fortunately, saturating the whole population is not the only  thing that can cause the two factors we care about to go down. The amount of exposure can also go down when people stop gathering and traveling,  and the infection rate can go down when people just wash their hands more. The other thing that's counterintuitive about exponential growth,  this time in a more optimistic sense, is just how sensitive it is to this constant. For example, if it's 15%, like it is as I'm recording this,  and we're at 21,000 cases now, that would mean that 61 days from now you hit  over 100 million. But if through a bit less exposure and infection,  that rate drops down to 5%, it doesn't mean the projection  also drops down by a factor of 3, it actually drops down to around 400,000. So if people are sufficiently worried, there's a lot less to worry about. But if no one is worried, that's when you should worry.

================================================================================
VIDEO ID: U_85TaXbeIo
TITLE: The quick proof of Bayes' theorem
URL: https://www.youtube.com/watch?v=U_85TaXbeIo
PUBLISHED: 2019-12-22T14:45:25Z
STATUS: SUCCESS
================================================================================
This is a footnote to the main video on Bayes' Theorem. If your goal is simply to understand why it's true from a mathematical standpoint,  there's actually a very quick way to see it based on breaking  down how the word AND works in probability. Let's say there are two events, A and B. What's the probability that both of them happen? On the one hand, you could start by thinking of the probability of A,  the proportion of all possibilities where A is true,  then multiply it by the proportion of those events where B is also true,  which is known as the probability of B given A. But it's strange for the formula to look asymmetric in A and B. Presumably, we should also be able to think of it as the proportion  of cases where B is true, among all possibilities,  times the proportion of those where A is also true, the probability of A given B. These are both the same, and the fact that they're both the same gives us a way  to express P of A given B in terms of P of B given A, or the other way around. So when one of these conditions is easier to put numbers to than the other,  say when it's easier to think about the probability of seeing some evidence given  a hypothesis rather than the other way around, this simple identity becomes a useful tool. Nevertheless, even if this is somehow a more pure or quick way to understand the formula,  the reason I chose to frame everything in terms of updating beliefs with  evidence in the main video is to help with that third level of understanding,  being able to recognize when this formula, among the wide landscape of  available tools in math, happens to be the right one to use. Otherwise, it's kind of easy to just look at it, nod along, and promptly forget. And you know, while we're here, it's worth highlighting a common  misconception that the probability of A and B is P of A times P of B. For example, if you hear that 1 in 4 people die of heart disease,  it's really tempting to think that that means the probability that both  you and your brother die of heart disease is 1 in 4 times 1 in 4, or 1 in 16. After all, the probability of two successive coin flips yielding tails is Â½ times Â½,  and the probability of rolling two 1s on a pair of dice is 1 6th times 1 6th, right? The issue is correlation. If your brother dies of heart disease, and considering certain genetic and lifestyle  links that are at play here, your chances of dying from a similar condition are higher. A formula like this, as tempting and clean as it looks, is just flat out wrong. What's going on with cases like flipping coins or rolling  two dice is that each event is independent of the last. So the probability of B given A is the same as the probability of B. What happens to A does not affect B. This is the definition of independence. Keep in mind, many introductory probability examples are given in very gamified contexts,  things with dice and coins, where genuine independence holds,  but all those examples can skew your intuitions. The irony is that some of the most interesting applications of probability,  presumably the whole motivation for the kind of courses using these gamified examples,  are only substantive when events aren't independent. Bayes' theorem, which measures exactly how much one variable depends on another,  is a perfect example of this.

================================================================================
VIDEO ID: HZGCoVF3YvM
TITLE: Bayes theorem, the geometry of changing beliefs
URL: https://www.youtube.com/watch?v=HZGCoVF3YvM
PUBLISHED: 2019-12-22T14:31:56Z
STATUS: SUCCESS
================================================================================
The goal is for you to come away from this video understanding one  of the most important formulas in all of probability, Bayes' theorem. This formula is central to scientific discovery,  it's a core tool in machine learning and AI, and it's even been used for treasure  hunting, when in the 1980s a small team led by Tommy Thompson,  and I'm not making up that name, used Bayesian search tactics to help uncover a  ship that had sunk a century and a half earlier,  and the ship was carrying what in today's terms amounts to $700 million worth of gold. So it's a formula worth understanding, but of course there  are multiple different levels of possible understanding. At the simplest there's just knowing what each one of the parts means,  so that you can plug in numbers. Then there's understanding why it's true, and later I'm going to show you a  certain diagram that's helpful for rediscovering this formula on the fly as needed. But maybe the most important level is being able to recognize when you need to use it. And with the goal of gaining a deeper understanding,  you and I are going to tackle these in reverse order. So before dissecting the formula or explaining the visual that makes it obvious,  I'd like to tell you about a man named Steve. Listen carefully now. Steve is very shy and withdrawn, invariably helpful but  with very little interest in people or the world of reality. A meek and tidy soul, he has a need for order and structure, and a passion for detail. Which of the following do you find more likely? Steve is a librarian, or Steve is a farmer? Some of you may recognize this as an example from a study  conducted by the two psychologists Daniel Kahneman and Amos Tversky. Their work was a big deal, it won a Nobel Prize,  and it's been popularized many times over in books like Kahneman's Thinking Fast and  Slow, or Michael Lewis's The Undoing Project. What they researched was human judgments, with a frequent focus on when these  judgments irrationally contradict what the laws of probability suggest they should be. The example with Steve, our maybe-librarian-maybe-farmer,  illustrates one specific type of irrationality,  or maybe I should say alleged irrationality, there are people who debate the  conclusion here, but more on all of that later on. According to Kahneman and Tversky, after people are given this description  of Steve as a meek and tidy soul, most say he's more likely to be a librarian. After all, these traits line up better with the  stereotypical view of a librarian than a farmer. And according to Kahneman and Tversky, this is irrational. The point is not whether people hold correct or biased views about the  personalities of librarians and farmers, it's that almost nobody thinks to  incorporate information about the ratio of farmers to librarians in their judgments. In their paper, Kahneman and Tversky said that in the US that ratio is about 20 to 1. The numbers I could find today put that much higher,  but let's stick with the 20 to 1 number, since it's a little easier to illustrate  and proves the point as well. To be clear, anyone who has asked this question is not expected to have perfect  information about the actual statistics of farmers and librarians and their personality  traits. But the question is whether people even think to consider  that ratio enough to at least make a rough estimate. Rationality is not about knowing facts, it's about recognizing which facts are relevant. Now if you do think to make that estimate, there's a pretty  simple way to reason about the question, which, spoiler alert,  involves all of the essential reasoning behind Bayes' theorem. You might start by picturing a representative sample of farmers and librarians,  say 200 farmers and 10 librarians. Then when you hear of this meek and tidy soul description,  let's say that your gut instinct is that 40% of librarians would fit that description,  and 10% of farmers would. If those are your estimates, it would mean that from your sample you would expect  about 4 librarians to fit the description, and about 20 farmers to fit that description. So the probability that a random person among those who  fit this description is a librarian is 4 out of 24, or 16.7%. So even if you think that a librarian is 4 times as likely as a farmer to fit this  description, that's not enough to overcome the fact that there are way more farmers. The upshot, and this is the key mantra underlying Bayes' theorem,  is that new evidence does not completely determine your beliefs in a vacuum. It should update prior beliefs. If this line of reasoning makes sense to you, the way that  seeing evidence restricts the space of possibilities,  and the ratio you need to consider after that, then congratulations! You understand the heart of Bayes' theorem. Maybe the numbers you would estimate would be a little different,  but what matters is how you fit the numbers together to update your beliefs based  on evidence. Now understanding one example is one thing, but see if you can take a minute  to generalize everything we just did and write it all down as a formula. The general situation where Bayes' theorem is relevant is when you have some hypothesis,  like Steve is a librarian, and you see some new evidence,  say this verbal description of Steve as a meek and tidy soul,  and you want to know the probability that your hypothesis holds given that  the evidence is true. In the standard notation, this vertical bar means given that,  as in we're restricting our view only to the possibilities where the evidence holds. Now remember the first relevant number we used,  it was the probability that the hypothesis holds before considering  any of that new evidence. In our example, that was 1 out of 21, and it came from considering  the ratio of librarians to farmers in the general population. This number is known as the prior. After that, we need to consider the proportion of librarians that fit this description,  the probability that we would see the evidence given that the hypothesis is true. Again, when you see this vertical bar, it means we're talking about  some proportion of a limited part of the total space of possibilities. In this case, that limited part is the left side, where the hypothesis holds. In the context of Bayes' theorem, this value also has a special name,  it's called the likelihood. Similarly, you need to know how much of the other side of the space includes the  evidence, the probability of seeing the evidence given that the hypothesis isn't true. This funny little elbow symbol is commonly used in probability to mean not. So with the notation in place, remember what our final answer was,  the probability that our librarian hypothesis is true given the evidence is the total  number of librarians fitting the evidence, 4, divided by the total number of people  fitting the evidence, 24. But where did that 4 come from? Well, it's the total number of people times the prior probability of being a librarian,  giving us the 10 total librarians, times the probability that  one of those fits the evidence. That same number shows up again in the denominator, but we need to add in the rest,  the total number of people times the proportion who are not librarians,  times the proportion of those who fit the evidence, which in our example gives 20. Now notice the total number of people here, 210, that gets cancelled out,  and of course it should, that was just an arbitrary choice made for the sake of  illustration. This leaves us finally with a more abstract representation purely  in terms of probabilities, and this, my friends, is Bayes' theorem. More often, you see this denominator written simply as P of E,  the total probability of seeing the evidence, which in our example would be  the 24 out of 210. But in practice, to calculate it, you almost always have to break it down  into the case where the hypothesis is true, and the one where it isn't. Capping things off with one final bit of jargon, this answer is called the posterior,  it's your belief about the hypothesis after seeing the evidence. Writing it out abstractly might seem more complicated than just  thinking through the example directly with a representative sample. And yeah, it is. Keep in mind though, the value of a formula like this is that it  lets you quantify and systematize the idea of changing beliefs. Scientists use this formula when they're analyzing the extent  to which new data validates or invalidates their models. Programmers will sometimes use it in building artificial intelligence,  where at times you want to explicitly and numerically model a machine's belief. And honestly, just for the way you view yourself and your own  opinions and what it takes for your mind to change,  Bayes' theorem has a way of reframing how you even think about thought itself. Putting a formula to it can also be more important  as the examples get more and more intricate. However you end up writing it, I actually encourage you not to try  memorizing the formula, but to instead draw out this diagram as needed. It's sort of a distilled version of thinking with a representative sample,  where we think with areas instead of counts, which is more flexible and easier to sketch  on the fly. Rather than bringing to mind some specific number of examples,  like 210, think of the space of all possibilities as a 1x1 square. Then any event occupies some subset of this space,  and the probability of that event can be thought about as the area of that subset. For example, I like to think of the hypothesis as living  in the left part of the square with a width of p of h. I recognize I'm being a bit repetitive, but when you see evidence,  the space of possibilities gets restricted, right? And the crucial part is that restriction might not be even between  the left and the right, so the new probability for the hypothesis  is the proportion it occupies in this restricted wonky shape. Now, if you happen to think that a farmer is just as likely to fit the evidence  as a librarian, then the proportion doesn't change, which should make sense, right? Irrelevant evidence doesn't change your beliefs. But when these likelihoods are very different from each other,  that's when your belief changes a lot. Bayes' theorem spells out what that proportion is,  and if you want you can read it geometrically. Something like p of h times p of e given h, the probability of both  the hypothesis and the evidence occurring together,  is the width times the height of this little left rectangle, the area of that region. Alright, this is probably a good time to take a step back and consider a few of the  broader takeaways about how to make probability more intuitive,  beyond just Bayes' theorem. First off, notice how the trick of thinking about a representative sample with some  specific number of people, like our 210 librarians and farmers, was really helpful. There's actually another Kahneman and Tversky result which is all about this,  and it's interesting enough to interject here. They did this experiment that was similar to the one with Steve,  but where people were given the following description of a fictitious woman named Linda. Linda is 31 years old, single, outspoken, and very bright. She majored in philosophy. As a student she was deeply concerned with issues of discrimination and social justice,  and also participated in the anti-nuclear demonstrations. After seeing this, people were asked what's more likely, 1. That Linda is a bank teller, or 2. That Linda is a bank teller and is active in the feminist movement. 85%, 85% of participants said that the latter is more likely than the former,  even though the set of bank tellers who are active in the feminist  movement is a subset of the set of bank tellers. It has to be smaller. So that's interesting enough, but what's fascinating is that there's a simple  way that you can rephrase the question that dropped this error from 85% to 0. Instead, if participants were told that there are 100 people who fit this description,  and then they're asked to estimate how many of those 100 are bank tellers,  and how many of them are bank tellers who are active in the feminist movement,  nobody makes the error. Everybody correctly assigns a higher number to the first option than to the second. It's weird, somehow phrases like 40 out of 100 kick our intuitions  into gear much more effectively than 40%, much less 0.4,  and much less abstractly referencing the idea of something being more or less likely. That said, representative samples don't easily capture the continuous  nature of probability, so turning to area is a nice alternative not just  because of the continuity, but also because it's way easier to sketch  out when you're sitting there pencil and paper puzzling over some problem. You see, people often think about probability as being the study of uncertainty,  and that is of course how it's applied in science, but the actual math of probability,  where all the formulas come from, is just the math of proportions,  and in that context turning to geometry is exceedingly helpful. I mean, take a look at Bayes' theorem as a statement about proportions,  whether that's proportions of people, of areas, whatever. Once you digest what it's saying, it's actually kind of obvious. Both sides tell you to look at the cases where the evidence is true,  and then to consider the proportion of those cases where the hypothesis is also true. That's it, that's all it's saying, the right hand side just spells out how to compute it. What's noteworthy is that such a straightforward fact about proportions  can become hugely significant for science, for artificial intelligence,  and really any situation where you want to quantify belief. I hope to give you a better glimpse of that as we get into more examples. But before more examples, we have a little bit of unfinished business with Steve. As I mentioned, some psychologists debate Kahneman and Tversky's conclusion,  that the rational thing to do is to bring to mind the ratio of farmers to librarians. They complain that the context is ambiguous. I mean, who is Steve, exactly? Should you expect that he's a randomly sampled American? Or would you be better to assume that he's a friend  of the two psychologists interrogating you? Or maybe that he's someone you're personally likely to know? This assumption determines the prior. I for one run into way more librarians in a given month than I do farmers. And needless to say, the probability of a librarian or farmer  fitting this description is highly open to interpretation. For our purposes, understanding the math, what I want to emphasize is that  any question worth debating here can be pictured in the context of the diagram. Questions about the context shift around the prior,  and questions about the personalities and stereotypes shift around the  relevant likelihoods. All that said, whether or not you buy this particular experiment,  the ultimate point that evidence should not determine beliefs, but update them,  is worth tattooing in your brain. I'm in no position to say whether this does or  does not run against natural human instinct. We'll leave that to the psychologists. What's more interesting to me is how we can reprogram our intuition to authentically  reflect the implications of math, and bringing to mind the right image can often do just  that.

================================================================================
VIDEO ID: Agbh95KyWxY
TITLE: Q&A with Grant, windy walk edition
URL: https://www.youtube.com/watch?v=Agbh95KyWxY
PUBLISHED: 2019-11-23T01:00:14Z
STATUS: SUCCESS
================================================================================
Who's your favorite mathematician? I always find favorite questions kind of silly,  but I will tell you about two different mathematicians that have been on my mind lately. So, a month or two ago I watched this documentary about Claude Shannon  called The Bit Player, and then that prompted me to read a little bit more  about Shannon in books like The Idea Factory or James Glick's The Information. And this guy was super interesting. I almost think of him as kind of a mixture between Donald Knuth and Adam Savage. So on the one hand, you know, he's the father of information theory. He wrote this absolutely seminal, super important paper about transmitting  information and storing it and encoding it and things like that. It really gave birth to the information age and  a lot of the foundations for computer science. To give you some indication of just how important this work was,  there's this one science fiction novel where all of the years,  instead of being measured B.C. and A.D. with respect to the birth of Christ, everything is before Shannon or after Shannon. It's viewed where the foundation of information theory is so pivotal in any kind  of civilization that it's worth setting your entire timeline around that point. So that's Shannon. Super influential on that one hand. But on the other hand, he was incredibly playful and very  willing to kind of pour his life into totally useless toys. So he spent a lot of time building different kinds of unicycles. He built this flaming trumpet for his son. He, you know, built this automatic juggling machine,  this mechanical calculator that would do computations in Roman numerals. Just wholly, completely useless things done for the purpose of play and nothing else. What I think you have to wonder is if this playfulness is wholly  incidental and unrelated to the important work that he did. Or if there's something that's necessary about it, right? If it's required that the kind of personality who's coming up with something totally new,  like original enough that it is a foundational moment for a new kind of science,  almost has to be the kind of personality that's also willing to make gizmos and toys  for his own pleasure that other people look at and see as useless, if somewhat fun. Another mathematician I've been thinking about for kind of related reasons is Edward  Lorenz, who is maybe not the father of chaos theory, but certainly one of the fathers. And he wasn't even a mathematician, actually. He was a meteorologist. But really, he was a mathematician to his core,  but wearing the external veneer of a meteorologist. And he's maybe most famous for this system of equations. It's just three variables, three unknowns. It's one of the earliest examples of something called a strange attractor. But it came about when he was studying weather patterns, right? And weather is famously hard to understand. You know, at the extreme, there's a huge number of unknown variables. If you go all the way to one extreme, you could say that  every atom in the atmosphere has six degrees of freedom. So you could have this truly ungodly monstrous system  of equations that no one could ever hope to analyze. So inevitably, you have to do something to simplify things down for pragmatism's sake. And a lot of people, I think, thought that the reason weather is  hard to predict is simply because of the number of variables at play. And one of the important contributions from Lorenz was to be able to simplify down  the unpredictability of it into a surprisingly simple set of equations to say, hey,  some of the facts here that are hard to predict when you make a, you know,  when you make some kind of measurement with a little bit of error around it,  and that error kind of propagates, that's not just because of the number of variables  at play. You can have that kind of chaos arising from surprisingly simple circumstances. So in order to do this, right, you have to have the strange mixture, again,  of a kind of pragmatism with a kind of more pure mathematician instinct. And I wonder if this is ever something that a pure mathematician could have done. If he wasn't grounded in a problem like weather,  where he was doing all of these computational models,  and really just in the weeds of, you know, convection or whatever else it might be. So in the same way that Shannon kind of represents this contrast  between playfulness and pragmatism, in my mind,  Lorenz sort of represents this contrast between, like, applied science and then pure math. And just as Shannon is the father of information theory,  it doesn't seem like a coincidence that we find in the father of another very  instrumental science to our modern age, chaos theory,  this sort of middle ground between those two. Now obviously there's a lot of selection bias at play here, right,  like most people that find themselves somewhere between pure and applied or  somewhere between pragmatic and playful don't give rise to completely new fields of study. But I do have to wonder if the novelty required to father a new field  necessitates breaking the norm and not falling into one clear-cut path. Some of you might be wondering if every question in this Q&A will have me  pontificating for many minutes, but I do have a broader point here,  which is that I think a number of people watching this channel,  especially those on the younger end, are clearly into pure math, right,  they're curious about it. I wouldn't be surprised if a lot of them are contemplating becoming mathematicians. And for that set of people, I kind of want to put out  the question of where do you think there's more value? Do you think it's if all of these people with this inclination towards  pure math go into that field, and that's where they get to collaborate  with a lot of folks who are like-minded, who think like them,  they resonate on the same wavelength, maybe they amplify each other's strengths? Or is there more value if each one of them kind of gets dispersed into some completely  different field, and each one is not so much a mathematician as a mathematician plus X,  right, they're a mathematician plus a builder plus a meteorologist plus whatever have you. And they take those instincts of playfulness towards puzzles or desire to abstract  the simplest form of a specific kind of hardness and basically bring that mathematician  instinct to something totally different, right, which of those worlds has more value? A teenage kid walks up to you and says they hate math. What do you tell or show them? I get the impression that the spirit of this question is for me to answer  with some piece of math that's so enticing that even the most ardent of  math haters would have to bring about some kind of affection for the subject. But the thing is, if someone comes to you and they admit that they don't like math,  or that they hate math, I don't think you should show them a piece of math,  even if you do want to convert them. It's a little bit like if, let's say you really love coffee, right,  and someone comes to you and they say, I just hate coffee,  but you like it a lot and you're kind of this snob and you really want to  turn them on to it. The way to do it is not to try to find the world's best cup of coffee and  then give it to them, because no matter what, it's going to taste like dirt. They don't like it. They're not addicted to it at this point. Instead, if you want to turn someone on to it, we have a couple options. One of them can be to first breed necessity, and then from there maybe get an addiction. So let's say it's a student and they need to stay up all night to  finish some kind of paper, and so they begrudgingly have to take some caffeine,  and after that a kind of culinary Stockholm syndrome kicks in,  and through the addiction they come to kind of like the substance. That's not the greatest, but that's a way to do it. The analog with the world of math might be trying to find something where  math is the drug necessary for someone to accomplish what they want to. You know, maybe they're really into video games,  so they want to make their own video game, and often in writing  the software for that you have to use geometry, trigonometry, maybe bits of calculus. It kind of depends on the game that you're building. So you breed the necessity. But in either case, I think the key is to just try to build up familiarity,  just be exposed to math in a lot of different contexts,  and importantly for it to not ever be traumatic when that happens. I think the reason a lot of people say that they hate math is because  their only exposure to it is tightly linked with a sense of failure, right? It's a hard subject, but importantly it's a very cumulative subject,  so if you miss one little part, it looks like you're failing in all of the later parts,  even if you would have been really good at those other parts without that missing link. So instead if the math comes about in a less judgmental context,  something where there's no grading, you know, maybe it's just playing with puzzles with  friends, or it's writing that bit of software for the video game,  or whatever it is where you're gaining exposure without that trauma,  I think after enough time, you're just going to like the subject. Because I think if we're all really honest with ourselves,  and we look back on why we like the things that we like,  it's often because someone in our life liked it. The time we were spending with them brought us to spending time with that thing,  and then it just stuck with us. What advice would you give to a math enthusiast suffering from anxiety disorder,  clinical depression, and ADHD? I'm not entirely sure how the word math enthusiast in the question changes the answer,  but I will say that for anything health related, and this goes double from mental health,  definitely seek professional help earlier than you think you need to. So don't be shy about finding a therapist or asking  your doctor about these kinds of things. One thing I will say, as a professional YouTuber,  I do think it's probably healthy for people to spend less time on the internet. You know, I always get this uneasy feeling if I hear about  someone binge watching all of my videos or something like that. Because on the one hand, I often do measure success in  terms of how much time people are watching the videos. It's some indication of how much it's reaching the world,  how deeply people want to engage with it, and all of that. But on the other hand, if I think of someone kind of staying up all night to  watch YouTube, or even just sitting in their house all day to watch YouTube,  no matter what that video is, no matter how enlightening or how educational it  seems to be, that's gotta be bad for you and unhealthy in comparison to occasionally,  you know, going outside or spending time with real people in the world,  or if you want to engage with math, doing it in a more physical, social kind of way. Is Ben Ben and Blue still a thing? Ah, yes, the podcast with the Bens. No, I don't think it'll continue. I don't think that's a bad thing. I think we had some really good conversations about education in there. I'm not sure how much we necessarily had to say. And I don't think all projects should live forever. I think there's something kind of nice about doing something a little different,  a little experimental, and then being willing to just walk away from it if it seems  better to spend time on, say, animated math videos or whatever else your main occupation  might be. Favorite podcasts? Alright, so there's three different podcasts where I  get actively excited if I see something new in the feed. And it's unfortunate because each one doesn't upload super regularly. First one is The Anthropocene Reviewed by John Green. So, as many of you probably know, John Green is an excellent writer. The podcast itself, he kind of reviews everyday things or aspects of human existence that  range from deeply philosophical ones to very mundane, like the Taco Bell breakfast menu. It's maybe 70% personal memoir, and you get this view into  his own very thoughtful but also very twisted and tortured mind. So, highly recommended. The second, which I think is super popular, so certainly don't need me saying this,  is Hardcore History by Dan Carlin. He often likes to go deep into the human experience of certain wars or  certain very violent times in human history that shaped the direction of things. And he does a good job just giving a super abundant amount of context,  maybe way too much context, which is why these podcasts sometimes  last as long as six hours and will be many, many part series. But sometimes you like that in a podcast. And then maybe foremost, that I like a lot, and this will just come as no surprise,  is the Numberphile podcast. I'm slightly biased because I was on it, but I  actually think I'm the least interesting guest there. Super interesting to hear from different mathematicians what their story is,  how they relate to the subject, what motivates them,  and of course Brady Haran is a phenomenal interviewer,  so it's just perfect for anyone who's into math, even in the slightest of ways. If you had both the responsibility and opportunity to best introduce the world of  mathematics to curious and intelligent minds before they are shaped by the antiquated,  disempowering, and demotivational education system of today, what would you do? Asking because I will soon be a father. First of all, let's just acknowledge that it's very weird for me to  be asked a question that has anything with the flavor of parenting advice,  because, well, look at me, like I'm 27, what the hell do I know? But one interesting place to look here, if we're thinking,  how do you make a child entering the world love math, or things related to math,  is Richard Feynman's dad. So, evidently, Feynman's dad was incredibly interested in making him into, like,  a physicist or an engineer or something like that,  and even when young Richard was just a newborn baby,  he would paint these interesting patterns that were meant to instill young Richard's  mind with a sense of mathematical patterns through the raw exposure. And as he grew up a little bit later, he would give these very deep,  thoughtful answers to questions about how the world worked, or why when you,  like, tug at a wagon that has a ball in it, the ball doesn't move. Feynman would tell all of these stories, they were some of his favorites to tell. You know, if I look back at my own childhood, there's definitely a lot  of influence from a very attentive, thoughtful father in that respect. I think I said this in a previous Q&A, but I'll just say it again here. I remember these games where he would stack these sugar cubes in interesting  geometric arrangements, and I would be asked to count how many there are. And you couldn't just straight up count because it was,  some of them were hidden in certain ways, right,  so you are effectively cubing numbers or something like that. And, of course, if I got it right, then I would  get one of the sugar cubes as this Pavlovian reward. And if you look at the success of someone like Feynman when it comes to problem solving,  and I definitely don't view myself as, like, a great problem solver,  but I do love the subject. I have this, like, deep-seated affection for it that probably is  not unassociated to the kind of games my dad would play with me. It's not so much that I think, oh, the painting of those patterns really did  instill young Richard's mind with a sense of math,  or that the answers that his father gave to certain questions were the ones that  made him deep and thoughtful later. I think it's just that when you're a parent and you're showing  a lot of attention towards something, you're signaling to the  kid that that something is important and it's worth thinking about. So all of the signaling that probably came from young Richard Feynman's dad showing  this deep attentiveness to questions about the physical world,  about mathematical patterns, probably made it such that young Richard would spend  a lot of his own time thinking about those things,  because they just pattern match off of their parents. Another thing I might say is try to draw a distinction between school math and math,  right? They can just be very separate things, and kind  of separating the brand of those two can't hurt. What's something you think could have been discovered long before it was  actually discovered? Well, just last week, all of the internet has been very  abuzz about a certain result that came from these three physicists studying  neutrinos about eigenvectors and eigenvalues, which is a crazy fundamental thing. You kind of wouldn't imagine that there are any new things to be discovered  about computing eigenvectors or computing eigenvalues, because it's so,  well, it's kind of old and it's very, I don't know, routine at this point. But they found what they thought was a result and they sent it to Terry Tao,  who actually responded and his initial thought was, this can't be true,  it would be in every textbook if it was true. And then within two hours, I think he found three independent proofs of the thing,  and yeah, it's just a different way to compute eigenvectors that was discovered in 2019,  even though that totally could have been discovered hundreds of years ago. Can we fix math on Wikipedia? Really serious here. I constantly go there after your vids for a bit of a deeper dive and learn nothing more,  ever. Compared to almost any other topic in the natural sciences or physics,  where at least I get an outline of where to go next, it's such a shame. So this question kind of reminds me of that classic trope where you've  got a girl and she's dating a boy and, you know, he's kind of a bad boy,  he does a couple things that are wrong that adds to his allure,  he's kind of sexy in that way, but she's thinking, oh, I can change him, right? He's flawed, but I can fix him. And everyone in her life is looking and saying, oh, honey, like, he's not going to change. People don't change. You have to find someone else. In the same way, if I see someone trying to learn math from Wikipedia  and not use it as a reference, it's like, it's not going to change. Don't try to change it. You've got to find a different source. There's lots of really great blogs that you can go to,  or Math Exchange and Quora are great in terms of people trying to  explain things in approachable ways, and don't forget about just good old textbooks. In math, more so than a lot of fields, I think there's a strong contrast between  what makes good reference material and what makes good pedagogical material. And a general rule of thumb, this is not universal, but general rule of thumb,  things that are single-authored, I believe, are better pedagogically. And I suspect the reason for this is that when you want to explain a topic,  often the best route to making it understandable is to start off by being a little  bit wrong. You explain kind of a simplified version of something that isn't entirely accurate,  but it's easier to get a foothold in. Then once you have that foothold, you slowly carve away what's wrong about  it until you end up at what is entirely accurate, but more complicated. But you've taken this path through incorrectness. Now when you have multiple authors, I think the tendency is that  you sort of wipe away and edit away the things that are incorrect. That's like the stable equilibrium that you reach. So what you're left with is a source that's entirely factually correct,  but it's harder to get a foothold into for that reason. And Wikipedia just represents the extreme of this,  but I also think you see it if you look at a textbook that has, you know,  three or four authors. Again, there are exceptions, but I like that as a rule of thumb. Real quick, I want to tell you about two new items that have  been added to the 3Blue1Brown store for any math enthusiasts. The first one, in the spirit of upping the level of formality on things,  is this knot theory themed tie. So as you can see, the pattern includes a lot of different simple mathematical knots. So almost any knot that you are likely to tie with your tie anyway is going to  be topologically equivalent to one of these, unless you just go totally crazy. In sourcing this, we wanted to make sure that it was, you know,  a legitimately high quality tie, and I'm really happy with what we found. Then as a supplement to the ties, I also got these vector field socks produced,  and what they represent is the phase space of a pendulum,  which some of you may know is most naturally represented on a cylinder,  hence printing it on a sock. So the whole item is just sort of a subtle nod to that fact. I believe DFTBA is going to do some kind of sale on Black Friday and Cyber Monday,  so if you're watching this before then, definitely check it out. And with that, I will see you all in the next,  probably much more typical, video. Thanks for watching!

================================================================================
VIDEO ID: EK32jo7i5LQ
TITLE: Why do prime numbers make these spirals? | Dirichletâ€™s theorem and pi approximations
URL: https://www.youtube.com/watch?v=EK32jo7i5LQ
PUBLISHED: 2019-10-08T17:02:51Z
STATUS: SUCCESS
================================================================================
I first saw this pattern that I'm about to show  you in a question on the Math Stack Exchange. It was asked by a user under the name Dwymark, and answered by Greg Martin,  and it relates to the distribution of prime numbers,  together with rational approximations for pi. You see, what the user had been doing was playing around with data in polar coordinates. As a quick reminder so we're all on the same page,  this means labeling points in 2D space not with the usual xy coordinates,  but instead with a distance from the origin, commonly called r for radius,  together with the angle that radial line makes with the horizontal, commonly called theta. For our purposes, this angle will be measured in radians,  which basically means that an angle of pi is halfway around, and 2 pi is a full circle. Notice, polar coordinates are not unique, in the sense that adding 2 pi to that second  coordinate doesn't change the location that this pair of numbers is referring to. The pattern that we'll look at centers around plotting points  where both of these coordinates are a given prime number. There is no practical reason to do this, it's purely fun,  we're just frolicking around in the playground of data visualization. To get a sense for what it means, look at all the whole numbers,  rather than just the primes. The point 1,1 sets a distance 1 away from the origin, with an angle of 1 radian,  which actually means this arc is the same length as that radial line. And then 2,2 has twice that angle, and twice the distance. And to get to 3,3, you rotate one more radian,  with a total angle that's now slightly less than a half turn,  since 3 is slightly less than pi, and you step one unit farther away from the origin. I really want you to make sure that it's clear what's being plotted,  because everything that follows depends on understanding it. Each step forward is like the tip of a clock hand,  which rotates one radian with each tick a little less than a sixth of a turn,  and it grows by one unit at each step. As you continue, these points spiral outwards,  forming what's known in the business as an archimedean spiral. Now if you make the admittedly arbitrary move to knock out everything  except the prime numbers, it initially looks quite random, after all,  primes are famous for their chaotic and difficult to predict behavior. But when you zoom out, what you start to see are these very clear  galactic-seeming spirals, and what's weird is some of the arms seem to be missing. And zooming out even further, those spirals give way to a different pattern,  these many different outward-pointing rays. And those rays seem to mostly come in clumps of four,  but there's the occasional gap, like a comb missing its teeth. The question for you and me, naturally, is what on earth is going on here? Where do these spirals come from, and why do we  instead get straight lines at this larger scale? If you wanted, you could ask a more quantitative question,  and count that there are 20 total spirals, and then up at that larger scale,  if you patiently went through each ray, you'd count up a total of 280. And so this adds a further mystery of where these numbers are coming from,  and why they would arise from primes. Now this is shocking, and beautiful, and you might think that  it suggests some divine hidden symmetry within the primes. but to study your expectations, I should say that the fact  that the person asking this question on math exchange jumped  right into prime numbers makes the puzzle a little misleading. If you look at all the whole numbers, not just the primes,  as you zoom out, you see very similar spirals. They're much cleaner, and now there's 44 of them instead of 20,  but it means that the question of where the spirals come from is,  perhaps disappointingly, completely separate from the question of what happens  when we limit our view to primes. But don't be too disappointed, because both these questions are still phenomenal puzzles. There's a very satisfying answer for the spirals,  and even if the primes don't cause the spirals,  asking what goes on when you filter for those primes does lead you to  one of the most important theorems about the distribution of prime numbers,  known in number theory as Dirichlet's theorem. To kick things off, let's zoom back in a little bit smaller. Did you notice that as we were zooming out, there were these six little spirals? This offers a good starting point to explain what's happening in the two larger patterns. Notice how all the multiples of 6 form one arm of this spiral. then the next one is every integer that's one above a multiple of 6,  and then includes all the numbers 2 above a multiple of 6, Then after that it includes all the numbers 2 above a multiple of 6, and so on. Why is that? Well, remember that each step forward in this sequence involves a turn of one radian,  so when you count up by 6, you've turned a total of 6 radians,  which is a little less than 2 pi, a full turn. So every time you count up by 6, you've almost made a full turn, it's just a little less. Another six steps, a slightly smaller angle. Six more steps, smaller still, and so on, with this angle changing  gently enough that it gives the illusion of a single curving line. When you limit the view to prime numbers, all but two of these spiral arms will go away. And think about it, a prime number can't be a multiple of 6,  and it also can't be 2 above a multiple of 6 unless it's 2,  or 4 above a multiple of 6, since all of those are even numbers. It also can't be 3 above a multiple of 6, unless it's the number 3 itself,  since all of those are divisible by 3. So, at least at this smaller scale, nothing magical is going on. And while we're in this simpler context, let me  introduce some terminology that mathematicians use. Each one of these sequences, where you're counting up by 6,  is fancifully called a residue class mod 6. The word residue here is sort of an overdramatic way of saying remainder,  and mod means something like where the thing you divide by is. So, for example, 6 goes into 20 three times, and it leaves a remainder of 2. So 20 has a residue of 2 mod 6. Together with all the other numbers leaving a remainder of 2 when  the thing you divide by is 6, you have a full residue class mod 6. I know that sounds like the world's most pretentious way of saying  everything 2 above a multiple of 6, but this is the standard jargon,  and it is actually handy to have some words for the idea. So looking at our diagram, in the lingo, each of these spiral arms  corresponds to a residue class mod 6, and the reason we see them  is that 6 is close to 2 pi, turning 6 radians is almost a full turn. And the reason we see only 2 of them when filtering for primes is that all prime  numbers are either 1 or 5 above a multiple of 6, with the exceptions of 2 and 3. With all that as a warmup, let's think about the larger scale. In the same way that 6 steps is close to a full turn,  taking 44 steps is very close to a whole number of turns. Here, let's compute it. There are 2 pi radians per rotation, right? So taking 44 steps, turning 44 radians, gives a total of 44 divided by 2 pi rotations,  which comes out to be just barely above 7 full turns. You could also write this by saying that 44 sevenths is a close approximation for 2 pi,  which some of you may better recognize as the famous 22 sevenths approximation for pi. What this means is when you count up by multiples of 44 in the diagram,  each point has almost the same angle as the last one, just a little bit bigger. So as you continue on with more and more, we get this  very gentle spiral as the angle increases very slowly. Similarly, all the numbers 1 above a multiple of 44 make another spiral,  but rotated one radian counterclockwise. Same for everything 2 above a multiple of 44, and so on,  eventually filling out the full diagram. To phrase it with our fancier language, each of  these spiral arms shows a residue class mod 44. And maybe now you can tell me what happens when we limit our view to prime numbers. Primes cannot be a multiple of 44, so that arm won't be visible. Nor can a prime be 2 above a multiple of 44, or 4 above, and so on,  since all those residue classes have nothing but even numbers. Likewise, any multiples of 11 can't be prime, except for 11 itself,  so the spiral of numbers 11 above a multiple of 44 won't be visible,  and neither will the spiral of numbers 33 above a multiple of 44. This is what gives the picture those Milky Way-seeming gaps. Each spiral we're left with is a residue class  that doesn't share any prime factors with 44. And within each one of those arms that we can't reject out of hand,  the prime numbers seem to be randomly distributed. That's a fact I'd like you to tuck away, we'll return to it later. This is another good chance to inject some of the jargon mathematicians use. What we care about right here are all the numbers between  0 and 43 that don't share a prime factor with 44, right? The ones that aren't even and aren't divisible by 11. When two numbers don't share any factors like this,  we call them relatively prime, or also co-prime. In this example you could count that there are 20 different numbers between 1  and 44 that are co-prime to 44, and this is a fact that a number theorist would  compactly write by saying phi of 44 equals 20,  where the Greek letter phi here refers to Euler's totient function,  yet another needlessly fancy word, which is defined to be the number of integers  from 1 up to n which are co-prime to n. It comes up enough that it's handy to have compact notation. More obscurely, and I had never heard this before but I find it too  delightful not to tell, these numbers are sometimes called the totitives of n. Back to the main thread, in short, what the user on math exchange was seeing  are two unrelated pieces of number theory but illustrated in one drawing. The first is that 44 sevenths is a very close rational approximation for 2 pi,  which results in the residue classes mod 44 being cleanly separated out. The second is that many of these residue classes contain zero prime numbers,  or sometimes just one, so they won't show up, but on the other hand primes do show  up enough in all 20 of the other residue classes that it makes these spiral arms visible. And at this point maybe you can predict what's going on at the larger scale. Just as 6 radians is vaguely close to a full turn,  and 44 radians is quite close to 7 full turns,  it just so happens that 710 radians is extremely close to a whole number of full turns. Visually, you can see this by the fact that the point ends up  almost exactly on the x-axis, but it's more compelling analytically. 710 radians is 710 divided by 2 pi rotations, which works out to be 113.000095. Some of you may have seen this in another form. It's saying that 710 one hundred thirteenths is a close approximation for 2 pi,  which is more commonly seen in saying that 355 over 113 is a very good approximation  for pi. If you want to understand where these rational approximations are coming from,  and what it means for one like this to be unusually good,  like way better than you would get for phi or e or square root of 2 or  other famous irrationals, I highly recommend taking a look at this great Mathologer video. For our storyline though, it means that when you move forward by steps of 710,  the angle of each new point is almost exactly the same as the last one,  just microscopically bigger. Even very far out, one of these sequences looks like a straight line. And of course, the other residue classes, mod 710, also form these nearly straight lines. 710 is a big number though, so when all of them are on screen,  and there's only so many pixels on the screen, it's a little hard to make them out. So in this case, it's actually easier to see when we limit the view to primes,  where you don't see many of those residue classes. In reality, with a little further zooming, you can see  that there actually is a very gentle spiral to these. But the fact that it takes so long to become prominent is a wonderful illustration,  maybe the best illustration I've ever seen, for just how good an approximation this is  for 2 pi. Tying up the remaining loose thread here, if you want to understand what  happens when you filter for primes, it's entirely analogous to what we did before. The factors of 710 are 71, 5, and 2, so if the remainder,  or residue, is divisible by any of those, then so is the number. When you pull up all of the residue classes with odd numbers,  it looks like every other ray in the otherwise quite crowded picture. And then of those that remain, these are the ones that are divisible by 5,  which are nice and evenly spaced at every 5th line. Notice the fact that prime numbers never show up in any of these is what  explains the pattern of the lines we saw at the beginning coming in clumps of 4. And moreover, of those remaining, these four residue classes are the ones that are  divisible by 71, so the primes aren't going to show up there,  and that's what explains why the clumps of 4 that we saw occasionally have a missing  tooth in your cone. And if you were wondering where that number 280 came from,  it comes from counting how many of the numbers from 1 up to 710 don't share any  prime factors with 710. These are the ones that we can't rule out for including  primes based on some obvious divisibility consideration. This of course doesn't guarantee that any particular one will contain prime numbers,  but at least empirically when you look at this picture,  it actually seems like the primes are pretty evenly distributed among the remaining  classes, wouldn't you agree? This last point is actually the most interesting observation of the whole deal. It relates to a pretty deep fact in number theory, known as Dirichlet's theorem. To take a simpler example than residue classes mod 710, think of those mod 10. Because we write numbers in base 10, this is the same thing  as grouping numbers together by what their last digit is. Everything whose last digit is 0 is a residue class,  everything whose last digit is 1 is another residue class, and so on. Other than 2, prime numbers can't have an even number as their last digit,  since that means they're even. And likewise, any prime bigger than 5 can't end in a 5. There's nothing surprising there, that's one of the  first facts you observe when you learn about prime numbers. Anything bigger than 5 has to end in either a 1, a 3, a 7, or a 9. A much more nuanced question, though, is how exactly these  primes are divvied up among those remaining four groups. Here, let's make a quick histogram, counting through each prime number,  where the bars are going to show what proportion of the primes we've seen so far have a  given last digit. So in particular, the 2 and the 5 slots should go down to 0 over time. What would you predict is going to happen as we move through more and more primes? Well, as we get a lot of them, it seems like a pretty  even spread between these four classes, about 25% each. And probably that's what you would expect. After all, why would prime numbers show some sort  of preference for one last digit over another? But primes aren't random, they are a definite sequence,  and they show patterns in other ways, and it's highly non-obvious how you would  prove something like this. Or, for that matter, how do you rigorously phrase what it is you want to prove? A mathematician might go about it something like this. If you look at all the prime numbers less than some big number x,  and you consider what fraction of them are, say, 1 above a multiple of 10,  that fraction should approach 1 fourth as x approaches infinity,  and likewise for all of the other allowable residue classes, like 3 and 7 and 9. Of course, there's nothing special about 10. A similar fact should hold for any other number. Considering our old friends the residue classes mod 44, for example,  let's make a similar histogram, showing what proportion of the primes show up in each  one of these. Again, as time goes on, we see an even spread between the 20 different  allowable residue classes, which you can think of in terms of each spiral  arm from our diagram having about the same number of primes as each of the others. Maybe that's what you'd expect, but this is a shockingly hard fact to prove. The first man who cracked this puzzle was Dirichlet in 1837,  and it forms one of the crowning jewels at the foundation of modern analytic  number theory. Histograms like these ones give a pretty good  illustration of what the theorem is actually saying. Nevertheless, you might find it enlightening to see how it might  be written in a math text, with all the fancy jargon and everything. It's essentially what we just saw for 10, but more general. Again, you look at all the primes up to some bound x,  but instead of asking for what proportion of them have a residue of, say, 1 mod 10,  you ask what proportion have a residue of r mod n, where n is any number,  and r is anything that's co-primed to n. Remember, that means it doesn't share any factors with n bigger than 1. Instead of approaching 1 fourth as x goes to infinity,  that proportion goes to 1 divided by phi of n,  where phi is that special function I mentioned earlier that gives the  number of possible residues co-primed to n. In case this is too clear for the reader, you might see it buried in more notation,  where this denominator and the numerator are both written  with a special prime-counting function. The convention, rather confusingly, is to use the symbol pi for this function,  even though it's totally unrelated to the number pi. In some contexts, when people refer to Dirichlet's theorem,  they refer to a much more modest statement, which is simply that each of  these residue classes that might have infinitely many primes does have infinitely many. In order to prove this, what Dirichlet did was show that the primes  are just as dense in any one of these residue classes as in any other. For example, imagine someone asks you to prove that there are  infinitely many primes ending in the number 1,  and the way you do it is by showing that a quarter of all the primes end in a 1. Together with the fact that there are infinitely many primes,  which we've known since Euclid, this gives a stronger statement,  and a much more interesting one. Now the proof, well, it's way more involved than would be reasonable to show here. One interesting fact worth mentioning is that it relies heavily on complex analysis,  which is the study of doing calculus with functions whose  inputs and outputs are complex numbers. Now that might seem weird, right? Prime numbers seem wholly unrelated to the continuous world of calculus,  much less when complex numbers end up in the mix, but since the early 19th century,  this is absolutely par for the course when it comes to understanding how primes are  distributed. And this isn't just antiquated technology either. Understanding the distribution of primes in residue classes  like this continues to be relevant in modern research too. Some of the recent breakthroughs on small gaps between primes,  edging towards that ever-elusive twin-prime conjecture,  have their basis in understanding how primes split up among these kinds  of residue classes. Okay, looking back over the puzzle, I want to emphasize something. The original bit of data visualization whimsy that led to these patterns,  well, it doesn't matter, no one cares. There's nothing special about plotting p,p in polar coordinates,  and most of the initial mystery in these spirals resulted from the artifacts  that come from dealing with integer number of radians, which is kind of weird. But on the other hand, this kind of play is clearly worth it if the  end result is a line of questions that leads you to something like Dirichlet's theorem,  which is important, especially if it inspires you to learn enough to  understand the tactics of the underlying proof. No small task, by the way. And this isn't a coincidence that a fairly random question  like this can lead you to an important and deep fact for math. What it means for a piece of math to be important  and deep is that it connects to many other topics. So even an arbitrary exploration of numbers, as long as it's not too arbitrary,  has a chance of stumbling into something meaningful. Sure, you'll get a much more concentrated dosage of important facts by going  through a textbook or a course, and there will be many fewer uninteresting dead ends,  but there is something special about rediscovering these topics on your own. If you effectively reinvent Euler's totient function before you've ever seen it defined,  or if you start wondering about rational approximations before learning about  continued fractions, or if you seriously explore how primes are divvied up between  residue classes before you've even heard the name Dirichlet,  then when you do learn those topics, you'll see them as familiar friends,  not as arbitrary definitions, and that will almost certainly mean that you learn  it more effectively. Thank you.

================================================================================
VIDEO ID: M64HUIJFTZM
TITLE: The unexpectedly hard windmill question (2011 IMO, Q2)
URL: https://www.youtube.com/watch?v=M64HUIJFTZM
PUBLISHED: 2019-08-04T17:03:51Z
STATUS: SUCCESS
================================================================================
Every year, more than 100 countries send six of their brightest teenagers,  or the occasional prepubescent prodigy, to represent them at the  International Math Olympiad, commonly known as the IMO. Considering that each country has its own elaborate system of contests leading  to their choice of six representatives, the IMO stands as the culminating  symbol for the surprisingly expansive and wonderful world that is contest math. The contest itself is essentially a test, split over two days,  with three questions given over four and a half hours each day. The questions are all proofs, meaning you don't simply find some numerical answer,  you have to discover and articulate a rigorous line of reasoning to answer each  difficult question, and then each one is scored on a scale from 0 up to 7. Of interest to you and me today is the one from 2011,  with 563 total participants representing 101 countries. I know what you're thinking, and the answer is yes,  those do all happen to be prime numbers. But that's not why this test was interesting. Out of all these prime problem solvers, only one of them,  Lisa Sauermann from Germany, got a perfect score. And the only thing standing between the next two runners  up that year and a perfect score was problem number two. And this problem is beautiful, and despite evading many of the world's best  mathematicians of their age, the solution is something that anyone watching this video  can understand. So let's begin by reading through it carefully. Let S be a finite set of at least two points on the plane. Okay, so as you read the question it's often helpful  to start drawing an example for yourself. Assume that no three points of S are collinear,  in other words you never have three points lining up,  so you can probably predict that the problem's going to involve drawing lines in  some way that three points on one line would mess things up. A windmill is a process that starts with the line L going through a single point P in S. The line rotates clockwise around the pivot P until the first  time that that line meets some other point belonging to S. And again, while reading it's helpful to draw out an example so we've  got this line that's pivoting around some point until it hits another. This point, Q, takes over as the new pivot, and the line now  rotates clockwise about Q until it next meets a point of S. This process continues indefinitely. Alright, that's kind of fun. We keep rotating and changing the pivot, and you can see why they call it a windmill  process, and you can also see why they specified that no three points lie on one line. You wouldn't want to run into the ambiguity where you don't know which pivot to switch to. Okay, so with all this setup, what's the question? Show that we can choose a point P in S and a line L going through P such that  the resulting windmill uses each point of S as a pivot infinitely many times. Alright, depending on your tolerance of puzzles for puzzle's sake,  you might wonder why would anyone care about such a question? There's a very good reason, in fact. I would argue that the act of solving this will make you better at math  and related fields, and I'll explain why once you've seen the solution. But certainly on the surface, it feels disconnected from other parts of math. I mean, you look at other Olympiad problems, and they often involve  some function to analyze, or a numerical pattern to deduce,  maybe a difficult counting setup or an elaborate geometric construction. But problem two, it's an unusually pure puzzle, and in some ways that's its charm. Proving that some initial condition will result in this windmill hitting all the points  infinitely many times, well that doesn't test your knowledge of a particular theorem. It tests if you can find a clever perspective. But that blade cuts both ways. Without resting on an existing result from math,  what could possibly prepare someone to study for something like this? And in fact, that brings us to the second unusual thing about this problem. Based on the results, I'm guessing that it turned out  to be much harder than the contest organizers expected. You see, typically the three problems each day are supposed to get progressively harder. They're all hard, of course, it's the IMO, but problems one and four should be doable. Problems two and five, they're challenging. And problems three and six, well they can be brutal. But take a look at how many of our 563 participants  that year got perfect scores on each of the problems. Only 22 of them got full marks for question number two. By contrast, 170 got a perfect score on problem five,  which is supposed to be about the same difficulty,  and more than twice as many got a perfect score for problem three,  which is supposed to be harder. Some of you might notice that only six students got full points for problem  six that year, so by some measure that was the hardest problem on the test. In fact, the way I introduced things earlier was a little disingenuous,  the full data would suggest that problem six was the real clincher. But what's strange is that if you look at the results of those six students  who solved this hardest problem, all of whom are clearly phenomenal world-class  problem solvers, this windmill puzzle evaded five out of six of them. But again, this problem is not hard because of the background knowledge it demands,  it asks only for insight. So how do you approach something like this? The first step with any puzzle is to simply play around with it and get a feel for it,  and it's always good to start simple and slowly get more complicated from there. The simplest case would be two points, where the line trades off between each point. That works well enough. Adding a third point, it's pretty clear that the line will just rotate around them. It might not be entirely clear how you would phrase this as a rigorous proof yet,  but right now we're just getting a feel for things. The fourth point is where it gets interesting. In some places, your windmill will go around the four points just like it did with the  triangle, but if we put it inside that triangle, it looks like our windmill never hits it. Looking back at the problem, it's asking you to show that for some starting position of  the line, not any position, the process will hit all the points infinitely many times. So for an example like this, if you start with the line  going through that troublesome middle point, what happens? And again, at this point we're just playing around,  perhaps moving your pencil among dots that you've drawn on a piece of scratch paper. You want to believe a result before you try too hard to prove it. Here you'd see that your windmill does indeed bounce off of all the  points as it goes through a cycle, and it ends up back where it started. The worry you might have is that in some large sets of points,  where some are kind of inside the others, you might be able to start off on the inside,  but maybe something about this windmill process takes the line to the outside,  where as time goes on to infinity it'll be blocked off from those inner points. If you play around, and mind you it can take some time to draw out many  examples and think this through, you would notice that when the line  starts off passing through the middle of the points, it tends to stay there. It never seems to venture off to the outside. But can you guarantee that this will always happen? Or rather, can you first make this idea of starting in the middle a little more rigorous,  and from there prove that all the points will be hit infinitely many times? As a general problem-solving tip, whenever you have a vague idea that feels productive,  you should of course find a way to be more exact about what you're saying,  but preferably put numbers to it, and then see if you can ask questions about those  numbers. In our example, one way to formalize this idea of a middle  is to count how many points are on either side of the line. If you give the line some orientation, you can reasonably talk about a left half,  say coloring all the points on the left blue, and a right half,  say coloring all the points on the right brown. And what it means for a line to be in the middle is that  there are as many blue points as there are brown points. For the moment, let's say that the total number of points is an odd number,  and the point that the line passes through is colored white, sort of a neutral color. So for example, if there were 11 points, you would have 5 blue ones on the left,  5 brown ones on the right, and the single white point as the pivot. The case with an even number of points will be similar, just slightly less symmetric. What this gives us is a new question to ask. What happens to the number of blue points and brown points as the process plays out? In the example on screen now, you might notice it's always 5 and 5, never changing. Playing around with other examples, you would find that the same is true. Take a moment to pause right now, and see if you  can think through why exactly that would happen. Why would these numbers not change? Well, the key is to think through what happens as the line changes its pivot. Having given the line an orientation, we can talk reasonably  about which half is above the pivot, and which one is below. If the line hits a blue point on its left, it must happen below the pivot. So then when it changes the pivot and continues rotating clockwise a bit, that old pivot,  now above the new one, ends up to the left, meaning it ends up in the blue region. And entirely symmetrically, when it hits a brown point,  it happens above the pivot, meaning that the old pivot ends up in the brown region. So no matter what, the number of points on a given side of the line cannot change,  except for the instances where the line is passing through two points at once. When you lose a blue point, you gain a new one. When you lose a brown point, you gain a new one. And that is our key insight number one. So why would this imply that the line must hit every point infinitely many times,  no matter what weird set of points you could dream up? The second key is to think about letting this process  go until the line has turned 180 degrees around. What that means is that it's parallel to the starting position,  and because it has to remain the case that half the points are on one side  and half the points are on the other, it must be passing through the same  point it started on. I mean, think about it, if it ended up on some other point,  it would change the number on a given side. Additionally, since the line has rotated halfway around,  everything that was blue has become brown, and everything which was  brown has become blue, and the only way to change the color is if you get hit by the line. So for our odd-numbered case, that means that after a half rotation,  the line is back where it started, and it's hit all of the other points. So as time goes forward, it repeats this exact set of motions over and over,  hitting all of those points infinitely many times. For the case with an even number of points, we need to alter the scheme slightly,  but only slightly. To make it so that the number of blues can equal the number of browns,  let's say that the pivot counts now as a brown point. So to define our initial condition, we still say for a given angle of the line,  select an initial point so that half of the points are blue, all on the left,  and half of them are brown, now either meaning they're on the right, or the pivot. The same argument from before implies that after a 180Â° turn,  everything has swapped colors, but this time the line will be passing through  a different point after that first half turn, specifically one that used to be blue,  but after another 180Â° it has to be passing through the one that it started on. Again, the logic is that it's parallel to its starting position,  and if it was passing through any other point,  the number of points on a given side would have to be different. So once more, we have a cycle which hits all of the points,  and which ends in the same position where it started. This time it takes 360Â°, but that doesn't matter,  as the cycle continues it'll hit all the points infinitely many times. Stepping back, there are two important lessons to take away from this puzzle,  the first one social and the second one mathematical. Once you know this solution, and if you ponder it a bit and  turn it around in your head a couple times, it's very easy to  fool yourself into thinking that the problem is easier than it is. After all, of course the number of points on a given side stays constant, right? Of course that's a question you would ask. And of course when you start in the middle, every  point will switch sides after a half a turn. But the advantage of this problem coming from the IMO is that we  don't have to rest on In the subject of statements,  we have the data to show it's a genuinely hard problem,  in that it evaded many of the world's best students who are demonstrably  able to solve hard problems. In math, it's extremely hard to empathize with  what it feels like to not understand something. I was discussing this video with a former coworker of mine from Khan Academy,  who worked a lot with people creating math exercises,  and he pointed out that across a wide variety of contributors, there's one constant. Nobody is able to tell how difficult their exercises are. Knowing when math is hard is way harder than the math itself. This is important to keep in mind when teaching,  but it's equally important to keep in mind when being taught. On our windmill puzzle, even if counting the number of points on one side  seems obvious in hindsight, you have to ask, given the vast space of possible  things you might consider, Why would anyone's mind turn to that particular idea? This brings us to the mathematical takeaway. What ultimately led to the solution was finding something about the  complex system which stays constant during this chaotic unfolding. This is a ubiquitous theme through math, and especially through physics. We're finding what's called an invariant. Topologists do this when they count the number of holes in a surface. Physicists do this when they define the ideas of energy and momentum,  or in special relativity when they define more abstract ideas like proper time. As a student, it's easy to take for granted the definitions handed down to you,  but the more puzzles you solve where the insight involves an invariant,  the more you come to appreciate that each one of these definitions was once a clever  discovery. Terence Tao, one of the greatest modern mathematicians and the world's  youngest IMO medalist, wrote that mathematical problems or puzzles are  important to real mathematics, like solving real-life problems, just as fables,  stories, and anecdotes are important to the young in understanding real life. Sure, these kinds of puzzles are contrived, but they carry lessons  relevant to useful problems you may actually need to solve one day. Maybe it seems silly to liken this windmill puzzle to a fairy tale,  a mathematical Aesop summarizing that the moral of the story is to seek quantities  which stay constant. But some of you watching this will one day face a problem where finding an invariant  reveals a slick solution, and you might even look like a genius for doing so.  If a made-up windmill prepares you for a real problem, who cares that it's a fiction?

================================================================================
VIDEO ID: v0YEaeIClKY
TITLE: e^(iÏ€) in 3.14 minutes, using dynamics | DE5
URL: https://www.youtube.com/watch?v=v0YEaeIClKY
PUBLISHED: 2019-07-07T14:08:18Z
STATUS: SUCCESS
================================================================================
One way to think about the function e to the t is to ask what properties does it have? Probably the most important one, and from some points of view the defining property, is that it is its own derivative. Together with the added condition that inputting 0 returns 1, it's actually the only function with this property. And you can illustrate what this means with a physical model. If e to the t describes your position on a number line as a function of time, then you start at the number 1, and what this equation is saying is your velocity, the derivative of position, is always equal to that position. The farther away from 0 you are, the faster you move. So even before knowing how to compute e to the t exactly, going from a specific time to a specific position, this ability to associate each position with a velocity paints a very strong intuitive picture of how the function must grow. You know that you'll be accelerating, and at an accelerating rate, with an all-around feeling of things getting out of hand quickly. And if you add a constant to that exponent, like e to the 2 times t, the chain rule tells us that the derivative is now 2 times itself. So at every point on the number line, rather than attaching a vector corresponding to the number itself, first double the magnitude of the position, then attach it. Moving so that your position is always e to the 2t is the same as moving in such a way that your velocity is always twice your position. The implication of that too is that our runaway growth feels all the more out of control. If that constant was negative, say negative 0.5, then your velocity vector is always negative 0.5 times your position vector, meaning you flip it around 180 degrees and scale its length by a half. Moving in such a way that your velocity always matches this flipped and squished copy of your position vector, you go the other direction, slowing down in an exponential decay towards 0. But what about if that constant was i, the square root of negative 1? If your position was always e to the i t, how would you move as the time t ticks forward? Well now the derivative of your position will always be i times itself, and multiplying by i has the effect of rotating numbers 90 degrees. So as you might expect, things only make sense here if we start thinking beyond the number line and in the complex plane. So even before you know how to compute e to the i times t, you know that for any position this might give for some value of time, the velocity at that time will be a 90 degree rotation of that position. Drawing this for all possible positions you might come across, you get a vector field, where as usual with vector fields you shrink things down to avoid clutter. At time t equals 0, e to the i t will be 1, that's our initial condition, and there's only one trajectory starting from that position where your velocity is always matching the vector that it's passing through, a 90 degree rotation of the position. It's when you go around a circle of radius 1 at a speed of 1 unit per second. So after pi seconds you've traced a distance of pi around, so e to the i times pi should be negative 1. After tau seconds you've gone full circle, e to the i times tau equals 1, and more generally e to the i times t equals a number that's t radians around this unit circle in the complex plane. Nevertheless, something might still feel immoral about putting an imaginary number up in that exponent, and you would be right to question that. What we write as e to the t is a bit of notational disaster, giving the number e and the idea of repeated multiplication way more emphasis than they deserve. But my time is up, so I'll spare you the full rant until the next video.

================================================================================
VIDEO ID: -qgreAUpPwM
TITLE: Pure Fourier series animation montage
URL: https://www.youtube.com/watch?v=-qgreAUpPwM
PUBLISHED: 2019-07-03T04:05:19Z
STATUS: SUCCESS
================================================================================
MUSIC you you you you you you you you you you

================================================================================
VIDEO ID: r6sGWTCMz2k
TITLE: But what is a Fourier series?  From heat flow to drawing with circles | DE4
URL: https://www.youtube.com/watch?v=r6sGWTCMz2k
PUBLISHED: 2019-06-30T14:50:20Z
STATUS: SUCCESS
================================================================================
Here, we look at the math behind an animation like this one,  what's known as a complex Fourier series. Each little vector is rotating at some constant integer frequency,  and when you add them together, tip to tail, the final tip draws out some shape over time. By tweaking the initial size and angle of each vector,  we can make it draw pretty much anything we want, and here you'll see how. Before diving into it all, I want you to take  a moment to just linger on how striking this is. This particular animation has 300 rotating arrows in total. Go full screen for this if you can, the intricacy is worth it. Think about this, the action of each individual arrow is perhaps  the simplest thing you could imagine, rotation at a steady rate. And yet the collection of all added together is anything but simple,  and the mind-boggling complexity is put into an even sharper focus the farther we  zoom in, revealing the contributions of the littlest, quickest,  and downright frenetic arrows. When you consider the chaotic frenzy you're looking at,  and the clockwork rigidity underlying all the motions,  it's bizarre how the swarm acts with a kind of coordination to trace  out some very specific shape. And unlike much of the emergent complexity you find elsewhere in nature,  this is something that we have the math to describe and to control completely. Just by tuning the starting conditions, nothing more,  we can make this swarm conspire in all of the right ways to draw anything you want,  provided you have enough little arrows. What's even crazier is that the ultimate formula for all of this is incredibly short. Now often, Fourier series are described in terms of something that looks a little  different, functions of real numbers being broken down as a sum of sine waves. That turns out to be a special case of this more general rotating vector  phenomenon that we'll build up to, but it's where Fourier himself started,  and there's good reason for us to start the story there as well. Technically, this is the third video in a sequence about the heat equation,  what Fourier was working on when he developed his big idea. I would like to teach you about Fourier series in a way that doesn't depend on  you coming from those chapters, but if you have at least a high-level idea for  the problem from physics which originally motivated this piece of math,  it gives some indication for just how unexpectedly far-reaching Fourier series are. All you need to know is that we had a certain equation which tells us  how the temperature distribution on a rod would evolve over time,  and incidentally it also describes many other phenomena unrelated to heat. While it's hard to directly use this equation to figure out what will happen to an  arbitrary heat distribution, there's a simple solution if the initial function just  happens to look like a cosine wave, with the frequency tuned so that it's flat at each  end point. Specifically, as you graph what happens over time,  these waves simply get scaled down exponentially,  with higher frequency waves having a faster exponential decay. The heat equation happens to be what's known in the business as a linear equation,  meaning if you know two solutions and add them up, that sum is a new solution. You can even scale them each by some constant,  which gives you some dials to turn to construct a custom function solving the equation. This is a fairly straightforward property that you can verify for yourself,  but it's incredibly important. It means we can take our infinite family of solutions,  these exponentially decaying cosine waves, scale a few of them by some  custom constants of our choosing, and combine them to get a solution for a new,  tailor-made initial condition, which is some combination of cosine waves. One important thing I'd like you to notice is that when you combine these waves,  because the higher frequency ones decay faster,  the sum you construct will tend to smooth out over time,  as all the high frequency terms quickly go to zero,  leaving only the low frequency terms dominating. So in a funny way, all of the complexity in the evolution of this heat  distribution which the heat equation implies is captured by this  difference in the decay rates for the different pure frequency components. It's at this point that Fourier gains immortality. I think most normal people at this stage would say, well,  I can solve the heat equation when the initial distribution just happens to look like  a wave, or a sum of waves, but what a shame it is that most real world distributions  don't at all look like that. I mean, for example, let's say you brought together two rods  which were each at some uniform temperature, and you wanted  to know what happens immediately after they come into contact. To make the number simple, let's say the temperature of the left rod is 1 degree,  and the right rod is negative 1 degree, and that the total length,  L, of the combined two rods is 1. What this means is our initial temperature distribution is a step function,  which is so obviously different from a sine wave, or the sum of sine waves,  don't you think? I mean, it's almost entirely flat, not wavy, and for god's sake it's even discontinuous! And yet Fourier thought to ask a question which seems absurd. How do you express this as a sum of sine waves? Even more boldly, how do you express any initial distribution as a sum of sine waves? And it's more constrained than just that! You have to restrict yourself to adding waves which satisfy a certain boundary condition,  and as we saw last video, that means working with these cosine functions whose  frequencies are all some whole number multiple of a given base frequency. And by the way, if you were working with some different boundary condition,  say that the endpoints have to stay fixed, you'd have a different set of waves at  your disposal to piece together, in this case replacing that cosine expression with  a sine. It's strange how often progress in math looks more like  asking a new question rather than simply answering old ones. Fourier really does have a kind of immortality now,  with his name essentially synonymous with the idea of breaking  down functions and patterns as combinations of simple oscillations. It's really hard to overstate just how important and far-reaching that idea  turned out to be, well beyond anything Fourier himself could have imagined. And yet, the origin of all this is a piece of physics which,  at first glance, has nothing to do with frequencies and oscillations. If nothing else, this should give you a hint about  the general applicability of Fourier series. Now hang on, I hear some of you saying, none of these sums of sine waves that  you're showing are actually the step function, they're all just approximations. And it's true, any finite sum of sine waves will never be perfectly flat,  except for a constant function, nor will it be discontinuous. But Fourier thought more broadly, considering infinite sums. In the case of our step function, it turns out to be equal to this infinite sum,  where the coefficients are 1, negative one third, plus one fifth, minus one seventh,  and so on for all the odd frequencies, and all of it is rescaled by 4 divided by pi. I'll explain where those numbers come from in a moment. Before that, it's worth being clear about what we mean by a phrase like infinite sum,  which runs the risk of being a little vague. Consider the simpler context of numbers, where you could say,  for example, that this infinite sum of fractions equals pi divided by 4. As you keep adding the terms one by one, at all times what you have is rational,  it never actually equals the irrational pi divided by 4. But this sequence of partial sums approaches pi over 4, which is to say,  the numbers you see, while never equaling pi over 4,  get arbitrarily close to that value, and they stay arbitrarily close to that value. That's all a mouthful to say, so instead we abbreviate  and just say the infinite sum equals pi over 4. With functions, you're doing the same thing, but with many different values in parallel. Consider a specific input, and the value of all  of these scaled cosine functions for that input. If that input is less than 0.5, as you add more and more terms, the sum will approach 1. If that input is greater than 0.5, as you add more and more terms,  it would approach negative 1. At the input 0.5 itself, all of the cosines are 0,  so the limit of the partial sums is also 0. That means that, somewhat awkwardly, for this infinite sum to be strictly true,  we have to prescribe the value of this set function at the point of  discontinuity to be 0, sort of halfway along the jump. Analogous to an infinite sum of rational numbers being irrational,  the infinite sum of wavy continuous functions can equal a discontinuous flat function. Getting limits into the game allows for qualitative changes,  which finite sums alone never could. There are multiple technical nuances that I'm sweeping under the rug here. Does the fact that we're forced into a certain value for the step function  at the point of discontinuity make any difference for the heat flow problem? For that matter, what does it really mean to solve  a PDE with a discontinuous initial condition? Can we be sure that the limit of solutions to the heat equation is also a solution? And can we be sure that all functions actually have a Fourier series like this? If not, when not? These are exactly the kind of questions which real analysis is built to answer,  but it falls a bit deeper in the weeds than I'd like to go here,  so I'll relegate that all to links in the video's description. The upshot is that when you take the heat equation solutions associated with  these cosine waves and add them all up, all infinitely many of them,  you do get an exact solution describing how the step function will evolve over time,  and if you had done this in 1822, you would have become immortal for doing so. The key challenge in all of this, of course, is to find these coefficients. So far, we've been thinking about functions with real number outputs,  but for the computations, I'd like to show you something more general than what  Fourier originally did, applying to functions whose output can be any complex number  in the 2D plane, which is where all these rotating vectors from the opening come  back into play. Why the added complexity? Well, aside from being more general, in my view, the computations become cleaner,  and it's easier to understand why they actually work. More importantly, it sets a good foundation for the ideas that will come up later on  in the series, like the Laplace transform, and the importance of exponential functions. We'll still think of functions whose input is some real number on a finite interval,  say from 0 up to 1 for simplicity, but whereas something like a temperature  function will have outputs on the real number line,  this broader view will let the outputs wander anywhere in the 2D complex plane. You might think of such a function as a drawing,  with a pencil tip tracing out different points in the complex plane as the  input ranges from 0 to 1. And instead of sine waves being the fundamental building block,  as you saw at the start, we'll focus on breaking these functions down  as a sum of little vectors, all rotating at some constant integer frequency. Functions with real number outputs are essentially really boring drawings,  a one-dimensional pencil sketch. You might not be used to thinking of them like this,  since usually we visualize such a function with a graph,  but right now the path being drawn is only in the output space. If you do one of these decompositions into rotating vectors for a boring one-dimensional  drawing, what will happen is that the vectors with frequency 1 and negative 1 will  have the same length, and they'll be horizontal reflections of each other. When you just look at the sum of these two as they rotate,  that sum stays fixed on the real number line, and it oscillates like a sine wave. If you haven't seen it before, this might be a really weird way to think about what a  sine wave is, since we're used to looking at its graph rather than the output alone  wandering on the real number line, but in the broader context of functions with complex  number outputs, this oscillation on the horizontal line is what a sine wave looks like. Similarly, the pair of rotating vectors with frequencies 2 and negative 2 will  add another sine wave component, and so on, with the sine waves we were looking  for earlier now corresponding to pairs of vectors rotating in opposite directions. So the context that Fourier originally studied,  breaking down real-valued functions into sine waves,  is a special case of the more general idea of 2D drawings and rotating vectors. And at this point, maybe you don't trust me that widening our view to  complex functions makes things easier to understand, but bear with me,  it's really worth the added effort to see the fuller picture,  and I think you'll be pleased with how clean the actual computation is in  this broader context. You may also wonder why, if we're going to bump things up into two dimensions,  we don't just talk about 2D vectors, what does the square root  of negative one have to do with anything? Well, the heart and soul of Fourier series is the complex exponential, e to the i times t. As the input t ticks forward with time, this value walks  around the unit circle at a rate of one unit per second. In the next video you'll see a quick intuition for why exponentiating imaginary  numbers walks around circles like this from the perspective of differential equations. And beyond that, as the series progresses, I hope to give you some  sense for why complex exponentials like this are actually very important. In theory, you could describe all of the Fourier series stuff purely in terms of vectors,  and never breathe a word of i, the square root of negative one. The formulas would become more convoluted, but beyond that,  leaving out the function e to the x would somehow no longer authentically  reflect why this idea turns out to be so useful for solving differential equations. For right now, if you want, you can think of e to the i t as a  notational shorthand for describing rotating vectors,  but just keep in the back of your mind that it is more significant than mere shorthand. You'll notice I'm being a little loose with language using the words vector and complex  numbers somewhat interchangeably, in large part because thinking of complex numbers  as little arrows makes the idea of adding a lot of them together easier to visualize. Alright, armed with the function e to the i times t,  let's write down a formula for each of these rotating vectors we're working with. For right now, think of each of them as starting  pointing one unit to the right at the number 1. The easiest vector to describe is the constant one, which stays at the number 1,  never moving, or if you prefer, it's quote-unquote rotating just at a frequency of 0. Then there will be the vector rotating one cycle every second,  which we write as e to the 2 pi i times t. That 2 pi is there because as t goes from 0 to 1,  it needs to cover a distance of 2 pi along the circle. Technically in what's being shown, it's actually one cycle every 10 seconds  so things aren't too dizzying, I'm slowing everything down by a factor of 10. We also have a vector rotating at one cycle per second in the other direction,  e to the negative 2 pi i times t. Similarly, the one going two rotations per second is e to the 2 times 2 pi i times t,  where that 2 times 2 pi in the exponent describes how much distance is covered in one  second. And we go on like this over all integers, both positive and negative,  with a general formula of e to the n times 2 pi times i t. Notice, this makes it more consistent to write that constant vector  as e to the 0 times 2 pi times i t, which feels like an awfully  complicated way to write the number 1, but at least it fits the pattern. The control that we have, the set of knobs and dials we get to turn,  is the initial size and direction of each of these numbers. The way we control that is by multiplying each one by some complex constant,  which I'll call c sub n. For example, if we wanted the constant vector not to be at the number 1,  but to have a length of 0.5, c sub 0 would be 0.5. If we wanted the vector rotating at 1 cycle per second to start off at an  angle of 45 degrees, we'd multiply it by a complex number which has the effect  of rotating it by that much, which you can write as e to the pi fourths times i. And if its initial length needed to be 0.3, then the  coefficient c sub 1 would be 0.3 times that amount. Likewise, everyone in our infinite family of rotating vectors has some complex constant  being multiplied into it, which determines its initial angle and its total magnitude. Our goal is to express any arbitrary function f of t,  say this one that draws an eighth note as t goes from 0 to 1,  as a sum of terms like this, so we need some way of picking out these constants  one by one, given the data of the function itself. The easiest of these to find is the constant term. This term represents a sort of center of mass for the full drawing. If you were to sample a bunch of evenly spaced values for the  input t as it ranges from 0 to 1, the average of all the outputs  of the function for those samples would be the constant term c0. Or more accurately, as you consider finer and finer samples,  the average of the outputs for these samples approaches c0 in the limit. What I'm describing, finer and finer sums of a function for samples of  t from the input range, is an integral, an integral of f of t from 0 to 1. Normally, since I'm framing this all in terms of averages,  you would divide the integral by the length of the input range,  but that length is 1, so in this case, taking an integral and taking an  average are the same thing. There's a very nice way to think about why this integral would pull out c0. Remember, we want to think of this function as a sum of rotating vectors,  so consider this integral, this continuous average, as being applied to that whole sum. The average of a sum like this is the same as the sum over the averages of each part. You can read this move as a sort of subtle shift in perspective. Rather than looking at the sum of all the vectors at each point in time  and taking the average value they sweep out, look at the average of an  individual vector as t goes from 0 to 1, and then add up all these averages. But each of these vectors just makes a whole number of rotations around 0,  so its average value as t ranges from 0 to 1 will be 0. The only exception is the constant term. Since it stays static and doesn't rotate, its average value  is just whatever number it happened to start on, which is c0. So doing this average over the whole function is a  sort of clever way to kill all the terms that aren't c0. But here's the actual clever part. Let's say you wanted to compute a different term, like c2,  sitting in front of the vector rotating two cycles per second. The trick is to first multiply f of t by something that makes that vector hold still,  sort of the mathematical equivalent of giving a smartphone to an overactive child. Specifically, if you multiply the whole function by e to the negative  2 times 2 pi i times t, think about what happens to each term. Since multiplying exponentials results in adding what's in the exponent,  the frequency term in each of our exponents gets shifted down by 2. So now, as we do our averages of each term, that c-1  vector spins around negative 3 times with an average of 0. The c0 vector, previously constant, now rotates twice as t ranges from 0 to 1,  so its average is also 0. And likewise, all vectors other than the c2 term make some whole number of rotations,  meaning they average out to be 0. So taking the average of this modified function is  a clever way to kill all the terms other than c2. And of course, there's nothing special about the number 2 here,  you could replace it with any other n, and you have a general formula for cn,  which is what we're looking for. Out of context, this expression might look complicated, but remember,  you can read it as first modifying our function, our 2d drawing,  so as to make the nth little vector hold still,  and then performing an average which kills all the moving vectors and  leaves you only with the still part. Isn't that crazy? All of the complexity in these decompositions you're seeing of drawings into  sums of many rotating vectors is entirely captured in this little expression. So when I'm rendering these animations, that's exactly what I'm having the computer do. It treats the path like a complex function, and for a certain range of values n,  it computes this integral to find the coefficient c of n. For those of you curious about where the data for a path itself comes from,  I'm going the easy route and just having the program read in an SVG,  which is a file format that defines the image in terms of mathematical curves rather  than with pixel values. So the mapping f of t from a time parameter to points in space basically comes predefined. In what's shown right now, I'm using 101 rotating vectors,  computing the values of n from negative 50 up to 50. In practice, each of these integrals is computed numerically,  basically meaning it chops up the unit interval into many small pieces of size delta t,  and then adds up this value, f of t times e to the negative n 2 pi i t times delta t,  for each one of them. There are fancier methods for more efficient numerical integration,  but this gives the basic idea. And after you compute these 101 constants, each one determines an initial  angle and magnitude for the little vectors, and then you just set them all rotating,  adding them tip to tail as they go, and the path drawn out by the final  tip is some approximation of the original path you fed in. As the number of vectors used approaches infinity,  the approximation path gets more and more accurate. To bring this all back down to earth, consider the example we were looking at earlier,  of a step function, which remember was useful for modeling the heat dissipation  between two rods at different temperatures after they come into contact. Like any real number valued function, the step function  is like a boring drawing that's confined to one dimension. But this one is an especially dull drawing, since for inputs between 0 and 0.5,  the output just stays static at the number 1, and then it discontinuously  jumps to negative 1 for inputs between 0.5 and 1. So in the Fourier series approximation, the vector sum stays really  close to 1 for the first half of the cycle, then quickly jumps to negative 1,  and stays close to that for the second half of the cycle. And remember, each pair of vectors rotating in opposite directions  corresponds to one of the cosine waves we were looking at earlier. To find the coefficients, you would need to compute this integral,  and for the ambitious viewers among you itching to work out some integrals by hand,  this is one where you can actually do the calculus to get an exact answer,  rather than just having a computer do it numerically for you. I'll leave it as an exercise to work this out,  and to relate it back to the idea of cosine waves by pairing off the vectors  that rotate in opposite directions. And for the even more ambitious, I'll leave another exercise up on the screen for  how to relate this more general computation with what you might see in a textbook  describing Fourier series only in terms of real valued functions with sines and cosines. By the way, if you're looking for more Fourier series content,  I highly recommend the videos by Mathologer and The Coding Train,  and I'd also recommend this blog post, links of course in the description. So on the one hand, this concludes our discussion of the heat equation,  which was a little window into the study of partial differential equations. But on the other hand, this Fourier-to-Fourier series is a first glimpse at a deeper idea. Exponential functions, including their generalization into complex  numbers and even matrices, play a very important role for differential equations,  especially when it comes to linear equations. What you just saw, breaking down a function as a combination  of these exponentials and using that to solve a differential equation,  comes up again and again in different shapes and forms. Thank you.

================================================================================
VIDEO ID: ToIXSwZ1pJU
TITLE: Solving the heat equation | DE3
URL: https://www.youtube.com/watch?v=ToIXSwZ1pJU
PUBLISHED: 2019-06-16T16:31:00Z
STATUS: SUCCESS
================================================================================
We last left off studying the heat equation in the one-dimensional case of a rod. The question is how the temperature distribution  along such a rod will tend to change over time. This gave us a nice first example for a partial differential equation. It told us that the rate at which the temperature at a given point changes over time  depends on the second derivative of that temperature at that point with respect to space. Where there's curvature in space, there's change in time. Here we're going to look at how to solve that equation. Actually, it's a little misleading to refer to all of this as solving an equation. The PDE itself only describes one out of three constraints that our  temperature function must satisfy if it's going to accurately describe heat flow. It must also satisfy certain boundary conditions,  which is something we'll talk about momentarily, and a certain initial condition,  that is, you don't get to choose how it looks at time t equals zero. These added constraints are really where all of the challenge lies. There is a vast ocean of functions solving the PDE,  in the sense that when you take their partial derivatives the thing is going to be equal,  and a sizable subset of that ocean satisfies the right boundary conditions. When Joseph Fourier solved this problem in 1822,  his key contribution was to gain control of this ocean,  turning all of the right knobs and dials, so as to be able to select from it the  particular solution fitting a given initial condition. We can think of his solution as being broken down into three fundamental observations. 1. Certain sine waves offer a really simple solution to this equation. 2. If you know multiple solutions, the sum of these functions is also a solution. And number three, Most surprisingly, any function can be expressed as a sum of sine waves. A pedantic mathematician might point out that there are some pathological exceptions,  but basically any distribution you would come across in practice,  including discontinuous ones, can be written as a sum of sine waves,  potentially infinitely many. And if you've ever heard of Fourier series, you've at least heard of this last idea. And if so, maybe you've wondered, why on earth would anyone  care about breaking down a function as a sum of sine waves? Well, in many applications, sine waves are nicer to deal with than anything else,  and differential equations offer us a really nice context where you can see how that  plays out. For our heat equation, when you write a function as a sum of these waves,  the relatively clean second derivatives make it easy to solve the heat equation  for each one of them, and as you'll see, a sum of solutions to this equation  gives us another solution, and so in turn that will give us a recipe for  solving the heat equation for any complicated distribution as an initial state. Here, let's dig into that first step. Why exactly would sine waves play nicely with the heat equation? To avoid messy constants, let's start simple and say that the temperature function  at time t equals 0 is simply sine of x, where x describes the point on the rod. Yes, the idea of a rod's temperature just happening to look like sine of x,  varying around whatever temperature our conventions arbitrarily label as 0,  is clearly absurd, but in math you should always be happy to play with examples that  are idealized, potentially well beyond the point of being realistic,  because they can offer a good first step in the direction of something more general,  and hence more realistic. The right-hand side of this heat equation asks about the second derivative of  our function, how much our temperature distribution curves as you move along space. The derivative of sine of x is cosine of x, whose  derivative in turn is negative sine of x. The amount the wave curves is, in a sense, equal and opposite to its height at each point. So at least at time t equals 0, this has the peculiar effect that each  point changes its temperature at a rate proportional to the temperature  of the point itself, with the same proportionality constant across all points. So after some tiny time step, everything scales down by the same factor,  and after that, it's still the same sine curve shape, just scaled down a bit,  so the same logic applies, and the next time step would scale it down uniformly again. This applies just as well in the limit, as the size of these time steps approaches 0. So unlike other temperature distributions, sine waves are peculiar in that they'll  get scaled down uniformly, looking like some constant times sine of x for all times t. Now when you see that the rate at which some value changes is proportional to  that value itself, your mind should burn with the thought of an exponential. And if it's not, or if you're a little rusty on the idea of taking derivatives of  exponentials, or what makes the number e special,  I'd recommend you take a look at this video. The upshot is that the derivative of e to some  constant times t is equal to that constant times itself. If the rate at which your investment grows, for example,  is always 0.05 times the total value, then its value over time is  going to look like e to the 0.05 times t times whatever the initial investment was. If the rate at which the count of carbon-14 atoms in an old bone changes is always equal  to some negative constant times that count itself,  then over time that number will look approximately like e to that negative constant times  t times whatever the initial count was. So when you look at our heat equation, and you know that for a sine wave,  the right hand side is going to be negative alpha times the temperature function itself,  hopefully it won't be too surprising to propose that the solution is to  scale down by a factor of e to the negative alpha t. Here, go ahead and check the partial derivatives. The proposed function of x and t is sine of x times e to the negative alpha t. Taking the second partial derivative with respect to x,  that e to the negative alpha t term looks like a constant, it doesn't have any x in it. So it just comes along for the ride, as if it was any other constant, like 2,  and the first derivative with respect to x is cosine of x times e to the negative alpha t. Likewise, the second partial derivative with respect to x  becomes negative sine of x times e to the negative alpha t. And on the flip side, if you look at the partial derivative with respect to t,  that sine of x term now looks like a constant, since it doesn't have a t in it. So we get negative alpha times e to the negative alpha t times sine of x. So indeed, this function does make the partial differential equation true. And oh, if it was only that simple, this narrative flow could be so nice,  we would just beeline directly to the delicious Fourier series conclusion. Sadly, nature is not so nice, knocking us off  onto an annoying but highly necessary detour. Here's the thing, even if nature were to somehow produce a  temperature distribution on this rod, which looks like this perfect sine wave,  the exponential decay is not actually how it would evolve. Assuming that no heat flows in or out of the rod,  here's what that evolution would actually look like. The points on the left are heated up a little at first,  and those on the right are cooled down by their neighbors to the interior. In fact, let me give you an even simpler solution to the PDE which fails  to describe actual heat flow, a straight line, that is,  the temperature function will be some non-zero constant times x,  and never change over time. The second partial derivative with respect to x is indeed zero,  I mean there is no curvature, and its partial derivative with  respect to time is also zero, since it never changes over time. And yet, if I throw this into the simulator, it does actually change over time,  slowly approaching a uniform temperature at the mean value. What's going on here is that the simulation I'm using treats the two  boundary points of the rod differently from how it treats all the others,  which is a more accurate reflection of what would actually happen in nature. If you'll recall from the last video, the intuition for where that second  derivative with respect to x actually came from was rooted in having each  point tend towards the average value of its two neighbors on either side. But at the boundary, there is no neighbor to one side. If we went back to thinking of the discrete version,  modeling only finitely many points on this rod,  you could have each boundary point tend towards its one neighbor at  a rate proportional to their difference. As we do this for higher and higher resolutions,  notice how pretty much immediately after the clock starts,  our distribution looks flat at either of those two boundary points. In fact, in the limiting case, as these finer and finer  discretized setups approach a continuous curve,  the slope of our curve at the boundary will be zero for all times after the start. One way this is often described is that the slope at any given  point is proportional to the rate of heat flow at that point. So if you want to model the restriction that no heat flows into or out of the rod,  the slope at either end will be zero. That's somewhat hand-wavy and incomplete, I know,  so if you want the fuller details, I've left links and resources in the description. Taking the example of a straight line, whose slope at the boundary  points is decidedly not zero, as soon as the clock starts,  those boundary values will shift infinitesimally such that the slope  there suddenly becomes zero and remains that way through the remainder of the evolution. In other words, finding a function satisfying the heat equation itself is not enough. It must also satisfy the property that it's flat at  each of those endpoints for all times greater than zero. Phrased more precisely, the partial derivative with respect to  x of our temperature function at 0T and at LT must be zero for  all times T greater than zero, where L is the length of the rod. This is an example of a boundary condition, and pretty much any time you have to solve  a partial differential equation in practice, there will also be some boundary condition  hanging along for the ride, which demands just as much attention as the PDE itself. All of this may make it feel like we've gotten nowhere,  but the function which is a sine wave in space and an exponential decay in time  actually gets us quite close, we just need to tweak it a little bit so that it's  flat at both endpoints. First off, notice that we could just as well use a cosine function instead of a sine. I mean, it's the same wave, it's just shifted in phase by a quarter of the period,  which would make it flat at x equals zero, as we want. The second derivative of cosine of x is also negative one times itself,  so for all the same reasons as before, the product cosine of x  times e to the negative alpha t still satisfies the PDE. To make sure that it also satisfies the boundary condition on that right side,  we're going to adjust the frequency of the wave. However, that will affect the second derivative,  since higher frequency waves curve more sharply,  and lower frequency ones curve more gently. Changing the frequency means introducing some constant,  say omega, multiplied by the input of this function. A higher value of omega means the wave oscillates more quickly,  since as you increase x, the input to the cosine increases more rapidly. Taking the derivative with respect to x, we still get negative sine,  but the chain rule tells us to multiply that omega on the outside,  and similarly the second derivative will still be negative cosine,  but now with omega squared. This means that the right hand side of our equation  has now picked up this omega squared term. So to balance things out, on the left hand side,  the exponential decay part should have an additional omega squared term up top. Unpacking what that actually means should feel intuitive. For a temperature function filled with sharper curves,  it decays more quickly towards an equilibrium, and evidently does this quadratically. For instance, doubling the frequency results in an exponential decay four times as fast. If the length of the rod is L, then the lowest frequency,  where that rightmost point of the distribution will be flat,  is when omega is equal to pi divided by L. You see that way, as x increases up to the value L,  the input of our cosine expression goes up to pi,  which is half the period of a cosine wave. Finding all the other frequencies which satisfy this boundary  condition is sort of like finding harmonics, you essentially go  through all the whole number multiples of this base frequency, pi over L. In fact, even multiplying it by zero works, since that gives us a constant function,  which is indeed a valid solution, boundary condition and all. And with that, we're off the bumpy boundary condition detour and back onto the freeway. Moving forward, we're equipped with an infinite family of  functions satisfying both the PDE and the pesky boundary condition. Things are definitely looking more intricate now,  but it all stems from the one basic observation that a function which  looks like a sine curve in space and an exponential decay in time fits this equation,  relating second derivatives in space with first derivatives in time. And of course, your formulas should start to look more intricate,  you're solving a genuinely hard problem. This actually makes for a pretty good stopping point,  so let's call it an end here, and in the next video,  we'll look at how to use this infinite family to construct a more general solution. To any of you worried about dwelling too much on a single example in a series that's  meant to give a general overview of differential equations,  it's worth emphasizing that many of the considerations which pop up here are frequent  themes throughout the field. First off, the fact that we modeled the boundary with its own special rule,  while the main differential equation only characterized the interior,  is a very regular theme, and a pattern well worth getting used to,  especially in the context of PDEs. Also, take note of how what we're doing is breaking  down a general situation into simpler idealized cases. This strategy comes up all the time, and it's actually quite common  for these simpler cases to look like some mixture of sine curves  and exponentials that's not at all unique to the heat equation,  and as time goes on, we're going to get a deeper feel for why that's true.

================================================================================
VIDEO ID: ly4S0oi3Yz8
TITLE: But what is a partial differential equation?  | DE2
URL: https://www.youtube.com/watch?v=ly4S0oi3Yz8
PUBLISHED: 2019-04-21T16:53:21Z
STATUS: SUCCESS
================================================================================
After seeing how we think about ordinary differential equations in chapter 1,  we turn now to an example of a partial differential equation, the heat equation. To set things up, imagine you have some object, like a piece of metal,  and you know how the heat is distributed across it at any one moment,  that is, what's the temperature of every individual point along this plate. The question is, how will this distribution change over time,  as the heat flows from warmer spots to cooler ones? The image on the left shows the temperature of an example plate using color,  with the graph of that temperature being shown on the right. To take a concrete one-dimensional example, let's say you have two different  rods at different temperatures, where that temperature is uniform along each one. You know that when you bring them into contact,  the temperature will flow from the hot one to the cool one,  tending to make the whole thing equal over time. But how exactly? What will the temperature distribution be at each point in time? As is typical with differential equations, the idea is that it's  easier to describe how this setup changes from moment to moment  than it is to jump straight to a description of the full evolution. We write this rule of change in the language of derivatives, though as you'll see,  we'll need to expand our vocabulary a bit beyond ordinary derivatives. And don't worry, we'll learn how to read the equations you're seeing now in just a minute. Variations of the heat equation show up in many other parts of math and physics,  like Brownian motion, the black-Scholes equations from finance,  and all sorts of diffusion, so there are many dividends to be had from a deep  understanding of this one setup. In the last video we looked at ways of building understanding while acknowledging  the truth that most differential equations are simply too difficult to actually solve. And indeed, PDEs tend to be even harder than ODEs,  largely because they involve modeling infinitely many values changing in concert. But our main character for today is an equation we can actually solve. In fact, if you've ever heard of Fourier series,  you may be interested to know that this is the physical problem which Babyface  Fourier over here was trying to solve when he stumbled across the corner of math  that is now so replete with his name. We'll dig into Fourier series much more deeply in the next chapter,  but I would like to give you at least a little hint of the beautiful connection  which is to come. This animation you're seeing right now shows how lots of little rotating vectors,  each rotating at some constant integer frequency, can trace out an arbitrary shape. To be clear, what's happening is that these vectors are being added together,  tip to tail, at each moment, and you might imagine that the last one  has some sort of pencil at its tip, tracing a path as it goes. For finitely many vectors, this tracing usually won't be a  perfect replica of the target shape, which in this animation is a lowercase f,  but the more circles you include, the closer it gets. What you're seeing now uses only 100 circles, and I think you'd  agree that the deviations from the real shape are negligible. What's mind-blowing is that just by tweaking the initial size and angle of each vector,  that gives you enough control to approximate any curve you want. At first, this might seem like an idle curiosity, a neat art project, but little more. In fact, the math that makes this possible is the  same as the math describing the physics of heat flow. But we're getting ahead of ourselves. Step one is simply to build up the heat equation, and for that,  let's start by being clear about what the function we're analyzing is exactly. We have a rod in one dimension, and we're thinking of it as sitting on an x-axis,  so each point of that rod is labeled with a unique number, x. The temperature is some function of that position, t of x, shown here as a graph above it. But really, since the value changes over time,  we should think of this function as having one more input, t, for time. You could, if you wanted, think of this input space as being two-dimensional,  representing space and time together, with the temperature being graphed as a surface  above it, each slice across time, showing you what that distribution looks like at any  given moment. Or you could simply think of this graph of temperature changing with time. Both are equivalent. This surface is not to be confused with what I was showing earlier,  the temperature graph of a two-dimensional body. Be mindful when you're studying equations like these of whether  time is being represented with its own axis, or if it's being  represented with literal changes over time, say in an animation. Last chapter, we looked at some systems where just a handful of  numbers changed over time, like the angle and angular velocity of a pendulum,  describing that change in the language of derivatives. But when we have an entire function changing with time,  the mathematical tools become slightly more intricate. Because we're thinking of this temperature function with multiple  dimensions to its input space, in this case one for space and one for time,  there are multiple different rates of change at play. There's the derivative with respect to x, how rapidly  the temperature changes as you move along the rod. You might think of this as the slope of our surface when you slice it  parallel to the x-axis, or given a tiny step in the x-direction and the  tiny change to temperature caused by it, giving a ratio between the two. But there's also the rate at which a single point on the rod changes with time,  what you might think of as the slope of the surface when you slice  it in the other direction, parallel to the time axis. Each one of these derivatives tells only part of the story for how  this temperature function changes, so we call them partial derivatives. To emphasize this point, the notation changes a little,  replacing the letter D with a special curly D, sometimes called del. Personally, I think it's a little silly to change the  notation for this since it's essentially the same operation. I would rather see notation that emphasizes that the delT terms up in the numerators  refer to different changes, one is a small change to temperature after a small change  in time, the other is a small change to temperature after a small step in space. To reiterate a point I made in the calculus series,  I do think it's healthy to initially read derivatives like this as a literal  ratio between a small change to the function's output and the small change to  the input that caused it. Just keep in mind that what this notation is meant to encode is the  limit of that ratio for smaller and smaller nudges to the input,  rather than a specific value of the ratio for a finitely small nudge. This goes for partial derivatives just as much as it does for ordinary derivatives. The heat equation is written in terms of these partial derivatives. It tells us that the way this function changes with respect  to time depends on how it changes with respect to space. More specifically, it's proportional to the second partial derivative with respect to x. At a high level, the intuition is that at points where the temperature distribution  curves, it tends to change more quickly in the direction of that curvature. Since a rule like this is written using partial derivatives,  we call it a partial differential equation. This has the funny result that to an outsider,  the name sounds like a tamer version of ordinary differential equations,  when quite to the contrary, partial differential equations tend to tell a much richer  story than ODEs, and are much harder to solve in general. The general heat equation applies to bodies in any number of dimensions,  which would mean more inputs to our temperature function,  but it'll be easiest for us to stay focused on the one-dimensional case of a rod. As it is, graphing this in a way which gives time its own  axis already pushes our visuals into the third dimension. So I threw out this equation, but where does this come from? How could you think up something like this yourself? Well, for that let's simplify things by describing a discrete version of the setup,  where you have only finitely many points x in a row. This is sort of like working in a pixelated universe where instead of  having a continuum of temperatures, we have a finite set of separate values. The intuition here is simple. For a particular point, if its two neighbors on either  side are on average hotter than it is, it will heat up. If they're cooler on average, it'll cool down. Here, specifically focus on these three neighboring points x1,  x2, and x3, with corresponding temperatures T1, T2, and T3. What we want to compare is the average of T1 and T3 with the value of T2. When this difference is greater than zero, T2 will tend to heat up. And the bigger the difference, the faster it heats up. Likewise, if it's negative, T2 will tend to cool down,  at a rate proportional to that difference. More formally, we write that the derivative of T2 with respect to time  is proportional to the difference between its neighbors and its own value. Alpha here is simply a proportionality constant. To write this in a way which will ultimately explain the second derivative  in the heat equation, let me rearrange this right hand a bit in terms of  the difference between T1 and T2, and the difference between T2 and T3. You can quickly check that these two are the same. The top has half of T1, and in the bottom there are two minus signs in front of T1,  so it's positive, and the half has been factored out. Likewise, both have half of T3. Then on the bottom we have a negative T2 that's effectively written twice,  so when you take half of that it's the same as the single negative T2 written up top. Like I said, the reason to rewrite it is that it  takes us a step closer to the language of derivatives. In fact, let's write these as delta T1 and delta T2. It's the same value on the right hand side, but we're  adding a new perspective to how to think about it. Instead of comparing the average of the neighbors to T2,  we're thinking about the difference of the differences. Here, take a moment to gut check that this makes sense. If those two differences are the same, then the average of T1 and T3 is the same as T2,  so T2 will not tend to change. If delta T2 is bigger than delta T1, meaning the difference of the differences is  positive, notice how the average of T1 and T3 is bigger than T2, so T2 tends to increase. And on the flip side, if the difference of the differences is negative,  which means delta T2 is smaller than delta T1,  it corresponds to an average of these neighbors being less than T2. We could be especially compact with our notation and write this whole term,  the difference between the differences, as delta delta T1. This is known in the lingo as a second difference. If it feels a little weird to think about, keep in mind,  it's essentially a compact way of writing the idea of how much T2 differs from the  average of its neighbors. It just has this extra factor of one half, is all. And that factor doesn't really matter, because either way we're  writing this equation in terms of some proportionality constant. The upshot is that the rate of change for the temperature of  a point is proportional to the second difference around it. As we go from this finite context to the infinite continuous case,  the analog of a second difference is the second derivative. Instead of looking at the difference between the temperature  values at points some fixed distance apart, you instead consider  what happens as you shrink the size of that step towards zero. And in calculus, instead of talking about absolute differences,  which would also approach zero, you think in terms of the rate of change. In this case, what's the rate of change in temperature per unit distance? And remember, there are two separate rates of change at play. How does that temperature change as time progresses,  and how does the temperature change as you move along the rod? The core intuition remains the same as what we had in the discrete case. To know how a point differs from its neighbors,  look not just at how the function changes from one point to the next,  but at how the rate of change itself changes. Now in calculus land, we write this as del-squared t over del x-squared,  the second partial derivative of our function with respect to x. Notice how this slope increases at points where the graph curves upwards,  meaning the rate of change of the rate of change is positive. Similarly, that slope decreases at points where the graph curves downwards,  where the rate of change of this rate of change is negative. Tuck that away as a meaningful intuition for problems well beyond the heat equation. Second derivatives give a measure of how a value compares to the average of its neighbors. Hopefully that gives some satisfying added color to the equation. It's already pretty intuitive when you read it as saying that curved points tend  to flatten out, but I think there's something even more satisfying about seeing  a partial differential equation like this arise almost mechanistically from  thinking about each point as simply tending towards the average of its neighbors. Take a moment to compare what this feels like  to the case of ordinary differential equations. For example, if we have multiple bodies in space tugging at each other with gravity,  what we're analyzing is a handful of changing numbers,  in this case the coordinates of each object. The rate of change for any one of these values depends on the values of  the other numbers, and we often write this down as a system of equations. On the left, we have the derivative of each value with respect to time,  and on the right there's some combination of all the other values. In our partial differential equation, the difference is that we have infinitely  many values changing from a continuum, and again,  the way that any one of these values changes depends on the other values,  but quite helpfully, each one only depends on its immediate neighbors in some  limiting sense of the word neighbor. So here, the relation on the right hand side is not a sum or product  of the other numbers, it's instead a kind of derivative,  just a derivative with respect to space instead of with respect to time. In a sense, when you think about it, this one partial differential equation  is like a system of infinitely many equations, one for each point on the rod. You might wonder about objects which are spread out in more than one dimension,  like a plate, or something three dimensional. In that case the equation looks quite similar,  but you include the second derivative with respect to the other spatial  directions as well. And adding up all of these second spatial derivatives like this  is common enough as an operation that it has its own special name,  the Laplacian, often written as this upside down triangle squared. It's essentially a multivariable version of the second derivative,  and the intuition for this equation is no different from the one dimensional case. This Laplacian can still be thought of as measuring how different  is a point from the average of its neighbors, but now these  neighbors aren't just left and right of it, they're all around. For the curious among you, I did a couple of videos during my time  at Khan Academy on this operator if you want to go check them out. For those of you with multivariable calculus under your belt,  it's nice to think about as the divergence of the gradient. But you don't have to worry about that, for our  purposes let's stay focused on the one dimensional case. If you feel like you understand all of this, pat yourself on the back. Being able to read a PDE is no joke, and it's a powerful addition  to have to your vocabulary for describing the world around you. But after all of this time spent interpreting the equations,  I say it's high time we start solving them, don't you? And trust me, there are few pieces of math quite as satisfying as  what Poodlehaired Fourier over here developed to solve this problem. All this and more in the next chapter. I was originally motivated to cover this particular topic when  I got an early view of Steve Strogatz's new book Infinite Powers. This isn't a sponsored message or anything like that,  but all cards on the table I do have two selfish ulterior motives for mentioning it. The first is that Steve has been a really strong, maybe even pivotal,  advocate for the channel since the very beginning,  and I've had an itch to repay that kindness for quite a while. And the second is to make more people love math, and calculus in particular. That might not sound selfish, but think about it, when more people love math,  the potential audience base for these videos gets bigger. And frankly there are few better ways to get people loving  the subject than to expose them to Strogatz's writing. So if you have friends who you know who you think would enjoy the ideas of calculus  but maybe have been a bit intimidated by math in the past,  this book does a really outstanding job communicating the heart of the subject,  both substantively and accessibly. Its main theme is the idea of constructing solutions to complex real-world problems  from simple idealized building blocks, which as you'll see is exactly what Fourier did. And for those of you who already know and love the subject,  you will find no shortage of fresh insights and enlightening stories. I certainly enjoyed it. Again, I kinda know that sounds like an ad, but it's not,  I just actually think you'll enjoy the book.

================================================================================
VIDEO ID: p_di4Zn4wz4
TITLE: Differential equations, a tourist's guide | DE1
URL: https://www.youtube.com/watch?v=p_di4Zn4wz4
PUBLISHED: 2019-03-31T15:15:50Z
STATUS: SUCCESS
================================================================================
Taking a quote from Stephen Strogatz, since Newton,  mankind has come to realize that the laws of physics are always expressed in the  language of differential equations. Of course, this language is spoken well beyond the boundaries of physics as well,  and being able to speak it and read it adds a new color to how you view the world around  you. In the next few videos, I want to give a sort of tour of this topic. The aim is to give a big picture view of what this piece of math is all about,  while at the same time being happy to dig into the details of specific examples as they  come along. I'll be assuming you know the basics of calculus,  like what derivatives and integrals are, and in later videos we'll need some basic linear  algebra, but not too much beyond that. Differential equations arise whenever it's easier  to describe change than absolute amounts. It's easier to say why population sizes, for example,  grow or shrink than it is to describe why they have the particular values they  do at some point in time. It may be easier to describe why your love for someone  is changing than why it happens to be where it is now. In physics, more specifically Newtonian mechanics,  motion is often described in terms of force, and force determines acceleration,  which is a statement about change. These equations come in two different flavors, ordinary differential equations,  or ODEs, involving functions with a single input, often thought of as time,  and partial differential equations, or PDEs, dealing with functions that have multiple  inputs. Partial differential equations are something we'll  be looking at more closely in the next video. You often think of them as involving a whole continuum of values changing with time,  like the temperature at every point of a solid body,  or the velocity of a fluid at every point in space. Ordinary differential equations, our focus for now,  involve only a finite collection of values changing with time. And it doesn't have to be time per se, your one independent variable  could be something else, but things changing with time are the  prototypical and most common example of differential equations. Physics offers a nice playground for us here, with simple examples to start with,  and no shortage of intricacy and nuance as we delve deeper. As a nice warmup, consider the trajectory of something you throw in the air. The force of gravity near the surface of Earth causes things  to accelerate downward at 9.8 meters per second per second. Now unpack what that's really saying. It means if you look at that object free from other forces,  and record its velocity at every second, these velocity vectors will accrue an  additional small downward component of 9.8 meters per second every second,  we call this constant 9.8 g for gravity. This is enough to give us an example of a differential equation,  albeit a relatively simple one. Focus on the y-coordinate as a function of time. Its derivative gives the vertical component of velocity,  whose derivative in turn gives the vertical component of acceleration. For compactness, let's write the first derivative  as y-dot and the second derivative as y-double-dot. Our equation says that y-double-dot is equal to negative g, a simple constant. This is one we can solve by integrating, which  is essentially working the question backwards. First, to find velocity, you ask, what function has negative g as a derivative? Well, it's negative g times t, or more specifically,  negative gt plus the initial velocity. Notice that there are many functions with this particular derivative,  so you have an extra degree of freedom which is determined by an initial condition. Now what function has this as a derivative? It turns out to be negative one-half g times t squared plus that initial velocity  times t, and again we're free to add an additional constant without changing the  derivative, and that constant is determined by whatever the initial position is. And there you go, we just solved a differential equation,  figuring out what a function is based on information about its rate of change. Things get more interesting when the forces acting on a body depend on where that body is. For example, studying the motion of planets, stars,  and moons, gravity can no longer be considered a constant. Given two bodies, the pole on one of them is in the direction of the other,  with a strength inversely proportional to the square of the distance between them. As always, the rate of change of position is velocity,  but now the rate of change of velocity, acceleration, is some function of position,  so you have this dance between two mutually interacting variables,  reminiscent of the dance between the two moving bodies which they describe. This is reflective of the fact that often in differential equations,  the puzzles you face involve finding a function whose derivative and  or higher order derivatives are defined in terms of the function itself. In physics it's most common to work with second order differential equations,  which means the highest derivative you find in this expression is a second derivative. Higher order differential equations would be ones involving third derivatives,  fourth derivatives, and so on, puzzles with more intricate clues. The sensation you get when really meditating on one of these  equations is one of solving an infinite continuous jigsaw puzzle. In a sense, you have to find infinitely many numbers, one for each point in time t,  but they're constrained by a very specific way that these values intertwine with  their own rate of change, and the rate of change of that rate of change. To get a feel for what studying these can look like,  I want you to take some time digging into a deceptively simple example, a pendulum. How does this angle theta that it makes with the vertical change as a function of time? This is often given as an example in introductory physics classes of harmonic motion,  meaning it oscillates like a sine wave. More specifically, one with a period of 2 pi times the square root of l over g,  where l is the length of the pendulum and g is the strength of gravity. However, these formulas are actually lies, or rather,  approximations which only work in the realm of small angles. If you were to go and measure an actual pendulum,  what you'd find is that as you pull it out farther,  the period is longer than what the high school physics formulas would suggest. And when you pull it out really far, this value of theta  plotted versus time doesn't even look like a sine wave anymore. To understand what's really going on, first things first,  let's set up the differential equation. We'll measure the position of the pendulum's weight as a distance x along this arc,  and if the angle theta we care about is measured in radians,  we can write x as l times theta, where l is the length of the pendulum. As usual, gravity pulls down with an acceleration of g,  but because the pendulum constrains the motion of this mass,  we have to look at the component of this acceleration in the direction of motion. A little geometry exercise for you is to show  that this little angle here is the same as theta. So the component of gravity in the direction of motion  opposite this angle will be negative g times sine of theta. Here we're considering theta to be positive when the pendulum is swung to the right,  and negative when it's swung to the left. This minus sign in the acceleration indicates that it's  always pointed in the opposite direction from displacement. So what we have is that the second derivative of x,  the acceleration, is negative g times sine of theta. As always, it's nice to do a quick gut check that our formula makes physical sense. When theta is zero, sine of zero is zero, so there's  no acceleration in the direction of movement. When theta is 90 degrees, sine of theta is 1, so the  acceleration is the same as it would be for freefall. Alright, that checks out. And because x is L times theta, that means the second  derivative of theta is negative g over L times sine of theta. To be a little more realistic, let's add in a term to account for the air resistance,  which maybe we model as being proportional to the velocity. We'll write this as negative mu times theta dot,  where mu is some constant that encapsulates all the air resistance  and friction and such that determines how quickly the pendulum loses energy. Now this, my friends, is a particularly juicy differential equation. It's not easy to solve, but it's not so hard that we can't  reasonably get some meaningful understanding out of it. At first glance, you might think that the sine function you  see here relates to the sine wave pattern for the pendulum. Ironically, though, what you'll eventually find is that the opposite is true. The presence of the sine in this equation is precisely  why real pendulums don't oscillate with a sine wave pattern. If that sounds odd, consider the fact that here,  the sine function is taking theta as an input,  but in the approximate solution you might see in a physics class,  theta itself is oscillating as the output of a sine function. Clearly something fishy is afoot. One thing I like about this example is that, even though it's comparatively simple,  it exposes an important truth about differential equations that you need to grapple with. They're really freaking hard to solve. In this case, if we remove that dampening term,  we can just barely write down an analytic solution, but it's hilariously complicated. It involves all these functions you've probably never heard of,  written in terms of integrals and weird inverse integral problems. When you step back, presumably the reason for finding a solution is to then be able  to make computations and build an understanding for whatever dynamics you're studying. In this case, those questions have been punted off to figuring out how to compute,  and more importantly, understand, these new functions. And more often, like if we add back in that dampening term,  there's not a known way to write down an exact analytic solution. Well, for any hard problem you could just define a new function to be the answer of  that problem, heck, even name it after yourself if you want, but again,  that's pointless unless it leads you to being able to make computations and build  understanding. So instead, in the study of differential equations, we often do a sort of short circuit,  and skip the actual solution part, since it's unattainable,  and go straight to building understanding and making computations from the  equations alone. Let me walk through what that might look like with a pendulum. What do you hold in your head, or what visualization can you get some software  to pull up for you, to understand the many possible ways that a pendulum,  governed by these laws, might evolve depending on its starting conditions? You might be tempted to try imagining the graph of theta vs. t, and somehow interpreting how this slope, position,  and curvature all interrelate with each other. However, what will turn out to be both easier and more general is to  start by visualizing all possible states in a two-dimensional plane. What I mean by the state of the pendulum is that you can describe it with two numbers,  the angle and the angular velocity. You can freely change either one of those two values without necessarily  changing the other, but the acceleration is purely a function of those two values. So each point of this two-dimensional plane fully  describes the pendulum at any given moment. You might think of these as all possible initial conditions of that pendulum. If you know the initial angle and the angular velocity,  that's enough to predict how the system will evolve as time moves forward. If you haven't worked with them before, these  sorts of diagrams can take a little getting used to. What you're looking at now, this inward spiral,  is a fairly typical trajectory for our pendulum,  so take a moment to think carefully about what is being represented. Notice how at the start, as theta decreases, theta dot,  the y-coordinate, gets more negative. Which makes sense, because the pendulum moves faster  in the leftward direction as it approaches the bottom. Keep in mind, even though the velocity vector on this pendulum is pointed to the left,  the value of that velocity is always being represented by  the vertical component of our space. It's important to remind yourself that this state space is an abstract thing,  and is distinct from the physical space where the pendulum itself lives and moves. Since we're modeling this as losing some of its energy to air resistance,  this trajectory spirals inward, meaning the peak velocity and  peak displacement each go down a bit with each swing. Our point is, in a sense, attracted to the origin, where theta and theta dot both equal 0. With this space, we can visualize a differential equation as a vector field. Here, let me show you what I mean. The pendulum state is a vector, theta, theta dot. Maybe you think of that as an arrow from the origin, or maybe you think of it as a point. What matters is that it has two coordinates, each a function of time. Taking the derivative of that vector gives you its rate of change,  the direction and speed that it will tend to move in this diagram. That derivative is a new vector, theta dot theta double dot,  which we visualize as being attached to the relevant point in space. Take a moment to interpret what this is saying. The first component for this rate of change vector is theta dot,  which is also a coordinate in our space. The higher up we are in the diagram, the more the point tends to move to the right,  and the lower we are, the more it tends to move to the left. The vertical component is theta double dot, which our differential  equation lets us rewrite entirely in terms of theta and theta dot itself. In other words, the first derivative of our state vector is some function of  that vector itself, with most of the intricacy tied up in that second coordinate. Doing the same at all points of this space will show  how that state tends to change from any position. As is typical with vector fields, we artificially scale down the vectors when  we draw them to prevent clutter, but use color to loosely indicate magnitude. Notice we've effectively broken up a single second-order  equation into a system of two first-order equations. You might even give theta dot a different name,  to emphasize that we're really thinking of two separate values,  intertwined via this mutual effect they have on one another's rate of change. This is a common trick in the study of differential equations. Instead of thinking about higher order changes of a single value,  we often prefer to think of the first derivative of vector values. In this form, we have a wonderful visual way to  think about what solving the equation means. As our system evolves from some initial state,  our point in this space will move along some trajectory in such a  way that at every moment, the velocity of that point matches the vector from this field. And again, keep in mind, this velocity is not the same thing as  the physical velocity of the pendulum, it's a more abstract rate of change,  encoding the rates of change for both theta and theta dot. You might find it fun to pause for a moment and think through  what exactly some of these trajectory lines say about the possible  ways the pendulum evolves from different starting conditions. For example, in regions where theta dot is quite high,  the vectors guide the point to travel to the right quite a ways before settling  down into an inward spiral. This corresponds to a pendulum with a high enough initial velocity that it  fully rotates around several times before settling into a decaying back and forth. Having a little more fun? When I tweak this air resistance term, mu, say increasing it,  you can immediately see how this will result in trajectories that spiral inward faster,  which is to say the pendulum slows down faster. That's obvious when I call it the air resistance term,  but imagine that you saw these equations out of context,  not knowing that they described a pendulum. It's not obvious just looking at them that increasing this value of mu  means the system as a whole tends towards some attracting state faster. So getting some software to draw these vector fields for you  can be a great way to build an intuition for how they behave. What's wonderful is that any system of ordinary differential equations can be  described by a vector field like this, so it's a very general way to get a feel for them. Usually, though, they have many more dimensions. For example, consider the famous three-body problem,  which is to predict how three masses in three-dimensional space evolve if  they act on each other with gravity, and if you know their initial positions  and velocities. Each mass has three coordinates describing its position,  and three more describing its momentum. So the system has 18 degrees of freedom in total,  and hence an 18-dimensional space of possible states. It's a bizarre thought, isn't it? A single point meandering through an 18-dimensional space that we cannot visualize,  obediently taking steps through time based on whatever vector it happens to  be sitting on from moment to moment, completely encoding the positions and  the momenta of the three masses we see in ordinary, physical 3D space. In practice, you can reduce the number of dimensions here by taking  advantage of the symmetries of your setup, but the point that more  degrees of freedom results in higher dimensional state spaces remains the same. In math, we often call a space like this a phase space. You'll hear me use that term broadly for spaces encoding all kinds of  states of changing systems, but you should know that in the context of physics,  especially Hamiltonian mechanics, the term is often reserved for a more special case,  namely a space whose axes represent position and momentum. So a physicist would agree that the 18-dimensional space describing the  three-body problem is a phase space, but they might ask that we make a couple  of modifications to our pendulum setup for it to properly deserve the term. For those of you who just watched the block collision video,  the planes we worked with there would be called phase spaces by math folk,  though a physicist might prefer other terminology. Just know that the specific meaning may depend on your context. It may seem like a simple idea, depending on how well indoctrinated you  are to modern ways of thinking about math, but it's worth keeping in mind  that it took humanity quite a while to really embrace thinking of dynamics  spatially like this, especially when the dimensions get very large. In his book Chaos, the author James Glick describes phase space as,  "One of the most powerful inventions of modern science".  One reason its powerful is that you can ask questions,  not just about a single initial condition but about a whole spectrum of initial states.  The collection of all possible trajectories is reminiscent of a moving fluid.  So we call it phase flow. To take one example of why phase flow is a fruitful idea,  consider the question of stability. The origin of our space corresponds to the pendulum standing still,  and so does this point over here, representing when the pendulum is perfectly  balanced upright. These are the so-called fixed points of our system,  and one natural question to ask is whether or not they're stable, that is,  will tiny nudges to the system result in a state that tends back towards that  fixed point, or away from it? Physical intuition for the pendulum makes the answer here kind of obvious,  but how would you think about stability just looking at the equations,  say if they arose in some completely different less intuitive context? We'll go over how to compute the answers to questions like this in following videos,  and the intuition for the relevant computations are guided heavily by  the thought of looking at small regions in space around a fixed point,  and asking whether the flow tends to contract or expand. And speaking of attraction and stability, let's take a brief side-step to talk about love. The Strogatz quote that I mentioned earlier comes from a whimsical column in  the New York Times on the mathematics of modelling affection,  an example well worth pilfering to illustrate that we're not just talking  about physics here. Imagine you've been flirting with someone, but there's been some frustrating  inconsistency to how mutual your affection seems,  and perhaps during a moment when you turn your attention towards physics  to keep your mind off the romantic turmoil, mulling over the broken-up  pendulum equations, you suddenly understand the on-again-off-again dynamics  of your flirtation. You've noticed that your own affection tends to increase when your  companion seems interested in you, but decrease when they seem colder. That is, the rate of change for your love is proportional to their feelings for you. But this sweetheart of yours is precisely the opposite,  strangely attracted to you when you seem uninterested,  but turned off once you seem too keen. The phase space for these equations looks very  similar to the center part of your pendulum diagram. The two of you will go back and forth between affection and repulsion in an endless cycle. A metaphor of pendulum swings in your feelings would not just be apt,  but mathematically verified. In fact, if your partner's feelings were further slowed when they feel  themselves too in love, let's say out of a fear of being made vulnerable,  we'd have a term matching the friction in the pendulum,  and you too would be destined to an inward spiral towards mutual ambivalence. I hear wedding bells already. The point is that two very different-seeming laws of dynamics, one from physics,  involving a single variable, and another from, uh, chemistry, with two variables,  actually have a very similar structure, easier to recognize when you're looking at the  phase diagram. Most notably, even though the equations are different,  for example there's no sine function in the romance equations,  the phase space exposes an underlying similarity nevertheless. In other words, you're not just studying a pendulum right now,  the tactics you develop to study one case have a tendency to transfer to many others. Okay, so phase diagrams are a nice way to build understanding,  but what about actually computing the answer to our equation? One way to do this is to essentially simulate what the universe would do,  but using finite time steps instead of the infinitesimals and limits defining calculus. The basic idea is that if you're at some point in this phase diagram,  take a step based on the vector you're sitting on for a small time step, delta t. Specifically, take a step equal to delta t times that vector. As a reminder, in drawing these vector fields,  the magnitude for each vector has been artificially scaled down to prevent clutter. When you do this repeatedly, your final location will be an approximation of theta t,  where t is the sum of all those time steps. If you think about what's being shown right now, though,  and what that would imply for the pendulum's movement,  you'd probably agree that this is grossly inaccurate. But that's only because the time step delta t of 0.5 is way too big. If we turned it down, say to 0.01, you can get a much more accurate approximation,  it just takes more repeated steps is all. In this case, computing theta of 10 requires 1000 little steps. Luckily, we live in a world with computers, so repeating a simple task 1000  times is as simple as articulating that task with a programming language. In fact, let's finish things off by writing a little  python program that computes theta of t for us. What it has to do is make use of the differential equation,  which returns the second derivative of theta as a function of theta and theta dot. You start off by defining two variables, theta and theta dot,  each in terms of some initial conditions. In this case I'll have theta start at pi thirds,  which is 60 degrees, and theta dot start at 0. Next, write a loop that corresponds to taking many little time steps  between 0 and time t, each of size delta t, which I'm setting here to be 0.01. In each step of this loop, increase theta by theta dot times delta t,  and increase theta dot by theta double dot times delta t,  where theta double dot can be computed based on the differential equation. After all these little time steps, simply return the value of theta. This is called solving a differential equation numerically. Numerical methods can get way more sophisticated and intricate than this to better  balance the tradeoff between accuracy and efficiency, but this loop gives the basic idea. So even though it sucks that we can't always find exact solutions,  there are still meaningful ways to study differential equations in the face of  this inability. In the following videos, we'll look at several methods for finding exact  solutions when it's possible, but one theme I'd like to focus on is how these  exact solutions can also help us to study the more general, unsolvable cases. But it gets worse. Just as there's a limit to how far exact analytic solutions can get us,  one of the great fields to have emerged in the last century, chaos theory,  has exposed that there are further limits on how well we can use these systems for  prediction with or without solutions. Specifically, we know that for some systems, small variations to the initial conditions,  say the kind due to necessarily imperfect measurements,  result in wildly different trajectories. We've even built some good understanding for why this happens. The three-body problem, for example, is known to have seeds of chaos within it. So looking back at the quote from earlier, it seems almost cruel of the  universe to fill its language with riddles that we either can't solve,  or where we know that any solution would be useless for long-term prediction anyway. It is cruel, but then again it should also be reassuring. It gives some hope that the complexity we see in the world around us can be studied  somewhere in this math, and that it's not hidden away in the mismatch between model and  reality.

================================================================================
VIDEO ID: jBsC34PxzoM
TITLE: Cramer's rule, explained geometrically | Chapter 12, Essence of linear algebra
URL: https://www.youtube.com/watch?v=jBsC34PxzoM
PUBLISHED: 2019-03-17T04:35:22Z
STATUS: SUCCESS
================================================================================
In a previous video I've talked about linear systems of equations,  and I sort of brushed aside the discussion of actually computing solutions to  these systems. And while it's true that number crunching is typically something we  leave to the computers, digging into some of these computational  methods is a good litmus test for whether or not you actually understand what's going on,  since that's really where the rubber meets the road. Here I want to describe the geometry behind a certain method  for computing solutions to these systems, known as Cramer's rule. The relevant background here is understanding determinants,  a little bit of dot products, and of course linear systems of equations,  so be sure to watch the relevant videos on those topics if you're unfamiliar or rusty. But first I should say up front that this Cramer's rule is not  actually the best way for computing solutions to linear systems of equations,  Gaussian elimination for example will always be faster. So why learn it? Well think of it as a sort of cultural excursion. It's a helpful exercise in deepening your knowledge of the theory behind these systems. Wrapping your mind around this concept is going to help consolidate ideas from linear  algebra, like the determinant and linear systems, by seeing how they relate to each other. Also from a purely artistic standpoint the ultimate result here is just  really pretty to think about, way more so than Gaussian elimination. Alright so the setup here will be some linear system of equations,  say with two unknowns x and y and two equations. In principle everything we're talking about will also work for systems  with larger number of unknowns and the same number of equations,  but for simplicity a smaller example is just nicer to hold in our heads. So as I talked about in a previous video you can think of this setup  geometrically as a certain known matrix transforming an unknown vector x y  where you know what the output is going to be, in this case negative 4 negative 2. Remember the columns of this matrix are telling you how that matrix acts as a transform,  each one telling you where the basis vectors of the input space land. So what we have is a sort of puzzle, which input vector  x y is going to land on this output negative 4 negative 2. One way to think about our little puzzle here is that we know the given  output vector is some linear combination of the columns of the matrix x  times the vector where i hat lands plus y times the vector where j hat lands,  but what we want is to figure out what exactly that linear combination should be. Remember the type of answer you get here can depend on whether or not the transformation  squishes all of space into a lower dimension, that is if it has a zero determinant. In that case either none of the inputs land on our given output,  or there's a whole bunch of inputs landing on that output. But for this video we'll limit our view to the case of a non-zero determinant,  meaning the outputs of this transformation still span the  full in-dimensional space that it started in. Every input lands on one and only one output, and every output has one and only one input. As a first pass let me show you an idea that's wrong but in the right direction. The x coordinate of this mystery input vector is what you  get by taking its dot product with the first basis vector 1 0. Likewise the y coordinate is what you get by dotting it with the second basis vector 0 1. So maybe you hope that after the transformation the dot products with  the transformed version of the mystery vector with the transformed  version of the basis vectors will also be these coordinates x and y. That'd be fantastic because we know what the transformed  version of each of those vectors are. There's just one problem with it, it's not at all true. For most linear transformations the dot product before  and after the transformation will look very different. For example, you could have two vectors generally pointing in the same direction  with a positive dot product, which get pulled apart from each other during the  transformation in such a way that they end up having a negative dot product. Likewise things that start off perpendicular with dot product 0,  like the two basis vectors, quite often don't stay perpendicular to each  other after the transformation, that is they don't preserve that 0 dot product. And looking at the example I just showed dot products certainly aren't preserved,  they tend to get bigger since most vectors are getting stretched out. In fact, worthwhile side note here, transformations which do preserve dot  products are special enough to have their own name, orthonormal transformations. These are the ones that leave all of the basis vectors  perpendicular to each other and still with unit lengths. You often think of these as the rotation matrices,  they correspond to rigid motion with no stretching or squishing or morphing. Solving a linear system with an orthonormal matrix is actually super easy. Because dot products are preserved, taking the dot product between the  output vector and all the columns of your matrix will be the same as taking  the dot product between the mystery input vector and all of the basis vectors,  which is the same as just finding the coordinates of that mystery input. So in that very special case, x would be the dot product of the first column with the  output vector, and y would be the dot product of the second column with the output vector. Why am I bringing this up when this idea breaks down for almost all linear systems? Well, it points us in a direction of something to look for. Is there an alternate geometric understanding for the coordinates  of our input vector that remains unchanged after the transformation? If your mind has been mulling over determinants,  you might think of the following clever idea. Take the parallelogram defined by the first basis  vector i-hat and the mystery input vector xy. The area of this parallelogram is the base, 1,  times the height perpendicular to that base, which is the y-coordinate  of that input vector. So the area of that parallelogram is a sort of screwy  roundabout way to describe the vector's y-coordinate. It's a wacky way to talk about coordinates, but run with me. And actually, to be a little more accurate, you should think of this as the  signed area of that parallelogram, in the sense described in the determinant video. That way, a vector with a negative y-coordinate would correspond to a  negative area for this parallelogram, at least if you think of i-hat as in  some sense being the first out of these two vectors defining the parallelogram. And symmetrically, if you look at the parallelogram spanned  by our mystery input vector and the second basis, j-hat,  its area is going to be the x-coordinate of that mystery vector. Again, it's a strange way to represent the x-coordinate,  but see what it buys us in a moment. And just to make sure it's clear how this might generalize,  let's look in three dimensions. Ordinarily, the way you might think about one of a vector's coordinates,  say its z-coordinate, would be to take its dot product with  the third standard basis vector, often called k-hat. But an alternate geometric interpretation would be to consider the  parallelepiped that it creates with the other two basis vectors, i-hat and j-hat. If you think of the square with area 1 spanned by i-hat and  j-hat as the base of this whole shape, then its volume is the same as its height,  which is the third coordinate of our vector. And likewise, the wacky way to think about the other coordinates of the vector  would be to form a parallelepiped using the vector and then all of the basis  vectors other than the one corresponding to the direction you're looking for. Then the volume of this gives you the coordinate. Or rather, we should be talking about the signed volume of parallelepiped  in the sense described in the determinant video using the right-hand rule. So the order in which you list these three vectors matters. That way, negative coordinates still make sense. Okay, so why think of coordinates as areas and volumes like this? Well, as you apply some sort of matrix transformation, the areas of these parallelograms,  well, they don't stay the same, they might get scaled up or down. But, and this is the key idea of determinants,  all of the areas get scaled by the same amount,  namely the determinant of our transformation matrix. For example, if you look at the parallelogram spanned by the vector  where your first basis vector lands, which is the first column of the matrix,  and the transformed version of xy, what is its area? Well, this is the transformed version of the parallelogram we were looking at earlier,  the one whose area was the y-coordinate of the mystery input vector. So its area is just going to be the determinant of  the transformation multiplied by that y-coordinate. So that means we can solve for y by taking the area of this new parallelogram  in the output space divided by the determinant of the full transformation. And how do you get that area? Well, we know the coordinates for where the mystery input vector lands,  that's the whole point of a linear system of equations. So what you might do is create a new matrix whose first column is the same as that of our  matrix, but whose second column is the output vector, and then you take its determinant. So look at that, just using data from the output of the transformation,  namely the columns of the matrix and the coordinates of our output vector,  we can recover the y-coordinate of the mystery input vector,  which is halfway to solving the system. Likewise, the same idea can give us the x-coordinate. Look at the parallelogram we defined earlier, which encodes the  x-coordinate of the mystery input vector spanned by that vector and j-hat. The transformed version of this guy is spanned by the output vector and the second column  of the matrix, and its area will have been multiplied by the determinant of that matrix. So to solve for x, you can take this new area  divided by the determinant of the full transformation. And similar to what we did before, you can compute the area of that  output parallelogram by creating a new matrix whose first column is the  output vector and whose second column is the same as the original matrix. So again, just using data from the output space,  the numbers we see in our original linear system, we can solve for what x must be. This formula for finding the solutions to a linear  system of equations is known as Cramer's rule. Here, just to sanity check ourselves, plug in some numbers here. The determinant of that top altered matrix is 4 plus 2, which is 6,  and the bottom determinant is 2, so the x-coordinate should be 3. And indeed, looking back at the input vector we started with, the x-coordinate is 3. Likewise, Cramer's rule suggests that the y-coordinate should be 4 divided by 2,  or 2, and that is in fact the y-coordinate of the input vector we were starting with. The case with three dimensions or more is similar,  and I highly recommend you take a moment to pause and think through it yourself. Here, I'll give you a little bit of momentum. What we have is a known transformation given by some 3x3 matrix  and a known output vector given by the right side of our linear system,  and we want to know what input lands on that output. And if you think of, say, the z-coordinate of that input vector as the volume of  that special parallelepiped we were looking at earlier, spanned by i-hat, j-hat,  and the mystery input vector, what happens to that volume after the transformation? And what are the various ways you can compute that volume? Really, pause and take a moment to think through the details  of generalizing this to higher dimensions, finding an expression  for each coordinate of the solution to a larger linear system. Thinking through more general cases like this and convincing yourself that it  works and why it works is where all the learning really happens,  much more so than listening to some dude on YouTube walk you through the same  reasoning again.

================================================================================
VIDEO ID: brU5yLm9DZM
TITLE: How colliding blocks act like a beam of light...to compute pi.
URL: https://www.youtube.com/watch?v=brU5yLm9DZM
PUBLISHED: 2019-02-03T16:23:07Z
STATUS: SUCCESS
================================================================================
You know that feeling you get when you have two mirrors facing each other, and it gives the illusion of there being an infinite tunnel of rooms. Or, if they're at an angle with each other, it makes you feel like you're a part of a strange kaleidoscopic world with many copies of yourself, all separated by angled pieces of glass. What many people may not realize is that the idea underlying these illusions can be surprisingly helpful for solving serious problems in math. We've already seen two videos describing the block-collision puzzle, with its wonderfully surprising answer. Big block comes in from the right, lots of clacks, the total number of clacks looks like pi, and we want to know why. Here, we see one more perspective explaining what's going on, where if the connection to pi wasn't surprising enough, we add one more unexpected connection to optics. But we're doing more than just answering the same question twice. This alternate solution gives a much richer understanding of the whole setup, and it makes it easier to answer other questions. And fun side note, it happens to be core to how I coded the accurate simulations of these blocks without requiring absurdly small time steps and huge computation time. The solution from the last video involved a coordinate plane, where each point encodes a pair of velocities. Here, we'll do something similar, but the points of our plane are going to encode the pair of positions of both blocks. Again, the idea is that by representing the state of a changing system with individual points in some space, problems in dynamics turn into problems in geometry, which hopefully are more solvable. Specifically, let the x-coordinate of a 2D plane represent the distance from the wall to the left edge of the first block, what I'll call d1, and let the y-coordinate represent the distance from the wall to the right edge of the second block, what we'll call d2. That way, the line y equals x shows us where the two blocks clack into each other, since this happens whenever d1 is equal to d2. Here's what it looks like for our scenario to play out. As the two distances of our blocks change, the two dimensional points of our configuration space move around, with positions that always fully encode the information of those two distances. You may notice that at the bottom there, it's bounded by a line, where d2 is the same as the small block's width, which, if you think about it, is what it means for the small block to hit the wall. You may be able to guess where we're going with this. The way this point bounces between the two bounding lines is a bit like a beam of light bouncing between two mirrors. The analogy doesn't quite work, though. In the lingo of optics, the angle of incidence doesn't equal the angle of reflection. Just think of the first collision. A beam of light coming in from the right would bounce off a 45 degree angled mirror, this x equals y line, in such a way that it ends up going straight down, which would mean that only the second block is moving. This does happen in the simplest case, where the second block has the same mass as the first, and picks up all of its momentum like a croquet ball. But in the general case, for other mass ratios, that first block keeps much of its momentum, so the trajectory of our point in this configuration space won't be pointed straight down, it'll be down and to the left a bit. And even if it's not immediately clear why this analogy with light would actually be helpful, and trust me, it will be helpful in many ways, run with me here and see if we can fix this for the general case. Seeking analogies in math is very often a good idea. As with the last video, it's helpful to rescale the coordinates. In fact, motivated by precisely what we did then, you might think to rescale the coordinates so that x is not equal to d1, but is equal to the square root of the first mass, m1, times d1. This has the effect of stretching our space horizontally, so changes in our big block's position now result in larger changes to the x-coordinate itself. And likewise, let's write the y-coordinate as square root of m2 times d2, even though in this particular case the second mass is 1, so it doesn't make a difference, but let's keep things symmetric. Maybe this strikes you as making things uglier, and kind of a random thing to do, but as with last time, when we include square roots of masses like this, everything plays more nicely with the laws of conserving energy and momentum. Specifically, the conservation of energy will translate into the fact that our little point in the space is always moving at the same speed, which in our analogy you might think of meaning there's a constant speed of light, and the conservation of momentum will translate to the fact that as our point bounces off the mirrors of our setup, so to speak, the angle of incidence equals the angle of reflection. Doesn't that seem bizarre in kind of a delightful way, that the laws of kinematics should translate to laws of optics like this? To see why it's true, let's roll up our sleeves and work out the actual math. Focus on the velocity vector of our point in the diagram. It shows which direction it's moving and how quickly. Now keep in mind, this is not a physical velocity, like the velocities of the moving blocks. Instead, it's a more abstract rate of change in the context of this configuration space, whose two dimensions worth of possible directions encode both velocities of the block. The x component of this little vector is the rate of change of x, and likewise its y component is the rate of change of y. What is the rate of change for the x-coordinate? x is the square root of m1 times d1, and the mass doesn't change, so it depends only on how d1 changes. What's the rate at which d1 changes? Well, that's the velocity of the big block. Let's call that v1. Likewise, the rate of change for y is going to be the square root of m2 times v2. Now, notice what the magnitude of our little configuration space changing vector is. Using the Pythagorean theorem, it's the square root of the sum of each of these component rates of change squared, which is square root of m1 times v1 squared plus m2 times v2 squared. This inner expression should look awfully familiar, it's exactly twice the kinetic energy of our system. So the speed of our point in the configuration space is some function of the total energy, and that stays constant throughout the whole process. Remember, a core over-idealizing assumption to this is that there's no energy lost to friction or to any of the collisions. All right, so that's pretty cool. With these rescaled coordinates, our little point is always moving with a constant speed. And I know it's not obvious why you would care, but among other things, it's important for the next step, where the conservation of momentum implies that these two bounding lines act like mirrors. First, let's understand this line d1 equals d2 a little bit better. In our new coordinates, it's no longer that nice 45 degree x equals y line. Instead, if we do a little algebraic manipulation here, we can see that that line is x over square root m1 equals y over square root m2. Rearranging a little bit more, we see that's a line with a slope of square root m2 over m1. That's a nice expression to tuck away in the back of your mind. After the blocks collide, meaning our point hits this line, the way to figure out how they move is to use the conservation of momentum, which says that the value m1 times v1 plus m2 times v2 is the same both before and after the collision. Now notice, this looks like a dot product between two column vectors, m1m2 and v1v2. Rewriting it slightly for our rescaled coordinates, the same thing could be written as a dot product between a column vector with the square roots of the masses, and one with the rates of change for x and y. I know this probably seems like a complicated way to talk about a comparatively simple momentum equation, but there is a good reason for shifting the language to one of dot products in our new coordinates. Notice that second vector is simply the rate of change vector for the point in our diagram that we've been looking at. The key now is that this square root of the masses vector points in the same direction as our collision line, since the rise over run is square root m2 over square root of m1. Now if you're unfamiliar with the dot product, there is another video on this channel describing it, but real quick let's go over what it means geometrically. The dot product of two vectors equals the length of the first one multiplied by the length of the projection of the second one onto that first, where it's considered negative if they point in opposite directions. You often see this written as the product of the lengths of the two vectors, and the cosine of the angle between them. So look back at this conservation of momentum expression, telling us that the dot product between this square root of the masses vector and our little change vector has to be the same, both before and after the collision. Since we just saw that this change vector has a constant magnitude, the only way for this dot product to stay the same is if the angle that it makes with the collision line stays the same. In other words, again using the lingo of optics, the angle of incidence and the angle of reflection off this collision line must be equal. Similarly, when the small block bounces off the wall, our little vector gets reflected about the x direction, since only its y coordinate changes. So our configuration point is bouncing off that horizontal line as if it was a mirror. So step back a moment and think about what this means for our original question of counting block collisions and trying to understand why on earth pi would show up. We can translate it to a completely different question. If you shine a beam of light at a pair of mirrors, meeting each other at some angle, let's say theta, how many times would that light bounce off of the mirrors as a function of that angle? Remember, the mass ratio of our blocks completely determines this angle theta in the analogy. Now I can hear some of you complaining, haven't we just replaced one tricky setup with another? This might make for a cute analogy, but how is it progress? It's true that counting the number of light bounces is hard, but now we have a helpful trick. When the beam of light hits the mirror, instead of thinking of that beam as reflected about the mirror, think of the beam as going straight, while the whole world gets flipped through the mirror. It's as if the beam is passing through a piece of glass into an illusory looking glass universe. Think of actual mirrors here. This wire on the left will represent a laser beam coming into the mirror, and the one on the right will represent its reflection. The illusion is that the beam goes straight through the mirror, as if passing through a window separating us from another room. But notice, crucially, for this illusion to work, the angle of incidence has to equal the angle of reflection. Otherwise, the flipped copy of the reflected beam won't line up with the first part. So all of that work we did, rescaling coordinates and futzing through the momentum equations, was certainly necessary. But now we get to enjoy the fruits of our labor. Watch how this helps us elegantly solve the question of how many mirror bounces there will be, which is also the question of how many block collisions there will be. Every time the beam hits a mirror, don't think of the beam as getting reflected, let it continue straight while the world gets reflected. As this goes on, the illusion to the beam of light is that instead of getting bounced around between two angled mirrors many times, it's passing through a sequence of angled pieces of glass all the same angle apart. Right now I'm showing you all of the reflected copies of the bouncing trajectory, which I think has a very striking beauty to it. But for a clearer view, let's just focus on the original bouncing beam and the illusory straight one. The question of counting bounces turns into a question of how many pieces of glass this illusory beam crosses. How many reflected copies of the world does it pass into? Well, calling the angle between the mirrors theta, the answer here is however many times you can add theta to itself before you get more than halfway around a circle, which is to say before you add up to more than pi total radians. Written as a formula, the answer to this question is the floor of pi divided by theta. So let's review. We started by drawing a configuration space for our colliding blocks where the x and the y coordinates represented the two distances from the wall. This kind of looked like light bouncing between two mirrors, but to make the analogy work properly we needed to rescale the coordinates by the square roots of the masses. This made it so that the slope of one of our lines was square root of m2 divided by square root of m1, so the angle between those bounding lines will be the inverse tangent of that slope. To figure out how many bounces there are between two mirrors like this, think of the illusion of the beam going straight through a sequence of looking glass universes separated by a semi-circular fan of windows. The answer then comes down to how many times the value of this angle fits into 180 degrees, which is pi radians. From here, to understand why exactly the digits of pi show up when the mass ratio is a power of 100, is exactly what we did in the last video, so I won't repeat myself here. And finally, as we reflect now on how absurd the initial appearance of pi seemed, and on the two solutions we've now seen, and on how unexpectedly helpful it can be to represent the state of your system with points in some space, I leave you with this quote from the computer scientist Alan Kay, A change in perspective is worth 80 IQ points.

================================================================================
VIDEO ID: HEfHFsfGXjs
TITLE: The most unexpected answer to a counting puzzle
URL: https://www.youtube.com/watch?v=HEfHFsfGXjs
PUBLISHED: 2019-01-13T16:12:47Z
STATUS: SUCCESS
================================================================================
Sometimes, math and physics conspire in ways that just feel too good to be true. Let's play a strange sort of mathematical croquet. We're going to have two sliding blocks and a wall. The first block starts by coming in at some velocity from the right,  while the second one starts out stationary. Being overly idealistic physicists, let's assume there's no friction and  all of the collisions are perfectly elastic, which means no energy is lost. The astute among you might complain that such collisions would make no sound,  but your goal here is to count how many collisions take place,  so in slight conflict with that assumption I want to leave a little clack sound to better  draw your attention to that count. The simplest case is when both blocks have the same mass. The first block hits the second, transferring all of its momentum,  then the second one bounces off the wall, and then transfers all of  its momentum back to the first, which then sails off towards infinity. Three total clacks. What about if the first block was 100 times the mass of the second one? I promise I will explain to you all the relevant physics in due course,  it's not entirely obvious how you would predict the dynamics here,  but in the spirit of getting to the punchline, let's watch what happens. The second one will keep bouncing back and forth between the wall and the first block,  100 times its mass, like a satisfying game of Breakout,  slowly and discreetly redirecting that first block's momentum to point in the  opposite direction. In total, there will be 31 collisions before each block is sliding off towards infinity,  never to be touched again. What if the first block was 10,000 times the mass of the second one? In that case, there would be quite a few more clacks,  all happening very rapidly at one point, adding up and all to 313 total collisions. Well, actually, hang on. Wait for it. Wait for it. Okay, 314 clacks. If the first block was 1,000,000 times the mass of the other, then again,  with all of our crazy idealistic conditions, almost all of the clacks  happen in one big burst, this time resulting in a total of 3,141 collisions. Perhaps you see the pattern here, though it's forgivable if you don't,  since it defies all expectation. When the mass of that first block is some power of 100 times the mass of the second,  the total number of collisions have the same digits as pi. This absolutely blew my mind when it was first shared with me. Credit to the viewer Henry Cavill for introducing me to this fact,  which was originally discovered by the mathematician Gregory Galperin in 1995 and  published in 2003. Part of what I love about this is that if ever there were Olympic games  for algorithms that compute pi, this one would have to win medals both  for being the most elegant, and for being the most comically inefficient. I mean, think about the actual algorithm here. Step 1, implement a physics engine. Step 2, choose the number of digits d of pi you'd like to compute. Step 3, set the mass of one of the blocks to be 100 to the power d-1,  then send it travelling on a frictionless surface towards a block of mass 1. Step 4, count all of the collisions. For example, to calculate only 20 digits of pi, which fits so cleanly on this screen,  one block would have to have 100 billion billion billion billion times the mass of  the other, which if that small block was 1 kilogram,  means the big one has a mass about 10 times that of the supermassive black hole at  the center of the Milky Way. That means you would need to count 31 billion billion collisions. At one point in this virtual process, the frequency of clacks would  be around 100 billion billion billion billion clacks per second. So let's just say you would need very good numerical precision to get this working  accurately, and it would take a very long time for the algorithm to complete. I'll emphasize again that this process is way over-idealized,  quickly departing from anything that could possibly happen in real physics. But of course, you all know this is not interesting because of its potential  as an actual pi computing algorithm or as a pragmatic physics demonstration. It's mind-boggling because why on earth would pi show up here? And it's in such a weird way too. Its decimal digits are counting something, but usually pi shows  up when its precise value is describing something continuous. I will show you why this is true. Where there is pi, there is a hidden circle, and in this case,  that hidden circle comes from the conservation of energy. In fact, you're going to see two separate methods,  which are each as stunning and surprising as the fact itself. Delaying gratification though, I will make you  wait until the next video to see what's going on. In the meantime, I highly encourage you to take a stab at it yourself,  and be social about it. It's a hard puzzle, so it never hurts to recruit some other smart minds to the task. Thanks for watching. I'll see you next time. Bye.

================================================================================
VIDEO ID: GNcFjFmqEc8
TITLE: But why is a sphere's surface area four times its shadow?
URL: https://www.youtube.com/watch?v=GNcFjFmqEc8
PUBLISHED: 2018-12-02T20:08:11Z
STATUS: SUCCESS
================================================================================
Some of you may have seen in school that the surface area of a sphere is 4 pi R squared, a suspiciously suggestive formula given that it's a clean multiple of the more popular pi R squared, the area of a circle with the same radius. But have you ever wondered why this is true? And I don't just mean proving the 4 pi R squared formula, I mean viscerally feeling to your bones a connection between this surface area and these four circles. How lovely would it be if there were some subtle shift in perspective that shows how you could nicely and perfectly fit these four circles onto the sphere's surface? Nothing can be quite that simple since the curvature of a sphere's surface is different from the curvature of a flat plane, which is why trying to fit, say, a piece of paper around the sphere just doesn't work. Nevertheless, I would like to show you two separate ways of thinking about the surface area that connect it in a satisfying way to these circles. The first comes from a classic, one of the true gems of geometry that I think all math students should experience the same way all English students should read at least some Shakespeare. The second line of reasoning is something of my own, which draws a more direct line between the sphere and its shadow. And lastly, I'll share why this fourfold relation is not unique to spheres, but is instead one specific instance of a much more general fact for all convex shapes in three dimensions. Starting with the bird's eye view here, the idea for the first approach is to show that the surface area of the sphere is the same as the area of a cylinder with the same radius and the same height as that sphere, or rather, a cylinder without the top and bottom, what you might call the label of that cylinder. And once you have that, you can unwrap that label to understand it simply as a rectangle. The width of this rectangle comes from the cylinder's circumference, so it's 2 pi times R, and the height comes from the height of the sphere, which is 2 times the radius. And this already gives us the formula, 4 pi R squared when we multiply the two. But in the spirit of mathematical playfulness, it's nice to see how four circles with radius R can actually fit into this picture. The idea will be to unwrap each circle into a triangle without changing its area, and then to fit those nicely into the unfolded cylinder label. More on that in a couple minutes. The more pressing question is, why on earth should the sphere be related to the cylinder in this way? The way I'm animating it is already suggestive of how this might work. The idea is to approximate the area of the sphere with many tiny rectangles covering it, and to show how if you project these rectangles directly outward, as if casting a shadow by little lights positioned on the z-axis, pointing parallel to the xy-plane, the projection of each rectangle onto the cylinder, surprisingly, ends up having the same area as the original rectangle. But why should that be? There are two competing effects at play here. For one of these rectangles, let's call the side along the latitude lines its width, and the side along the longitude lines its height. On the one hand, as the rectangle is projected outward, its width will get scaled up. For rectangles towards the poles, that length is scaled up quite a bit, since they're projected over a longer distance. But for those closer to the equator, the effect might be close to nothing. But on the other hand, because these rectangles are at a slant with respect to the z-direction, during this projection, the height of each rectangle will get scaled down. Think about holding some flat object and looking at its shadow. As you reorient that object, the shadow looks more or less squished for some angles. Take a look, those rectangles towards the poles are quite slanted this way, so their height will get squished down by a lot. For those closer to the equator, oriented somewhere closer to parallel to the z-axis, the effect is not as much. It will turn out that these two effects of stretching the width and squishing the height cancel each other out perfectly. Already, as a rough sketch, wouldn't you agree that this is a very pretty way of reasoning? Of course, the meat here comes from showing why these two competing effects cancel each other out, and in some ways the details fleshing this out are just as pretty as the zoomed out structure of the full argument. So let's dig in. Let me go ahead and cut away half of the sphere so that we can get a better look. For any mathematical problem solving, it never hurts to start by giving things names. So let's say that the radius of the sphere is r, and for one specific rectangle, let's call the distance between that rectangle and the z-axis d. You could rightfully complain that the distance d is a little ambiguous, depending on which point of that rectangle you're going from. But for tinier and tinier rectangles, that ambiguity will become negligible, and tinier and tinier is when this approximation with rectangles gets closer to the true surface area anyway. To choose an arbitrary standard, let's say that d is the distance from the bottom of the rectangle. To think about projecting this out to the cylinder, we'll picture two similar triangles. The first one shares its base with the base of the rectangle on the sphere, and has a tip at the same height but on the z-axis, a distance d away. The second triangle is a scaled-up version of this, scaled so that it just barely reaches the cylinder, meaning its long side now has a length R. So the ratio of their bases, which is how much our rectangle's width gets stretched out, is R divided by d. What about the height? How precisely does that get scaled down as we project? Again, let's slice a cross-section for a cleaner view. In fact, why don't we go ahead and completely focus our view to this two-dimensional cross-section. To think about the projection, let's make a little right triangle, like this, where what was the height of our spherical rectangle is the hypotenuse, and the projection is one of the legs. Pro tip, any time you're doing geometry with circles or spheres, keep in the forefront of your mind that anything tangent to the circle is perpendicular to the radius drawn to that point of tangency. It's crazy just how helpful that one little fact can be for making progress. In our case, once we draw that radial line, together with the distance d, we have another right triangle. And often in geometry, I like to imagine tweaking the parameters of a setup and imagining how the relevant shapes change. This helps to make guesses about what the relations might be. In this case, you might predict that the two triangles I've drawn are similar to each other, since their shapes seem to change in concert with each other. This is indeed true, but as always, don't take my word for it. See if you can justify this for yourself. Again, it never hurts to give more names to things. Maybe let's call this angle alpha, and this other one beta. Since this is a right triangle, we know that alpha plus beta plus 90 degrees must be 180 degrees. Now let's zoom in on our little triangle and see if we can figure out what its angles might be. Notice this 90 degree angle, which comes from the radius being perpendicular to the tangent, and how when it's combined with this beta here and some other little angle, it forms a straight line. So that other little angle must be alpha. This lets us fill out a few more values, which reveals that this little triangle also has angles alpha, beta, and 90 degrees, so it is indeed similar to the big one. Deep in the weeds like this, it's sometimes easy to forget why we're doing this. Remember, what we want to know is how much the height of the sphere rectangle gets squished down as we project it out, and that's the ratio of this little hypotenuse to the leg on the right side. By the similarity with the big triangle, the ratio of those two sides is again R divided by d. So indeed, as this rectangle gets projected outward, the effect of stretching out the width is perfectly cancelled out by how much that height is getting squished due to the slant. As a fun side note, you might notice that it looks like the projected rectangle is a 90 degree rotation of the original. This would not at all be true in general, but by a lovely coincidence, the way I'm parameterizing the sphere results in rectangles where the ratio of the width to the height starts out as d to r. So for this very specific case, rescaling the width by r over d, and rescaling the height by d over r, actually does have the effect of a 90 degree rotation. And this lends itself to a rather bizarre way to animate the relation, where instead of projecting each rectangular piece as if casting a shadow, you can rotate each one of them 90 degrees, and rearrange them all to make the cylinder. Now if you're really thinking critically, you might still not be satisfied that this shows us what the surface area of the sphere is, because all of these little rectangles only approximate the relevant areas. Well, the idea is that this approximation gets closer and closer to the true value for finer and finer coverings. And since for any specific covering, the sphere rectangles have the same area as the cylinder rectangles, whatever value each of these two series of approximations are approaching must actually be the same. I mean, as you get really aggressively philosophical about what we even mean by surface area, these sorts of rectangular approximations are not just aids in our problem-solving toolbox, they end up serving as a way to rigorously define the idea of area in the context of smooth curved surfaces. This kind of reasoning is essentially calculus, just without any of the jargon. In fact, I think neat geometric arguments like this, which require no background in calculus to understand, can serve as a great way to tee things up for new calculus students, so that they have the core ideas already in their head before seeing the definitions which make them precise, rather than going the other way around. Alright, so as I said before, if you're the kind of person who's just itching to see a direct connection to these four circles, one nice way to do that is to unwrap those circles into triangles. If this is something you haven't seen before, I go into much more detail about why this works in the first video of the calculus series. The basic idea is to relate thin concentric rings of the circle with horizontal slices of this triangle. Because the circumference of each such ring increases linearly in proportion to the radius, always 2 pi times that radius, when you unwrap them all and line them up like this, their ends will form a straight line, as opposed to some other curved shape, which gives us a triangle with base 2 pi r, and height r. And four of these unwrapped circles fit perfectly into our rectangle, which is in some sense an unwrapped version of the sphere's surface. Now that's pretty satisfying, but you might nevertheless be wondering if there's some way to relate this sphere directly to a circle with the same radius, rather than going through this intermediary of a cylinder. I do have proof for you to this effect, leveraging a little trigonometry, though I have to admit I still think the comparison to the cylinder wins out on raw elegance. Now I'm a big believer that the best way to really learn math is to do problems for yourself, which is a bit hypocritical coming from a channel essentially consisting of lectures, so I'm going to try something a little different here, and present the proof as a heavily-guided sequence of exercises. Yes, I know that's less fun, and it means you have to pull out some paper to do a little work, but I guarantee you will get more out of it this way. At a high level, the approach will be to cut the sphere into many thin rings parallel to the xy-plane, and compare the area of these rings to the area of their shadows on the xy-plane. All of the shadows of the rings from, say, the northern hemisphere, make up a circle with the same radius as the sphere, right? The main idea will be to show a correspondence between these ring shadows and every second ring on the sphere. Challenge mode here is to pause now and see if you can predict how that comparison might go. Let's label each one of these rings based on the angle theta between a line from the sphere's center to that ring, and the z-axis. So theta ranges from 0 at the north pole all the way up to 180 degrees at the south pole, which is to say from 0 to pi radians. And let's call the change in the angle from one ring to the next d-theta, which means the thickness of those rings will be the radius R times d-theta. All right, structured exercise time. We'll ease in with a warm-up. Question number one, what is the circumference of this ring, say, at the inner edge, in terms of R and theta? Once you have that, go ahead and multiply the answer by the thickness, R times d-theta, to get an approximation for the ring's area, an approximation that will get better and better as you chop up the sphere more and more finely. At this point, if you know your calculus, you could integrate, but our goal is not just to find the answer, it's to feel the connection between the sphere and its shadow. So question number two, what is the area of the shadow of one of these rings on the x-y plane, again expressed in terms of R, theta, and d-theta? For this one, it might be helpful to think back to that tiny little right triangle we were talking about earlier. Question number three, and this is really the heart of it, each one of these rings' shadows has precisely half the area of one of the rings on the sphere. It's not the one that's an angle theta straight above it, but another one. The question is, which one? As a hint, you might want to reference some trig identities for this one. Question number four, I said at the outset that there's a correspondence between all of the shadows from the northern hemisphere, which make up a circle with radius R, and every second ring on the sphere. Use your answer to the last question to spell out what exactly that correspondence is. And for question five, bring it on home. Why does this imply that the area of the circle is exactly one-fourth the surface area of the sphere, particularly as we consider thinner and thinner rings? If you want answers or hints, I'm quite sure that people in comments and on Reddit will have them waiting for you. And finally, I would be remiss not to make at least a brief mention of the fact that the surface area of a sphere is a very specific instance of a much more general fact. If you take any convex shape and look at the average area of all of its shadows, averaged over all possible orientations in 3D space, that average will be exactly one-fourth the surface area of your shape. As to why this is true, I'll have to leave those details for another day. Thanks for watching!

================================================================================
VIDEO ID: yuVqxCSsE7c
TITLE: Using topology for discrete problems | The Borsuk-Ulam theorem and stolen necklaces
URL: https://www.youtube.com/watch?v=yuVqxCSsE7c
PUBLISHED: 2018-11-18T14:09:20Z
STATUS: SUCCESS
================================================================================
You know that feeling you get when things that seem  completely unrelated turn out to have a key connection? In math especially, there's a certain tingly sensation I get  whenever one of those connections starts to fall into place. This is what I have in store for you today. It takes some time to set up, I have to introduce a fair division puzzle from  discrete math called the stolen necklace problem,  as well as a topological fact about spheres that we'll use to solve it,  called the Borsuk-Ulam theorem. But trust me, seeing these two seemingly disconnected  pieces of math come together is well worth the setup. Let's start with the puzzle we're going to solve. You and your friend steal a necklace full of a bunch of jewels,  maybe it's got some sapphires, emeralds, diamonds, and rubies. They're all arranged on the necklace in some random order. And let's say it happens to be an even number of each type of jewel. Here I have 8 sapphires, 10 emeralds, 4 diamonds, and 6 rubies. You and your friend want to split up the booty evenly,  with each of you getting half of each jewel type, that is 4 sapphires, 5 emeralds,  2 diamonds, and 3 rubies each. Of course you could just cut off all the jewels and divvy them up evenly,  but that's boring, there's not a puzzle there. Instead, the challenge is for you to make as few cuts to the necklace as  possible so that you can divvy up the resulting segments between you and  your co-conspirator, with each of you getting half of each jewel type. For example, for the arrangement I'm showing here, I just did it with 4 cuts. If I give the top 3 strands to you, and these bottom 2 strands to your co-conspirator,  each of you ends up with 4 sapphires, 5 emeralds, 2 diamonds, and 3 rubies. The claim, the thing I want to prove in this video,  is that if there are N different jewel types, it's always possible to do this fair  division with only N cuts, or fewer. So with 4 jewel types, no matter what random ordering of the jewels,  it should be possible to cut it in 4 places and divvy up the 5 necklace  pieces so that each thief has the same number of each jewel type. With 5 jewel types you should be able to do it with 5 cuts,  no matter the arrangement, and so on. It's kind of hard to think about, right? You need to keep track of all of these different jewel types,  ensuring they're divided fairly, while making as few cuts as possible. And if you sit down to try this, this is a shockingly hard fact to prove. Maybe the puzzle seems a little contrived, but its core characteristics,  like trying to minimize sharding and allocating some collections of  things in a balanced way, these are the kind of optimization issues  that actually come up quite frequently in practical applications. For the computer system folks among you, I'm sure you can imagine  how this is analogous to kinds of efficient memory allocation problems. Also for the curious among you, I've left a link in the description  to an electrical engineering paper that applies this specific problem. Independent from the usefulness though, it certainly does make for a good puzzle. Can you always find a fair division using only as many cuts as there are types of jewels? So that's the puzzle, remember it, and now we take a seemingly unrelated  sidestep to the total opposite side of the mathematical universe, topology. Imagine taking a sphere in 3D space and squishing it somehow onto the 2D plane,  stretching and morphing it however you'd like to do so. The only constraint I'll ask is that you do this continuously,  which you can think of as meaning never cut the sphere or tear it in any way  during this mapping. As you do this, many different pairs of points will land on top of  each other once they hit the plane, and that's not really a big deal. The special fact we're going to use, known as the Borsuk-Ulam theorem,  is that you will always be able to find a pair of points that started off on  the exact opposite sides of the sphere, which land on each other during the mapping. Points on the exact opposite like this are called antipodes, or antipodal points. For example, if you think of the sphere as Earth,  and you're mapping as a straight projection of every point directly onto the  plane of the equator, the north and the south pole, which are antipodal,  each land on the same point. And in this example, that's the only antipodal pair that lands on the same point,  and the other antipodal pair will end up offset from each other somehow. If you tweaked this function a bit, maybe shearing it during the projection,  the north and the south pole don't land on each other anymore. But when the topology gods close a door, they open a window,  because the Borsuk-Ulam theorem guarantees that no matter what,  there must be some other antipodal pair that now land on top of each other. The classic example to illustrate this idea, which math educators  introducing Borsuk-Ulam are required by law to present,  is that there must exist some pair of points on the opposite side of  the Earth where the temperature and the barometric pressure are both precisely the same. This is because associating each point on the surface of the Earth with  a pair of numbers, temperature and pressure, is the same thing as mapping  the surface of the Earth onto a 2D coordinate plane,  where the first coordinate represents temperature, and the second represents pressure. The implicit assumption here is that temperature and pressure each vary continuously  as you walk around the Earth, so this association is a continuous mapping from the  sphere onto a plane, some non-tearing way to squish that surface into two dimensions. So what Borsuk-Ulam implies is that no matter what the weather patterns on Earth,  or any other planet for that matter, two antipodal points must land on top of each other,  which means they map to the same temperature-pressure pair. Since you're watching this video, you're probably a mathematician at heart,  so you want to see why this is true, not just that it's true. So let's take a little sidestep through topology-proof land,  and I think you'll agree that this is a really satisfying line of reasoning. First rephrasing what it is we want to show slightly more symbolically,  if you have some function f that takes in a point p of the sphere and spits out some  pair of coordinates, you want to show that no matter what crazy choice of function  this is, as long as it's continuous, you'll be able to find some point p so that f  of p equals f of negative where negative p is the antipodal point on the other side  of the sphere. The key idea here, which might seem small at first,  is to rearrange this and say f of p minus f of negative p equals zero zero,  and focus on a new function g of p that's defined to be this left-hand side here,  f of p minus f of negative p. This way, what we need to show is that g maps some  point of the sphere onto the origin in 2D space. So rather than finding a pair of colliding points which could land anywhere,  this helps limit our focus to just one point of the output space, the origin. This function g has a pretty special property which is going to help us out,  that g of negative p is equal to negative g of p. Basically negating the input involves swapping these terms. In other words, going to the antipodal point of the sphere  results in reflecting the output of g through the origin of the output space,  or rotating the output 180 degrees around the origin. Notice what this means if you were to continuously  walk around the equator and look at the outputs of g. What happens when you go halfway around? Well, the output needs to have wandered to the  reflection of the starting point through the origin. Then, as you continue walking around the other half,  the second half of your output path must be the reflection of the first half,  or equivalently, it's the 180 degree rotation of that first path. Now, there's a slim possibility that one of these points happens to pass  through the origin, in which case you've lucked out and were done early. But otherwise, what we have here is a path that winds around the origin at least once. Now, look at that path on the equator, and imagine continuously  deforming it up to the north pole, cinching that loop tight. As you do this, the resulting path in the output space is also  continuously deforming to a point, since the function g is continuous. Now, because it wound around the origin at some point during this process,  it must cross the origin, and this means there is some point p on the sphere where  g of p has the coordinates 0,0, which means f of p minus f of negative p equals 0,0,  meaning f of p is the same as f of negative p, the antipodal collision we're looking for. Isn't that clever? And it's a pretty common style of argument in the context of topology. It doesn't matter what particular continuous function from the  sphere to the plane you define, this line of reasoning will  always zero in on an antipodal pair that lands on top of each other. At this point, maybe you're thinking, yeah yeah, lovely math and all,  but we've strayed pretty far away from the necklace problem. But just you wait, here's where things start getting clever. First, answer me this. What is a sphere, really? Well, points in 3D space are represented with three coordinates,  in some sense that's what 3D space is to a mathematician at least,  all possible triplets of numbers. And the simplest sphere to describe with coordinates is the standard unit  sphere centered at the origin, the set of all points a distance 1 from the origin,  meaning all triplets of numbers so that the sum of their squares is 1. So the geometric idea of a sphere is related to the  algebraic idea of a set of positive numbers that add up to 1. That might sound simple, but tuck that away in your mind. If you have one of these triplets, the point on the opposite side of the sphere,  the corresponding antipodal point, is whatever you get by  flipping the sign of each coordinate, right? So let's just write out what the Borsuk-Ulam theorem is saying symbolically. Trust me, this will help with getting back to the necklace problem. For any function that takes in points on the sphere,  triplets of numbers who square sum to 1, and spits out some point in 2D space,  some pair of coordinates like temperature and pressure,  as long as the function is continuous, there will be some input so that flipping  all of its signs doesn't change the output. With that in mind, look back at the necklace problem. Part of the reason these two things feel so very unrelated is that the necklace  problem is discrete, while the Borsuk-Ulam theorem is continuous,  so our first step is to translate the stolen necklace problem into a continuous version,  seeking the connection between necklace divisions and points on the sphere. For right now, let's limit ourselves to the case where there's only two jewel types,  say sapphires and emeralds, and we're hoping to make a fair  division of this necklace after only two cuts. As an example, just to have up on the screen, let's  say there's 8 sapphires and 10 emeralds on the necklace. Just as a reminder, this means the goal is to cut the necklace in two different spots,  and divvy up those three segments so that each thief ends up with  half of the sapphires and half of the emeralds. Notice the top and bottom each have 4 sapphires and 5 emeralds. For our continuousification, think of the necklace as a line with length 1,  with the jewels sitting evenly spaced on it, and divide up that  line into 18 evenly sized segments, one for each jewel. And rather than thinking of each jewel as a discrete, indivisible entity on each segment,  remove the jewel itself, and just paint that segment the color of the jewel. So in this case, 8 18ths of the line would be painted sapphire,  and 10 18ths would be painted emerald. The continuous variant of the puzzle is now to ask if we can find two cuts  anywhere on this line, not necessarily on the 1 18th interval marks,  that lets us divide up the pieces so that each thief has an equal length of each color. In this case, each thief should have a total of 4 18ths of sapphire colored segments,  and 5 18ths of emerald colored segments. An important but somewhat subtle point here is that if you can solve  the continuous variant, you can also solve the original discrete version. To see this, let's say you did find a fair division whose  cuts didn't happen to fall cleanly between the jewels. Maybe it cuts only part way through an emerald segment. Well, because this is a fair division, the length of emerald in both top and bottom has  to add up to 5 total emerald segments, a whole number multiple of the segment lengths. So even if the division cut partially into an emerald segment on the left,  it has to cut partially into an emerald segment on the right,  and more specifically in such a way that the total length adds up to a whole number  multiple of the segment length. What that means is that you can adjust each cut without affecting  the division so that they ultimately do line up on the 1 18th marks. Now why are we doing all this? Well, in the continuous case, where you can cut wherever you want on this line,  think about all of the choices going into dividing the necklace and allocating the pieces. First you choose two locations to cut the interval,  but another way to think about that is to choose three positive numbers  that add up to one. For example, maybe you choose 1 6th, 1 3rd, and 1 half,  which correspond to these two cuts. Any time you find three positive numbers that add up to one,  it gives you a way to cut the necklace, and vice versa. After that, you have to make a binary choice for each of these pieces,  for whether it goes to thief 1 or thief 2. Now compare that to if I asked you to choose some arbitrary point on a sphere in  three-dimensional space, some point with coordinates x, y, z,  so that x2 plus y2 plus z2 equals 1. Well, you might start off by choosing three positive numbers that add to one. Maybe you want x2 to be 1 6th, y2 to be 1 3rd, and z2 to be 1 half. Then you have to make a binary choice for each one of them,  choosing whether to take the positive square root or the negative square root,  in a way that's completely parallel to dividing the necklace and allocating the pieces. Alright, hang with me now, because this is the key observation of the whole video. It gives a correspondence between points on the sphere and necklace divisions. For any point x, y, z on the sphere, because x2 plus y2 plus z2 is 1,  you can cut the necklace so that the first piece has a length x2,  the second has a length y2, and the third has a length z2. For that first piece, if x is positive, give it to thief 1, otherwise give it to thief 2. For the second piece, if y is positive, give it to thief 1,  otherwise give it to thief 2, and likewise give the third  piece to thief 1 if z is positive, and to thief 2 if z is negative. And you could go the other way around. Any way that you divide up the necklace and divvy  up the pieces gives us a unique point on the sphere. It's as if the sphere is a weirdly perfect way to encapsulate the  idea of all possible necklace divisions, just with a geometric object. And here we are tantalizingly close. Think of the meaning of antipodal points under this association. If the point x, y, z on the sphere corresponds to some necklace allocation,  what does the point negative x, negative y, and negative z correspond to? Well, the squares of these three coordinates are the same,  so each one corresponds to making the same cuts on the necklace. The difference is that every piece switches which thief it belongs to. So jumping to an antipodal point on the opposite side  of the sphere corresponds with exchanging the pieces. Now remember what it is that we're actually looking for. We want the total length of each jewel type belonging  to thief 1 to equal that for thief 2. Or in other words, in a fair division, performing this antipodal  swap doesn't change the amount of each jewel belonging to each thief. Your brain should be burning with the thought of Borsuk Ulam at this point. Specifically, you might construct a function that takes in a given necklace  allocation and spits out two numbers, the total length of sapphire belonging to thief 1,  and the total length of emerald belonging to thief 1. We want to show that there must exist a way to divide the necklace, with two cuts,  and divvy up the pieces so that these two numbers are the same as what they would be for  thief 2. Or said differently, where swapping all of the pieces wouldn't change those two numbers. Because of this back and forth between necklace allocations and the points of the sphere,  and because pairs of numbers correspond with points on the xy-plane,  this is, in effect, a map from the sphere onto the plane. And the animation you're looking at right now is  that literal map for the necklace I was showing. So the Borsuk-Ulam theorem guarantees that some antipodal pair of points on  the sphere land on each other in the plane, which means there must be some  necklace division using two cuts that gives a fair division between the thieves. That, my friends, is what beautiful math feels like. Alright, and if you're anything like me, you're just basking in the glow of what  a clever proof that is, and it might be easy to forget that what we actually want  to solve is the more general stolen necklace problem, with any number of jewel types. Luckily, we've now done 95% of the work. Generalizing is pretty brief. The main thing to mention is that there is a more general version of  the Borsuk-Ulam theorem, one that applies to higher dimensional spheres. As an example, Borsuk-Ulam applies to mapping  hyperspheres in 4D space into three dimensions. And what I mean by a hypersphere is the set of all possible lists  of four coordinates where the sum of their squares equals one. Those are the points in 4D space a distance one from the origin. Borsuk-Ulam says that if you try to map that set,  all those special quadruplets of numbers, into three-dimensional space,  continuously associating each one with some triplet of numbers,  there must be some antipodal collision, an input x1, x2, x3, x4,  where flipping all of the signs wouldn't change the output. I'll leave it to you to pause and ponder and think about how this could  apply to the 3-jewel case, and about what the general statement of Borsuk-Ulam might be,  and how it applies to the general necklace problem. And maybe, just maybe, this gives you an inkling of why  mathematicians care about things like higher dimensional spheres,  regardless of whether or not they exist in physical reality. It's not always about the sphere per se, it's about  what other problems in math they can be used to encode.

================================================================================
VIDEO ID: _UoTTq651dE
TITLE: Why 5/3 is a fundamental constant for turbulence
URL: https://www.youtube.com/watch?v=_UoTTq651dE
PUBLISHED: 2018-11-07T20:20:32Z
STATUS: SUCCESS
================================================================================
The air around you is in constant and chaotic motion,  replete with nearly impossible to predict swirls, ranging from large to minuscule. What you're looking at right now is a cross-section of the flow in a typical room,  made visible using a home demo involving a laser, a glass rod, and a fog machine. Predicting the specifics of turbulent motion like this has long evaded  mathematicians and physicists, but we are steadily getting closer to understanding  some consistent patterns in this chaos, and in a minute I'll share with you  one specific quantitative result describing a certain self-similarity to this motion. To back up a bit, I was recently in San Diego and spent a day with Diana Cowern,  aka Physics Girl, and her frequent collaborator, Dan Walsh,  playing around with vortex rings. This is a really surprising fluid flow phenomenon,  where a donut-shaped region of fluid stays surprisingly stable as it moves through space. If you take some open container with a lip and fill it with smoke or fog,  you can use this to actually see the otherwise invisible ring. Diana just published a video over on her channel showing much more  of that particular demo, including a genuinely fascinating observation  about what happens when you change the shape of the opening. The story for you and me starts when her friend Dan had the clever idea to  visualize a slice of what's going on with these vortex rings using a planar laser. So you know how if you shine a laser through the fog,  photons will occasionally bounce off of the particles in the fog  along that beam towards your eye, thereby revealing the beam of the laser? Well, Dan's thought was to refract that light through a glass rod so that  it was relatively evenly spread across an entire plane,  then the same phenomenon would reveal the laser light along a thin plane through that fog. The result was awesome! The cross-section of such a smoke ring looks like two hurricanes rotating next  to each other, and this makes abundantly clear how the surface of these rings  rotates as they travel, and also how chaotic they leave the air behind them. And, as an added bonus, the setup doubles as a  great Death Eater themed Halloween decoration. If you do want to try this at home, I should say,  be super careful with the laser, make sure not to point it near anyone's eyes. This concern is especially relevant when the laser is spread along a full plane,  basically treat it like a gun. Also, credit where credit is due, I'd like to point out that  after we did this we found that the channel Nighthawk and  Light has a video doing a similar demo, link in the description. Even though our original plan was to illuminate vortex rings,  I actually think the most notable part of this visual is how it sheds  light on what ordinary airflow in a room looks like, in all of its intricacy and detail. We call this chaotic flow turbulence, and just as vortex rings give an example of  unexpected order in the otherwise messy world of fluid dynamics,  I'd like to share with you a more subtle instance of order amidst chaos in the  math of turbulence. First off, what exactly is turbulence? The term is familiar to many of us as that annoying thing that makes plane rides bumpy,  but nailing down a specific definition is a little tricky. It's easiest to describe qualitatively. Turbulence involves many swirling eddies, it's chaotic, and it mixes things together. One approach here would be to describe turbulence based on what it's not, laminar flow. This term stems from the same Latin word that lamination does lamina,  meaning a thin layer of a material, and it refers to smooth flow in a fluid,  where the moving particles stay largely confined to distinct layers. Turbulence, in contrast, contains many eddies, points of some vorticity,  also known as positive curl, also known as a high swirly swirly factor,  breaking down the notion of distinct layers. However, vorticity does not necessarily imply that a flow is turbulent. Patterns like whirlpools or even smoke rings have high vorticity since  the fluid is rotating, but can nevertheless be smooth and predictable. Instead, turbulence is further characterized as being chaotic,  meaning small changes to the initial conditions result in large changes to the  ensuing patterns. It's also diffusive in the sense of mixing together different parts of the fluid,  and diffusing the energy and momentum from isolated parts of the fluid to the rest. Notice how in this clip, over time, the image shifts from having a crisp  delineation between fog and air to instead being a murky mixture of both of them. As to something more mathematically precise, there's not really a single widely  agreed upon clear-cut criterion the way there is for most other terms in math. The intricacy of the patterns you're seeing is mirrored by a  difficulty to parse the physics describing all of this,  and that can make the notion of a rigorous definition somewhat slippery. You see, the fundamental equations describing fluid dynamics,  the Navier-Stokes equations, are famously challenging to understand. We won't go through the full details here, but if you're curious,  the main equation is essentially a form of Newton's second law,  that the acceleration of a body times its mass equals the sum of the forces acting on it. It's just that writing mass times acceleration looks a bit more complicated in this  context, and the force is broken down into the different types of forces acting on  a fluid, which again can look a bit intimidating in the context of continuum dynamics. Not only are these hard to solve in the sense of feeding in some initial state  of a fluid and figuring out how the equations predict that fluid will evolve,  there are several unsolved problems around a much more modest task of  understanding whether or not quote-unquote reasonable solutions will always exist. Reasonable here means things like not blowing up to a point of having infinite  kinetic energy, and that smooth initial states yield smooth solutions,  where the word smooth carries with it a very precise meaning in this context. The questions formalizing the idea of these equations predicting  reasonable behavior actually have a $1 million prize associated with them. And all of that is just for the case of incompressible fluid flow,  where something compressible like air makes things trickier still. And the heart of the difficulty, both for the specific solutions and the general  theoretical results surrounding them, is that tricky-to-pin-down phenomenon of turbulence. But we're not completely in the dark. The hard work of a lot of smart people throughout history has led us to  understanding some of the patterns underlying this chaos,  and I'd like to share with you one found by the 19th century mathematician  Andrei Komagorov. It has to do with how kinetic energy in turbulent  motion is distributed at different length scales. In simpler-to-think-about physics, we often think about kinetic  energy at two different length scales, a macroscale,  say the energy carried by your moving car, or a molecular scale, which we call heat. As you apply your brakes, energy is transferred more or less directly from that  macroscale motion to the molecular scale motion,  as your brakes and the surrounding air heats up,  meaning all of their molecules start jiggling even faster. Turbulence, on the other hand, is characterized by kinetic energy  at a whole spectrum of length scales, from the movement of large  eddies to smaller ones and smaller ones and smaller ones still. Moreover, this energy tends to cascade down the spectrum,  where what I mean by that is that the energy of large eddies gets  converted into that of smaller eddies, which in turn bring about smaller eddies still. This goes on until it's small enough that the energy dissipates directly  to heat in the fluid, which is to say molecular scale jiggling,  due to the fluid's viscosity, which is to say how much the particles tug at each other. Or, as this was all phrased in a poem by Lewis F. Richardson, Big whorls have little whorls which feed on their velocity,  and little whorls have lesser whorls, and so on to viscosity. Now you might wonder whether more of the kinetic energy of this fluid is  carried by all of the larger eddies, say all those with diameter 1 meter,  or by all of the smaller ones, say all those with diameter 1 cm, counted together. Or more generally, if you were to look at all of the swirls with a diameter d,  about how much of the fluid's total energy do they collectively carry? Is that even an answerable question? Komagorov hypothesized that the amount of energy in a turbulent flow carried by  eddies with diameter d tends to be proportional to d to the power 5 thirds,  at least within a specific range of length scales known fancifully as the inertial  subrange. For air, this ranges from about 0.1 cm up to 1 km. This fact has since been verified by experiment many times over. It would appear that 5 thirds is a sort of fundamental constant of turbulence. It's an oddly specific fact, I know, but what I love about  the existence of a constant like this is that it suggests there's some predictability,  however slight, to this whole mass. There is something ironic about talking about this energy cascade while viewing  two-dimensional slices of a fluid, because it is a distinctly three-dimensional  phenomenon. While fluid flow in two dimensions can have a sort of turbulence,  this energy transfer actually tends to go the other way,  from the small scales up to larger ones. So keep in mind, while you're looking at this 2d slice of turbulence,  it's actually very different in character from turbulence in 2d. One of the mechanisms behind this energy cascade,  which could only ever happen in three dimensions, is a process known as vortex stretching. A rotating part of the fluid will tend to stretch out perpendicular  to the plane of rotation, resulting in smaller eddies spinning faster. This transition from energy held in a large vortex to instead being held in smaller  vortices would be impossible if there weren't another dimension to stretch in. Or if this vortex were bent around to meet itself in a ring shape,  in a way it's like a vortex which is blocking itself from stretching out this way. And as mentioned earlier, this is indeed a surprisingly stable configuration for a fluid,  order amidst chaos. Interestingly though, when we made these vortex rings in practice and followed them  over a long period of time, they do have a tendency to slowly stretch out,  albeit at a much longer time scale than the vortex stretching I was just talking about. Which brings us back to Diana and Dan. Huge thanks to the both of them for getting so much footage and making all of this happen. Make sure to hop over to Physics Girl now to see some of the vortex ring demos,  and as I said, you'll also get to learn about something that happens  when you change the shape of the hole in this vortex cannon. The result and its specifics certainly surprised me,  and you'll get to hear it through Diana's typical, and infectious,  superhuman level of enthusiasm.

================================================================================
VIDEO ID: zjMuIxRvygQ
TITLE: Quaternions and 3d rotation, explained interactively
URL: https://www.youtube.com/watch?v=zjMuIxRvygQ
PUBLISHED: 2018-10-26T16:31:52Z
STATUS: SUCCESS
================================================================================
In a moment, I'll point you to a separate website hosting  a short sequence of what we're calling explorable videos. It was done in collaboration with Ben Eater, who some of you may  know as that guy who runs the excellent computer engineering channel. And if you don't know who he is, viewers of this channel  would certainly enjoy the content of his, so do check it out. This collaboration was something a little different though, for both of us,  and all of the web development that made these explorable videos possible is completely  thanks to Ben. I don't want to say too much about it here, it's really something you have to experience  for yourself, certainly one of the coolest projects I've had the pleasure of working on. Before that though, if you can contain your excitement,  I want to use this video as a chance to tee things up with a little bit of  surrounding context. So to set the stage, last video I described quaternions,  a certain 4-dimensional number system that the 19th century versions of  Wolverine and the old man from Home Alone called evil for how convoluted  it seemed at the time. And perhaps you too are wondering why on earth anyone  would bother with such an alien-seeming number system. One of the big reasons, especially for programmers,  is that they give a really nice way for describing 3D orientation,  which is not susceptible to the bugs and edge cases of other methods. I mean they're interesting mathematically for a lot of reasons,  but this application for computer graphics and robotics and virtual reality  and anything involving 3D orientation is probably the biggest use case for quaternions. To take one example, a friend of mine who used to work at Apple, Andy Matuszczak,  delighted in telling me about shipping code to hundreds of millions of devices  that uses quaternions to track the phone's model for how it's oriented in space. That's right, your phone almost certainly has software  running somewhere inside of it that relies on quaternions. The thing is, there are other ways to think about computing rotations,  many of which are way simpler to think about than quaternions. For example, any of you familiar with linear algebra will know  that 3x3 matrices can really nicely describe 3D transformations. And a common way that many programmers think about constructing a rotation matrix for  a desired orientation is to imagine rotating an object around three easy-to-think-about  axes, where the relevant angles for these rotations are commonly called Euler angles. And this mostly works, but one big problem is that it's  vulnerable to something called gimbal lock, where when two of  your axes of rotation get lined up, you lose a degree of freedom. And it can also cause difficulties and ambiguities when  trying to interpolate between two separate orientations. If you're curious for more of the details, there are many  great sources online for learning about Euler angles and gimbal lock,  and I've left links in the description to a few of them. Not only do quaternions avoid issues like gimbal lock,  they give a really seamless way to interpolate between two three-dimensional  orientations, one which lacks the ambiguities of Euler angles,  and which avoids the issues of numerical precision and normalization that arise in  trying to interpolate between two rotation matrices. To warm up to the idea of how multiplication in some higher-dimensional  number system might be used to compute rotations,  take a moment to remember how it is that complex numbers give a slick method  for computing 2D rotations. Specifically, let's say you have some point in two-dimensional space,  like 4, 1, and you want to know the new coordinates you'd get  if you rotate this point 30 degrees around the origin. Complex numbers give a sort of snazzy way to do this. You take the complex number that's 30 degrees off the horizontal with magnitude 1,  cos 30 degrees plus sin 30 degrees times i, and then you just multiply  this by your point, represented as a complex number. The only rule you need to know to carry out this computation is that i2 equals negative 1. Then in what might feel like a bit of black magic to those first learning it,  carrying out this product from that one simple rule gives the coordinates of a new point,  the point rotated 30 degrees from the original. Using quaternions to describe 3D rotations is similar,  though the look and feel is slightly different. Let's say you want to rotate some angle about some axis. You first define that axis with a unit vector, which we'll write as having i, j,  and k components, normalized so that the sum of the squares of those components is 1. Similar to the case of complex numbers, you use the angle to construct  a quaternion by taking cosine of that angle as the real part,  plus sin of that angle times an imaginary part,  except this time the imaginary part has three components,  the coordinates of our axis of rotation. Well, actually you take half of the angle, which might feel totally arbitrary,  but hopefully that makes sense by the end of this whole experience. Let's say you have some 3D point, which we'll write with i, j,  and k components, and you want to know the coordinates you'd get when  you rotate this point by your specified angle around your specified axis. What you do is not just a single quaternion product, but a sort of quaternion sandwich,  where you multiply by q from the left and the inverse of q from the right. If you know the rules for how i, j, and k multiply amongst themselves,  you can carry out these two products by expanding everything out,  or more realistically by having a computer do it for you. And in what might feel like a bit of black magic,  this big computation will return for you the rotated version of the point. Our goal is to break this down and visualize what's  happening with each of these two products. I'll review the method for thinking about quaternion multiplication described last video,  and explain why half the angle is used, and why you would  multiply from the right by the inverse. On the screen now and at the top of the description you'll find a link to  eater.net slash quaternions, which is where Ben set up the explorable video tutorial,  where I explain what's going on with this rotation computation. It's just really cool. Eater did something awesome here. So at the very least just take a couple minutes to go look at it,  but I'd love it if you went through the full experience.

================================================================================
VIDEO ID: d4EgbgTm0Bg
TITLE: Visualizing quaternions (4d numbers) with stereographic projection
URL: https://www.youtube.com/watch?v=d4EgbgTm0Bg
PUBLISHED: 2018-09-06T14:59:33Z
STATUS: SUCCESS
================================================================================
What you're looking at right now is something called quaternion multiplication, or rather you're looking at a certain representation of a specific motion happening on a four-dimensional sphere being represented in our three-dimensional space, one which you'll understand by the end of this video. Quaternions are an absolutely fascinating and often underappreciated number system from math. Just as complex numbers are a two-dimensional extension of the real numbers, quaternions are a four-dimensional extension of complex numbers. But they're not just playful mathematical shenanigans, they have a surprisingly pragmatic utility for describing rotation in three dimensions, and even for quantum mechanics. The story of their discovery is also quite famous in math. The Irish mathematician William Rowan Hamilton spent much of his life seeking a three-dimensional number system, analogous to the complex numbers. And as the story goes, his son would ask him every morning whether or not he had figured out how to divide triples, and he would always say no, not yet. But on October 16, 1843, while crossing the Broom Bridge in Dublin, he realized, with a supposed flash of insight, that what he needed was not to add a single dimension to the complex numbers, but to add two more imaginary dimensions, three imaginary dimensions describing space and the real numbers, sitting perpendicular to that in some kind of fourth dimension. He carved the crucial equation describing these three imaginary units into the bridge, which today bears a plaque in his honor showing that equation. Now you have to understand, our modern notion of vectors with their dot product and the cross product and things like that didn't really exist in Hamilton's time, at least not in a standardized form. So after his discovery, he pushed hard for quaternions to be the primary language with which we teach students to describe three-dimensional space, even forming an official quaternion society to proselytize his discovery. Unfortunately, this was balanced with mathematicians on the other side of the fence, who believed that the confusing notion of quaternion multiplication was not necessary for describing three dimensions, resulting in some truly hilarious old-timey trash talk legitimately calling them evil. It's even believed that the Mad Hatter scene from Alice in Wonderland, whose author you may know was an Oxford mathematician, was written in reference to quaternions, that the chaotic table placement changes were mocking their multiplication, and that certain quotes were referencing their non-commutative nature. Fast forward about a century, and the computing industry gave quaternions a resurgence among programmers who work with graphics and robotics and anything involving orientation in 3D space. And this is because they give an elegant way to describe and compute 3D rotations, which is computationally more efficient than other methods, and which also avoids a lot of the numerical errors that arise in these other methods. The 20th century also brought quaternions some more love from a completely different direction, quantum mechanics. The special actions that quaternions describe in four dimensions are actually quite relevant to the way that two-state systems like spin of an electron or the polarization of a photon are described mathematically. What I'll show you here is a way to visualize quaternions in their full four-dimensional glory. It would surprise me if this approach was fully original, but I can say that it's certainly not the standard way to teach quaternions, and that the specific four-dimensional right-hand rule image that I'd like to build up to is something that I haven't seen elsewhere. Building up an understanding for this visual will take us meaningful time, but once you have it, there is a very natural and satisfying intuition for how to think about quaternion multiplication. It won't be until the next video that I show you how exactly quaternions describe orientation in three dimensions, which is for some people the whole reason we care about it, but once we're able to go at it armed with the image of what they're doing to a 4D hypersphere, there's a pleasing understanding to be had for the otherwise opaque formulas characterizing this relationship. The structure here will be to start by imagining teaching complex numbers to someone who only understands one dimension, then describing 3D rotations to someone who only understands two dimensions, and ultimately to represent what quaternions are doing up in four dimensions within the constraints of our 3D space. Our first character is Linus the Linelander, whose mind can only grasp the one-dimensional geometry of lines and the algebra of real numbers. We're going to try to describe complex numbers to Linus, and it's really important for you to empathize with him as much as you can during this, because in a few minutes you're going to be in his shoes. On the one hand, you could define complex numbers purely algebraically. You say each one is expressed as some real number plus some other real number times i, where i is a newly invented constant whose defining property is that i times i equals negative one. Then you say to Linus, to multiply two complex numbers, you just use the distributive property, what many people learn in school as FOIL, and you apply this rule that i times i equals negative one to simplify things down further. And that's fine, that totally works, and the standard textbook way to introduce quaternions is analogous to this, showing the algebraic rules and calling it done. But I think something is missing if we don't at least try to show Linus the geometry of complex numbers, and what complex multiplication looks like, since the problems in math and physics where complex numbers are shockingly useful often leverage this spatial intuition. You and I, who understand two dimensions, might think of it like this. When you multiply two complex numbers, z times w, you can think of z as a sort of function acting on w, rotating and stretching it in some way. I like to think of this by broadening the view and asking, what does z do to the entire plane? You can think of that bird's eye view action by imagining using one hand to fix the number zero in place, and using another hand to drag the point at one up to z, since anything times zero is zero, and anything times one is itself. In two dimensions, there is one and only one stretching rotating action on the plane that'll do this. This is also how I'll have you thinking about quaternion multiplication later on, where the number on the left acts as a kind of function to the one on the right, and we'll understand this function by seeing how it acts by transforming space, although instead of rotating 2d space, it does a sort of double rotation in 4d space. By the way, if you want to review thinking about complex numbers as a kind of action, a good warmup for this video might be the one I did on e to the pi i explained with introductory group theory. Now Linus the line lander is pretty comfortable with the idea of stretching, that's what multiplication by real numbers looks like. Maybe it's a little weird for him to think about stretching in multiple dimensions, but it's not fundamentally different. The difficult thing to communicate to Linus is rotation. Specifically, focus on the unit circle of the complex plane, all the numbers a distance 1 from 0. Since multiplication by these numbers corresponds to pure rotation, how would you explain to Linus the look and feel of multiplying by these numbers? At first, that might seem impossible, rotation is just such an intrinsically two-dimensional idea. But, on the other hand, rotation involves only one degree of freedom, a single number, the angle, specifies a given rotation uniquely. So in principle, it should be possible to associate the set of all rotations to the one-dimensional continuum that is Linus's world. And there are many ways you could do this, but the one I'm going to show you is called a stereographic projection, it's a special way to map a circle onto a line, or a sphere into a plane, or even a 4D hypersphere into 3D space. For every point on the unit circle, draw a line from negative 1 through that point, and wherever it intersects the vertical line through the circle's center, that's where the point of the circle gets projected. So for example, the point at 1 gets projected into the center of the line, the point i actually stays fixed in place, as does negative i. All of the points on that 90 degree arc between 1 and i will get projected somewhere in the interval between where 1 landed and where i landed. As you continue farther around the circle on the arc between i and negative 1, the projected points end up farther and farther away at an increasing rate. Similarly, if you come around the other way towards negative 1, the projected points end up farther and farther on the other end of the line. This line of projected points is what we show to Linus, labeling a few key points, like 1 and i and negative 1 all for reference. Technically, the point at negative 1 has no projection under this map, since the tangent line to the circle at that point never crosses the vertical line. But what we say is that negative 1 ends up at the point at infinity, a special point you imagine adding to the line where you would approach it if you walk infinitely far along the line in either direction. It's important to remember, and remind Linus, that what he's seeing is only the complex numbers that are a distance 1 from the origin, the unit circle. Linus doesn't see most numbers, like 0, or 1 plus i, or negative 2 minus i, but that's okay, because right now we just want to describe complex numbers z where multiplying by z has the effect of a pure rotation, so he only needs to understand the unit circle. For example, when we take the number i and multiply it by any other complex number w, the effect is to rotate by 90 degrees counterclockwise, and when we apply this action to the circle being projected down to the line for Linus, what does he see? Well, it's a bit of a strange morphing action on the line, one which I want you to become familiar with for something we'll see later on. It's easiest to understand by following a few key reference points. i times 1 is i, so that means the number 1 should move up to i. i times i is negative 1, so the point at i slides off to infinity. i times negative 1 is equal to negative i, so that point at infinity kind of comes back around from the bottom to the position 1 unit below the center. i times negative i is 1, so the point at negative i slides up to 1. Even though this is kind of a weird motion, it lets us communicate some important ideas to Linus. For example, multiplying by i four times, which corresponds to rotating by 90 degrees four times in a row, gets us back to where we started. i to the fourth equals 1. To get more of a feel for things, let me just show the circle rotated at various different angles, on both the left and right half of the screen. I'm putting a hand on the point that started at the number 1 to help us and help Linus keep track of the overall motion. Next, let's introduce Felix the Flatlander, who only understands two-dimensional geometry. Imagine trying to explain rotations of a sphere to Felix. In the spirit of transitioning from complex numbers to quaternions, let's extend the complex numbers with its horizontal axis of real numbers and its vertical axis of imaginary numbers with a third axis, defined by some newly invented constant, j, sitting one unit away from zero, perpendicular to the complex plane. Instead of having this new axis in the z-direction, like you might expect, for a better analogy with how we'll visualize quaternions, we'll want to orient things so that the i and j axes sit in the x and y directions, with the real number line aligned along the z-direction. Every point in 3D space is described as some real number plus some real number times i plus some real number times j. As it happens, it's not possible to define a notion of multiplication for a 3D number system like this that would satisfy the usual algebraic properties that make multiplication a useful construct. Perhaps I'll outline why this is the case in a follow-on video, but staying focused on our current goal, think about describing 3D rotations in this coordinate system to Felix the Flatlander. The unit sphere consists of all those numbers which are a distance 1 from 0 at the origin, meaning the sum of the squares of their coordinates is 1. We can't show all of 3D space to Felix, but what we can do is project this 2D surface to him and give him a feel for what reorientations of the sphere look like under that projection. Analogous to what we did before, stereographic projection will associate almost every point on the unit sphere with a unique point on the horizontal plane defined by the i and the j axes. For each point on the sphere, draw a line from negative 1 at the south pole through that point and see where it intersects the plane. So the point 1 at the north pole ends up at the center of the plane. all of the points of the northern hemisphere get mapped somewhere inside the unit circle of the i-j plane, and that unit circle which passes through i, j, negative i, negative j, stays fixed in place. And that's an important point to make note of. Even though most points and lines and patches that Felix the Flatlander sees are warped projections of the real sphere, this unit circle is the one thing he has which is an honest part of our unit sphere, unaltered by projection. All of the points in the southern hemisphere get projected outside that unit circle, each getting farther and farther away as you approach negative 1 at the south pole. And again, negative 1 has no projection under this mapping, but what we say is that it ends up at some point at infinity. That point at infinity is something such that no matter which direction you walk on the plane, as you go infinitely far out, you'll be approaching that point. It's analogous to how if you walk any direction away from the north pole, you're approaching the south pole. Now let me just pull up a view of what Felix sees in two dimensions. As I rotate the sphere in various ways, the lines of latitude and longitude drawn on that sphere get projected into various circles and lines in Felix's space. And the way I've done things up here, the checkerboard pattern on the surface of the sphere is accurately reflected in the projected view you see with Felix, and the pinker view represents where the point that started at the north pole ends up after the rotation, and the yellow circle represents where the equator ended up after the projection. The more you put yourself in Felix's shoes right now, the easier quaternions will be in a moment, and as with Linus, it helps to focus on a few key reference objects rather than trying to see the whole sphere. This circle, passing through 1, i, negative 1, and negative i, gets mapped onto a line which Felix sees as the horizontal axis. It's important to remind Felix that what he sees is not the same thing as the i-axis. Remember, we're only projecting the numbers that have a distance 1 from the origin, so most points on the actual i-axis, like 0, 2i, 3i, etc., are completely invisible to Felix. Similarly, the circle that passes through 1, j, negative 1, and negative j gets projected onto what he sees as a vertical line. In general, any line Felix sees comes from some circle on the sphere that passes through negative 1. In some sense, a line is just a circle that passes through the point at infinity. Now think about what Felix sees as we rotate the sphere. A 90 degree rotation about the j-axis brings 1 to i, i to negative 1, negative 1 to negative i, and negative i to 1. So what Felix the Flatlander sees is an extension of the rotation that Linus the Linelander was seeing. Notice also that this action rotates the i, j unit circle to the position where the 1, j unit circle used to be. So what Felix sees is his yellow unit circle getting transformed into a vertical line, while the red vertical line gets transformed into the unit circle. Of course, from our perspective, we know this is all just rigid motion, no actual stretching or morphing is taking place. All of that is just an artifact of the projection. Similarly, a rotation about the i-axis involves moving 1 to j, j to negative 1, negative 1 to negative j, and negative j to 1. This rotation turns the i, j unit circle into the 1, i unit circle, which to Felix looks like the unit circle getting transformed into a horizontal line. A rotation about the real axis is actually quite easy for Felix to understand, since the whole projection simply gets rotated about the origin, where the only points staying fixed in place are 1 at the origin and negative 1 off at infinity. In the same way that the complex numbers included the real numbers with a single extra quote unquote imaginary dimension, represented by the unit i, and that the not-actually-a-number system thing we had in three dimensions included a second imaginary direction, j, the quaternions include the real numbers together with three separate imaginary dimensions, represented by the units i, j, and k. Each of these three imaginary dimensions is perpendicular to the real number line, and they're all perpendicular to each other somehow. So in the same way that complex numbers are represented as a pair of real numbers, each quaternion can be written using four real numbers, and it lives in four-dimensional space. You often think of this as being broken up into a real or scalar part, and then a 3D imaginary part. And Hamilton used a special word for quaternions that had no real part and just i, j, k components, a word which was previously somewhat foreign in the lingo of math and physics, vector. On the one hand, you could just define quaternion multiplication by giving the rules for how i, j, and k multiply together, and saying that everything must distribute nicely. This is analogous to defining complex multiplication by saying that i times i is negative 1, and then distributing and simplifying products. And indeed, this is how you would tell a computer to perform quaternion multiplication, and the relative compactness of this operation compared to say matrix multiplication is what's made quaternion so useful for graphics programming and many other things. There's also a rather elegant form of this multiplication rule written in terms of the dot product and the cross product, and in some sense, quaternion multiplication subsumes both of these notions, at least as they appear in three dimensions. But just as a deeper understanding for complex multiplication comes from understanding its geometry that multiplying by a complex number involves a combination of scaling and rotating, you and I are here for the four-dimensional geometry of quaternion multiplication. And just as the magnitude of a complex number, its distance from zero, is the square root of the sum of the squares of its component, that same operation gives you the magnitude of a quaternion. And multiplying one quaternion, q1, by another, q2, has the effect of scaling q2 by the magnitude of q1, followed by a very special type of rotation in four dimensions. And those special 4D rotations, the heart of what we need to understand, correspond to the hypersphere of quaternions, a distance 1 from the origin, both in the sense that the quaternions whose multiplying action is a pure rotation live on that hypersphere, and in the sense that we can understand this weird 4D action just by following points on the hypersphere, rather than trying to look at all the points in the inconceivable stretches of four-dimensional space. Analogous to what we did for Linus and Felix, we stereographically project this hypersphere into 3D space. This label in the upper right is going to show a given unit quaternion, and this little pink dot will show where that particular quaternion gets projected in our 3D space. Just as before, we're projecting from the number negative 1, which sits on the real number line that is somehow perpendicular to all of our 3D space, and beyond our perception. Just as before, the number 1 ends up projected straight into the center of our space. And in the same way that i and negative i were fixed in place for Linus, and that the ij unit circle was fixed in place for Felix, we get a whole sphere passing through i, j, and k on that unit hypersphere, which stays in place under the projection. So what we see as a unit sphere in our 3D space represents the only unaltered part of the hypersphere of quaternions getting projected down onto us. It's something analogous to the equator of a 3D sphere, and it represents all of the unit quaternions whose real part is zero, what Hamilton would have described as unit vectors. The unit quaternions with positive real parts, between 0 and 1, end up somewhere inside this unit sphere, closer to the number 1 in our 3D space, which should feel analogous to how the northern hemisphere got mapped inside the unit circle for Felix. On the other hand, all the unit quaternions with negative real part end up somewhere outside that unit sphere. The number negative 1 is sitting off at the point at infinity, which you can easily find by walking in any direction. Keep in mind, even though we see the projection of some of these quaternions as being closer or farther from the origin of our 3D space, everything you're looking at represents a unit quaternion, so everything you're looking at really has the same magnitude, the same distance from the number 0. And that number 0 itself is nowhere to be found in this picture. Like all other non-unit quaternions, it's invisible to us. In the same way that for Felix, the circle passing through 1, i, negative 1, and negative i got projected into a line through the origin, when we see this line through the origin passing through i and negative i, we should understand that it really represents a circle. Likewise, up on the hypersphere, invisible to us, there is a unit sphere passing through 1, i, j, negative 1, negative i, and negative j, and that whole sphere gets projected into the plane that we see passing through 1, i, negative i, j, negative j, and negative 1, off at infinity, what you and I might call the xy plane. In general, any plane that you see here really represents the projection of a sphere somewhere up on the hypersphere which passes through the number negative 1. The action of taking a unit quaternion and multiplying it by any other quaternion from the left can be thought of in terms of two separate 2D rotations, happening perpendicular to and in sync with each other in a way that could only ever be possible in four dimensions. As a first example, let's look at multiplication by i. We already know what this does to the circle that passes through 1 and i, which we see as a line. 1 goes to i, i goes to negative 1, off at infinity, negative 1 comes back around to negative i, and negative i goes to 1. Remember, just like what Linus saw, all of this is the stereographic projection of a 90 degree rotation. Now look at the circle passing through j and k, which is in a sense perpendicular to the circle passing through 1 and i. It might feel weird to talk about two circles being perpendicular to each other, especially when they have the same center and radius and don't touch each other at all, but nothing could be more natural in four dimensions. You can think of the action of i on this perpendicular circle as obeying a certain right-hand rule, if you'll excuse the intrusion of my ghostly green-screen hand into our otherwise pristine platonic mathematical stage. You let that thumb of your right hand point from the number 1 to i, and you curl your fingers. The j-k circle will rotate in the direction of that curl. How much? Well, by the same amount as the 1i circle rotates, which is 90 degrees in this case. This is what I meant by two rotations perpendicular to and in sync with each other. So j goes to k, k goes to negative j, negative j goes to negative k, and negative k goes to j. This gives us a little table for what the number i does to the other quaternions, but I want this not to be something that you memorize, but something that you could close your eyes and you could really see. Computationally, if you know what a quaternion does to the numbers 1, i, j, and k, you know what it does to any arbitrary quaternion, since multiplication distributes nicely. In the language of linear algebra, 1, i, j, and k form a basis of our 4-dimensional space, so knowing what our transformation does to them gives us the full information about what it does to all of space. Geometrically, a 4-dimensional creature would be able to look at those two perpendicular rotations I just described, and understand that they lock you into one and only one rigid motion for the hypersphere. We might lack the intuitions of such a hypothetical creature, but we can maybe try to get close. Here's what the action of repeatedly multiplying by i looks like on our stereographic projection of the ijk sphere. It gets rotated into what we see as a plane, then gets rotated further back to where it used to be, though the orientation is reversed now, then gets rotated again into what we see as a plane, and after the fourth iteration, it ends up right back where it started. As another example, think of a quaternion like q equals negative square root of 2 over 2 plus square root of 2 over 2 times i, which if we pull up a picture of a complex plane, is a 135 degree rotation away from 1 in the direction of i. Under our projection, we see this along the line from 1 to i somewhere outside the unit sphere. If that sounds weird, just remember how Linus would have seen this same number. The action of multiplying this q by all other quaternions will look to us like dragging the point at 1 all the way to this projected version of q, while the jk circle gets rotated 135 degrees, according to our right-hand rule. Multiplication by any other quaternion is completely similar. For example, let's see what it looks like for j to act on other quaternions by multiplication from the left. The circle through 1 and j, which we see projected as a line through the origin, gets rotated 90 degrees, dragging 1 up to j, so j times 1 is 1 and j times j is negative 1. The circle perpendicular to that one, passing through i and k, gets rotated 90 degrees according to this right-hand rule, where you point your thumb from 1 to j, so j times i is negative k, and j times k is i. In general, for any other unit quaternion you see somewhere in space, start by drawing the unit circle passing through 1, q, and negative 1, which we see in our projection as a line through the origin. Then draw the circle perpendicular to that 1 on what we see as the unit sphere. You rotate the first circle so that 1 ends up where q was, and rotate the perpendicular circle by the same amount according to the right-hand rule. One thing worth noticing here is that order of multiplication matters. It's not, as mathematicians would say, commutative. For example, i times j is k, which you might think of in terms of i acting on the quaternion j, rotating it up to k, but if you think of j as acting on i, j times i, it rotates i to negative k. In fact, commutativity, this ability to swap the order of multiplication, is a way more special property than a lot of people realize. And most groups of actions on some space don't have it. It's like how in solving a Rubik's cube, order matters a lot, or how rotating a cube about the z-axis and then about the x-axis gives a different final state from rotating it about the x-axis, then about the z-axis. And last, as one final but rather important point, so far I've shown you how to think about quaternions as acting by left multiplication, where when you read an expression like i times j, you think of i as a kind of function morphing all of space, and j is just one of the points that it's acting on. But you can also think of them as a different sort of action, by multiplying from the right, where in this expression, j would be acting on i. In that case, the rule for multiplication is very similar. It's still the case that 1 goes to j, and j goes to negative 1, etc., but instead of applying the right-hand rule to the circle perpendicular to the 1j circle, you would use your left hand. So either way, i times j is equal to k, but you can either think about this with your right hand curling the number j to the number k as your thumb points from 1 to i, or as your left hand curling i to k as its thumb points from 1 to j. Understanding this left-hand rule for multiplication from the other side will be extremely useful for understanding how unit quaternions describe rotation in three dimensions. And so far, it's probably not clear how exactly quaternions do describe 3D rotation. I mean, if you consider one of these actions on the unit sphere, passing through i, j, and k, it doesn't leave that sphere in place, it morphs it out of position. So the way that this works is slightly more complicated than a single quaternion product. It involves a process called conjugation, and I'll make a full follow-on video all about it so that we have the time to go through some examples. In the meantime, for more information on the story of quaternions and their relation to orientation in 3D space, Quanta, a mathematical publication I'm sure a lot of you are familiar with, just put out a post in a kind of loose conjunction with this video. Link in the description. If you enjoyed this, consider sharing it with some friends, and if you felt like the narrative structure here was actually helpful for understanding, maybe reassure those friends who would be turned off by a large timestamp that good math is actually worth the time. And many thanks to the patrons among you. I actually spent way longer than I care to admit on this project, so your patience and support is especially appreciated this time around.

================================================================================
VIDEO ID: Qe6o9j4IjTo
TITLE: Q&A with Grant Sanderson (3blue1brown)
URL: https://www.youtube.com/watch?v=Qe6o9j4IjTo
PUBLISHED: 2018-08-24T16:34:02Z
STATUS: SUCCESS
================================================================================
What is a Grobner Basis? If that is your intent for what this Q&A episode is going to be,  as far as technicality and deep explanation is concerned,  you're going to be grossly disappointed. Same goes to whoever asked about what the Fourier  Transform has to do with quantum computing. I can say at a high level it's because the Fourier Transform gives  you a unitary operation, and quantum computing is very fast when  it comes to anything that can be expressed as a unitary matrix. But those words won't make sense if you don't already know what it means,  and this is not at all meant to be a video that's going to go into some deep math  explanation. But when I do cover quantum computing, which I will at some point... What would you do professionally if it weren't  for YouTube slash what are you doing professionally? So a lot of you might know I used to work for Khan Academy,  and I think if I wasn't doing this, I would definitely seek out some other way of  doing math outreach online. The intent of the question is maybe more what  would I do that has nothing to do with math outreach. I spent a lot of time doing random software engineering things through college. Like my summer internships were often spent at a tech company,  rather than doing something explicitly math related. But if I really turn on that parallel universe machine,  I think going into data science was a very real possibility. One of the internships that I was doing, at the end of it they asked if I wanted to,  instead of going to college again, just stick around and maybe have a full-time job,  and just see what unfolded there. And I seriously considered it, you know, it's pretty compelling. Ultimately the love for pure math won out, so  I did go back to school as you're supposed to. But I kind of do wonder what would have been if  instead I went that professional data science route. How arbitrary do you think our mathematical perspective is as humans on Earth? If an alien civilization developed math from scratch,  do you think we would see clearer similarities in their development of the fields? Like number theory, trigonometry, and calculus. So this is an interesting question because it cuts  right to the heart of is math invented or discovered? And I like the phrasing where you kind of imagine an  alien civilization coming and comparing your math to theirs. It's hard to speculate on this, right? Like I have no idea. Some aliens came, we have no way of knowing whether  their math would look completely different from ours. One thing you can be pretty sure of, and this might seem superficial,  is that the notation would be entirely different, right? There's a lot of arbitrary choices in how we write things down. Newton's notation for calculus versus Leibniz notation for calculus. You know, a lot of the really silly things we have,  like which side of the variable the function goes on. Writing out the letters s-i-n for sine, cosine. I had the whole triangle of power video about notations for radicals and exponentials. And on the one hand that might not feel substantive,  but I think it's really interesting to contemplate other ways where the notation shapes  the way that we think about it and shapes the axioms and theorems we even choose more  so than we give it credit for. So a project I'm actively working on right now is about quaternions. And I was a little bit surprised to learn how up in the air the potential  notations and conventions for teaching students about vectors was. Like a lot of the actual notation and terminology we have for vectors and cross  products dot products the way we think of them in 3D ultimately stems from quaternions. You know, even the fact that we use i, j, and k as letters to represent the x,  y, and z directions. And if Hamilton had had his way, we would still teach engineering students primarily  about quaternions and then things like the dot product and cross product would be  viewed as subsets of what the quaternions do and what quaternion multiplication is. And I think there's a compelling case to be made for the fact that  we would use that if we could visualize four dimensions better. But the reason that quaternions never really won out as the notation du  jour is because they're confusing because no one really understood them. There's all sorts of hilarious quotes from Lord Kelvin and the like about how quaternions  are just needlessly confuddling when you're trying to phrase some fact about the universe. Like Maxwell's equations were originally written much  more quaternionically than we teach them to students now. And arguably they're much more elegant that way,  but it's confusing because we can't visualize it. So I think if you had some alien civilization that came but they had a very  good spatial conception for four dimensions, they would look at our vector  notation and think that it was not capturing the deeper realities of math. Arguably, who knows? What do you think is the main thing that drives people away from math? Always hard to answer on these kind of things,  but I really suspect that as soon as you wrap something in a certain kind of judgment  of there's a notion of being correct or incorrect or an implicit statement there's  a notion of being good at math. Some people are math people, some people aren't math people. As soon as you get someone identifying that they're not a math person,  first you know insinuating that that even makes sense and then insinuating  that they fall into that, like of course you're not going to like it. Of course your natural mind churnings aren't going to go in  the direction of some puzzle because you'd much rather think  about things that you're good at and that make you feel happy. All of the latest stuff about growth mindsets and  Carol DeWack and Joe Bowler are really behind that. You know, the idea that if you're trying to tell a student something about how  they're doing with math rather than framing it around, oh you must be so smart, right? Frame it around, oh you must have worked very  hard or you must have put a lot of time into that. There's a lot of much less judgmental things that we have out there, like reading. Even though there's some notions of reading comprehension tests for  students in school and you know you're reading at an eighth grade level,  people usually aren't like, oh I'm not a reading person, right? Like I, those words like some people that just make sense to  them but for me those letters I don't know how they come together. When it comes to contest math like the AMC, I think those  can be really good for high schoolers as a bank of problems. I think they can be really bad for high schoolers as an insinuation of there's  some like top-tier math folk and they can do these problems really quickly. But if you give the same questions to the student and you say  rather than being forced to go through all of these in 75 minutes,  you say let's spend 30 minutes on just one of them, right? Really delving into it. They're really solid problems that kind of engage in the spirit  of problem solving and you know removing that judgmental aspect,  removing that time aspect, I think you know that can help out a lot. A lot of people ask about certain things that I've  made promises for but haven't necessarily delivered on. In a recent video, you know, I did one on divergence and curl  and I mentioned at the end an example of using complex numbers  to model fluid flow and a certain model for flow around a wing. And you might notice I have yet to actually put out a video on that and I've  certainly seen a number of commenters you know hampering on me for that fact. If there's ever a thing that I promise and then I don't make a video on it,  it's probably because I spent a good amount of time trying to write a  script for it that I just didn't feel was compelling for whatever reason. And I think maybe the granddaddy here is the probability series,  which at the moment I have five videos that I've made that are you know released  to patrons. I don't, I just don't feel great about them and I kind of want the stuff  that I put out to you guys to be something I feel is you know if not original,  something that wouldn't be out there otherwise from other creators. And there's a lot of good probability material online. I will probably do something to release the material that I have,  either just as it is but on some second channel with the acknowledgement,  hey this isn't the greatest work I think I've done,  or trying to rework them and make them standalones. But as far as you know essence of blank content,  I feel much clearer about how I would want to extend the linear algebra  series rather than spinning my wheels on certain scripts and animations  that I ultimately don't think are going to deliver something to you guys  that I would feel proud of. Do you have any questions, Jabril? I'm just reading from, reading from some Reddit ones here, but we do something live. How much compromise if any do you have to give with like what  you can animate versus like what your script is trying to convey? Usually if I can't animate a thing, and it's a mathematical thing,  it's not like a frivolous cartoonish type thing,  I change the tool so that it can animate that thing right and then  that might take more time. And it's possible that subconsciously that means I resist  topics that I know would be more difficult to animate. I don't think that happens, I like to use that to encourage creation of new things right,  like on the divergence curl didn't have good fluid flow stuff  but it was fun to play around with that. For quaternions right now I think there's a lot of 3D related things that  I wanted to sort of upgrade because the previous way I was doing a lot  of 3D animations was clunky and not as extensible as I wanted it to be. So usually that is a good excuse to just improve the graphics tool. We have somewhere a question on here, what sort of music do you listen to? Which I mostly wanted to answer to like mention my renewed love for the Punch Brothers. I don't know if any of you know about them, they're actually super weird,  they're like a avant-garde bluegrass band. It's just five geniuses who get together and put out phenomenal art,  so can't complain about that. How do you compare making your videos to making videos for Khan Academy? So very different processes right, like Khan Academy you imagine  sitting next to someone and tutoring them and just explaining it,  you're writing everything by hand, for the most part you do it live. On this channel I obviously script things, I put  a lot of time into creating the visuals for it. Sometimes in a way that makes me feel you know if at Khan  Academy I could sit down and make like three videos in an  afternoon and here it's taking me like three weeks to do one video. You know, which of these actually carries more of an impact. I think there's a proper balance for both of them and I think there's a lot of people  out there who do the Khan style stuff to include Khan Academy but also many others. The way I like to think about things is what wouldn't happen if I wasn't doing it? But there is that little part of me that thinks maybe I should start some  sort of second channel of the super cheap, just like me and a notebook  and a pencil like scrapping through some sort of explanation super quickly. Who makes the awesome music playing in your videos? Vince Rubenetti. Link in the description, link in all of the descriptions actually,  he does really good work and just go you know download some of the music  and leave him a little tip if you feel like it's something that you enjoy. What is your favorite Palomino?
188
00:09:51,560 --> 00:09:51,200
Palomino? Palomino? Polymono? This one. I'll figure it out later and insert it on the screen. All right folks, thanks for watching, stick around for whenever the next upload is. It's going to be on Quaternions and I hope you like it. This is your close-up and this is your wide. All right.  Does that probably mean I should be looking at the wide one?  Or do I do a dramatic like camera number two?

================================================================================
VIDEO ID: pQa_tWZmlGs
TITLE: Why slicing a cone gives an ellipse (beautiful proof)
URL: https://www.youtube.com/watch?v=pQa_tWZmlGs
PUBLISHED: 2018-08-01T15:13:51Z
STATUS: SUCCESS
================================================================================
Suppose you love math, and you had to choose just one proof to show someone to explain  why it is that math is beautiful, something that can be appreciated by anyone from a wide  range of backgrounds while still capturing the spirit of progress and cleverness in math. What would you choose? After I put out a video on Feynman's Lost Lecture about why planets orbit in ellipses,  published as a guest video over on MinutePhysics,  someone on Reddit asked about why the definition of an ellipse given in that video,  the classic two thumbtacks and a piece of string construction,  is the same as the definition involving slicing a cone. Well, my friend, you've asked about one of my all-time favorite proofs,  a lovely bit of 3D geometry which, despite requiring almost no background,  still captures the spirit of mathematical inventiveness. For context and to make sure we're all on the same page,  there are at least three main ways you could define an ellipse geometrically. One is to say you take a circle and stretch it out in one dimension. For example, maybe you consider all of the points as xy coordinates,  and you multiply just the x coordinate by some special factor for all the points. Another is the classic two thumbtacks and a piece of string construction,  where you loop a string around two thumbtacks stuck into a piece of paper,  pull it taut with a pencil, and trace around, keeping the string taut the whole time. What you're drawing by doing this is the set of all points so that the sum of  the distances from each pencil point to the two thumbtack points stays constant. Those two thumbtack points are each called a focus of the ellipse,  and what we're saying here is that this constant focal sum  property can be used to define what an ellipse even is. And yet another way to define an ellipse is to slice a cone with a plane at an angle,  an angle that's smaller than the slope of the cone itself. The curve of points where this plane and the cone intersect forms an ellipse,  which is why you'll often hear ellipses referred to as a conic section. Of course, an ellipse is not just one curve, it's a family of curves,  ranging from a perfect circle up to something that's infinitely stretched. The specific shape of an ellipse is typically quantified with a number called  its eccentricity, which I sometimes just read in my head as squishification. A circle has eccentricity 0, and the more squished the ellipse is,  the closer its eccentricity is to the number 1. For example, Earth's orbit has an eccentricity 0.0167, very low squishification,  meaning it's really close to just being a circle,  while Halley's comet has an orbit with eccentricity 0.9671, very high squishification. In the thumbtack definition of an ellipse, based on the constant  sum of the distances from each point to the two foci,  this eccentricity is determined by how far apart the two thumbtacks are. Specifically, it's the distance between the foci  divided by the length of the longest axis of the ellipse. For slicing a cone, the eccentricity is determined  by the slope of the plane you used for the slicing. And you might justifiably ask, especially if you're a certain reddit user,  why on Earth should these three definitions have anything to do with each other? I mean, sure, it kind of makes sense that each should produce some vaguely  oval-looking stretched out loop, but why should the family of curves produced  by these three totally different methods be precisely the same shapes? In particular, when I was younger I remember feeling really  surprised that slicing a cone would produce such a symmetric shape. You might think that the part of the intersection farther down  would kind of bulge out and produce a more lopsided egg shape. But nope, the intersection curve is an ellipse,  the same evidently symmetric curve you'd get by just stretching a circle or  tracing around two thumbtacks. But of course, math is all about proofs, so how do you give an airtight  demonstration that these three families of curves are actually the same? For example, let's focus our attention on just one of these equivalences,  namely that slicing a cone will give us a curve that could also be drawn using the  thumbtack construction. What you need to show here is that there exist two thumbtack points somewhere inside that  slicing plane such that the sum of the distances from any point of the intersection curve  to those two points remains constant, no matter where you are on that intersection curve. I first saw the trick to showing why this is true in Paul Lockhart's  magnificent book Measurement, which I would highly recommend to anyone  young or old who needs a reminder of the fact that math is a form of art. The stroke of genius comes in the very first step,  which is to introduce two spheres into this picture,  one above the plane and one below it, each one of them sized just right  so as to be tangent to the cone along a circle of points,  and tangent to the plane at just a single point. Why you would think to do this, of all things,  is a tricky question to answer, and one that we'll turn back to. For right now, let's just say that you have a particularly playful mind  that loves engaging with how different geometric objects all fit together. But once these spheres are sitting here, I actually  bet that you could prove the target result yourself. Here, I'll help you step through it, but at any point if you feel inspired,  please do pause and try to carry on without me. First off, these spheres have introduced two special points inside the curve,  the points where they're tangent to the plane. So a reasonable guess might be that these two tangency points are the focus points. That means that you're going to want to draw lines from these foci to some  point along the ellipse, and ultimately the goal is to understand what  the sum of the distances of those two lines is,  or at the very least to understand why that sum doesn't depend on where  you are along the ellipse. Keep in mind, what makes these lines special is that each one does not simply touch  one of the spheres, it's actually tangent to that sphere at the point where it touches. And in general, for any math problem, you want to  use the defining features of all the objects involved. Another example here is what even defines the spheres. It's not just the fact that they're tangent to the plane,  but that they're also tangent to the cone, each one at some circle of tangency points. So you're going to need to use those two circles of tangency points in some way. But how exactly? One thing you might do is just draw a line straight from  the top circle down to the bottom one along the cone. And there's something about doing this that feels vaguely reminiscent  of the constant sum thumbtack property, and hence promising. You see, it passes through the ellipse, and so by snipping that line  at the point where it crosses the ellipse, you can think of it as the  sum of two line segments, each one hitting the same point on the ellipse. And you can do this through various different points of the ellipse,  depending on where you are around the cone, always getting two line segments with a  constant sum, namely whatever the straight line distance from the top circle to the  bottom circle is. So you see what I mean about it being vaguely analogous to the thumbtack property,  in that every point of the ellipse gives us two distances whose sum is a constant. Granted, these lengths are not to the focal points,  they're to the big and the little circle, but maybe that leads you to making  the following conjecture. The distance from a given point on this ellipse, this intersection curve,  straight down to the big circle is, you conjecture,  equal to the distance to the point where that big sphere is tangent to the plane,  our first proposed focus point. Likewise, perhaps the distance from that point on the ellipse to  the small circle is equal to the distance from that point to the  second proposed focus point, where the small sphere touches the plane. So is that true? Well, yes! Here, let's give a name to that point we have on the ellipse, q. The key is that the line from q to the first proposed focus is tangent to the big sphere,  and the line from q straight down along the cone is also tangent to the big sphere. Here, let's look at a different picture for some clarity. If you have multiple lines drawn from a common point to a sphere,  all of which are tangent to that sphere, you can probably see,  just from the symmetry of the setup, that all of these lines have to have the same length. In fact, I encourage you to try proving this yourself,  or to otherwise pause and ponder on the proof I've left on the screen. But, looking back at our cone slicing setup, your conjecture would be correct. The two lines extending from the point q on the  ellipse tangent to the big sphere have the same length. Similarly, the line from q to the second proposed focus point  is tangent to the little sphere, as is the line from q straight up along the cone,  so those two also have the same length. And so, the sum of the distances from q to the two proposed focus  points is the same as the straight line distance from the little  circle down to the big circle along the cone, passing through q. And clearly, that does not depend on which point of the ellipse you chose for q. Bada-boom-bada-bang, slicing the cone is the same as the thumbtack construction,  since the resulting curve has the constant focal sum property. Now this proof was first found by Germenal, Germenal, Germenal, who cares, Dandelin,  a guy named Dandelin in 1822, so these two spheres are sometimes called Dandelin spheres. You can also use the same trick to show why slicing a cylinder at an angle will give you  an ellipse, and if you're comfortable with the claim that projecting a shape from one  plane onto another tilted plane has the effect of simply stretching out that shape,  this also shows why the definition of an ellipse as a stretched circle is the same as the  other two. More homework. So why do I think this proof is such a good representative for math itself? That if you had to show just one thing to explain to a non-math  enthusiast why you love the subject, why this would be a good candidate. The obvious reason is that it's substantive and beautiful without  requiring too much background, but more than that,  it reflects a common feature of math that sometimes there is no single  most fundamental way of defining something, that what matters more is  showing equivalences. And even more than that, the proof itself involves one key moment  of creative construction, adding the two spheres,  while most of it leaves room for a nice systematic and principled approach. And this kind of creative construction is, I think,  one of the most thought-provoking aspects of mathematical discovery,  and you might understandably ask where such an idea comes from. In fact, talking about this particular proof,  here's what Paul Lockhart says in Measurement. I agree, but I think we can say at least a little something more about this. While it is ingenious, we can perhaps decompose how someone who  has immersed themselves in a number of other geometry problems  might be particularly primed to think of adding these specific spheres. First, a common tactic in geometry is to relate one length to another,  and in this problem, you know from the outset that being able to relate these two  lengths to the foci to some other two lengths, especially ones that line up,  would be a useful thing, even though at the start you don't even know where the  focus points are. And even if it's not clear exactly how you'd do that,  throwing spheres into the picture isn't all that crazy. Again, if you've built up a relationship with geometry through practice,  you would be well acquainted with how relating one length to another happens  all the time when the circles and spheres are in the picture,  because it cuts straight to the defining feature of what it even means to be  a circle or a sphere. This is obviously a specific example, but the point I want to  make is that you can often view glimpses of ingeniousness not as inexplicable miracles,  but as the residue of experience. And when you do, the idea of genius goes from being  mesmerizing to instead being actively inspirational.

================================================================================
VIDEO ID: VcgJro0sTiM
TITLE: Other math channels you'd enjoy
URL: https://www.youtube.com/watch?v=VcgJro0sTiM
PUBLISHED: 2018-06-27T16:29:07Z
STATUS: SUCCESS
================================================================================
This is almost surreal to say, but the channel recently
passed 1 million subscribers! And I know what
you're thinking: "just 48,576 more to go
before the next big milestone!" And indeed, I'll hold off proper
celebrations until then. But, you know, seeing that seventh digit really
does make you reflect on what led to this point. And if I'm being honest, a lot of the growth for this
channel just had to do with some very kind people
sharing and promoting the content, both in terms of certain specific
shoutouts from creators with big audiences, and in terms of individuals
just sharing with their friends, so what I want to do now is take a moment to let
you all know about a few other math creators online who I think you
would like a lot. There's just so much good creation that
happens under a lot of people's radars. First up, we have the channel "Think Twice". I honestly have no idea why this channel isn't
better known among online math communities. It contains these really
beautifully done math animations, and if you like this channel, you're definitely gonna like it. You absolutely get the sense
looking at any one of these that it comes from someone who
thinks very visually about math. Naturally, this often takes the
form in some very pretty geometry or some algebraic results that
are explained geometrically, and the focus tends to be a little bit more
short form and bite-sized pieces, so if you ever want a quick little
reminder of why math is beautiful, This is just a great
channel to pop over to. Here, let me just let a couple more
of these animations just play out. Next up, I'd recommend you check out
LeiosOS, run by James Schloss. what I like about James is that he seems to think
first and foremost about community, and creating content seems to be more of
a vehicle for bringing people together online. Let me turn things over to him to explain
what it's all about, both on and off YouTube. James Schloss: LeiosOS is fundamentally a channel about
algorithms and works with the Arcane Algorithm Archive, an open source and collaborative effort to document every
algorithm in existence in every language possible. We're just getting started and it's
obviously an impossible goal, but that's half the fun. This means that we cover a range of different
topics and here are some clips of the videos. Any light that enters a lens leaves on the other side
of the lens with the same angle it came in with. it's almost as if the light
never entered the lens at all, and hence the name,
the invisible lens. If we take any arbitrary matrix, say, the identity
matrix with zeros along the ð‘¤-dimension, the rotation doesn't
look quite right. This is because most tesseract
depictions use stereographic projections, which resemble the act of holding
a light source behind an object and checking a shadow
against the screen. Here, we divide our points into smaller packages and
use the Graham Scan to find their convex holes. We then take the vertices from the
holes and plug them into the Jarvis March to create a wrapped 
gift of wrapped gifts. This is, of course, just a small subset
of the types of videos on our channel. Quickly, I would like to thank Grant for
making such amazing videos on 3Blue1Brown. It's inspiring to see such a
large and dedicated community attempting to understand
the true beauty of mathematics. You guys are honestly amazing, so even if I don't see you guys again, please keep being such
an awesome community. Grant Sanderson: For my part, I think it would be
awesome to see this algorithm's archive grow more. both of the last two, at least on
YouTube, have shorter form content, So, next, let's switch to a channel
with more of a long-form focus: Welch Labs, run by Stephen Welch. Now, I suspect many of you already
know about Stephen's work, for example, the excellent series
"Imaginary Numbers are Real". But there are many other great playlists from the
channel that you should absolutely take a look at. In fact, one of the things I like
most about this channel is that Stephen thinks in terms of series
rather than in terms of individual videos. And each one of them includes clear
points where the viewer can engage with the materials more than just
through a passive viewing experience, often including workbooks
and associated PDFs, so the focus really is on learning
more so than just entertainment. To get a feel here, let me just play some snippets from the start and then
from the end of his "Imaginary Numbers are Real" series, which should give you a pretty good
feel for the style in the scope, and I'll also throw in a snippet
from his series on machine learning. Stephen Welch: Algebraically, this new
dimension has everything to do with a problem that was considered
impossible for over 2,000 years: The square root of negative one. When we include this missing
dimension in our analysis, our parabola gets
WAY more interesting. Now that our input numbers are
in their full two dimensional form, We can see how our
function xÂ²+1 really behaves. Our function does
cross the x-axis, We were just looking
in the wrong dimension. So why is this extra dimension that
numbers possessed not common knowledge? Part of the reason is that it has
been given a terrible, terrible name. A name that suggests that
these numbers aren't even real! All right, ready? We'll draw the same
exact paths on ð‘¤ and see how they show up on our Riemann
surface as they are mapped to our ð‘§-plane. [upbeat techno music] So, why does our green path start out at one
location on our ð‘§-plane only to end up in another? Simply because our green path leads
us to the other layer of our surface. From the perspective of our ð‘¤-plane, it appears that
we've returned exactly to our starting point. But actually, we haven't. The ð‘¤-plane is just a projection; a shadow. In reality, our path has led us to a
completely different branch of our function. [typing] This is a decision tree. Right now, it's learning. When it's done, it'll have learned
to do something very human, something that everyone knows how to do,
but no one can quite explain how they do it, something that is fooled
generations of brilliant scientists with its apparent simplicity,
but practical complexity. something that has only become
possible in the last few decades thanks to creative solutions
in the face of huge complexity: it's learning to see. Let's test it out. With the help of a
camera and a computer, our decision tree sees exactly
how many fingers were holding up. Now, depending on
who you are, the fact that a machine can perform this
task may be completely mind-blowing, not all that out
of the ordinary, or may not even be
all that impressive. The good news here is
whichever camp you're in, you're in good company. Our finger counting machine is a simple example that
belongs to a deceptively complex class of problems, problems that arise from
thinking about how we think. Grand Sanderson: And finally, turning
away from the YouTube world, I want to highlight the blog
"Infinity Plus One". The tone of the writing and the associated
visuals are both delightfully playful, but the author James Dilts manages to get in some
pretty substantive math all while keeping it accessible. A particularly good sequence of posts is the
one he did on relativity, both special and general, and it's a little hard to directly feature
text posts and video forms, but I'll leave you some links in the
description to some of my favorite posts, and, of course, the description also has links for
the other three creators mentioned here.

================================================================================
VIDEO ID: rB83DpBJQsE
TITLE: Divergence and curl:  The language of Maxwell's equations, fluid flow, and more
URL: https://www.youtube.com/watch?v=rB83DpBJQsE
PUBLISHED: 2018-06-21T18:34:59Z
STATUS: SUCCESS
================================================================================
Today, you and I are going to get into divergence and curl. To make sure we're all on the same page, let's begin by talking about vector fields. Essentially a vector field is what you get if you associate  each point in space with a vector, some magnitude and direction. Maybe those vectors represent the velocities of particles of fluid  at each point in space, or maybe they represent the force of gravity  at many different points in space, or maybe a magnetic field strength. Quick note on drawing these, often if you were to draw the vectors to scale,  the longer ones end up just cluttering up the whole thing,  so it's common to basically lie a little and artificially shorten ones that are too long,  maybe using color to give some vague sense of length. In principle, vector fields in physics might change over time. In almost all real-world fluid flow, the velocities of particles in a given  region of space will change over time in response to the surrounding context. Wind is not a constant, it comes in gusts. An electric field changes as the charged particles characterizing it move around. But here we'll just be looking at static vector fields,  which maybe you think of as describing a steady-state system. Also, while such vectors could in principle be three-dimensional,  or even higher, we're just going to be looking at two dimensions. An important idea which regularly goes unsaid is that you can often  understand a vector field which represents one physical phenomenon  better by imagining what if it represented a different physical phenomenon. What if these vectors describing gravitational force instead defined a fluid flow? What would that flow look like? And what can the properties of that flow tell us about the original gravitational force? And what if the vectors defining a fluid flow were thought  of as describing the downhill direction of a certain hill? Does such a hill even exist? And if so, what does it tell us about the original flow? These sorts of questions can be surprisingly helpful. For example, the ideas of divergence and curl are particularly viscerally understood  when the vector field is thought of as representing fluid flow,  even if the field you're looking at is really meant to describe something else,  like an electric field. Here, take a look at this vector field, and think of each  vector as describing the velocity of a fluid at that point. Notice that when you do this, that fluid behaves in a very strange, non-physical way. Around some points, like these ones, the fluid seems to just spring  into existence from nothingness, as if there's some kind of source there. Some other points act more like sinks, where the  fluid seems to disappear into nothingness. The divergence of a vector field at a particular point of the plane tells you  how much this imagined fluid tends to flow out of or into small regions near it. For example, the divergence of our vector field evaluated at all  of those points that act like sources will give a positive number. And it doesn't just have to be that all of the fluid is flowing away from that point. The divergence would also be positive if it was just that the fluid coming  into it from one direction was slower than the flow coming out of it in another  direction, since that would still insinuate a certain spontaneous generation. Now on the flip side, if in a small region around a point there seems to be more fluid  flowing into it than out of it, the divergence at that point would be a negative number. Remember, this vector field is really a function that takes  in 2-dimensional inputs and spits out 2-dimensional outputs. The divergence of that vector field gives you a new function,  one that takes in a single 2d point as its input,  but its output depends on the behavior of the field in a small  neighborhood around that point. In this way it's analogous to a derivative, and that output is just a single number,  measuring how much that point acts as a source or a sink. I'm purposely delaying discussion of computations here,  the understanding for what it represents is more important. Notice, this means that for an actual physical fluid,  like water rather than some imagined one used to illustrate an arbitrary vector field,  then if that fluid is incompressible, the velocity vector field must have a divergence  of zero everywhere. That's an important constraint on what kinds of vector  fields could solve real-world fluid flow problems. For the curl at a given point, you also think about the fluid flow around it,  but this time you ask how much that fluid tends to rotate around the point. As in, if you were to drop a twig in the fluid at that point,  somehow fixing its center in place, would it tend to spin around? Regions where that rotation is clockwise are said to have positive curl,  and regions where it's counterclockwise have negative curl. It doesn't have to be that all the vectors around the input are  pointing counterclockwise, or all of them are pointing clockwise. A point inside a region like this one, for example, would also have non-zero curl,  since the flow is slow at the bottom, but quick up top,  resulting in a net clockwise influence. And really, true proper curl is a three-dimensional idea,  one where you associate each point in 2d space with a new vector characterizing  the rotation around that point, according to a certain right-hand rule,  and I have plenty of content from my time at Khan Academy describing this in more  detail if you want, but for our main purpose, I'll just be referring to the  two-dimensional variant of curl, which associates each point in 2d space with a  single number rather than a new vector. As I said, even though these intuitions are given in the context of fluid flow,  both of these ideas are significant for other sorts of vector fields. One very important example is how electricity and  magnetism are described by four special equations. These are known as Maxwell's equations, and they're  written in the language of divergence and curl. This top one, for example, is Gauss's law, stating that the divergence of an  electric field at a given point is proportional to the charge density at that point. Unpacking the intuition for this, you might imagine positively charged regions  as acting like sources of some imagined fluid,  and negatively charged regions as being the sinks of that fluid,  and throughout parts of space where there is no charge,  the fluid would be flowing incompressibly, just like water. Of course, there's not some literal electric fluid,  but it's a very useful and pretty way to read an equation like this. Similarly, another important equation is that the divergence of the  magnetic field is zero everywhere, and you can understand that by  saying that if the field represents a fluid flow,  that fluid would be incompressible, with no sources and no sinks, it acts just like water. This also has the interpretation that magnetic monopoles,  something that acts just like a north or south end of a magnet in isolation,  don't exist, there's nothing analogous to positive and negative charges in  an electric field. Likewise, the last two equations tell us that the way one of  these fields changes depends on the curl of the other field. And really, this is a purely three-dimensional idea,  and a little outside of our main focus here, but the point is that  divergence and curl arise in contexts that are unrelated to flow,  and side note, the back and forth from these last two equations is what  gives rise to light waves. And quite often, these ideas are useful in contexts  which don't even seem spatial in nature at first. To take a classic example that students of differential equations often study,  let's say that you wanted to track the population sizes of two different species,  where maybe one of them is a predator of another. The state of this system at a given time, meaning the two population sizes,  could be thought of as a point in two-dimensional space,  what you would call the phase space of this system. For a given pair of population sizes, these populations may be  inclined to change based on things like how reproductive are the two species,  or just how much does one of them enjoy eating the other one. These rates of change would typically be written  analytically as a set of differential equations. It's okay if you don't understand these particular equations,  I'm just throwing them up for those of you who are curious,  and because replacing variables with pictures makes me laugh a little bit. But the relevance here is that a nice way to visualize what such a set of  equations is really saying is to associate each point on the plane,  each pair of population sizes, with a vector, indicating the rates of change  for both variables. For example, when there are lots of foxes, but relatively few rabbits,  the number of foxes might tend to go down because of the constrained food supply,  and the number of rabbits might also tend to go down because they're getting  eaten by all of the foxes, potentially at a rate that's faster than they can reproduce. So a given vector here is telling you how, and how quickly,  a given pair of population sizes tends to change. Notice, this is a case where the vector field is not about physical space,  but instead it's a representation of a certain dynamic system that has two variables,  and how that system evolves over time. This can maybe also give a sense for why mathematicians  care about studying the geometry of higher dimensions. What if our system was tracking more than just two or three numbers? The flow associated with this field is called the phase flow for  our differential equation, and it's a way to conceptualize,  at a glance, how many possible starting states would evolve over time. Operations like divergence and curl can help to inform you about the system. Do the population sizes converge towards a particular pair of numbers,  or are there some values they diverge away from? Are there cyclic patterns, and are those cycles stable or unstable? To be perfectly honest with you, for something like this you'd often want to bring  in related tools beyond just divergence and curl, those would give you the full story,  but the frame of mind that practice with these two ideas brings you carries over  well to studying setups like this with similar pieces of mathematical machinery. If you really want to get a handle on these ideas,  you'd want to learn how to compute them and practice those computations,  and I'll leave links to where you can learn about this and practice if you want. Again, I did some videos and articles and worked examples for Khan Academy on this  topic during my time there, so too much detail here will start to feel redundant for me. But there is one thing worth bringing up, regarding  the notation associated with these computations. Commonly, the divergence is written as a dot product between this upside-down triangle  thing and your vector field function, and the curl is written as a similar cross product. Sometimes students are told that this is just a notational trick,  each computation involves a certain sum of certain derivatives,  and treating this upside-down triangle as if it was a vector of derivative operators can  be a helpful way to keep everything straight. But it is actually more than just a mnemonic device,  there is a real connection between divergence and the dot product,  and between curl and the cross product. Even though we won't be doing practice computations here,  I would like to give you at least some vague sense for how these four ideas are connected. Imagine taking some small step from one point of your vector field to another. The vector at this new point will likely be a little different from the one  at the first point, there will be some change to the function after that step,  which you might see by subtracting off your original vector from that new one. And this kind of difference to your function over  small steps is what differential calculus is all about. The dot product gives you a measure of how aligned two vectors are, right? The dot product of your step vector with that difference vector it causes  tends to be positive in regions where the divergence is positive, and vice versa. In fact, in some sense, the divergence is a sort of average value for  this dot product of a step with a change to the output it causes over  all possible step directions, assuming that things are rescaled appropriately. I mean, think about it, if a step in some direction causes a change to that vector in  that same direction, this corresponds to a tendency for outward flow,  for positive divergence. And on the flip side, if those dot products tend to be negative,  meaning the difference vector is pointing in the opposite direction from the step vector,  that corresponds with a tendency for inward flow, negative divergence. Similarly, remember that the cross product is a sort of measure for how perpendicular  two vectors are, so the cross product of your step vector with the difference vector  it causes tends to be positive in regions where the curl is positive, and vice versa. You might think of the curl as a sort of average  of this step vector difference vector cross product. If a step in some direction corresponds to a change perpendicular to that step,  that corresponds to a tendency for flow rotation. So, typically this is the part where there might be some kind of sponsor message. But one thing I want to do with the channel moving ahead is to stop doing sponsored  content, and instead make things just about the direct relationship with the audience. I mean that not only in the sense of the funding model,  with direct support through Patreon, but also in the sense that I think these videos  can better accomplish their goal if each one of them feels like it's just about you  and me sharing in a love of math, with no other motive,  especially in the cases where the viewers are students. There are some other reasons, and I wrote up some of my full thoughts on this over on  Patreon, which you certainly don't have to be a supporter to read,  that's just where it lives. I think advertising on the internet occupies a super wide spectrum,  from truly degenerate clickbait up to genuinely well-aligned win-win-win partnerships. I've always taken care only to do promotions for  companies that I would genuinely recommend. To take one example, you may have noticed that I did a number of promos for Brilliant,  and it's really hard to imagine better alignment than that. I try to inspire people to be interested in math,  but I'm also a firm believer that videos aren't enough,  that you need to actively solve problems, and here's a platform that provides practice. And likewise for any others I've promoted too, I always make sure to feel good alignment. But even still, even if you seek out the best possible partnerships,  whenever advertising is in the equation, the incentives will  always be to try reaching as many people as possible. But when the model is more exclusively about a direct relationship with the audience,  the incentives are pointed towards maximizing how valuable  people find the experiences they're given. I think those two goals are correlated, but not always perfectly. I like to think that I'll always try to maximize the value of the  experience no matter what, but for that matter I also like to think  that I can consistently wake up early and resist eating too much sugar. What matters more than wanting something is to actually align incentives. Anyway, if you want to hear more of my thoughts, I'll link to the Patreon post. And thank you again to existing supporters for making this possible,  and I'll see you all next video.

================================================================================
VIDEO ID: CfW845LNObM
TITLE: The other way to visualize derivatives | Chapter 12, Essence of calculus
URL: https://www.youtube.com/watch?v=CfW845LNObM
PUBLISHED: 2018-05-19T14:09:16Z
STATUS: SUCCESS
================================================================================
The months ahead of you hold within them a lot of hard work, some neat examples,  some not-so-neat examples, beautiful connections to physics,  not-so-beautiful piles of formulas to memorize,  plenty of moments of getting stuck and banging your head into a wall,  a few nice aha moments sprinkled in as well, and some genuinely lovely  graphical intuition to help guide you through it all. But if the course ahead of you is anything like my first introduction to calculus,  or any of the first courses I've seen in the years since,  there's one topic you will not see, but which I believe stands to greatly accelerate  your learning. You see, almost all of the visual intuitions from that first year are based on graphs. The derivative is the slope of a graph, the integral is a certain area under that graph. But as you generalize calculus beyond functions whose inputs and outputs are  simply numbers, it's not always possible to graph the function you're analyzing. So if all your intuitions for the fundamental ideas, like derivatives,  are rooted too rigidly in graphs, it can make for a very tall and largely  unnecessary conceptual hurdle between you and the more quote-unquote advanced  topics like multivariable calculus and complex analysis, differential geometry. What I want to share with you is a way to think about derivatives,  which I'll refer to as the transformational view,  that generalizes more seamlessly into some of those more general contexts  where calculus comes up. And then we'll use this alternate view to analyze a fun puzzle about repeated fractions. But first off, I just want to make sure we're all  on the same page about what the standard visual is. If you were to graph a function, which simply takes real numbers as inputs and outputs,  one of the first things you learn in a calculus course is that the derivative gives  you the slope of this graph, where what we mean by that is that the derivative of  the function is a new function which for every input x returns that slope. Now I'd encourage you not to think of this derivative  as slope idea as being the definition of a derivative. Instead think of it as being more fundamentally about how  sensitive the function is to tiny little nudges around the input. And the slope is just one way to think about that sensitivity  relevant only to this particular way of viewing functions. I have not just another video, but a full series on this  topic if it's something you want to learn more about. The basic idea behind the alternate visual for the derivative is to  think of this function as mapping all of the input points on the  number line to their corresponding outputs on a different number line. In this context, what the derivative gives you is a measure of how  much the input space gets stretched or squished in various regions. That is, if you were to zoom in around a specific input and take a look at some  evenly spaced points around it, the derivative of the function of that input is  going to tell you how spread out or contracted those points become after the mapping. Here, a specific example helps. Take the function x2, it maps 1 to 1, 2 to 4, 3 to 9, and so on. You can also see how it acts on all of the points in between. If you were to zoom in on a little cluster of points around the input 1,  and see where they land around the relevant output,  which for this function also happens to be 1, you'd notice that they tend  to get stretched out. In fact, it roughly looks like stretching out by a factor of 2. The closer you zoom in, the more this local behavior looks just like multiplying by a  factor of 2. This is what it means for the derivative of x2 at the input x equals 1 to be  2. It's what that fact looks like in the context of transformations. If you looked at a neighborhood of points around the input 3,  they would get stretched out by a factor of 6. This is what it means for the derivative of this function at the input 3 to equal 6. Around the input 1 fourth, a small region tends to get contracted specifically by a  factor of 1 half, and that's what it looks like for a derivative to be smaller than 1. The input 0 is interesting. Zooming in by a factor of 10, it doesn't really  look like a constant stretching or squishing. For one thing, all of the outputs end up on the right positive side of things. As you zoom in closer and closer, by 100x, or by 1000x,  it looks more and more like a small neighborhood of points around 0 just  gets collapsed into 0 itself. This is what it looks like for the derivative to be 0. The local behavior looks more and more like multiplying the whole number line by 0. It doesn't have to completely collapse everything to a point at a particular zoom level,  instead it's a matter of what the limiting behavior is as you zoom in closer and closer. It's also instructive to take a look at the negative inputs here. Things start to feel a little cramped since they collide with where all the positive  input values go, and this is one of the downsides of thinking of functions as  transformations. But for derivatives, we only really care about the local behavior anyway,  what happens in a small range around a given input. Here, notice that the inputs in a little neighborhood around, say,  negative 2, don't just get stretched out, they also get flipped around. Specifically, the action on such a neighborhood looks more  and more like multiplying by negative 4 the closer you zoom in. This is what it looks like for the derivative of a function to be negative. And I think you get the point, this is all well and good,  but let's see how this is actually useful in solving a problem. A friend of mine recently asked me a pretty fun question about the infinite  fraction 1 plus 1 divided by 1 plus 1 divided by 1 plus 1 divided by 1,  and clearly you watch math videos online, so maybe you've seen this before,  but my friend's question actually cuts to something you might not have  thought about before, relevant to the view of derivatives we're looking at here. The typical way you might evaluate an expression like this is to set it equal to x,  and then notice that there is a copy of the full fraction inside itself. So you can replace that copy with another x, and then just solve for x. That is, what you want is to find a fixed point of the function 1 plus 1 divided by x. But here's the thing, there are actually two solutions for x,  two special numbers where 1 plus 1 divided by that number gives you back the same thing. One is the golden ratio, phi, around 1.618, and the other is negative 0.618,  which happens to be negative 1 divided by phi. I like to call this other number phi's little brother,  since just about any property that phi has, this number also has. And this raises the question, would it be valid to say that the infinite  fraction we saw is somehow also equal to phi's little brother, negative 0.618? Maybe you initially say, obviously not, everything on the left hand side is positive,  so how could it possibly equal a negative number? Well, first we should be clear about what we actually mean by an expression like this. One way you could think about it, and it's not the only way,  there's freedom for choice here, is to imagine starting with some constant, like 1,  and then repeatedly applying the function 1 plus 1 divided by x, and then asking,  what is this approach as you keep going? I mean, certainly symbolically what you get looks more and more  like our infinite fraction, so maybe if you wanted to equal a number,  you should ask what this series of numbers approaches. And if that's your view of things, maybe you start off with a negative number,  so it's not so crazy for the whole expression to end up negative. After all, if you start with negative 1 divided by phi,  then applying this function 1 plus 1 over x, you get back the same number,  negative 1 divided by phi, so no matter how many times you apply it,  you're staying fixed at this value. But even then, there is one reason you should  view phi as the favorite brother in this pair. Here, try this, pull up a calculator of some kind, then start with any random number,  and plug it into this function, 1 plus 1 divided by x,  and plug that number into 1 plus 1 over x, and again, and again, and again, and again. No matter what constant you start with, you eventually end up at 1.618. Even if you start with a negative number, even one that's really close to phi's  little brother, eventually it shies away from that value and jumps back over to phi. So, what's going on here? Why is one of these fixed points favored above the other one? Maybe you can already see how the transformational understanding of derivatives  is helpful for understanding this setup, but for the sake of having a point of contrast,  I want to show you how a problem like this is often taught using graphs. If you were to plug in some random input to this function,  the y value tells you the corresponding output, right? So to think about plugging that output back into the function,  you might first move horizontally until you hit the line y equals x,  and that's going to give you a position where the x value corresponds to your  previous y value, right? So then from there, you can move vertically to see what output this new x value has,  and then you repeat. You move horizontally to the line y equals x to find a point whose x value is the same  as the output you just got, and then you move vertically to apply the function again. Now personally, I think this is kind of an awkward way  to think about repeatedly applying a function, don't you? I mean, it makes sense, but you kind of have to pause  and think about it to remember which way to draw the lines. And you can, if you want, think through what conditions make this spiderweb  process narrow in on a fixed point, versus propagating away from it. In fact, go ahead, pause right now, and try to think it through as an exercise. It has to do with slopes. Or if you want to skip the exercise for something that I think gives a much more  satisfying understanding, think about how this function acts as a transformation. So I'm going to go ahead and start here by drawing a bunch of  arrows to indicate where the various sampled input points will go. And side note, don't you think this gives a neat emergent pattern? I wasn't expecting this, but it was cool to see it pop up when animating. I guess the action of 1 divided by x gives this nice emergent circle,  and then we're just shifting things over by 1. Anyway, I want you to think about what it means to repeatedly apply some function,  like 1 plus 1 over x, in this context. Well after letting it map all of the inputs to the outputs,  you could consider those as the new inputs, and then just apply the same process again,  and then again, and do it however many times you want. Notice, in animating this with a few dots representing the sample points,  it doesn't take many iterations at all before all of those dots kind of clump in around 1. 618. Now remember, we know that 1.618 and its little brother,  negative 0.618 on and on, stay fixed in place during each iteration of this process. But zoom in on a neighborhood around phi. During the map, points in that region get contracted around phi,  meaning that the function 1 plus 1 over x has a derivative with a magnitude less  than 1 at this input. In fact, this derivative works out to be around negative 0.38. So what that means is that each repeated application scrunches the neighborhood  around this number smaller and smaller, like a gravitational pull towards phi. So now tell me what you think happens in the neighborhood of phi's little brother. Over there, the derivative actually has a magnitude larger than 1,  so points near the fixed point are repelled away from it. And when you work it out, you can see that they get  stretched by more than a factor of 2 in each iteration. They also get flipped around, because the derivative is negative here,  but the salient fact for the sake of stability is just the magnitude. Mathematicians would call this right value a stable fixed point,  and the left one is an unstable fixed point. Something is considered stable if when you perturb it just a little bit,  it tends to come back towards where it started, rather than going away from it. So what we're seeing is a very useful little fact,  that the stability of a fixed point is determined by whether or not the magnitude of its  derivative is bigger or smaller than 1. This explains why phi always shows up in the numerical play,  where you're just hitting enter on your calculator over and over,  but phi's little brother never does. As to whether or not you want to consider phi's little brother a  valid value of the infinite fraction, well that's really up to you. Everything we just showed suggests that if you think of this expression  as representing a limiting process, then because every possible seed  value other than phi's little brother gives you a series converging to phi,  it does feel silly to put them on equal footing with each other. But maybe you don't think of it as a limit, maybe the kind of math  you're doing lends itself to treating this as a purely algebraic object,  like the solutions of a polynomial, which simply has multiple values. Anyway, that's beside the point, and my point here is not that viewing derivatives  as this change in density is somehow better than the graphical intuition on the whole. In fact, picturing an entire function this way can be  kind of clunky and impractical as compared to graphs. My point is that it deserves more of a mention in most of the  introductory calculus courses, because it can help make a  student's understanding of the derivative a little more flexible. Like I mentioned, the real reason I'd recommend you carry this perspective  with you as you learn new topics is not so much for what it does with your  understanding of single variable calculus, it's for what comes after.

================================================================================
VIDEO ID: 8GPy_UMV-08
TITLE: The Wallis product for pi, proved geometrically
URL: https://www.youtube.com/watch?v=8GPy_UMV-08
PUBLISHED: 2018-04-20T18:59:28Z
STATUS: SUCCESS
================================================================================
Alright, I think you're going to like this. I want to show you a beautiful result that reveals a surprising connection  between a simple series of fractions and the geometry of circles. But unlike some other results like this that you may have seen before,  this one involves multiplying things instead of adding them up. Now, the video you're about to watch is particularly exciting for us at 3Blue1Brown,  because it came about a little differently from most of the videos that we've done. If you step back and think about it, the value of any kind of  math presentation comes from a combination of the underlying  math and all of the choices that go into how to communicate it. And for almost all of the content on this channel,  the underlying math is something that's well known in the field,  itâ€™s either based on general theory or some particular paper,  and my hope is for the novelty to come from the communication half. And with this video, the result we're discussing, a very famous infinite product for pi,  known as the Wallace product, is indeed well known math. However, what we'll be presenting is, to our knowledge,  a more original proof of this result. For context, after watching our video on the Basel problem, Sweeter,  the new 3b1b member who some of you may remember from the video about color and  winding numbers, well, he spent some time thinking about the approach taken in that  video, as well as thinking about the connection between the Basel problem and the  Wallace product, and he's tumbled into a new proof of the relationship between the  Wallace product and pi. I mean, I'll leave open the possibility that an argument of this style is  hidden somewhere in the literature beyond what our searching pulled up,  but I can at least say that it was found independently,  and that if it does exist out there, it has done a fantastic job hiding  itself from the public view. So, without further ado, let's dive into the math. Consider the product 2 over 1 times 4 over 3 times 6 over 5 on and on and on,  where what we're doing is including all the even numbers as the  numerators and odd numbers as the denominators. Of course, all the factors here are bigger than 1, so as you go through the series,  multiplying each new factor in one by one, the result keeps getting bigger and bigger. In fact, it turns out that it eventually gets bigger than any finite limit,  so in that sense it's not super interesting, it just blows up to infinity. And on the other hand, if you shift things over slightly,  looking at 2 divided by 3 times 4 divided by 5 times 6 divided by 7,  on and on, all of those factors are less than 1,  so the result keeps getting smaller and smaller,  and this time the series turns out to approach 0. But, what if we mixed the two? If you looked at 2 over 1 times 2 over 3 times 4 over 3 times 4 over 5,  on and on like this, where now the partial products along the way keep going  up and then down, and then up and then down, then up a little bit,  and then down a little bit less, until all of these jumps and falls are of  almost no change at all. So now it must be converging to some kind of positive finite value,  but what is that value? Believe it or not, we'll discover that this equals pi divided by 2. And to understand the connection between this product, apparently unrelated to circles,  and pi, we're going to need to take a slight digression through a few geometric tools. It's a productive digression though, since these are some useful ideas  to have in your problem-solving tool belt for all kinds of other math. The setup here involves a circle with many different points evenly spaced around it,  and then one additional special point. This is similar to what we had in the video on the Basel problem,  where we pictured these evenly spaced points as lighthouses,  and thought of that special point as an observer. Back then, the quantity we cared about involved looking at the  distance between the observer and each lighthouse,  then taking the inverse square of each of those distances and adding them all up. This is why we had the whole narrative with lighthouses in the first place,  since the inverse square law gave a really nice physical interpretation to this quantity,  it was the total amount of light received by that observer. But despite that nice physical interpretation,  there's nothing magical about adding inverse square distances,  that just happened to be what was useful for that particular problem. Now to tackle our new problem, of 2 over 1 times 2 over 3 times 4 over 3 times 4  over 5 and so on, we're going to do something similar but different in the details. Instead of using the inverse square distances,  just look at the distances themselves directly, and instead of adding them up,  we'll be multiplying them, giving a quantity I'll be referring to as the distance  product for the observer, that will be important. And even though this distance product no longer has a nice physical analogy,  I still kinda want to illustrate it with lighthouses and an observer, because, well,  I don't know, it's pretty, and also itâ€™s just more fun than just abstract geometric  points. Now, for this proof of the Wallace product, we're going to need  two key facts about this distance product, two little lemmas. First, if the observer is positioned halfway between two lighthouses on the circle,  this distance product, the thing that you get by multiplying together the lengths of  all these lines, works out to be exactly 2, no matter how many lighthouses there are. And second, if you remove one of those lighthouses and put the observer in its place,  this distance product from all the remaining lighthouses happens to  equal the number of lighthouses you started with. Again, no matter how many lighthouses there are. And if those two facts seem crazy, I agree! I mean, it's not even obvious that the distance product  here should work out to be an integer in either case. And also, it seems super tricky to actually compute all  of the distances and then multiply them together like this. But it turns out there is a, well, a trick to  this tricky calculation that makes it quite simple. The main idea is that the geometric property of these points being  evenly spaced around a circle corresponds to a really nice algebraic  property if we imagine this to be the unit circle in the complex plane,  with each of those lighthouses now sitting on some specific complex number. Some of you might recognize these as the roots of unity,  but let me quickly walk through this idea in case any of you are unfamiliar. Think about squaring one of these numbers. It has a magnitude of one, so that's going to stay the same,  but the angle it makes with the horizontal will double,  that's how squaring complex numbers works. Similarly, cubing this number is going to triple the angle it makes with the horizontal,  and in general, raising it to the nth power multiplies the angle by n. So, for example, on screen right now there are seven evenly spaced points  around the unit circle, which I'll call l0, l1, l2, and so on,  and they're rotated in such a way that l0 is sitting at the number 1 on that  right hand side. So because the angle that each one of these makes with the horizontal  is an integer multiple of 1 seventh of a turn,  raising any one of these numbers to the 7th power rotates you around to  landing on the number 1. In other words, these are all solutions to the  polynomial equation x to the 7th minus 1 equals 0. But on the other hand, we could construct a polynomial that has these numbers as roots a  totally different way, by taking x minus l0 times x minus l1, on and on and on,  up to x minus l6, I mean you plug in any one of these numbers and that product will have  to equal 0. And because these two degree-7 polynomials have the same seven distinct roots and the  same leading term, it's just x to the 7th in both cases,  they are in fact one and the same. Now take a moment to appreciate just what a marvelous fact that is. This right hand side looks like it would be an absolute nightmare to expand. Not only are there a lot of terms, but writing down what exactly each of those  complex numbers is is going to land us in a whole mess of sines and cosines. But because of the symmetry of the setup, we know that when all of the algebraic  dust settles, it's going to simplify down to just being x to the 7th minus 1. All of the other terms will cancel out. And of course there's nothing special about 7 here. If you have n points evenly spaced around a circle like this,  they are the roots of x to the n minus 1 equals 0. And now you might see why this would give a nice simplifying trick  for computing the distance product that we defined a moment ago. If you consider the observer to be any other complex number,  not necessarily on the circle, and then you plug in that number for x,  that right hand side there is giving you some new complex number whose  magnitude is the product of the distances between the observer and each lighthouse. But look at that left hand side, it is a dramatically simpler way to  understand what that product is ultimately going to simplify down to. Surprisingly, this means that if our observer sits on the same circle as the lighthouses,  the actual number of lighthouses won't be important. It's only the fraction of the way between adjacent lighthouses  that describes our observer which will come into play. If this fraction is f, then observer to the power n lands f of the way around a  full circle, so the magnitude of the complex number observer to the n minus 1 is  the distance between the number 1 and a point f of the way around a full unit circle. For example, on screen right now we have 7 lighthouses,  and the observer is sitting 1 third of the way between the first and the second. So when you raise the complex number associated with that observer to the 7th power,  they end up 1 third of the way around the full circle. So the magnitude of observer to the 7 minus 1 would be the length of this cord  right here, which for 1 third of the way around the circle happens to be about 1.73. And remember, this value is, quite remarkably,  the same as the full distance product that we care about. We could increase or decrease the number of lighthouses, and no matter what,  so long as that observer is 1 third of the way between lighthouses,  we would always get the length of this same cord as our distance product. In general, let's define a special function for ourselves, cord of f,  which will mean for any fraction f, the length of a cord corresponding to that fraction  of a unit circle. So for example, what we just saw was cord of 1 third. Actually, it's not so hard to see that cord of f amounts to the same  thing as 2 times the sine of f halves times 2 pi, which is 2 times the sine of f pi,  but sometimes it's easier to just think of it as cord of f. So the result we've just shown is that for an observer,  f of the way between two lighthouses, the total distance product,  as complicated as that might seem, works out to be exactly cord of f,  no matter how many lighthouses there are. So in particular, think about cord of 1 half. This is the distance between two points on the opposite ends of a unit circle, which is 2. So we see that no matter how many lighthouses there are,  equally spread around the unit circle, putting an observer exactly  halfway along the circle between two of them results in a distance product of precisely 2. And that's our first key fact, so just tuck that away. For the next key fact, imagine putting the observer right on one of the lighthouses. Well, then of course the distance product is 0. The distance 0 lighthouses ends up annihilating all other factors. But suppose we just got rid of that one troublesome lighthouse,  and considered only the contributions from all the other ones. What would that distance product work out to be? Well, now instead of considering the polynomial observer to the n-1,  which has a root at all of these n roots of unity,  we're looking at the polynomial observer to the n-1 divided by observer-1,  which has a root at all of the roots of unity except for the number 1 itself. And a little algebra shows that this fraction is the same thing as 1 plus  observer plus observer squared, on and on and on, up to observer to the n-1. And so if you plug in observer equals 1, since that's the number he's sitting on,  what do you get? All of the terms here become 1, so it works out to be n,  which means the total distance product for this setup equals the number of  original lighthouses. Now this does depend on the total number of lighthouses, but only in a very simple way. Think about this, this is incredible, the total distance product that an observer  sitting at one of the lighthouses receives from all other lighthouses is precisely n,  where n is the total number of lighthouses, including the ignored one. That is our second key fact. And by the way, proving geometric facts with complex polynomials like this is  pretty standard in math, and if you went up to your local mathematician and showed  him or her these two facts, or other facts like these,  they'd recognize both that these facts are true,  and how to prove them using the methods we just showed. And now, so can you! So next, with both these facts in our back pocket,  let's see how to use them to understand the product we're interested in,  and how it relates to pi. Take this setup, with n lighthouses evenly spaced around a unit circle,  and imagine two separate observers, what I'll call the keeper and the sailor. Put the keeper directly on one of the lighthouses,  and put the sailor halfway between that point and the next lighthouse. The idea here will be to look at the distance product for  the keeper divided by the distance product for the sailor,  and then we are going to compute this ratio in two separate ways. From the first key fact, we know that the total distance product for the sailor is 2. And the distance product for the keeper? Well, it's 0, since he's standing right on top of 1. But if we got rid of that lighthouse, then by our second key fact,  the remaining distance product for that keeper is n. And of course, by getting rid of that lighthouse,  we've also gotten rid of its contribution to the sailor's distance product,  so that denominator now has to be divided by the distance between the two observers. And simplifying this just a little bit, it means that the ratio  between the keeper's distance product and the sailor's is n  times the distance between the two observers, all divided by 2. But, we could also compute this ratio in a different way:  by considering each lighthouse individually. For each lighthouse, think about its contribution to the keeper's distance product,  meaning just its distance to the keeper, divided by its contribution to  the sailor's distance product, its distance to the sailor. And when we multiply all of these factors up over each lighthouse,  we have to get the same ratio in the end, n times the distance between the observers,  all divided by 2. Now that might seem like a super messy calculation, but as n gets larger,  this actually gets simpler for any particular lighthouse. For example, think about the first lighthouse after the keeper,  in the sense of counter-clockwise from him. This is a bit closer to the sailor than it is to the keeper,  specifically the angle from this lighthouse to the keeper is  exactly twice the angle from this lighthouse to the sailor. And those angles aren't exactly proportional to the straight line distances,  but as n gets larger and larger, the correspondence gets better and better. And for a very large n, the distance from the lighthouse to the keeper  is very nearly twice the distance from that lighthouse to the sailor. And in the same way, looking at the second lighthouse after the keeper,  it has an angle to keeper divided by angle to sailor ratio of exactly 4 thirds,  which is very nearly the same as the distance to keeper divided by distance to sailor  ratio as n gets large. And that third lighthouse, L3, is going to contribute a fraction  that gets closer and closer to 6 fifths as n is approaching infinity. Now for this proof, we're going to want to consider all the lighthouses  on the bottom of the circle a little bit differently,  which is why I've enumerated them negative 1, negative 2, negative 3, and so on. If you look at that first lighthouse before the keeper,  it has a distance to keeper over distance to sailor ratio that approaches 2 thirds  as n approaches infinity. And then the second lighthouse before it, L-2 here,  contributes a ratio that gets closer and closer to 4 fifths,  and the third lighthouse, L-3, contributes a fraction closer and closer to 6 sevenths,  and so on. Combining this over all of the lighthouses, we get the product 2 over 1 times 2  over 3 times 4 over 3 times 4 over 5 times 6 over 5 times 6 over 7, on and on and on. This is the product that we're interested in studying,  and in this context, each one of those terms reflects what the  contribution for a particular lighthouse is as n approaches infinity. And when I say contribution, I mean the contribution to this ratio of the  keeper's distance product to the sailor's distance product,  which we know at every step has to equal n times the distance between the  observers divided by 2. So what does that value approach as n approaches infinity? Well, the distance between the observers is half of 1 over n of a full turn  around the circle, and since this is a unit circle, its total circumference is 2 pi,  so the distance between the observers approaches pi divided by n,  and therefore n times this distance divided by 2 approaches pi divided by 2. So there you have it! Our product, 2 over 1 times 2 over 3 times 4 over 3 times 4 over 5,  on and on and on, must approach pi divided by 2. This is a truly marvelous result, and it's known as the Wallace product,  named after 17th century mathematician John Wallace,  who first discovered this fact in a way more convoluted way. And also, a little bit of trivia, this is the same guy who discovered,  or well, invented, the infinity symbol. And, actually, if you look back at this argument,  we've pulled a little bit of sleight of hand in the informality here,  which the particularly mathematically sophisticated among you might have caught. What we have here is a whole bunch of factors which we knew multiplied together  to get n times the distance between the observers divided by 2,  and then we looked at the limit of each factor individually as n went to infinity,  and concluded that the product of all of those limiting terms had to equal  whatever the limit of n times the distance between the observers divided by 2 is. But what that assumes is that the product of limits is equal to the limit of products,  even when there's infinitely many factors. And this kind of commuting of limits in infinitary arithmetic, well, it's not always true. It often holds, but it sometimes fails. Here, let me show you a simple example of a case where  this kind of commuting of limits doesn't actually work out. So we've got a grid here where every row has a single 7 and then a whole bunch of ones. So if you were to take the infinite product of each row,  you just get 7 for each one of them. So since every one of these products is 7, the limit of the products is also 7. But look at what happens if you take the limits first. If you look at each column, the limit of a given column is going to be 1,  since at some point it's nothing but 1s. But then, if you're taking the product of those limits,  you're just taking the product of a bunch of ones, so you get a different answer,  namely 1. Luckily, mathematicians have spent a lot of time thinking about this phenomenon,  and they've developed tools for quickly seeing certain conditions  under which this exchanging of the limits actually works. In this case, a particular standard result known as dominated convergence  quickly assures us that the argument we just showed will go through in full rigor. For those of you who are interested, Sridhar has written up a supplemental  blog post to this video which covers those details, along with many more things. And I should also say, we need to be a little  careful about how to interpret a product like this. Remember, we have contributions from lighthouses counterclockwise from the keeper,  as well as lighthouses clockwise from the keeper,  and what we did was interleave these in order to get our product. The lighthouses counterclockwise from the keeper contribute 2 over 1, 4 over 3, 6 over 5,  on and on, and the ones clockwise from the keeper contribute 2 over 3, 4 over 5, 6 over 7. And like I said before, if you play around with those individual series,  you'll find that the first one gets larger and larger and blows up to infinity,  and the second one gets smaller and smaller, approaching zero. So it's actually pretty delicate to make sense out of this overall product  in terms of computing the two halves separately and then combining them. And indeed, we'll find that if you intermix these two halves differently,  for example taking twice as many factors from one of them for each factor from the other,  you could get a different result for the overall product. It's only when you specifically combine them in this one-for-one  manner that you get a product that converges to pi halves. This is something that falls out of the way that dominated convergence justifies us in  commuting limits the way we did, and again, for more details, see the supplemental post. Still, those are just technicalities. The conceptual gist for what's going on here is exactly what we just showed. And in fact, after doing all that work, it would be a shame not to take a  quick moment to talk about one more neat result that falls out of this argument. Arguably, this is the coolest part of the whole proof. You see, we can generalize this whole discussion. Think back to when we discovered our first key fact,  where we saw that you could not only consider placing the sailor precisely  halfway between lighthouses, but any fraction, f, of the way between adjacent lighthouses. In that more general setting, the distance product for the sailor wasn't necessarily 2,  but it was chord of f, where f is that fraction of the way between lighthouses. And if we go through the same reasoning that we just did with the sailor at this location  instead and change nothing else, what we'll find is that the ratio of the keeper's  distance product to the sailor's distance product is now n times the distance between  them divided by chord of f, which approaches f times 2 pi divided by chord of f as n gets  larger. And in the same way as before, you could alternatively calculate  this by considering the contributions from each individual lighthouse. If you take the time to work this out, the kth lighthouse after the  keeper will contribute a factor of k divided by k-f to this ratio. And all the lighthouses before the keeper, they contribute the same thing,  but you're just plugging in negative values for k. If you combine all those contributions over all non-zero integers k,  where in the same way as before you have to be careful about how you bundle the  positive and negative k terms together, what you'll get is that the product of k  divided by k-f over all non-zero integers k is going to equal f times 2 pi divided  by chord of f. Put another way, since chord of f is 2 times the sine of f pi,  this product is the same as f times 2 pi divided by 2 times sine of f pi,  which is f pi over sine of f pi. Now rewriting this a little bit more, what you get is a pretty interesting fact. Sine of f times pi is equal to f pi times this really big product,  the product of 1 minus f over k over all non-zero integers k. So what we found is a way to express sine of x as an infinite product,  which is really cool if you think about it. So not only does this proof give us the Wallace product,  which is incredible in its own right? It also generalizes to give us the product  formula for the sine. And what's neat about that is that it connects to how Euler originally  solved the Basel problem, the sum that we saw in the previous video. He was looking at this very infinite product for sine. I mean, connecting these formulas for pi to circles is one thing,  but connecting them to each other is another thing entirely. And once again, if you want more details on all of this,  check out the supplementary blog post.

================================================================================
VIDEO ID: b7FxPsqfkOY
TITLE: Winding numbers and domain coloring
URL: https://www.youtube.com/watch?v=b7FxPsqfkOY
PUBLISHED: 2018-03-24T14:42:51Z
STATUS: SUCCESS
================================================================================
There's two things here, the main topic and the meta topic. The main topic is going to be this really neat algorithm for solving  two-dimensional equations, things that have two unknown real numbers,  or also those involving a single unknown which is a complex number. So for example, if you wanted to find the complex roots of a polynomial,  or maybe some of those million dollar zeros of the Riemann zeta function,  this algorithm would do it for you. And this method is super pretty, since a lot of colors are involved. And more importantly, the core underlying idea applies to all  sorts of math well beyond this algorithm for solving equations,  including a bit of topology, which I'll talk about afterwards. But what really makes this worth 20 minutes or so of your time is that  it illustrates a lesson much more generally useful throughout math,  which is try to define constructs that compose nicely with each other. You'll see what I mean by that as the story progresses. To motivate the case with functions that have 2D inputs and 2D outputs,  let's start off simpler with functions that just take in a real number and spit out  a real number. If you want to know when a function f of x equals some other function g of x,  you might think of this as searching for when the graphs of those functions intersect,  right? I mean that gives you an input where both functions have the same output. To take a very simple example, imagine f of x is x squared,  and g of x is the constant function 2. In other words, you want to find the square root of 2. Even if you know almost nothing about finding square roots,  you can probably see that 1 squared is less than 2, and 2 squared is bigger than 2,  so you realize, ah, there's going to be some solution in between those two values. And then if you wanted to narrow it down further,  maybe you try squaring the halfway point, 1.5. This comes out to be 2.25, a little too high,  so you'd focus on the region between 1 and 1.5. And so on, you can probably see how this would keep going,  you'd keep computing at the midpoint and then chopping your search space in half. Another way to think about this, which is going to make it easier for us  once we get up to higher dimensions, is to instead focus on the equivalent  question for when the difference between these two functions is zero. In those terms, we found a region of inputs where that difference  was negative on one end, and it was positive on another end. And then we split it into two, and the half that we narrowed our  attention to was the one where the outermost points had varying signs. And like this, we were able to keep going forever,  taking each region with varying signs on the border,  finding a smaller such region among its halves,  knowing that ultimately we have to be narrowing in on a point which is going to be  exactly zero. In short, solving equations can always be framed as finding when a certain  function is equal to zero, and to do that, we have this heuristic,  if f is positive at one point and negative at another point,  you can find someplace in between where it's zero,  at least if everything changes smoothly with no sudden jumps. Now the amazing thing I want to show you is that you can extend  this kind of thinking into two-dimensional equations,  equations between functions whose inputs and outputs are both two-dimensional. For example, complex numbers are 2D, and this tool we're  developing is perfect for finding solutions to complex equations. Now since we're going to be talking about these 2D functions so much,  let's take a brief side step and consider how we illustrate these. Graphing a function with a 2D input and a 2D output would require four dimensions,  and that's not going to work so well in our 3D world on our 2D screens,  but we still have a couple good options. One is to just look at both the input space and the output space side by side. Each point in the input space moves to a particular point in the output space,  and I can show how moving around that input point corresponds  to certain movements in the output space. All of the functions we consider will be continuous,  in the sense that small little changes to the input only  correspond to small little changes in the output, there's no sudden jumps. Another option we have is to imagine the arrow from the origin of the output space to  that output point, and to attach a miniature version of that arrow to the input point. This can give us a sense, at a glance, for where a given input point goes,  or where many different input points go by drawing the full vector field. And unfortunately when you do this at a lot of points it can get pretty cluttered,  so here let me make all of the arrows the same size,  and what this means is we can get a sense of the direction of each output point. But perhaps the prettiest way to illustrate two-dimensional functions,  and the one we'll be using most this video, is to associate each point in that output  space with a color. Here we've used hues, that is where the color falls along a rainbow or a color wheel,  to correspond to the direction away from the origin,  and we're using darkness or brightness to correspond to the distance from the origin. For example, focusing just on this array of outputs,  all of these points are red, but the ones closer to the origin are a little darker,  and the ones farther away are a little brighter. And focusing just on this array of outputs, all of the points are green,  and again, closer to the origin means darker, farther away means lighter. And so on, all we're doing here is assigning a specific color to each direction,  all changing continuously. You might notice the darkness and brightness differences here are pretty subtle,  but for this video, all we care about is the direction of outputs,  not the magnitudes, the hues, not the brightness. The one important thing about brightness for you to notice is that near the origin,  which has no particular direction, all of the colors fade to black. So for thinking about functions, now that we've decided on a color for each output,  we can visualize 2D functions by coloring each point in the input space  based on the color of the point where it lands in the output space. I like to imagine many different points from that input space hopping over to their  corresponding outputs in the output space, then getting painted based on the color of  the point where they land, and then hopping back to where they came from in the input  space. Doing this for every point in the input space,  you can get a sense just by looking at that input space for roughly where  the function takes each point. For example, this stripe of pink points on the left tells us that all of those points  get mapped somewhere in the pink direction, that lower left of the output space. Also those three points which are black with lots  of colors around them are the ones that go to zero. Alright, so just like the 1D case, solving equations of 2D functions  can always be reframed by asking when a certain function is equal to zero. So that's our challenge right now, create an algorithm that  finds which input points of a given 2D function go to zero. Now you might point out that if you're looking at a color map like this by  seeing those black dots, you already know where the zeros of the function are. So does that count? Well keep in mind that to create a diagram like this,  we've had the computer compute the function at all of the pixels on the plane,  but our goal is to find a more efficient algorithm that only requires computing  the function at as few points as possible, only having a limited view of the colors,  so to speak. And also from a more theoretical standpoint, it'd be nice to have a general construct  that tells us the conditions for whether or not a zero exists inside a given region. Now remember, in one dimension the main insight was that if a continuous function is  positive at one point and negative at another, then somewhere in between it must be zero. So how do we extend that into two dimensions? We need some sort of analog of talking about signs. One way to think about what signs even are is directions. Positive means you're pointing to the right along the number line,  and negative means you're pointing to the left. Two dimensional quantities also have direction, but for them the options are much wider,  they can point anywhere along a whole circle of possibilities. So the same way that in one dimension we were asking whether a given function  is positive or negative on the boundary of a range, which is just two points,  for 2D functions we're going to be looking at the boundary of a region,  which is a loop, and ask about the direction of the function's output along that boundary. For example, we see that along this loop around this zero,  the output goes through every possible direction, all the colors of the rainbow,  red, yellow, green, blue, back to red, and everything in between along the way. But along this loop over here, with no zeros inside of it,  the output doesn't go through every color, it goes through some of the orangish ones,  but never, say, green or blue. And this is promising, it looks a lot like how things worked in one dimension. Maybe in the same way that if a 1D function takes both possible signs on the boundary  of a 1D region, there was a zero somewhere inside,  we might hypothesize that if a 2D function hits outputs of all possible directions,  all possible colors, along the boundary of a 2D region,  then somewhere inside that region it must go to zero. So that's our guess, and take a moment to think about if this should be true,  and if so, why? If we start thinking about a tiny loop around some input point,  we know that since everything is continuous, our function takes it to some tiny loop near  the corresponding output. But look, for most tiny loops, the output varies in color. If you pick any output point other than zero, and draw a sufficiently tight loop near it,  the loop's colors are all going to be about the same color as that point. A tight loop over here is all bluish, a tight loop over here is all yellowish,  you certainly aren't going to get every color of the rainbow. The only point where you can tighten loops around it while  still getting all the colors is the colorless origin, zero itself. So it is indeed the case that if you have loops going through every color of the rainbow,  tightening and tightening, narrowing in on a point,  then that point must in fact be a zero. And so, let's set up a 2D equation solver just like our one-dimensional equation solver. When we find a large region whose border goes through every color,  split it into two, and then look at the colors on the boundary of each half. In the example shown here, the border on the left half doesn't go through all colors,  there are no points that map to the orangish-yellowish directions, for example. So I'll grey out this area as a way of saying we don't want to search it any further. The right half does go through all the colors,  spends a lot of time in the green direction, then passes through yellow-orange-red,  as well as blue-violet-pink. Now remember, what that means is that points of this  boundary get mapped to outputs of all possible directions. So we'll explore it further, subdividing again and checking the boundary for each region. The boundary of the top is all green, so we'll stop searching there. But the bottom is colorful enough to deserve a subdivision. And just continue like this. Check which subregion has a boundary covering all possible colors,  meaning points of that boundary get mapped to all possible directions,  and keep chopping those regions in half like we did for the one-dimensional case,  eventually leading us to a zero over the func- Well, hang on a second. What happened here? Neither of those last subdivisions on the bottom right passed through all the colors,  so our algorithm stopped because it didn't want to search through either of those,  but it also didn't find a zero. Okay, clearly something's wrong here. And that's okay, being wrong is a regular part of doing math. If we look back, we had this hypothesis, and it led us to this proposed algorithm,  so we were mistaken somewhere. And being good at math isn't about being right the first time,  it's about having the resilience to carefully look back and understand the mistakes,  and understand how to fix them. Now the problem here is that we had a region whose border went through every color,  but when we split it in the middle, neither subregion's border went through every color,  we had no options for where to keep searching next, and that broke the zero finder. Now in one dimension, this sort of thing never happened. Any time you had an interval whose endpoints have different signs,  if you split it up, you know that you're guaranteed to get  some subinterval whose endpoints also have different signs. Or, put another way, any time you have two intervals whose endpoints don't change signs,  if you combine them, you'll get a bigger interval whose endpoints also don't change sign. But in two dimensions, it's possible to find two regions whose  borders don't go through every color, but whose boundaries  combine to give a region whose border does go through every color. And in just this way, our proposed zero-finding algorithm broke. In fact, if you think about it, you can find a big loop whose border  goes through every possible color without there being a zero inside of it. Now that's not to say that we were wrong in our claims about tiny loops when we said  that a forever narrowing loop going through every color has to be narrowing in on a zero. But what made a mess of things for us is that this  does-my-border-go-through-every-color-or-not property doesn't combine in a nice,  predictable way when you combine regions. But don't worry, it turns out we can modify this slightly to a more  sophisticated property that does combine to give us what we want. The idea is that instead of simply asking whether we can find  a color at some point along the loop, let's keep more careful  track of how these colors change as we walk around that loop. Let me show you what I mean with an example. I'll keep a little color wheel up here in the corner to help us keep track. When the colors along a path of inputs move through the rainbow in a specific direction,  from red to yellow, yellow to green, green to blue, or blue to red,  the output is swinging clockwise. But on the other hand, if the colors move the other way through the rainbow,  from blue to green, green to yellow, yellow to red, or red to blue,  the output is swinging counterclockwise. So walking along this short path here, the colors wind  a fifth of the way clockwise through the color wheel. And walking along this path here, the colors wind  another fifth of the way clockwise through the color wheel. And of course that means that if you go through both paths, one after the other,  the colors wind a total of two-fifths of a full turn clockwise. The total amount of winding just adds up, and this is going to be key,  this is the kind of straightforward combining that will be useful to us. Now when I say total amount of winding, I want you to imagine  an old-fashioned odometer that ticks forward as the arrow spins clockwise,  but backwards as the arrow spins counterclockwise. So counterclockwise winding counts as negative clockwise winding. The outputs may turn a lot, but if some of that turning is in the opposite direction,  it cancels out. For example, if you move forward along this path,  and then move backwards along that same path, the total amount of winding  ends up being zero. The backwards movement literally rewinds through the previously seen colors,  reversing all the previous winding, and returning the odometer back to where it started. For our purposes, we'll care most about looking at the winding along loops. For example, let's say we walk around this entire loop clockwise. The outputs that we come across wind around a total of three full clockwise turns. The colors swung through the rainbow, ROYGBIV, in order,  from red to red again, and then again, and again. In the jargon mathematicians use, we say that along this loop,  the total winding number is three. Now for other loops, it could be any other whole number,  maybe a larger one if the output swings around many times as the input  walks around a single loop, or it could be a smaller number if the output  only swings around once or twice, or that winding number could even be a  negative integer if the output was swinging counterclockwise as we walk  clockwise around the loop. But along any loop, this total amount of winding has to be a whole number. I mean, by the time you get back to where you started,  you'll have the same output that you started with. Incidentally, if a path actually contains a point where the output is precisely zero,  then technically you can't define a winding number along that,  since the output has no particular direction. Now this isn't going to be a problem for us, because our whole goal is to find zeros,  so if this ever comes up, we just lucked out early. Alright, so the main thing to notice about these winding numbers  is that they add up nicely when you combine paths into bigger paths. But what we really want is for the winding numbers along the borders of  regions to add up nicely when we combine regions to make bigger regions. So do we have that property? Well, take a look. The winding number as we go clockwise around this region on the left is the sum of  the winding numbers from these four paths, and the winding as we go clockwise around  this region on the right is the sum of the winding numbers from these four paths. And when we combine those two regions into a bigger one,  most of those paths become part of the clockwise border of the bigger region. And as for those two paths that don't? Well, they cancel out perfectly. One of them is just the reverse, the rewinding of the other one, like we saw before. So the winding numbers along borders of regions add up in just the way we want them to. Also side note, this reasoning about oriented borders adding up nicely like this  comes up a lot in mathematics, and it often goes under the name Stokes' theorem. Those of you who've studied multivariable calculus might recognize it from that context. So now, finally, with winding numbers in hand,  we can get back to our equation solving goals. The problem with the region we saw earlier is that even though its border  passed through all possible colors, the winding number was actually zero. The outputs wound around halfway, through yellow to red,  and then started going counterclockwise back the other direction,  then continued going through blue and hitting red from the other way,  all in such a way that the total winding netted out to be zero. But if you find a loop which not only hits every color,  but has the stronger condition of a non-zero winding number,  then if you were to split it in half, you're guaranteed that at least one  of those halves has a non-zero winding number as well,  since things add up nicely in the way we want them to. So in this way, you can keep going, narrowing in further and further onto one point. And as you narrow in onto a point, you'll be doing so with tiny loops that have  non-zero winding numbers, which implies they go through all possible colors,  and therefore, like I said before, the point they're narrowing in on must be a zero. And that's it! We have now created a two-dimensional equation solver,  and this time, I promise, there are no bugs. Winding numbers are precisely the tool we need to make this work. We can now solve equations that look like where does f of x equal g of x in two  dimensions just by considering how the difference between f and g winds around. Whenever we have a loop whose winding number isn't zero,  we can run this algorithm on it and we're guaranteed to find a solution  somewhere within it. And what's more, just like in one dimension, this algorithm is incredibly efficient. We keep narrowing in on half the size of our region each round,  thus quickly narrowing in on the zeros, and all the while,  we only have to check the value of the function along points of these loops,  rather than checking it on the many points of the interior. So in some sense, the overall work done is proportional only to  the search space's perimeter, not the full area, which is amazing. Now once you understand what's going on, it's weirdly mesmerizing to just  watch this in action, giving it some function and letting it search for zeros. Like I said before, complex numbers are two-dimensional,  so let's apply it to some equation with complex numbers. For example, here's the algorithm finding the zeros of the  function x to the fifth minus x minus one over the complex plane. It started by considering a very large region around the origin,  which ended up having a winding number of five. Each time you find a loop with a non-zero winding number,  you split it in half and figure out the winding number of the two smaller loops. Either one or both of them is guaranteed to have a non-zero winding number,  and when you see this, you know there's a zero somewhere inside that smaller loop,  so you keep going in the same way, searching the smaller space. We also stop exploring a region if the path we're computing along happens to stumble  across a zero, which actually happened once for this example on the right half here. Those rare occurrences interfere with our ability to compute winding numbers,  but hey, we got a zero. And as for loops whose winding number is zero, you just don't explore those further. Maybe they have a solution inside, maybe they don't, we have no guarantees. And letting our equation solver continue in the same way,  it eventually converges to lots of zeros for this polynomial. By the way, it is no coincidence that the total  winding number in this example happened to be five. With complex numbers, the operation x to the n directly corresponds to walking  around the output's origin n times as you walk around the input's origin once. So with the polynomial, for large enough inputs,  every term other than the leading term becomes insignificant in comparison. So any complex polynomial whose leading term is x to the  n has a winding number of n around a large enough loop. And in that way, our winding number technology actually  guarantees that every complex polynomial has a zero. This is such an important fact that mathematicians  call it the fundamental theorem of algebra. Having an algorithm for finding numerical solutions to equations like this is  extremely practical, but the fundamental theorem of algebra is a good example  of how these winding numbers are also quite useful on a theoretical level,  guaranteeing the existence of a solution to a broad class of equations for  suitable conditions, which is much more the kind of thing mathematicians like  thinking about. I'll show you a couple more amazing applications of this in the context of topology in  a follow-up video, which includes correcting a mistake from an old 3blue1brown video. Which one? Well, watch all of the videos, everything on this channel,  and see if you can spot the error first. The primary author of this video is one of the newest 3blue1brown team members,  Sridhar Ramesh. Thank you for watching.

================================================================================
VIDEO ID: bcPTiiiYDs8
TITLE: How pi was almost 6.283185...
URL: https://www.youtube.com/watch?v=bcPTiiiYDs8
PUBLISHED: 2018-03-14T13:05:32Z
STATUS: SUCCESS
================================================================================
I'm sure you're already familiar with the whole pi vs. tau debate. A lot of people say that the fundamental circle constant we hold up  should be the ratio of a circle's circumference to its radius,  which is around 6.28, not the ratio to its diameter, the more familiar 3.14. These days we often call that larger constant tau,  popularized by Michael Hartle's tau manifesto,  although personally I'm quite partial to Robert Palace's proposed  notation of a pi with three legs. In either of these manifestos, and on many other places of the internet,  you can read to no end about how many formulas look a lot cleaner using tau,  largely because the number of radians describing a given fraction of a circle is actually  that fraction of tau. That dead horse is beat, I'm not here to make that case further. Instead, I'd like to talk about the seminal moment  in history when pi as we know it became the standard. For this, one fruitful place to look is at the old notes and letters  by one of history's most influential mathematicians, Leonhard Euler. Luckily, we now have an official 3b1 brown Switzerland correspondent,  Ben Hambrecht, who was able to go to the library in Euler's  hometown and get his hands on some of the original documents. And in looking through some of those, it might surprise you to see Euler write,  Let pi be the circumference of a circle whose radius is 1, that is,  the 6.28 constant we would now call tau, and it's likely he was using the Greek letter  pi as a p for perimeter. So was it the case that Euler, genius of the day,  was more notationally enlightened than the rest of the world,  fighting the good fight for 6.28? And if so, who's the villain of our story, pushing the  3.1415 constant shoved in front of most students today? The work that really established pi as we now know it as the commonly  recognized circle constant was an early calculus book from 1748. At the start of chapter 8, in describing the semi-circumference of a circle with  radius 1, and after expanding out a full 128 digits of this number, one of them wrong,  by the way, the author adds, which for the sake of brevity I may write pi. There were other texts and letters here and there with varying conventions for the  notation of various circle constants, but this book, and this section in particular,  was really the one to spread the notation throughout Europe, and eventually the world. So what monster wrote this book with such an unprincipled take towards circle constants? Well, Euler again. In fact, if you look further, you can find instances of Euler using the symbol pi to  represent a quarter turn of the circle, what we would call today pi halves,  or tau fourths. In fact, Euler's use of the letter pi seems to be much  more analogous to our use of the Greek letter theta. It's typical for us to let it represent an angle, but no one angle in particular. Sometimes it's 30 degrees, maybe other times it's 135,  and most times it's just a variable for a general statement. It depends on the problem and the context before us. Likewise, Euler let pi represent whatever circle constant best suited the  problem before him, though it's worth pointing out that he typically framed  things in terms of unit circles with radius one,  so the 3.1415 constant would almost always have been thought of as the ratio  of a circle's semi-circumference to its radius,  none of this circumference to its diameter nonsense. And I think Euler's use of this symbol carries with  it a general lesson about how we should approach math. The thing you have to understand about Euler is that this man solved problems,  a lot of problems. I mean, day in, day out, breakfast, lunch, and dinner,  he was just churning out puzzles and formulas and having insights and creating entire  new fields, left and right. Over the course of his life, he wrote over 500 books and papers,  which amounted to a rate of 800 pages per year, and these are dense math pages. And then after his death, another 400 publications surfaced. It's often joked that formulas and math have to be named after the second  person to prove them, because the first is always going to be Euler. His mind was not focused on what circle constant we should take as fundamental,  it was on solving the task sitting in front of him in a particular moment,  and writing a letter to the Bernoullis to boast about doing so afterwards. For some problems, the quarter circle constant was most natural to think about,  for others the full circle constant, and for others still,  say at the start of chapter 8 of his famous calculus book,  maybe the half circle constant was most natural to think about. Too often in math education, the focus is on which  of multiple competing views about a topic is right. Is it correct to say that the sum of all positive integers is negative 1 12th,  or is it correct to say that it diverges to infinity? Can the infinitesimal values of calculus be taken literally,  or is it only correct to speak in terms of limits? Are you allowed to divide a number by zero? These questions in isolation just don't matter. Our focus should be on specific problems and puzzles,  both those of practical application and those of idle pondering for knowledge's own sake. Then, when questions of standards arise, you can  answer them with respect to a given context. And inevitably, different contexts will lend themselves  to different answers of what seems most natural. But that's okay. Outputting 800 pages a year of dense transformative insights seems  to be more correlated with a flexibility towards conventions than  it does with focusing on which standards are objectively right. So on this Pi Day, the next time someone tells you that, you know,  we should really be celebrating math on June 28th,  see how quickly you can change the topic to one where you're actually  talking about a piece of math.

================================================================================
VIDEO ID: d-o3eB9sfls
TITLE: Why is pi here?  And why is it squared?  A geometric answer to the Basel problem
URL: https://www.youtube.com/watch?v=d-o3eB9sfls
PUBLISHED: 2018-03-02T16:23:29Z
STATUS: SUCCESS
================================================================================
Take 1 plus 1 fourth plus 1 ninth plus 1 sixteenth and so on  where you're adding the inverses of the next square number What  does this sum approach as you keep adding on more and more terms? Now this is a challenge that remained unsolved for 90 years  after it was initially posed until finally it was Euler who  found the answer Super surprisingly to be pi squared divided by 6. I mean isn't that crazy? What is pi doing here? And why is it squared? We don't usually see it squared in honor of Euler whose hometown was basil This infinite  sum is often referred to as the basil problem But the proof that I'd like to show you  is very different from the one that Euler had I've said in a previous video that whenever  you see pi show up There will be some connection to circles and there are those who like  to say that pi is not fundamentally about circles and Insisting on connecting equations  like these ones with a geometric intuition stems from a stubborn insistence on only  understanding pi in the context where we first discovered it and That's all well and  good But whatever your own perspective holds as fundamental the fact is pi is very much  tied to circles So if you see it show up there will be a path somewhere in the massive  interconnected web of mathematics Leading you back to circles and geometry The question  is just how long and convoluted that path might be and in the case of the basil problem  It's a lot shorter than you might first think and it all starts with light Here's the  basic idea Imagine standing at the origin of a positive number line and putting a little  lighthouse on all of the positive integers one two three four and so on that first  lighthouse has some Apparent brightness from your point of view some amount of energy  that your eye is receiving from the light per unit time and Let's just call that a  brightness of one For reasons I'll explain shortly the apparent brightness of the second  lighthouse is 1 fourth as much as the first and the apparent brightness of the third is  1 9th as much as the first and then 1 16th and so on and you can probably see why this  is useful for the basil problem It gives us a physical representation of what's being  asked Since the brightness received from the whole infinite line of lighthouses is going  to be 1 plus 1 4th plus 1 9th Plus the 16th and so on So the result that we are aiming  to show is that this total brightness is equal to pi squared divided by 6 times the  brightness of that first lighthouse And at first that might seem useless I mean,  we're just re-asking the same original question But the progress comes from a new  question that this framing raises are there ways that we can rearrange these lighthouses  That don't change the total brightness for the observer And if so,  can you show this to be equivalent to a setup that's somehow easier to compute To start  let's be clear about what we mean when we reference apparent brightness to an observer  Imagine a little screen which maybe represents the retina of your eye or a digital camera  sensor or something like that You could ask what proportion of the rays coming out of  the source hit that screen or phrase differently What is the angle between the ray  hitting the bottom of that screen and the ray hitting the top? Or rather since we should be thinking of these lights as being in three dimensions. It might be more accurate to ask What is the angle the  light covers in both directions perpendicular to the source? In spherical geometry you sometimes talk about the solid angle of a shape Which is the  proportion of a sphere it covers as viewed from a given point You see the first of two  places this story we're thinking of screens is going to be useful is in understanding  the inverse square law Which is a distinctly three-dimensional phenomenon think of all  of the rays of light hitting a screen one unit away from the source as You double the  distance those rays will now cover an area with twice the width and twice the height So  it would take four copies of that original screen to receive the same rays at that  distance And so each individual one receives 1 fourth as much light This is the sense in  which I mean a light would appear 1 fourth as bright two times the distance away Likewise  when you're three times farther away You would need nine copies of that original screen  to receive the same rays so each individual screen only receives 1 9th as much light and  This pattern continues because the area hit by a light increases by the square of the  distance the brightness of that light decreases by the inverse square of that distance  and As I'm sure many of you know this inverse square law is not at all special to light  It pops up whenever you have some kind of quantity that spreads out evenly from a point  source whether that's sound or heat or a radio signal things like that and Remember it's  because of this inverse square law that an infinite array of evenly spaced lighthouses  physically implements the Basel problem But again what we need if we're going to make  any progress here is to understand how we can manipulate setups with light sources like  this without changing the total brightness for the observer and The key building block  is an especially nice way to transform a single lighthouse into two Think of an observer  at the origin of the XY plane and a single lighthouse sitting out somewhere on that plane  Now draw a line from that lighthouse to the observer and then another line perpendicular  to that one at the lighthouse Now place two lighthouses where this new line intersects  the coordinate axes Which I'll go ahead and call lighthouse a over here on the left and  lighthouse B on the upper side It turns out and you'll see why this is true in just a  minute the brightness that the observer Experiences from that first lighthouse is equal  to the combined brightness experienced from lighthouses A and B together And I should  say by the way that the standing assumption throughout this video is that all lighthouses  are equivalent They're using the same light bulb emanating the same power all of that So  in other words assigning variables to things here if we call the distance from the  observer to lighthouse a little a and The distance from the observer to lighthouse B  little B and the distance to the first lighthouse H We have the relation 1 over a squared  plus 1 over B squared equals 1 over H squared This is the much less well-known Inverse  Pythagorean theorem which some of you may recognize from math ologer's most recent and  I'll say most excellent video on the many cousins of the Pythagorean theorem Pretty cool  relation don't you think and if you're a mathematician at heart you might be asking right  now how you prove it and There are some straightforward ways where you express the  triangles area in two separate ways and apply the usual Pythagorean theorem But there is  another quite pretty method that I'd like to briefly outline here that falls much more  nicely into our storyline because again It uses intuitions of light and screens Imagine  scaling down the whole right triangle into a tinier version and think of this miniature  Hypotenuse as a screen receiving light from the first lighthouse If you reshape that  screen to be the combination of the two legs of the miniature triangle like this Well,  it still receives the same amount of light, right? I mean the rays of light hitting one of those two legs are precisely the same as the rays  that hit the hypotenuse Then the key is that the amount of light from the first  lighthouse that hits this left side the limited angle of rays that end up hitting that  screen is Exactly the same as the amount of light over here coming from lighthouse a  which hits that side it'll be the same angle of rays and Symmetrically the amount of  light from the first house hitting the bottom portion of our screen is The same as the  amount of light hitting that portion from lighthouse B Why you might ask well,  it's a matter of similar triangles This animation already gives you a strong hint for how  it works And we've also left a link in the description to a simple GeoGebra applet for  those of you who want to think this through in a slightly more interactive environment  and in playing with that One important fact here that you'll be able to see is that the  similar triangles only apply in the limiting case for a very tiny screen The inverse  Pythagorean theorem Alright buckle up now because here's where things get good We've got  this inverse Pythagorean theorem, right? And that's going to let us transform a single lighthouse into two others without  changing the brightness experienced by the observer With that in hand and no small  amount of cleverness we can use this to build up the infinite array that we need  Picture yourself at the edge of a circular lake directly opposite a lighthouse We're  going to want it to be the case that the distance between you and the lighthouse Along  the border of the lake is one so we'll say the lake has a circumference of two now  the apparent brightness is one divided by the diameter squared and In this case the  diameter is that circumference 2 divided by pi so the apparent brightness works out  to be pi squared divided by 4 Now for our first transformation draw a new circle twice  as big so circumference 4 and Draw a tangent line to the top of the small circle then  replace the original lighthouse with two new ones where this tangent line intersects  the larger circle an Important fact from geometry that we'll be using over and over  here Is that if you take the diameter of a circle and form a triangle with any point  on the circle? The angle at that new point will always be 90 degrees the significance of that in our  diagram here is that it means the inverse Pythagorean theorem applies and the brightness  from those two new lighthouses equals the brightness from the first one namely pi squared  divided by 4 as The next step draw a new circle twice as big as the last with a  circumference 8 Now for each lighthouse take a line from that lighthouse through the  top of the smaller circle Which is the center of the larger circle and consider the two  points where that intersects with the larger circle Again,  since this line is a diameter of that large circle Then the lines from those two new  points to the observer are going to form a right angle Likewise by looking at this right  triangle here whose hypotenuse is the diameter of the smaller circle You can see that  the line from the observer to that original lighthouse is at a right angle With a new  long line that we drew Good news, right? because that means we can apply the inverse Pythagorean theorem and that means  that the apparent brightness from the original lighthouse is the same as the  combined brightness from the two newer ones and Of course,  you can do that same thing over on the other side drawing a line through the  top of the smaller circle and getting two new lighthouses on the larger circle  and Even nicer these four lighthouses are all going to be evenly spaced around  the lake Why? Well, the lines from those lighthouses to the center are at 90 degree angles with each  other So since things are symmetric left to right that means that the distances along  the circumference are 1, 2, 2, 2, and 1 Alright, you might see where this is going,  but I want to walk through this for just one more step You draw a circle twice as big so  circumference of 16 now and for each lighthouse You draw a line from that lighthouse  through the top of the smaller circle Which is the center of the bigger circle and then  create two new lighthouses where that line intersects with the larger circle Just as  before because the long line is a diameter of the big circle those two new lighthouses  make a right angle with the observer, right and Just as before the line from the observer  to the original lighthouse is Perpendicular to the long line and those are the two facts  that justify us in using the inverse Pythagorean theorem But what might not be as clear  is that when you do this for all of the lighthouses to get eight new ones on the Big lake  those eight new lighthouses are going to be evenly spaced This is the final bit of  geometry proofiness before the final thrust To see this remember that if you draw lines  from two adjacent lighthouses on the small lake to the center They make a 90 degree angle  If instead you draw lines to a point anywhere on the circumference of the circle that's  not between them the very useful inscribed angle theorem from geometry tells us that this  will be Exactly half of the angle that they make with the center in this case 45 degrees  But when we position that new point at the top of the lake These are the two lines which  define the position of the new lighthouses on the larger lake What that means then is  that when you draw lines from those eight new lighthouses into the center They divide  the circle evenly into 45 degree angle pieces and that means the eight lighthouses are  evenly spaced around the circumference with the distance of two between each one of them  and Now just imagine this thing playing on at every step doubling the size of each circle  and Transforming each lighthouse into two new ones along a line drawn through the center  of the larger circle at every step the apparent brightness to the observer remains the  same pi squared over 4 and at every step the lighthouse has remained evenly spaced with  a distance 2 between each one of them on the circumference and In the limit what we're  getting here is a flat horizontal line with an infinite number of lighthouses evenly  spaced in both directions and Because the apparent brightness was pi squared over 4 the  entire way that will also be true in this limiting case And This gives us a pretty  awesome infinite series the sum of the inverse squares 1 over n squared Where n covers  all of the odd integers 1 3 5 and so on but also negative 1 negative 3 negative 5 off in  the leftward direction Adding all of those up is going to give us pi squared over 4  That's amazing and it's the core of what I want to show you and Just take a step back  and think about how unreal this seems The sum of simple fractions that at first sight  have nothing to do with geometry nothing to do with circles at all Apparently gives us  this result that's related to pi Except now you can actually see what it has to do with  geometry the number line is kind of like a limit of ever-growing circles and As you sum  across that number line making sure to sum all the way to infinity on either side It's  sort of like you're adding up along the boundary of an infinitely large circle and a very  loose But very fun way of speaking But wait, you might say this is not the sum that you  promised us at the start of the video And well, you're right. We do have a little bit of thinking left First things first,  let's just restrict the sum to only being the positive odd numbers which gets us pi  squared divided by 8 Now the only difference between this and the sum that we're looking  for that goes over all the positive integers odd and even is That it's missing the sum  of the reciprocals of even numbers what I'm coloring in red up here Now you can think of  that missing series as a scaled copy of the total series that we want Where each  lighthouse moves to being twice as far away from the origin one gets shifted to two two  gets shifted to four three gets shifted to six and so on and Because that involves  doubling the distance for every lighthouse. it means that the apparent brightness would be decreased by a factor of four and That's  also relatively straightforward algebra going from the sum over all the integers to the  sum over the even integers Involves multiplying by 1 4th and what that means is that  going from all the integers to the odd ones Would be multiplying by 3 4ths since the  evens plus the odds have to give us the whole thing So if we just flip that around that  means going from the sum over the odd numbers to the sum over all positive integers  requires multiplying by 4 thirds So taking that pi squared over 8 multiplying by 4 thirds  badda boom badda bing We've got ourselves a solution to the basil problem Now this video  that you just watched was primarily written and animated by one of the new three blue  one brown team members Ben Hambricht an addition made possible.  Thanks to you guys through patreon You

================================================================================
VIDEO ID: MBnnXbOM5S4
TITLE: The more general uncertainty principle, regarding Fourier transforms
URL: https://www.youtube.com/watch?v=MBnnXbOM5S4
PUBLISHED: 2018-02-25T00:25:00Z
STATUS: SUCCESS
================================================================================
You've probably heard of the Heisenberg uncertainty principle from quantum mechanics,  that the more you know about a particle's position,  the less certain you can be of its momentum and vice versa. Michael here is for you to come away from this  video feeling like this is utterly reasonable. It'll take some time, but I think you'll agree that digging deep is well worth it. You see, the uncertainty principle is actually one specific  example of a much more general trade-off that shows up in a  lot of everyday totally non-quantum circumstances involving waves. The plan here is to see what this means in the context of sound waves,  which should feel reasonable, and then Doppler radar,  which should again feel reasonable and a little bit closer to the quantum case,  and then for particles, which if you're willing to accept one or two premises of quantum  mechanics, hopefully feels just as reasonable as the first two. The core idea here has to do with the interplay between frequency and duration,  and I bet you already have an intuitive idea of this principle  before we even get into the math or the quantum. If you were to pull up behind a car at a red light,  and your turn signals were flashing together for a few seconds,  you might kind of think they have the same frequency,  but at that point for all you know they could fall out of sync as more time passes,  revealing that they actually had different frequencies. So an observation over a short period of time gave  you low confidence over what their frequencies are. But, if you were to set it at that red light for a full minute,  and the signals continued to click in sync, you would be a  lot more confident that the frequencies are actually the same. So that certainty about the frequency information  required an observation spread out over time. And this trade-off right here, between how short your observation can be and how  confident you can feel about the frequency, is an example of the general uncertainty  principle. Similarly, think of a musical note. The shorter it lasts in time, the less certain  you can be about what its exact frequency is. In the extreme, I could ask you what the pitch of a clap or shockwave is,  and even someone with perfect pitch would be unable to answer. And on the flip side, a more definite frequency requires a longer duration signal. Or rather than talking about definiteness or certainty,  it would be a little more accurate here to say that the short signal  correlates highly with a wider range of frequency,  and that the signal correlating strongly with only a narrow range of  frequencies must last for a longer time. Here, that's the kind of phrase that's made a little clearer when we  bring in the actual math, so let's turn now to talking about the Fourier transform,  which is the relevant construct for analyzing frequencies. The last video I put out was a visual intuition for this transform,  and yes, it probably would be helpful if you've seen it,  but I'm going to give a quick recap here to remind ourselves how it went. Let's say you have a signal and it plays 5 beats per second over the course of 2 seconds. The Fourier transform gives a way to view any signal not in terms of the intensity at  each point in time, but instead in terms of the strength of various frequencies within it. The main idea was to take this signal and kind of wind it around a circle,  as in, imagine some rotating vector whose length is determined  by the height of the graph at each point in time. Right now, this little vector is rotating at 0.3 cycles per second,  that's the frequency with which we're winding the graph around the circle. And for most frequencies, the signal is kind of just averaged out over the circle. This was the fun part of last video, don't you think? Just seeing the different patterns that come up as  you wind a pure cosine around a circle like this. But the key point is what happens when that winding frequency  matches the signal frequency, in this case 5 cycles per second. As our little vector is rotating around and it draws,  all of the peaks line up on one side and all of the valleys on another side,  so the whole weight of the graph is kind of off-center, so to speak. The idea behind the Fourier transform is that if you follow the center  of mass of the wound-up graph with frequency f,  the position of that center of mass encodes the strength of that frequency  in the original signal. The distance between that center of mass and the origin captures the strength of that  frequency, and this is something I didn't really talk about in the main video,  but the angle of that center of mass off the horizontal corresponds to the phase of the  given frequency. One way to think of this whole winding mechanism is that it's a way  to measure how well your signal correlates with a given pure frequency. So remember, when we say the Fourier transform,  we're referring to this new function whose input is that winding frequency,  and whose output is the center of mass, thought of as a complex number. Or more technically, it's a certain multiple of that center of mass,  but whatever, the overall shape remains the same. And the graph I'm drawing is just going to be the x-coordinate of that center of mass,  the real part of its output. If you wanted, you could also plot the distance between the  center of mass and the origin, and maybe that better conveys  how strongly each possible frequency correlates with a signal. The downside is that you lose some of the nice  linearity properties I talked about last video. Anyway, point is, this spike above the winding frequency of 5 is the Fourier transform's  way of telling us that the dominant frequency of the signal is 5 beats per second. And equally importantly, the fact that it's a little bit spread  out around that 5 is an indication that pure sine waves near  5 beats per second also correlate pretty well with the signal. And that last idea is key for the uncertainty principle. What I want you to do is think about how this spread  changes as the signal persists longer or shorter over time. You've already seen this at an intuitive level,  all we're doing right now is just illustrating it in the language of Fourier transforms. If the signal persists over a long period of time,  then when the winding frequency is even slightly different from 5,  the signal goes on long enough to wrap itself around the circle and balance out. So looking at the Fourier plot over here, that corresponds to a super sharp drop-off in  the magnitude of the transform as your frequency shifts away from that 5 beats per second. On the other hand, if your signal was really localized to a short period of time,  then as you adjust the frequency away from 5 beats per second,  the signal doesn't really have as much time to balance itself out around the circle. You have to change the winding frequency to be meaningfully  different from 5 before that signal starts to balance out again. Over on the frequency plot, that corresponds to  a much broader peak around the 5 beats per second. And that's the uncertainty principle, just phrased a little bit more mathematically. A signal concentrated in time must have a spread out Fourier transform,  meaning it correlates with a wide range of frequencies,  and a signal with a concentrated Fourier transform has to be spread out in time. And one other place where this comes up in a really tangible way is Doppler radar. So with radar, the idea is you send out some radio wave pulse,  and the pulse might reflect off of objects, and the time it takes for  this echo signal to return to you lets you deduce how far away those objects are. And you can actually take this one step further and make deductions  about the velocities of those objects using the Doppler effect. Think about sending out a pulse with some frequency. If this gets reflected off an object moving towards you,  then the beats of that wave get kind of smushed together,  so the echo you hear back is going to be a slightly higher frequency. Fourier transforms give a neat way to view this. The Fourier transform of your original signal tells you the frequencies that go into it,  and for simplicity let's think of that as being dominated by a single pure frequency,  though as you know if it's a short pulse that means that our Fourier  transform has to be spread out a little bit. And now think about the Doppler shifted echo. By coming back at a higher frequency, it means that the  Fourier transform will look like a similar plot shifted up a bit. Moreover, if you look at the size of that shift,  you can deduce how quickly the object was moving. By the way, there is an important technical point that I'm choosing to gloss over here,  and I've outlined it a little more in the video description. What follows is meant to be a distilled, if somewhat  oversimplified description of the Fourier tradeoff in this setup. This salient fact is that time and frequency of that echo signal correspond respectively  to the position and velocity of the object being measured,  which is what makes this example much more closely analogous to the quantum mechanical  Heisenberg uncertainty principle. You see, there is a very real way in which a radar operator faces a dilemma,  where the more certain you can be about the positions of things,  the less certain you are about their velocities. Here, imagine sending out a pulse that persists over a long period of time. Then that means the echo from some object is also spread out over time. And on its own, that might not seem like an issue. But in practice, there's all sorts of different objects in the field,  so these echoes are all going to start to get overlapped with each other. Combine that with other noise and imperfections,  and this can make the locations of multiple objects extremely ambiguous. Instead, a more precise understanding of how far away all these things are  would require having a very quick little pulse confined to a small amount of time. But think about the frequency representations of such a short echo. As you saw with the sound example, the Fourier  transform of a quick pulse is necessarily more spread out. So for many objects with various velocities, that would mean  that the Doppler shifted echoes, despite having been nicely separated in time,  are more likely to overlap in frequency space. So since what you're looking at is the sum of all of these,  it can be really ambiguous how you break it down. If you wanted a nice clean sharp view of the velocities,  you would need to have an echo that only occupies a very small amount of frequency space. But for a signal to be concentrated in frequency space,  it necessarily has to be spread out in time. This is the Fourier tradeoff. You cannot have crisp delineation for both. And this brings us to the quantum case. Do you know who else spent some time immersed in  the pragmatic world of radio wave transmissions? A young, otherwise philosophically inclined history major in WWI France, Louis de Broglie. And this was a strangely fitting post, given his  predispositions to philosophizing about the nature of waves. After the war, as de Broglie switched from the humanities to physics,  in his 1924 PhD thesis he proposed that all matter has wave-like properties. And more than that, he concluded that the momentum of any moving particle is proportional  to the spatial frequency of that wave, how many times that wave cycles per unit distance. Ok, now that's the kind of phrase that can easily fly into one ear and out the other. As soon as you say matter is a wave, it's easy to  throw up your hands and say physics is just weird. But really, think about this. Even if you're willing to grant that particles behave like waves,  in some way, whatever that means, why on earth should the momentum of those particles,  the thing we classically think of as mass times velocity,  have anything to do with the spatial frequency of that wave? Now being more of a math than a physics guy, I asked a number of people  with deeper backgrounds in physics about helpful intuitions here,  and one thing that became clear is that there is a surprising variety of viewpoints. Now personally, one thing I found to be interesting was just going back to the  source and seeing how de Broglie framed things in his seminal paper on the topic. You see, there is a sense in which it's not all that different from the Doppler effect,  where relative movement corresponds to shifts in frequency. It has a slightly different flavor, since we're not talking about frequency over time,  instead we're talking about frequency over space,  and special relativity is going to come into play,  but I still think it's an interesting analogy. In his thesis, de Broglie lays out what is, in his own words,  a crude comparison for the kind of wave phenomenon he has in mind. Imagine many weights hanging from springs, with all of these weights oscillating  up and down in sync, and with most of the mass concentrated towards a single point. The energy of these oscillating weights is meant to be a metaphor for  the energy of a particle, specifically the E equals mc squared style  energy residing in its mass, and de Broglie emphasized how the conception  he had in mind involves the particle being dispersed across all of space. The whole premise he was exploring here is that the energy of a  particle might have to do with something that oscillates over time,  since this was known to be the case for photons,  and these oscillating weights are meant to be a metaphor for whatever  that something might be. With Einstein's relatively new theory of relativity in mind,  he pointed out that if you view this whole setup while moving relative to it,  all of the weights are going to appear to fall out of phase. That's not obvious, and I'm certainly exaggerating the effect in this animation. It has to do with a core fact from special relativity,  that what you consider to be simultaneous events in one  reference frame may not be simultaneous in a different reference frame. So even though from one point of view, you might see two of these weights as  reaching their peaks and valleys at the same instant,  from a different moving point of view, those events might actually be happening  at different times. Understanding this more fully requires some knowledge of special relativity,  so we'll all just have to wait for Henry Reich's series on that topic to come out. Right here our only goal is to get an inkling for why momentum,  that thing we usually think of as mass times velocity,  should have anything to do with spatial frequency. And the basic line of reasoning here is if mass is the same as energy,  via E equals mc squared, and if that energy was carried as some kind of oscillating  phenomenon, similar to how it is for photons, then this sort of relativistic Doppler  effect means changes to how that mass moves corresponds to changes in the spatial  frequency. So what does our general Fourier tradeoff tell us in this case? Well if a particle is described as a little wave packet over space,  then the Fourier transform, where we're thinking of this as a function over space,  not over time, tells us how much various pure frequencies correspond with this top wave. So if the momentum is the spatial frequency, up to a constant multiple,  then the momentum is also a kind of wave, namely some multiple  of the Fourier transform of the original wave. So if that wave was very concentrated around a single point,  as we have seen multiple times now, that means that its Fourier transform must  necessarily be more spread out, and hence the wave describing its momentum must be  more spread out, and vice versa. Notice unlike the Doppler radar case, where the ambiguity arose because  waves were being used to measure an object with a definite distance and speed,  what we're seeing here is that the particle is the wave. So the spread out over space and over momentum is not some artifact  of imperfect measurement techniques, it's a spread fundamental to what the particle is,  analogous to how a musical note being spread out over time is  fundamental to what it even means to be a musical note. One pet peeve I have in mainstream references to quantum is that they often treat  Heisenberg's uncertainty principle as some fundamental example of things being  unknowable in the quantum realm, as if it is a core nugget of the universe's  indeterminacy. But really it's just a trade-off between how concentrated a  wave and its frequency representation can be applied to the  premise that matter is some kind of wave, and hence spread out. All of the stuff about randomness and unknowability is still there,  but it comes one level deeper in the way that these waves have come to be interpreted. You see, when you measure these particles, say trying to detect if it's in a given  region, whether or not you find it there appears to be probabilistic,  where the probability of finding it is proportional to the strength of the wave in  that region. So when one of these waves is concentrated near a point,  what that actually means is that we have a higher probability  of finding it near that point, that we are more certain of its location. And just to beat this drum one more time, since that concentration implies  a more spread out Fourier transform, then the wave describing its momentum  would also be more spread out, so you wouldn't be able to find a narrow  range of momenta that the particle has a high probability of occupying. I quite like how if you look at the German word for this principle,  it might be more directly translated as the unsharpness relation,  which I think more faithfully captures the Fourier trade-off at play here without  imposing on questions of no ability. When I think of the Heisenberg uncertainty principle,  what makes it fascinating is not so much that it's a statement about randomness. I mean, yes, that randomness is very thought-provoking and contentious and just plain  weird, but to me equally fascinating is that underpinning Heisenberg's conclusion is  that position and momentum have the same relationship as sound and frequency,  as if a particle's momentum is somehow the sheet music describing how it moves through  space.
281
00:17:46,380 --> 00:17:43,160
.

================================================================================
VIDEO ID: spUNpyF58BY
TITLE: But what is the Fourier Transform?  A visual introduction.
URL: https://www.youtube.com/watch?v=spUNpyF58BY
PUBLISHED: 2018-01-26T18:47:48Z
STATUS: SUCCESS
================================================================================
This right here is what we're going to build to this video,  a certain animated approach to thinking about a super important idea from math,  the Fourier transform. For anyone unfamiliar with what that is, my number one goal  here is just for the video to be an introduction to that topic. But even for those of you who are already familiar with it,  I still think that there's something fun and enriching about seeing what all of its  components actually look like. The central example to start is going to be the classic one,  decomposing frequencies from sound. But after that I also want to show a glimpse of how this idea extends well beyond  sound and frequency into many seemingly disparate areas of math, and even physics. Really, it's crazy just how ubiquitous this idea is. Let's dive in. This sound right here is a pure A, 440 beats per second,  meaning if you were to measure the air pressure right next to your  headphones or your speaker as a function of time,  it would oscillate up and down around its usual equilibrium in this wave,  making 440 oscillations each second. A lower pitch note, like a D, has the same structure, just fewer beats per second. And when both of them are played at once, what do you think the resulting pressure vs. time graph looks like? Well, at any point in time, this pressure difference is going to  be the sum of what it would be for each of those notes individually,  which let's face it is kind of a complicated thing to think about. At some points the peaks match up with each other, resulting in a really high pressure. At other points they tend to cancel out. And all in all, what you get is a wave-ish pressure vs. time graph that is not a pure sine wave, it's something more complicated. And as you add in other notes, the wave gets more and more complicated. But right now, all it is is a combination of four pure frequencies,  so it seems needlessly complicated given the low amount of information put into it. A microphone recording any sound just picks up on the air pressure  at many different points in time, it only sees the final sum. So our central question is going to be how you can take a signal  like this and decompose it into the pure frequencies that make it up. Pretty interesting, right? Adding up those signals really mixes them all together,  so pulling them back apart feels akin to unmixing multiple paint colors that have  all been stirred up together. The general strategy is going to be to build for ourselves a mathematical machine that  treats signals with a given frequency differently from how it treats other signals. To start, consider simply taking a pure signal,  say with a lowly 3 beats per second, so we can plot it easily. And let's limit ourselves to looking at a finite portion of this graph,  in this case the portion between 0 seconds and 4.5 seconds. The key idea is going to be to take this graph and sort of wrap it up around a circle. Concretely, here's what I mean by that. Imagine a little rotating vector where at each point in time  its length is equal to the height of our graph for that time. So high points of the graph correspond to a greater distance from the origin,  and low points end up closer to the origin. And right now I'm drawing it in such a way that moving forward 2  seconds in time corresponds to a single rotation around the circle. Our little vector drawing this wound up graph is rotating at half a cycle per second. So this is important, there are two different frequencies at play here. There's the frequency of our signal, which goes up and down 3 times per second,  and then separately there's the frequency with which we're wrapping the graph  around the circle, which at the moment is half of a rotation per second. But we can adjust that second frequency however we want. Maybe we want to wrap it around faster? Or maybe we go and wrap it around slower? And that choice of winding frequency determines what the wound up graph looks like. Some of the diagrams that come out of this can be pretty complicated,  although they are very pretty, but it's important to keep in mind that  all that's happening here is that we're wrapping the signal around a circle. The vertical lines that I'm drawing up top, by the way,  are just a way to keep track of the distance on the original graph that corresponds to  a full rotation around the circle. So lines spaced out by 1.5 seconds would mean  it takes 1.5 seconds to make one full revolution. And at this point we might have some sort of vague sense that something special will  happen when the winding frequency matches the frequency of our signal, 3 beats per second. All of the high points on the graph happen on the right side of the circle,  and all of the low points happen on the left. But how precisely can we take advantage of that in  our attempt to build a frequency unmixing machine? Well, imagine this graph is having some kind of mass to it, like a metal wire. This little dot is going to represent the center of mass of that wire. As we change the frequency and the graph winds up differently,  that center of mass kind of wobbles around a bit. And for most of the winding frequencies, the peaks and valleys are all spaced out  around the circle in such a way that the center of mass stays pretty close to the origin. But when the winding frequency is the same as the frequency of our signal,  in this case 3 cycles per second, all of the peaks are on the right,  and all of the valleys are on the left, so the center of mass is unusually far  to the right. Here, to capture this, let's draw some kind of plot that keeps  track of where that center of mass is for each winding frequency. Of course, the center of mass is a two-dimensional thing,  it requires two coordinates to fully keep track of, but for the moment,  let's only keep track of the x-coordinate. So for a frequency of zero, when everything is bunched up on the right,  this x-coordinate is relatively high. And then as you increase that winding frequency,  and the graph balances out around the circle, the x-coordinate of  that center of mass goes closer to zero, and it just kind of wobbles around a bit. But then, at 3 beats per second, there's a spike, as everything lines up to the right. This right here is the central construct, so let's sum up what we have so far. We have that original intensity vs time graph,  and then we have the wound up version of that in some two-dimensional plane,  and then as a third thing, we have a plot for how the winding frequency influences  the center of mass of that graph. And by the way, let's look back at those really low frequencies near zero. This big spike around zero in our new frequency plot just  corresponds to the fact that the whole cosine wave is shifted up. If I had chosen a signal that oscillates around zero, dipping into negative values,  then as we play around with various winding frequencies,  this plot of the winding frequency vs center of mass would only have a spike  at the value of 3. But negative values are a little bit weird and messy to think about,  especially for a first example, so let's just continue thinking in terms of the  shifted up graph. I just want you to understand that that spike around zero only corresponds to the shift. Our main focus, as far as frequency decomposition is concerned, is that bump at 3. This whole plot is what I'll call the almost Fourier transform of the original signal. There's a couple small distinctions between this and the actual Fourier transform,  which I'll get to in a couple minutes, but already you might be able to  see how this machine lets us pick out the frequency of a signal. Just to play around with it a little bit more, take a different Fourier signal,  let's say with a lower frequency of 2 beats per second, and do the same thing. Wind it around a circle, imagine different potential winding frequencies,  and as you do that keep track of where the center of mass of that graph is,  and then plot the x coordinate of that center of mass as you adjust the winding frequency. Just like before, we get a spike when the winding frequency is the same as  the signal frequency, which in this case is when it equals 2 cycles per second. But the real key point, the thing that makes this machine so delightful,  is how it enables us to take a signal consisting of multiple frequencies and pick out  what they are. Imagine taking the two signals we just looked at,  the wave with 3 beats per second and the wave with 2 beats per second, and add them up. Like I said earlier, what you get is no longer a nice pure cosine wave,  it's something a little more complicated. But imagine throwing this into our winding frequency machine. It is certainly the case that as you wrap this thing around it looks a  lot more complicated, you have this chaos and chaos and chaos and chaos,  and then whoop, things seem to line up really nicely at 2 cycles per second. Then as you continue on it's more chaos and more chaos and more chaos and chaos  and chaos and chaos, whoop, things nicely align again at 3 cycles per second. And like I said before, the wound up graph can look kind of busy and complicated,  but all it is is the relatively simple idea of wrapping the graph around a circle. It's just a more complicated graph and a pretty quick winding frequency. Now what's going on here with the two different spikes is that if you were to  take two signals and then apply this almost Fourier transform to each of them  individually, and then add up the results, what you get is the same as if you  first added up the signals and then applied this almost Fourier transform. And the attentive viewers among you might want to pause and ponder  and convince yourself that what I just said is actually true. It's a pretty good test to verify for yourself that it's clear  what exactly is being measured inside this winding machine. Now this property makes things really useful to us,  because the transform of a pure frequency is close to zero everywhere except  for a spike around that frequency, so when you add together two pure frequencies,  the transform graph just has these little peaks above the frequencies that went into it. So this little mathematical machine does exactly what we wanted. It pulls out the original frequencies from their jumbled up sums,  unmixing the mixed bucket of paint. And before continuing into the full math that describes this operation,  let's just get a quick glimpse of one context where this thing is useful, sound editing. Let's say that you have some recording and it's got an  annoying high pitch that you would like to filter out. Well at first your signal is coming in as a function of various intensities over time,  different voltages given to your speaker from one millisecond to the next. But we want to think of this in terms of frequencies. So when you take the Fourier transform of that signal,  the annoying high pitch is going to show up just as a spike at some high frequency. Filtering that out by just smushing the spike down,  what you'd be looking at is the Fourier transform of a sound that's just like your  recording, only without that high frequency. Luckily there's a notion of an inverse Fourier transform that tells  you which signal would have produced this as its Fourier transform. I'll be talking about that inverse much more fully in the next video,  but long story short, applying the Fourier transform to the Fourier  transform gives you back something close to the original function. Kind of, this is a little bit of a lie, but it's in the direction of truth. And most of the reason it's a lie is that I still have yet to  tell you what the actual Fourier transform is,  since it's a little more complex than this x-coordinate of the center of mass idea. First off, bringing back this wound up graph and looking at its center of mass,  the x-coordinate is really only half the story, right? I mean, this thing is in two dimensions, it's got a y-coordinate as well. And as is typical in math, whenever you're dealing with something two-dimensional,  it's elegant to think of it as the complex plane,  where this center of mass is going to be a complex number that has both a real  and an imaginary part. And the reason for talking in terms of complex numbers,  rather than just saying it has two coordinates,  is that complex numbers lend themselves to really nice descriptions of  things that have to do with winding and rotation. For example, Euler's formula famously tells us that if you take e to some number times i,  you're going to land on the point that you get if you were to walk that number of  units around a circle with radius 1 counterclockwise starting on the right. So imagine you wanted to describe rotating at a rate of 1 cycle per second. One thing you could do is take the expression e to the 2 pi times i times t,  where t is the amount of time that has passed, since for a circle with radius 1,  2 pi describes the full length of its circumference. And this is a little dizzying to look at, so maybe you want to describe  a different frequency, something lower and more reasonable,  and for that you would just multiply that time t in the exponent by the frequency f. For example, if f was 1 tenth, then this vector makes one full turn every 10 seconds,  since the time t has to increase all the way to 10 before the full exponent looks like 2  pi i. I have another video giving some intuition on why this is the  behavior of e to the x for imaginary inputs, if you're curious,  but for right now we're just going to take it as a given. Now why am I telling you this, you might ask? Well it gives us a really nice way to write down the idea  of winding up the graph into a single tight little formula. First off, the convention in the context of Fourier transforms is to think about  rotating in the clockwise direction, so let's throw a negative sign up into that exponent. Now take some function describing a signal intensity versus time,  like this pure cosine wave we had before, and call it g of t. If you multiply this exponential expression times g of t,  it means that the rotating complex number is getting scaled up and down according to  the value of this function. So you can think of this little rotating vector with  its changing length as drawing the wound up graph. So think about it, this is awesome, this really small expression  is a super elegant way to encapsulate the whole idea of  winding a graph around a circle with a variable frequency, f. And remember, the thing we want to do with this wound up graph is to track  its center of mass, so think about what formula is going to capture that. Well, to approximate it at least, you might sample a whole bunch of times  from the original signal, see where those points end up on the wound up graph,  and then just take an average, that is, add them all together as complex numbers,  and then divide by the number of points you've sampled. This will become more accurate if you sample more points which are closer together. And in the limit, rather than looking at the sum of a whole bunch of  points divided by the number of points, you take an integral of this  function divided by the size of the time interval we're looking at. The idea of integrating a complex valued function might seem weird,  and to anyone who's shaky with calculus maybe even intimidating,  but the underlying meaning here really doesn't require any calculus knowledge. The whole expression is just the center of mass of the wound up graph. So great, step by step, we have built up this kind of complicated but let's face it,  surprisingly small expression for the whole winding machine idea I talked about,  and now there is only one final distinction to point out between this and the actual  honest-to-goodness Fourier transform, namely, just don't divide out by the time interval. The Fourier transform is just the integral part of this. What that means is that instead of looking at the center of mass,  you would scale it up by some amount. If the portion of the original graph you were using spanned 3 seconds,  you would multiply the center of mass by 3. If it was spanning 6 seconds, you would multiply the center of mass by 6. Physically, this has the effect that when a certain frequency persists for a long time,  then the magnitude of the Fourier transform at that frequency is scaled up more and more. For example, what we're looking at here is how when you have a pure frequency of 2  beats per second and you wind it around the graph at 2 cycles per second,  the center of mass stays in the same spot, just tracing out the same shape.  But the longer that signal persists, the larger the value of the Fourier transform  at that frequency. For other frequencies, even if you just increase it by a bit,  this is cancelled out by the fact that for longer time intervals,  you're giving the wound-up graph more of a chance to balance itself around the circle. That is a lot of different moving parts, so let's  step back and summarize what we have so far. The Fourier transform of an intensity vs. time function, like g of t, is a new function, which doesn't have time as an input,  but instead takes in a frequency, what I've been calling the winding frequency. In terms of notation, by the way, the common convention is to  call this new function g-hat with a little circumflex on top of it. The output of this function is a complex number,  some point in the 2d plane that corresponds to the strength of a given  frequency in the original signal. The plot I've been graphing for the Fourier transform is just the real  component of that output, the x-coordinate, but you could also graph  the imaginary component separately if you wanted a fuller description. And all of this is encapsulated inside that formula we built up. And out of context, you can imagine how seeing this formula would seem sort of daunting,  but if you understand how exponentials correspond to rotation,  how multiplying that by the function g of t means drawing a wound up version of the  graph, and how an integral of a complex valued function can be interpreted in terms  of a center of mass idea, you can see how this whole thing carries with it a very rich  intuitive meaning. And by the way, one quick small note before we can call this wrapped up. Even though in practice, with things like sound editing,  you'll be integrating over a finite time interval,  the theory of Fourier transforms is often phrased where the bounds of this  integral are negative infinity and infinity. Concretely, what that means is that you consider this expression  for all possible finite time intervals, and you just ask,  what is its limit as that time interval grows to infinity? And man oh man, there is so much more to say. So much, I don't want to call it done here. This transform extends to corners of math well  beyond the idea of extracting frequencies from signal. So the next video I put out is going to go through a couple of these,  and that's really where things start getting interesting. So stay subscribed for when that comes out, or an alternate option  is to just binge on a couple 3Blue and Brown videos so that the  YouTube recommender is more inclined to show you new things that come out. Really the choice is yours. Thank you.

================================================================================
VIDEO ID: VvCytJvd4H0
TITLE: Why this puzzle is impossible
URL: https://www.youtube.com/watch?v=VvCytJvd4H0
PUBLISHED: 2017-12-23T16:43:38Z
STATUS: SUCCESS
================================================================================
It's the holiday season, a time of year to bring people together and to do something a little bit different. So... Mythologer here. I'm Matt Parker from Stand Up Maths. Hey, this is Sam from Wendover Productions and Half as Interesting. Hi everyone, this is James Grime from the Singing Bin Honor channel. What's Brady reporting for service from Numberphile, Objectivity and various other channels. Hey everyone, my name is Stephen Welch, my channel is Welch Labs. I'm from the channel Looking Glass Universe. Grant told me he was sending me a puzzle and a mug. Hey Grant, I am here. I've got a mug and some paper and some markers and I'm ready to do your puzzle. I really should know how to solve this mug because I'm the guy that makes and sells them with Matt Parker. So I've been instructed not to read the directions before starting. Hi Ben. Hi Grant. So a friend just gave me this mug. You are going to be challenged and I'm just going to kind of make you do this on camera to embarrass you. We've got three different houses here, three different cottages and then three different utilities, the gas, the power and the water. Draw a line from each of the three utilities to each of the three houses, so nine lines in total. Okay, without letting any two cross. No two lines cross. So right here, if you wanted to just go straight from power to the house, that's a new go, right? Okay, interesting. That is quite the challenge. So nine lines that don't cross. That doesn't even sound possible. I've got my mug. I've got my utilities mug here. Okay, so here it is. Here's my handmade mug. I've even got real coffee in the mug. I mean that, look at that, that's attention to detail. I'm willing to give this a go. I'm just worried I'm going to muck it up. I tend to make a bit of a parker square of these things when I, ooh, when I try, ah, see? Let's just fill in as many as I can and see what happens. I'm sure this will end terribly. So there's one, there's the other. Here we go. Gas line, it's going to be easy. We're going to go like this. Sound effects are crucial. I'm not going to go around the green one. Don't want to fall for that. I can do another one and now we're up to five. We have four to go. I'm looking at my display over here. I should have put it over there, but oh well. Oh, that should go to the, that should go to the second house.
57
00:02:18,620 --> 00:02:18,340
Okay, I'll put it to the second house. Okay, I'll put it to the second house. This is easy enough. So we just need to get from here to there. I have one, two, three, four, five, six, seven lines, two to go. So I have that one connected to that one. I need that one connected to that one. Oh, now we get into trouble. Okay, now I start to see the problem. And there I have made my fatal error in not paying attention. I have boxed in this house right here. As you can see, there's no way to get to it. Gas needs to get to number one and two. And that's the problem because we're cut off. I kind of want to try it on paper. Okay, it's getting really awkward to draw on a mug. I think what I'm going to do is I'm going to go to a piece of paper. This kind of property that you can make lines go from here to here and also all the way around makes it seem like I should be drawing a sphere. Something like that. Okay, I need bigger lines, bigger space. Uh... Now I've just blocked off. How is this possible? This isn't getting anywhere. Let's try again. Water I need to the first and second. What? Oh, I really messed it up. Okay. To make that at least look easier, I'm going to go around here. Around, around, around, around, around to two. Go around the mug with the gas here. So I'm just going to go all the way around. I'm going to go around. Let's go underneath the handle here. Over, over, over, over, over, over. So now it's close. We just need to figure out how to get that red in there. House number three is all done and good. Look at that. House number three, good to go. So this house has all three and that house has all three, but this one in the middle doesn't have gas. All right, let me try something new. Let me just try an experiment here. Let's, let's be, let's be empirical. What's really nice about the mug is that it's shiny. So if you use a dry erase marker, you can undo your mistakes. You just rub it off. Pause it. Okay, so there's some very pleasing math within this puzzle for you and me to dive into. But first, let me just say a really big thanks to everyone here who was willing to be my guinea pigs in this experiment. Each of them runs a channel that I respect a lot and many of them have been incredibly kind and helpful to this channel. So if there's any there that you're unfamiliar with or that you haven't been keeping track with, they're all listed in the description, so most certainly check them out. We'll get back to all of them in just a minute. Here's the thing about the puzzle. If you try it on a piece of paper, you're going to have a bad time. But if you're a mathematician at heart, when a puzzle seems hard, you don't just throw up your hands and walk away. Instead, you try to solve a meta-puzzle of sorts. See if you can prove that the task in front of you is impossible. In this case, how on earth do you do that? How do you prove something is impossible? For background, anytime that you have some objects with a notion of connection between those objects, it's called a graph, often represented abstractly with dots for your objects, which I'll call vertices, and lines for your connections, which I'll call edges. In most applications, the way you draw a graph doesn't matter. What matters is the connections. But in some peculiar cases, like this one, the thing that we care about is how it's drawn. And if you can draw a graph in the plane without crossing its edges, it's called a planar graph. So the question before us is whether or not our utilities puzzle graph, which in the lingo is fancifully called a complete bipartite graph, K3-3, is planar or not. And at this point, there are two kinds of viewers. Those of you who know about Euler's formula and those who don't. Those who do might see where this is going. But rather than pulling out a formula from thin air and using it to solve the meta puzzle, I want to flip things around here and show how reasoning through this conundrum step by step can lead you to rediscovering a very charming and very general piece of math. To start, as you're drawing lines here between homes and utilities, one really important thing to keep note of is whenever you enclose a new region. That is, some area that the paint bucket tool would fill in. Because you see, once you've enclosed a region like that, no new line that you draw will be able to enter or exit it. So you have to be careful with these. In the last video, remember how I mentioned that a useful problem solving tactic is to shift your focus onto any new constructs that you introduce, trying to reframe your problem around them? Well, in this case, what can we say about these regions? Right now, I have up on the screen an incomplete puzzle, where the water is not yet connected to the first house, and it has four separate regions. But can you say anything about how many regions a hypothetically complete puzzle would have? What about the number of edges that each region touches? What can you say there? There's lots of questions you might ask and lots of things you might notice. And if you're lucky, here's one thing that might pop out. For a new line that you draw to create a region, it has to hit a vertex that already has an edge coming out of it. Here, think of it like this. Start by imagining one of your nodes as lit up while the other five are dim. And then every time you draw an edge from a lit up vertex to a dim vertex, light up the new one. So at first, each new edge lights up one more vertex. But if you connect to an already lit up vertex, notice how this closes off a new region. And this is a very simple way to do it. You can see how this closes off a new region. And this gives us a super useful fact. Each new edge either increases the number of lit up nodes by one, or it increases the number of enclosed regions by one. This fact is something that we can use to figure out the number of regions that a hypothetical solution to this would cut the plane into. Can you see how? When you start off, there's one node lit up and one region, all of 2D space. By the end, we're going to need to draw nine lines, since each of the three utilities gets connected to each of the three houses. Five of those lines are going to light up the initially dim vertices. So the other four lines each must introduce a new region. So, a hypothetical solution would cut the plane into five separate regions. And you might say, okay, that's a cute fact, but why should that make things impossible? What's wrong with having five regions? Well again, take a look at this partially complete graph. Notice that each region is bounded by four edges. And in fact, for this graph, you could never have a cycle with fewer than four edges. Say you start at a house, then the next line has to be to some utility, and then a line out of that is going to go to another house, and you can't cycle back to where you started immediately, because you have to go to another utility before you can get back to that first house. So all cycles have at least four edges. And this right here gives us enough to prove the impossibility of our puzzle. Having five regions, each with a boundary of at least four edges, would require more edges than we have available. Here, let me draw a planar graph that's completely different from our utilities puzzle, but useful for illustrating what five regions with four edges each would imply. If you went through each of these regions and add up the number of edges that it has, well, you end up with five times four, or twenty. And of course, this way over counts the total number of edges in the graph, since each edge is touching multiple regions. But in fact, each edge is touching exactly two regions, so this number twenty is precisely double counting the edges. So any graph that cuts the plane into five regions, where each region is touching four edges, would have to have ten total edges. But our utilities puzzle has only nine edges available. So even though we concluded that it would have to cut the plane into five regions, it would be impossible for it to do that. So there you go, bada boom bada bang, it is impossible to solve this puzzle on a piece of paper without intersecting lines. Tell me that's not a slick proof. And before getting back to our friends and the mug, it's worth taking a moment to pull out a general truth sitting inside of this. Think back to the key rule where each new edge was introducing either a new vertex by being drawn to an untouched spot, or it introduced a new enclosed region. That same logic applies to any planar graph, not just our specific utilities puzzle situation. In other words, the number of vertices minus the number of edges plus the number of regions remains unchanged, no matter what graph you draw. Namely, it started at two, so it always stays at two. And this relation, true for any planar graph, is called Euler's characteristic formula. Historically, by the way, the formula came up in the context of convex polyhedra, like a cube for example, where the number of vertices minus the number of edges plus the number of faces always equals two. So when you see it written down, you often see it with an F for faces instead of talking about regions. Now before you go thinking of me as some kind of grinch that sends friends an impossible puzzle and then makes them film themselves trying to solve it, keep in mind, I didn't give this puzzle to people on a piece of paper. And I'm betting the handle has something to do with this. Okay. Otherwise, why would you have brought a mug over here and not a piece of paper? This is a valid observation. Ooh, I have one cool idea, maybe. Use the mug handle to be... Oh yeah, I think I see it. Okay. I feel like it has to do something with the handle and because that's our ability to hop one line over the other. I'm gonna start by, I think, taking advantage of the handle because I think that that is the key to this. You know what? I think actually a sphere is the wrong thing to be thinking about. I mean like famously, a mug is topologically the same as a donut. So to solve this thing, you're gonna have to use the torusiness of the mug. You're gonna have to use the handle somehow. That's the thing that makes this a torus. So let's take the green and go over the handle here. Okay. And then the red can kind of come under. Nice. And there we go. There you go. I think I did it. All right. Wow. My approach is to get as far as you can with, as far as you can as if you were on a plane and then see where you get stuck. So look, I'm gonna draw this to here like that. And now I've come across a problem because electricity can't be joined to this house. This is where you have to use the handle. So whatever you did, do it again, but go around the handle. So I'm gonna go down here. I'm gonna loop underneath, come back around and back to where I started. And now I'm free to get my electricity through. I'm gonna go over the handle like that. There we go. Bit messy, but there you go. And then I'm gonna go on the inside of the handle. Go all the way around the inside of the handle. And finally connect to the gas company. To solve this puzzle, just join the M and there's three more connections to go. Let's just make them one, two, and now we have to connect those two guys, right? Just watch it. In through the front door, out through the back door. Done. No intersections. Maybe you think that's cheating. Well, so it's a topological puzzle, so it means the relative positions of things don't matter. What that means is we can take this handle and move it here, creating another connection. Ho, ho, ho. Oh my god, am I done? Is this over? I think I might have gotten it. 24 minutes. Grant, you said this would take 15 minutes. There you go. I think I've solved it. You're in the success category. Hard but not impossible. Hard but not impossible. This is maybe perhaps not the most elegant solution to this problem. If I drew this line here, you'll think, oh no, he's blocked that house. There's no way to get the gas in, but this is why it's on a mug, right? Because if you take the gas line all the way up here to the top, you then take it over and into the mug. If you draw the line under the coffee, it wets the pen. So when the line comes back out again, the pen's not working anymore. You can go straight across there in and join it up, and because it wasn't drawing, you haven't had to cross the lines. Easy. By the way, funny story. So I was originally given this mug as a gift, and I didn't really know where it came from. And it was only after I had invited people to be a part of this that I realized the origin of the mug, MathsGear, is a website run by three of the YouTubers I had just invited, Matt, James, and Steve. Small world. Given just how helpful these three guys were in the logistics of a lot of this, really the least I could do to thank them is give a small plug for how gift cards from MathsGear could make a pretty good last minute Christmas present. Back to the puzzle though, this is one of those things where once you see it, it kind of feels obvious. The handle of the mug can basically be used as a bridge to prevent two lines from crossing. But this raises a really interesting mathematical question. We just proved that this task is impossible for graphs on a plane. So where exactly does that proof break down on the surface of a mug? And I'm actually not going to tell you the answer here. I want you to think about this on your own. And I don't just mean saying, oh it's because Euler's formula is different on surfaces with a hole. Really, think about this. Where specifically does the line of reasoning that I laid out break down when you're working on a mug? I promise you, thinking this through will give you a deeper understanding of math. Like anyone tackling a tricky problem, you will likely run into walls and moments of frustration. But the smartest people I know actively seek out new challenges, even if they're just toy puzzles. They ask new questions, they aren't afraid to start over many times, and they embrace every moment of failure. So give this and other puzzles an earnest try, and never stop asking questions. But Grant, I hear you complaining, how am I supposed to practice my problem solving if I don't have someone shipping me puzzles on topologically interesting shapes? Well, let's close things off by going through a couple puzzles created by this week's mathematically oriented sponsor, brilliant.org. So here I'm in their intro to problem solving course and going through a particular sequence called flipping pairs. And the rules here seem to be that we can flip adjacent pairs of coins, but we can't flip them one at a time. And we are asked, is it possible to get it so that all three coins are gold side up? Well, clearly I just did it, so yes. And the next question, we start with a different configuration, have the same rules, and we're asked the same question, can we get it so that all three of the coins are gold side up? And, you know, there's not really that many degrees of freedom we have here, just two different spots to click, so you might quickly come to the conclusion that no, you can't. Even if you don't necessarily know the theoretical reason yet, that's totally fine. So no, and we kind of move along. So next, it's kind of showing us every possible starting configuration that there is, and asking for how many of them can we get it to a point where all three gold coins are up? Obviously, I'm kind of giving away the answer, it's sitting here four on the right, because I've gone through this before. But if you want to go through it yourself, this particular quiz has a really nice resolution, and a lot of others in this course do build up genuinely good problem solving instincts. So you can go to brilliant.org slash 3b1b to let them know that you came from here, or even slash 3b1b flipping to jump straight into this quiz. And you can make an account for free, a lot of what they offer is free, but they also have a annual subscription service, if you want to get the full suite of experiences that they offer. And I just think they're really good. I know a couple of the people there, and they're incredibly thoughtful about how they put together math explanations. Water goes to one, and then wraps around to the other. And naively at this point... Oh, wait, I've already messed up. Then from there, water can make its way to cottage number three. Ah, I'm trapped! I've done this wrong again.

================================================================================
VIDEO ID: liL66CApESk
TITLE: Q&A #2 + Net Neutrality Nuance
URL: https://www.youtube.com/watch?v=liL66CApESk
PUBLISHED: 2017-12-14T15:57:43Z
STATUS: SUCCESS
================================================================================
Hey everyone! No math here, I just wanted to post two quick
announcements for you. First, the number of you who have opted to
subscribe to this channel has once again rolled over a power of 2, which is just mind-boggling
to me. Iâ€™m still touched that thereâ€™s so many
of you who enjoy math like this, just for fun, and who have helped support the channel
by watching, by sharing the content here, and for many of you on Patreon, very directly
supporting it. Really, each one of the 2^19 of you means
a lot to me. As a thanks, and just for fun, Iâ€™ll be doing
a second Q&A session. Iâ€™ve left a link to where you can ask and
upvote questions on the screen here and in the description, and just like with the first
one Iâ€™ll answer the questions in the podcast I do with Ben Eater and Ben Stenhuag, since
I think discussions are more fun than answers in a vacuum. By the way, if you guys donâ€™t already know
about Ben Eaterâ€™s channel, what are yaâ€™ doing! This man is the Bob Ross of computer engineering. If you want to understand how a computer works,
and I mean really understand it from the ground up, his channel is the place to go. Trust me, he is a very good explainer. Anyway, the reason I bring him up is that
he and I just recorded a pretty interesting conversation about Net Neutrality. I want to be very clear: Ben Eater is not
against net neutrality, and nor am I. However, the issue is a lot more nuanced than
I first realized. And because there are already many great videos
about Net Neutrality, and why itâ€™s a good thing, to offer content you may not have seen
before this conversation was a chance to unearth some of the tradeoffs at play here. You see, the thing about Eater is that before
he was creating educational content, he worked for many years in the networking industry,
so he has a pretty clear view of both sides of this equation. Iâ€™m going to play you just a minute of it
here, and then link to the full video if you want to go see it on Benâ€™s channel, which
you should be going to check out anyway. For those of you who would prefer to listen
to a 45-minute conversation in podcast form, we did also publish it as an episode  of Ben, Ben, and Blue.

================================================================================
VIDEO ID: OkmNXy7er84
TITLE: The hardest problem on the hardest test
URL: https://www.youtube.com/watch?v=OkmNXy7er84
PUBLISHED: 2017-12-08T15:04:57Z
STATUS: SUCCESS
================================================================================
Do you guys know about the Putnam? It's a math competition for undergraduate students. It's a six-hour long test that just has 12 questions  broken up into two different three-hour sessions. And each one of those questions is scored 1 to 10,  so the highest possible score would be 120. And yet, despite the fact that the only students taking this thing each year are those  who clearly are already pretty interested in math, the median score is around 1 or 2. So it's a hard test. And on each one of those sections of six questions,  the problems tend to get harder as you go from 1 to 6,  although of course difficulty is in the eye of the beholder. But the thing about those fives and sixes is that even though they're  positioned as the hardest problems on a famously hard test,  quite often these are the ones with the most elegant solutions available,  some subtle shift in perspective that transforms it from very challenging to doable. Here I'm going to share with you one problem that came up  as the sixth question on one of these tests a while back. And those of you who follow the channel know that rather than just jumping  straight to the solution, which in this case would be surprisingly short,  when possible I like to take the time to walk you through how you might  have stumbled across the solution yourself, where the insight comes from. That is, make a video more about the problem-solving  process than about the problem used to exemplify it. So anyway, here's the question. If you choose four random points on a sphere, and consider the  tetrahedron with these points as its vertices,  what is the probability that the center of the sphere is inside that tetrahedron? Go ahead, take a moment and kind of digest this question. You might start thinking about which of these tetrahedra contain the sphere's center,  which ones don't, how you might systematically distinguish the two,  and how do you approach a problem like this? Where do you even start? Well, it's usually a good idea to think about simpler cases,  so let's knock things down to two dimensions, where you'll choose three random  points on a circle, and it's always helpful to name things so let's call these guys P1,  P2, and P3. The question is, what's the probability that the triangle  formed by these points contains the center of the circle? I think you'll agree it's way easier to visualize now, but it's still a hard question. So again, you ask, is there a way to simplify what's going on,  get ourselves to some kind of foothold that we can build up from? Well, maybe you imagine fixing P1 and P2 in place, and only letting that third point vary. And when you do this, and play around with it in your mind,  you might notice that there's a special region, a certain arc,  where when P3 is in that arc, the triangle contains the center, otherwise not. Specifically, if you draw lines from P1 and P2 through the center,  these lines divide up the circle into four different arcs,  and if P3 happens to be in the one on the opposite side as P1 and P2,  the triangle has the center. If it's in any of the other arcs though, no luck. We're assuming here that all of the points of the circle are equally likely. So what is the probability that P3 lands in that arc? It's the length of that arc divided by the full circumference of the circle,  the proportion of the circle that this arc makes up. So what is that proportion? Obviously that depends on where you put the first two points. I mean, if they're 90 degrees apart from each other,  then the relevant arc is one quarter of the circle. But if those two points were farther apart, that proportion would be something closer  to a half, and if they were really close together, that proportion gets closer to zero. So think about this for a moment. P1 and P2 are chosen randomly, with every point on the circle being equally likely. So what is the average size of this relevant arc? Maybe you imagine fixing P1 in place, and just  considering all the places that P2 might be. All of the possible angles between these two lines,  every angle from 0 degrees up to 180 degrees, is equally likely. So every proportion between 0 and 0.5 is equally likely,  and that means that the average proportion is 0.25. So, if the average size of this arc is a quarter of the full circle,  the average probability that the third point lands in it is a quarter,  and that means that the overall probability that our triangle contains the  center is a quarter. But can we extend this into the three-dimensional case? If you imagine three out of those four points just being fixed in place,  which points of the sphere can the fourth one be on so that the  tetrahedron that they form contain the center of the sphere? Just like before, let's go ahead and draw some lines from each  of those fixed three points through the center of the sphere. It's also helpful if we draw some planes that are determined by any pair of these lines. What these planes do, you might notice, is divide the sphere into  eight different sections, each of which is a sort of spherical triangle. And our tetrahedron is only going to contain the center of the sphere if the  fourth point is in the spherical triangle on the opposite side as the first three. Now, unlike the 2D case, it's pretty difficult to think about the  average size of this section, as we let the initial three points vary. Those of you with some multivariable calculus under your belt might think,  let's just try a surface integral. And by all means, pull out some paper and give it a try. But it's not easy. And of course it should be difficult. I mean, this is the sixth problem on a Putnam, what do you expect? And what do you even do with that? Well, one thing you can do is back up to the two-dimensional case and  contemplate if there is a different way to think about the same answer we got. That answer, one-fourth, looks suspiciously clean,  and raises the question of what that four represents. One of the main reasons I wanted to make a video about this particular problem is that  what's about to happen carries with it a broader lesson for mathematical problem solving. Think about those two lines we drew for p1 and p2 through the origin. They made the problem a lot easier to think about. And in general, whenever you've added something to the problem  setup that makes it conceptually easier, see if you can reframe  the entire question in terms of those things you just added. In this case, rather than thinking about choosing three points randomly,  start by saying, choose two random lines that pass through the circle's center. For each line, there's two possible points it could correspond to,  so just flip a coin for each one to choose which of the endpoints is going to be p1,  and likewise for the other, which endpoint is going to be p2. Choosing a random line and flipping a coin like this is the same thing as choosing  a random point on the circle, it just feels a little bit convoluted at first. But the reason for thinking about the random process this  way is that things are actually about to become easier. We'll still think about that third point, p3, as just being a random point on the circle,  but imagine that it was chosen before you do the two coin flips. Because you see, once the two lines and the third point are set in stone,  there's only four possibilities for where P1 and P2 might end up,  based on those coin flips, each one being equally likely. But one and only one of those four outcomes leaves p1 and p2 on the opposite  side of the circle as p3, with the triangle they form containing the center. So no matter where those two lines end up, and where that p3 ends up,  it's always a 1 fourth chance that the coin flips leave us with a triangle containing  the center. Now that's very subtle. Just by reframing how we think about the random process for choosing points,  the answer 1 quarter popped out in a very different way from how it did before. And importantly, this style of argument generalizes seamlessly up into three dimensions. Again, instead of starting off by picking four random points,  imagine choosing three random lines through the center of the sphere,  and then some random point for p4. That first line passes through the sphere at two points,  so flip a coin to decide which of those two points is going to be p1. Likewise, for each of the other lines, flip a coin to decide where p2 and p3 end up. There's eight equally likely outcomes of those coin flips,  but one and only one of them is going to place p1, p2,  and p3 on the opposite side of the center as p4. So one and only one of these eight equally likely  outcomes gives us a tetrahedron that contains the center. Again, it's kind of subtle how that pops out to us, but isn't that elegant? This is a valid solution to the problem, but admittedly  the way I've stated it so far rests on some visual intuition. If you're curious about how you might write it up in a way that doesn't  rely on visual intuition, I've left a link in the description to one  such write-up in the language of linear algebra, if you're curious. And this is pretty common in math, where having the key insight and  understanding is one thing, but having the relevant background to articulate  that understanding more formally is almost a separate muscle entirely,  one that undergraduate math students kind of spend most of their time building up. But the main takeaway here is not the solution itself,  but how you might find that key insight if it was put in front of you and you  were just left to solve it. Namely, just keep asking simpler versions of the  question until you can get some kind of foothold. And then when you do, if there's any kind of added construct that proves to be useful,  see if you can reframe the whole question around that new construct. To close things off here, I've got another probability puzzle,  one that comes from this video sponsor, brilliant.org. Suppose you have eight students sitting in a circle taking the Putnam. It's a hard test, so each student tries to cheat off of his neighbor,  choosing randomly which neighbor to cheat from. Now circle all of the students that don't have somebody cheating off of their test. What is the expected number of such circled students? It's an interesting question, right? Brilliant.org is a site where you can practice your problem  solving abilities with questions like this and many, many more. And that really is the best way to learn. You're going to find countless interesting questions curated in a pretty  thoughtful way so that you really do come away better at problem solving. If you want more probability, they have a really good course on probability,  but they've got all sorts of other math and science as well,  so you're almost certainly going to find something that interests you. Me? I've been a fan for a while, and if you go to brilliant.org slash 3b1b,  it lets them know that you came from here, and the first 256 of you to visit that  link can get 20% off their premium membership, which is the one I use,  if you want to upgrade. Also if you're just itching to see a solution to this puzzle,  which by the way uses a certain tactic in probability that's useful in a lot of  other circumstances, I also left a link in the description that just jumps you  straight to the solution.

================================================================================
VIDEO ID: tIeHLnjs5U8
TITLE: Backpropagation calculus | Deep Learning Chapter 4
URL: https://www.youtube.com/watch?v=tIeHLnjs5U8
PUBLISHED: 2017-11-03T14:08:09Z
STATUS: SUCCESS
================================================================================
The hard assumption here is that you've watched part 3, giving an intuitive walkthrough of the backpropagation algorithm. Here we get a little more formal and dive into the relevant calculus. It's normal for this to be at least a little confusing, so the mantra to regularly pause and ponder certainly applies as much here as anywhere else. Our main goal is to show how people in machine learning commonly think about the chain rule from calculus in the context of networks, which has a different feel from how most introductory calculus courses approach the subject. For those of you uncomfortable with the relevant calculus, I do have a whole series on the topic. Let's start off with an extremely simple network, one where each layer has a single neuron in it. This network is determined by three weights and three biases, and our goal is to understand how sensitive the cost function is to these variables. That way, we know which adjustments to those terms will cause the most efficient decrease to the cost function. And we're just going to focus on the connection between the last two neurons. Let's label the activation of that last neuron with a superscript L, indicating which layer it's in, so the activation of the previous neuron is a(L-1). These are not exponents, they're just a way of indexing what we're talking about, since I want to save subscripts for different indices later on. Let's say that the value we want this last activation to be for a given training example is y, for example, y might be 0 or 1. So the cost of this network for a single training example is (a(L) - y) squared. We'll denote the cost of that one training example as C0. As a reminder, this last activation is determined by a weight, which I'm going to call w(L), times the previous neuron's activation plus some bias, which I'll call b(L). And then you pump that through some special nonlinear function like the sigmoid or ReLU. It's actually going to make things easier for us if we give a special name to this weighted sum, like z, with the same superscript as the relevant activations. This is a lot of terms, and a way you might conceptualize it is that the weight, previous action and the bias all together are used to compute z, which in turn lets us compute a, which finally, along with a constant y, lets us compute the cost. And of course a(L-1) is influenced by its own weight and bias and such, but we're not going to focus on that right now. All of these are just numbers, right? And it can be nice to think of each one as having its own little number line. Our first goal is to understand how sensitive the cost function is to small changes in our weight w(L). Or phrase differently, what is the derivative of C with respect to w(L)? When you see this del w term, think of it as meaning some tiny nudge to W, like a change by 0.01, and think of this del C term as meaning whatever the resulting nudge to the cost is. What we want is their ratio. Conceptually, this tiny nudge to w(L) causes some nudge to z(L), which in turn causes some nudge to a(L), which directly influences the cost. So we break things up by first looking at the ratio of a tiny change to z(L) to this tiny change q, that is, the derivative of z(L) with respect to w(L). Likewise, you then consider the ratio of the change to a(L) to the tiny change in z(L) that caused it, as well as the ratio between the final nudge to C and this intermediate nudge to a(L). This right here is the chain rule, where multiplying together these three ratios gives us the sensitivity of C to small changes in w(L). So on screen right now, there's a lot of symbols, and take a moment to make sure it's clear what they all are, because now we're going to compute the relevant derivatives. The derivative of C with respect to a(L) works out to be 2(a(L)-y). Notice this means its size is proportional to the difference between the network's output and the thing we want it to be, so if that output was very different, even slight changes stand to have a big impact on the final cost function. The derivative of a(L) with respect to z(L) is just the derivative of our sigmoid function, or whatever nonlinearity you choose to use. And the derivative of z(L) with respect to w(L) comes out to be a(L-1). Now I don't know about you, but I think it's easy to get stuck head down in the formulas without taking a moment to sit back and remind yourself of what they all mean. In the case of this last derivative, the amount that the small nudge to the weight influenced the last layer depends on how strong the previous neuron is. Remember, this is where the neurons-that-fire-together-wire-together idea comes in. And all of this is the derivative with respect to w(L) only of the cost for a specific single training example. Since the full cost function involves averaging together all those costs across many different training examples, its derivative requires averaging this expression over all training examples. And of course, that is just one component of the gradient vector, which itself is built up from the partial derivatives of the cost function with respect to all those weights and biases. But even though that's just one of the many partial derivatives we need, it's more than 50% of the work. The sensitivity to the bias, for example, is almost identical. We just need to change out this del z del w term for a del z del b. And if you look at the relevant formula, that derivative comes out to be 1. Also, and this is where the idea of propagating backwards comes in, you can see how sensitive this cost function is to the activation of the previous layer. Namely, this initial derivative in the chain rule expression, the sensitivity of z to the previous activation, comes out to be the weight w(L). And again, even though we're not going to be able to directly influence that previous layer activation, it's helpful to keep track of, because now we can just keep iterating this same chain rule idea backwards to see how sensitive the cost function is to previous weights and previous biases. And you might think this is an overly simple example, since all layers have one neuron, and things are going to get exponentially more complicated for a real network. But honestly, not that much changes when we give the layers multiple neurons, really it's just a few more indices to keep track of. Rather than the activation of a given layer simply being a(L), it's also going to have a subscript indicating which neuron of that layer it is. Let's use the letter k to index the layer L-1, and j to index the layer L. For the cost, again we look at what the desired output is, but this time we add up the squares of the differences between these last layer activations and the desired output. That is, you take a sum over a(L)j minus yj squared. Since there's a lot more weights, each one has to have a couple more indices to keep track of where it is, so let's call the weight of the edge connecting this kth neuron to the jth neuron, w(L)jk. Those indices might feel a little backwards at first, but it lines up with how you'd index the weight matrix I talked about in the part 1 video. Just as before, it's still nice to give a name to the relevant weighted sum, like z, so that the activation of the last layer is just your special function, like the sigmoid, applied to z. You can see what I mean, where all of these are essentially the same equations we had before in the one-neuron-per-layer case, it's just that it looks a little more complicated. And indeed, the chain-ruled derivative expression describing how sensitive the cost is to a specific weight looks essentially the same. I'll leave it to you to pause and think about each of those terms if you want. What does change here, though, is the derivative of the cost with respect to one of the activations in the layer L-1. In this case, the difference is that the neuron influences the cost function through multiple different paths. That is, on the one hand, it influences a(L)0, which plays a role in the cost function, but it also has an influence on a(L)1, which also plays a role in the cost function, and you have to add those up. And that, well, that's pretty much it. Once you know how sensitive the cost function is to the activations in this second-to-last layer, you can just repeat the process for all the weights and biases feeding into that layer. So pat yourself on the back! If all of this makes sense, you have now looked deep into the heart of backpropagation, the workhorse behind how neural networks learn. These chain rule expressions give you the derivatives that determine each component in the gradient that helps minimize the cost of the network by repeatedly stepping downhill. If you sit back and think about all that, this is a lot of layers of complexity to wrap your mind around, so don't worry if it takes time for your mind to digest it all.

================================================================================
VIDEO ID: Ilg3gGewQ5U
TITLE: Backpropagation, intuitively | Deep Learning Chapter 3
URL: https://www.youtube.com/watch?v=Ilg3gGewQ5U
PUBLISHED: 2017-11-03T14:03:37Z
STATUS: SUCCESS
================================================================================
Here, we tackle backpropagation, the core algorithm behind how neural networks learn. After a quick recap for where we are, the first thing I'll do is an intuitive walkthrough for what the algorithm is actually doing, without any reference to the formulas. Then, for those of you who do want to dive into the math, the next video goes into the calculus underlying all this. If you watched the last two videos, or if you're just jumping in with the appropriate background, you know what a neural network is, and how it feeds forward information. Here, we're doing the classic example of recognizing handwritten digits whose pixel values get fed into the first layer of the network with 784 neurons, and I've been showing a network with two hidden layers having just 16 neurons each, and an output layer of 10 neurons, indicating which digit the network is choosing as its answer. I'm also expecting you to understand gradient descent, as described in the last video, and how what we mean by learning is that we want to find which weights and biases minimize a certain cost function. As a quick reminder, for the cost of a single training example, you take the output the network gives, along with the output you wanted it to give, and add up the squares of the differences between each component. Doing this for all of your tens of thousands of training examples and averaging the results, this gives you the total cost of the network. And as if that's not enough to think about, as described in the last video, the thing that we're looking for is the negative gradient of this cost function, which tells you how you need to change all of the weights and biases, all of these connections, so as to most efficiently decrease the cost. Backpropagation, the topic of this video, is an algorithm for computing that crazy complicated gradient. And the one idea from the last video that I really want you to hold firmly in your mind right now is that because thinking of the gradient vector as a direction in 13,000 dimensions is, to put it lightly, beyond the scope of our imaginations, there's another way you can think about it. The magnitude of each component here is telling you how sensitive the cost function is to each weight and bias. For example, let's say you go through the process I'm about to describe, and you compute the negative gradient, and the component associated with the weight on this edge here comes out to be 3.2, while the component associated with this edge here comes out as 0.1. The way you would interpret that is that the cost of the function is 32 times more sensitive to changes in that first weight, so if you were to wiggle that value just a little bit, it's going to cause some change to the cost, and that change is 32 times greater than what the same wiggle to that second weight would give. Personally, when I was first learning about backpropagation, I think the most confusing aspect was just the notation and the index chasing of it all. But once you unwrap what each part of this algorithm is really doing, each individual effect it's having is actually pretty intuitive, it's just that there's a lot of little adjustments getting layered on top of each other. So I'm going to start things off here with a complete disregard for the notation, and just step through the effects each training example has on the weights and biases. Because the cost function involves averaging a certain cost per example over all the tens of thousands of training examples, the way we adjust the weights and biases for a single gradient descent step also depends on every single example. Or rather, in principle it should, but for computational efficiency we'll do a little trick later to keep you from needing to hit every single example for every step. In other cases, right now, all we're going to do is focus our attention on one single example, this image of a 2. What effect should this one training example have on how the weights and biases get adjusted? Let's say we're at a point where the network is not well trained yet, so the activations in the output are going to look pretty random, maybe something like 0.5, 0.8, 0.2, on and on. We can't directly change those activations, we only have influence on the weights and biases. But it's helpful to keep track of which adjustments we wish should take place to that output layer. And since we want it to classify the image as a 2, we want that third value to get nudged up while all the others get nudged down. Moreover, the sizes of these nudges should be proportional to how far away each current value is from its target value. For example, the increase to that number 2 neuron's activation is in a sense more important than the decrease to the number 8 neuron, which is already pretty close to where it should be. So zooming in further, let's focus just on this one neuron, the one whose activation we wish to increase. Remember, that activation is defined as a certain weighted sum of all the activations in the previous layer, plus a bias, which is all then plugged into something like the sigmoid squishification function, or a ReLU. So there are three different avenues that can team up together to help increase that activation. You can increase the bias, you can increase the weights, and you can change the activations from the previous layer. Focusing on how the weights should be adjusted, notice how the weights actually have differing levels of influence. The connections with the brightest neurons from the preceding layer have the biggest effect since those weights are multiplied by larger activation values. So if you were to increase one of those weights, it actually has a stronger influence on the ultimate cost function than increasing the weights of connections with dimmer neurons, at least as far as this one training example is concerned. Remember, when we talk about gradient descent, we don't just care about whether each component should get nudged up or down, we care about which ones give you the most bang for your buck. This, by the way, is at least somewhat reminiscent of a theory in neuroscience for how biological networks of neurons learn, Hebbian theory, often summed up in the phrase, neurons that fire together wire together. Here, the biggest increases to weights, the biggest strengthening of connections, happens between neurons which are the most active, and the ones which we wish to become more active. In a sense, the neurons that are firing while seeing a 2 get more strongly linked to those firing when thinking about a 2. To be clear, I'm not in a position to make statements one way or another about whether artificial networks of neurons behave anything like biological brains, and this fires together wire together idea comes with a couple meaningful asterisks, but taken as a very loose analogy, I find it interesting to note. Anyway, the third way we can help increase this neuron's activation is by changing all the activations in the previous layer. Namely, if everything connected to that digit 2 neuron with a positive weight got brighter, and if everything connected with a negative weight got dimmer, then that digit 2 neuron would become more active. And similar to the weight changes, you're going to get the most bang for your buck by seeking changes that are proportional to the size of the corresponding weights. Now of course, we cannot directly influence those activations, we only have control over the weights and biases. But just as with the last layer, it's helpful to keep a note of what those desired changes are. But keep in mind, zooming out one step here, this is only what that digit 2 output neuron wants. Remember, we also want all the other neurons in the last layer to become less active, and each of those other output neurons has its own thoughts about what should happen to that second to last layer. So, the desire of this digit 2 neuron is added together with the desires of all the other output neurons for what should happen to this second to last layer, again in proportion to the corresponding weights, and in proportion to how much each of those neurons needs to change. This right here is where the idea of propagating backwards comes in. By adding together all these desired effects, you basically get a list of nudges that you want to happen to this second to last layer. And once you have those, you can recursively apply the same process to the relevant weights and biases that determine those values, repeating the same process I just walked through and moving backwards through the network. And zooming out a bit further, remember that this is all just how a single training example wishes to nudge each one of those weights and biases. If we only listened to what that 2 wanted, the network would ultimately be incentivized just to classify all images as a 2. So what you do is go through this same backprop routine for every other training example, recording how each of them would like to change the weights and biases, and average together those desired changes. This collection here of the averaged nudges to each weight and bias is, loosely speaking, the negative gradient of the cost function referenced in the last video, or at least something proportional to it. I say loosely speaking only because I have yet to get quantitatively precise about those nudges, but if you understood every change I just referenced, why some are proportionally bigger than others, and how they all need to be added together, you understand the mechanics for what backpropagation is actually doing. By the way, in practice, it takes computers an extremely long time to add up the influence of every training example every gradient descent step. So here's what's commonly done instead. You randomly shuffle your training data and then divide it into a whole bunch of mini-batches, let's say each one having 100 training examples. Then you compute a step according to the mini-batch. It's not going to be the actual gradient of the cost function, which depends on all of the training data, not this tiny subset, so it's not the most efficient step downhill, but each mini-batch does give you a pretty good approximation, and more importantly, it gives you a significant computational speedup. If you were to plot the trajectory of your network under the relevant cost surface, it would be a little more like a drunk man stumbling aimlessly down a hill but taking quick steps, rather than a carefully calculating man determining the exact downhill direction of each step before taking a very slow and careful step in that direction. This technique is referred to as stochastic gradient descent. There's a lot going on here, so let's just sum it up for ourselves, shall we? Backpropagation is the algorithm for determining how a single training example would like to nudge the weights and biases, not just in terms of whether they should go up or down, but in terms of what relative proportions to those changes cause the most rapid decrease to the cost. A true gradient descent step would involve doing this for all your tens of thousands of training examples and averaging the desired changes you get. But that's computationally slow, so instead you randomly subdivide the data into mini-batches and compute each step with respect to a mini-batch. Repeatedly going through all of the mini-batches and making these adjustments, you will converge towards a local minimum of the cost function, which is to say your network will end up doing a really good job on the training examples. So with all of that said, every line of code that would go into implementing backprop actually corresponds with something you have now seen, at least in informal terms. But sometimes knowing what the math does is only half the battle, and just representing the damn thing is where it gets all muddled and confusing. So for those of you who do want to go deeper, the next video goes through the same ideas that were just presented here, but in terms of the underlying calculus, which should hopefully make it a little more familiar as you see the topic in other resources. Before that, one thing worth emphasizing is that for this algorithm to work, and this goes for all sorts of machine learning beyond just neural networks, you need a lot of training data. In our case, one thing that makes handwritten digits such a nice example is that there exists the MNIST database, with so many examples that have been labeled by humans. So a common challenge that those of you working in machine learning will be familiar with is just getting the labeled training data you actually need, whether that's having people label tens of thousands of images, or whatever other data type you might be dealing with.

================================================================================
VIDEO ID: IHZwWFHWa-w
TITLE: Gradient descent, how neural networks learn | Deep Learning Chapter 2
URL: https://www.youtube.com/watch?v=IHZwWFHWa-w
PUBLISHED: 2017-10-16T16:48:20Z
STATUS: SUCCESS
================================================================================
Last video I laid out the structure of a neural network. I'll give a quick recap here so that it's fresh in our minds, and then I have two main goals for this video. The first is to introduce the idea of gradient descent, which underlies not only how neural networks learn, but how a lot of other machine learning works as well. Then after that we'll dig in a little more into how this particular network performs, and what those hidden layers of neurons end up looking for. As a reminder, our goal here is the classic example of handwritten digit recognition, the hello world of neural networks. These digits are rendered on a 28x28 pixel grid, each pixel with some grayscale value between 0 and 1. Those are what determine the activations of 784 neurons in the input layer of the network. And then the activation for each neuron in the following layers is based on a weighted sum of all the activations in the previous layer, plus some special number called a bias. Then you compose that sum with some other function, like the sigmoid squishification, or a relu, the way I walked through last video. In total, given the somewhat arbitrary choice of two hidden layers with 16 neurons each, the network has about 13,000 weights and biases that we can adjust, and it's these values that determine what exactly the network actually does. Then what we mean when we say that this network classifies a given digit is that the brightest of those 10 neurons in the final layer corresponds to that digit. And remember, the motivation we had in mind here for the layered structure was that maybe the second layer could pick up on the edges, and the third layer might pick up on patterns like loops and lines, and the last one could just piece together those patterns to recognize digits. So here, we learn how the network learns. What we want is an algorithm where you can show this network a whole bunch of training data, which comes in the form of a bunch of different images of handwritten digits, along with labels for what they're supposed to be, and it'll adjust those 13,000 weights and biases so as to improve its performance on the training data. Hopefully, this layered structure will mean that what it learns generalizes to images beyond that training data. The way we test that is that after you train the network, you show it more labeled data that it's never seen before, and you see how accurately it classifies those new images. Fortunately for us, and what makes this such a common example to start with, is that the good people behind the MNIST database have put together a collection of tens of thousands of handwritten digit images, each one labeled with the numbers they're supposed to be. And as provocative as it is to describe a machine as learning, once you see how it works, it feels a lot less like some crazy sci-fi premise, and a lot more like a calculus exercise. I mean, basically it comes down to finding the minimum of a certain function. Remember, conceptually, we're thinking of each neuron as being connected to all the neurons in the previous layer, and the weights in the weighted sum defining its activation are kind of like the strengths of those connections, and the bias is some indication of whether that neuron tends to be active or inactive. And to start things off, we're just going to initialize all of those weights and biases totally randomly. Needless to say, this network is going to perform pretty horribly on a given training example, since it's just doing something random. For example, you feed in this image of a 3, and the output layer just looks like a mess. So what you do is define a cost function, a way of telling the computer, no, bad computer, that output should have activations which are 0 for most neurons, but 1 for this neuron, what you gave me is utter trash. To say that a little more mathematically, you add up the squares of the differences between each of those trash output activations and the value you want them to have, and this is what we'll call the cost of a single training example. Notice this sum is small when the network confidently classifies the image correctly, but it's large when the network seems like it doesn't know what it's doing. So then what you do is consider the average cost over all of the tens of thousands of training examples at your disposal. This average cost is our measure for how lousy the network is, and how bad the computer should feel. And that's a complicated thing. Remember how the network itself was basically a function, one that takes in 784 numbers as inputs, the pixel values, and spits out 10 numbers as its output, and in a sense it's parameterized by all these weights and biases? Well the cost function is a layer of complexity on top of that. It takes as its input those 13,000 or so weights and biases, and spits out a single number describing how bad those weights and biases are, and the way it's defined depends on the network's behavior over all the tens of thousands of pieces of training data. That's a lot to think about. But just telling the computer what a crappy job it's doing isn't very helpful. You want to tell it how to change those weights and biases so that it gets better. To make it easier, rather than struggling to imagine a function with 13,000 inputs, just imagine a simple function that has one number as an input and one number as an output. How do you find an input that minimizes the value of this function? Calculus students will know that you can sometimes figure out that minimum explicitly, but that's not always feasible for really complicated functions, certainly not in the 13,000 input version of this situation for our crazy complicated neural network cost function. A more flexible tactic is to start at any input, and figure out which direction you should step to make that output lower. Specifically, if you can figure out the slope of the function where you are, then shift to the left if that slope is positive, and shift the input to the right if that slope is negative. If you do this repeatedly, at each point checking the new slope and taking the appropriate step, you're going to approach some local minimum of the function. The image you might have in mind here is a ball rolling down a hill. Notice, even for this really simplified single input function, there are many possible valleys that you might land in, depending on which random input you start at, and there's no guarantee that the local minimum you land in is going to be the smallest possible value of the cost function. That will carry over to our neural network case as well. And I also want you to notice how if you make your step sizes proportional to the slope, then when the slope is flattening out towards the minimum, your steps get smaller and smaller, and that kind of helps you from overshooting. Bumping up the complexity a bit, imagine instead a function with two inputs and one output. You might think of the input space as the xy-plane, and the cost function as being graphed as a surface above it. Now instead of asking about the slope of the function, you have to ask which direction you should step in this input space so as to decrease the output of the function most quickly. In other words, what's the downhill direction? Again, it's helpful to think of a ball rolling down that hill. Those of you familiar with multivariable calculus will know that the gradient of a function gives you the direction of steepest ascent, which direction should you step to increase the function most quickly. Naturally enough, taking the negative of that gradient gives you the direction to step that decreases the function most quickly. Even more than that, the length of this gradient vector is an indication for just how steep that steepest slope is. If you're unfamiliar with multivariable calculus and want to learn more, check out some of the work I did for Khan Academy on the topic. Honestly though, all that matters for you and me right now is that in principle there exists a way to compute this vector, this vector that tells you what the downhill direction is and how steep it is. You'll be okay if that's all you know and you're not rock solid on the details. Cause If you can get that, the algorithm for minimizing the function is to compute this gradient direction, then take a small step downhill, and repeat that over and over. It's the same basic idea for a function that has 13,000 inputs instead of 2 inputs. Imagine organizing all 13,000 weights and biases of our network into a giant column vector. The negative gradient of the cost function is just a vector, it's some direction inside this insanely huge input space that tells you which nudges to all of those numbers is going to cause the most rapid decrease to the cost function. And of course, with our specially designed cost function, changing the weights and biases to decrease it means making the output of the network on each piece of training data look less like a random array of 10 values, and more like an actual decision we want it to make. It's important to remember, this cost function involves an average over all of the training data, so if you minimize it, it means it's a better performance on all of those samples. The algorithm for computing this gradient efficiently, which is effectively the heart of how a neural network learns, is called backpropagation, and it's what I'm going to be talking about next video. There, I really want to take the time to walk through what exactly happens to each weight and bias for a given piece of training data, trying to give an intuitive feel for what's happening beyond the pile of relevant calculus and formulas. Right here, right now, the main thing I want you to know, independent of implementation details, is that what we mean when we talk about a network learning is that it's just minimizing a cost function. And notice, one consequence of that is that it's important for this cost function to have a nice smooth output, so that we can find a local minimum by taking little steps downhill. This is why, by the way, artificial neurons have continuously ranging activations, rather than simply being active or inactive in a binary way, the way biological neurons are. This process of repeatedly nudging an input of a function by some multiple of the negative gradient is called gradient descent. It's a way to converge towards some local minimum of a cost function, basically a valley in this graph. I'm still showing the picture of a function with two inputs, of course, because nudges in a 13,000 dimensional input space are a little hard to wrap your mind around, but there is a nice non-spatial way to think about this. Each component of the negative gradient tells us two things. The sign, of course, tells us whether the corresponding component of the input vector should be nudged up or down. But importantly, the relative magnitudes of all these components kind of tells you which changes matter more. You see, in our network, an adjustment to one of the weights might have a much greater impact on the cost function than the adjustment to some other weight. Some of these connections just matter more for our training data. So a way you can think about this gradient vector of our mind-warpingly massive cost function is that it encodes the relative importance of each weight and bias, that is, which of these changes is going to carry the most bang for your buck. This really is just another way of thinking about direction. To take a simpler example, if you have some function with two variables as an input, and you compute that its gradient at some particular point comes out as 3,1, then on the one hand you can interpret that as saying that when you're standing at that input, moving along this direction increases the function most quickly, that when you graph the function above the plane of input points, that vector is what's giving you the straight uphill direction. But another way to read that is to say that changes to this first variable have 3 times the importance as changes to the second variable, that at least in the neighborhood of the relevant input, nudging the x-value carries a lot more bang for your buck. Let's zoom out and sum up where we are so far. The network itself is this function with 784 inputs and 10 outputs, defined in terms of all these weighted sums. The cost function is a layer of complexity on top of that. It takes the 13,000 weights and biases as inputs and spits out a single measure of lousiness based on the training examples. And the gradient of the cost function is one more layer of complexity still. It tells us what nudges to all these weights and biases cause the fastest change to the value of the cost function, which you might interpret as saying which changes to which weights matter the most. So, when you initialize the network with random weights and biases, and adjust them many times based on this gradient descent process, how well does it actually perform on images it's never seen before? The one I've described here, with the two hidden layers of 16 neurons each, chosen mostly for aesthetic reasons, is not bad, classifying about 96% of the new images it sees correctly. And honestly, if you look at some of the examples it messes up on, you feel compelled to cut it a little slack. Now if you play around with the hidden layer structure and make a couple tweaks, you can get this up to 98%. And that's pretty good! It's not the best, you can certainly get better performance by getting more sophisticated than this plain vanilla network, but given how daunting the initial task is, I think there's something incredible about any network doing this well on images it's never seen before, given that we never specifically told it what patterns to look for. Originally, the way I motivated this structure was by describing a hope we might have, that the second layer might pick up on little edges, that the third layer would piece together those edges to recognize loops and longer lines, and that those might be pieced together to recognize digits. So is this what our network is actually doing? Well, for this one at least, not at all. Remember how last video we looked at how the weights of the connections from all the neurons in the first layer to a given neuron in the second layer can be visualized as a given pixel pattern that the second layer neuron is picking up on? Well, when we actually do that for the weights associated with these transitions, from the first layer to the next, instead of picking up on isolated little edges here and there, they look, well, almost random, just with some very loose patterns in the middle there. It would seem that in the unfathomably large 13,000 dimensional space of possible weights and biases, our network found itself a happy little local minimum that, despite successfully classifying most images, doesn't exactly pick up on the patterns we might have hoped for. And to really drive this point home, watch what happens when you input a random image. If the system was smart, you might expect it to feel uncertain, maybe not really activating any of those 10 output neurons or activating them all evenly, but instead it confidently gives you some nonsense answer, as if it feels as sure that this random noise is a 5 as it does that an actual image of a 5 is a 5. Phrased differently, even if this network can recognize digits pretty well, it has no idea how to draw them. A lot of this is because it's such a tightly constrained training setup. I mean, put yourself in the network's shoes here. From its point of view, the entire universe consists of nothing but clearly defined unmoving digits centered in a tiny grid, and its cost function never gave it any incentive to be anything but utterly confident in its decisions. So with this as the image of what those second layer neurons are really doing, you might wonder why I would introduce this network with the motivation of picking up on edges and patterns. I mean, that's just not at all what it ends up doing. Well, this is not meant to be our end goal, but instead a starting point. Frankly, this is old technology, the kind researched in the 80s and 90s, and you do need to understand it before you can understand more detailed modern variants, and it clearly is capable of solving some interesting problems, but the more you dig into what those hidden layers are really doing, the less intelligent it seems. Shifting the focus for a moment from how networks learn to how you learn, that'll only happen if you engage actively with the material here somehow. One pretty simple thing I want you to do is just pause right now and think deeply for a moment about what changes you might make to this system and how it perceives images if you wanted it to better pick up on things like edges and patterns. But better than that, to actually engage with the material, I highly recommend the book by Michael Nielsen on deep learning and neural networks. In it, you can find the code and the data to download and play with for this exact example, and the book will walk you through step by step what that code is doing. What's awesome is that this book is free and publicly available, so if you do get something out of it, consider joining me in making a donation towards Nielsen's efforts. I've also linked a couple other resources I like a lot in the description, including the phenomenal and beautiful blog post by Chris Ola and the articles in Distill. To close things off here for the last few minutes, I want to jump back into a snippet of the interview I had with Leisha Lee. You might remember her from the last video, she did her PhD work in deep learning. In this little snippet she talks about two recent papers that really dig into how some of the more modern image recognition networks are actually learning. Just to set up where we were in the conversation, the first paper took one of these particularly deep neural networks that's really good at image recognition, and instead of training it on a properly labeled dataset, shuffled all the labels around before training. Obviously the testing accuracy here was going to be no better than random, since everything's just randomly labeled. But it was still able to achieve the same training accuracy as you would on a properly labeled dataset. Basically, the millions of weights for this particular network were enough for it to just memorize the random data, which raises the question for whether minimizing this cost function actually corresponds to any sort of structure in the image, or is it just memorization? ...to memorize the entire dataset of what the correct classification is. And so half a year later at ICML this year, there was not exactly rebuttal paper, but paper that addressed some aspects of like, hey, actually these networks are doing something a little bit smarter than that. If you look at that accuracy curve if you were just training on a random data set that curve went down very slowly, almost in a linear fashion. So youâ€™re really struggling to find that local minimum of the right weights. Whereas if you're actually training on a structured dataset, one that has the right labels, you fiddle around a little bit in the beginning, but then you kind of dropped very fast to get to that accuracy level, and so in some sense it was easier to find that local maxima. And so what was also interesting about that is it brings into light another paper from actually a couple of years ago, which has a lot more simplifications about the network layers, but one of the results was saying how if you look at the optimization landscape, the local minima that these networks tend to learn are actually of equal quality, so in some sense if your dataset is structured, you should be able to find that much more easily. My thanks, as always, to those of you supporting on Patreon. I've said before just what a game changer Patreon is, but these videos really would not be possible without you. I also want to give a special thanks to the VC firm Amplify Partners and their support of these initial videos in the series. Thank you.

================================================================================
VIDEO ID: aircAruvnKk
TITLE: But what is a neural network? | Deep learning chapter 1
URL: https://www.youtube.com/watch?v=aircAruvnKk
PUBLISHED: 2017-10-05T15:11:25Z
STATUS: SUCCESS
================================================================================
This is a 3. It's sloppily written and rendered at an extremely low resolution of 28x28 pixels, but your brain has no trouble recognizing it as a 3. And I want you to take a moment to appreciate how crazy it is that brains can do this so effortlessly. I mean, this, this and this are also recognizable as 3s, even though the specific values of each pixel is very different from one image to the next. The particular light-sensitive cells in your eye that are firing when you see this 3 are very different from the ones firing when you see this 3. But something in that crazy-smart visual cortex of yours resolves these as representing the same idea, while at the same time recognizing other images as their own distinct ideas. But if I told you, hey, sit down and write for me a program that takes in a grid of 28x28 pixels like this and outputs a single number between 0 and 10, telling you what it thinks the digit is, well the task goes from comically trivial to dauntingly difficult. Unless you've been living under a rock, I think I hardly need to motivate the relevance and importance of machine learning and neural networks to the present and to the future. But what I want to do here is show you what a neural network actually is, assuming no background, and to help visualize what it's doing, not as a buzzword but as a piece of math. My hope is that you come away feeling like the structure itself is motivated, and to feel like you know what it means when you read, or you hear about a neural network quote-unquote learning. This video is just going to be devoted to the structure component of that, and the following one is going to tackle learning. What we're going to do is put together a neural network that can learn to recognize handwritten digits. This is a somewhat classic example for introducing the topic, and I'm happy to stick with the status quo here, because at the end of the two videos I want to point you to a couple good resources where you can learn more, and where you can download the code that does this and play with it on your own computer. There are many many variants of neural networks, and in recent years there's been sort of a boom in research towards these variants, but in these two introductory videos you and I are just going to look at the simplest plain vanilla form with no added frills. This is kind of a necessary prerequisite for understanding any of the more powerful modern variants, and trust me it still has plenty of complexity for us to wrap our minds around. But even in this simplest form it can learn to recognize handwritten digits, which is a pretty cool thing for a computer to be able to do. And at the same time you'll see how it does fall short of a couple hopes that we might have for it. As the name suggests neural networks are inspired by the brain, but let's break that down. What are the neurons, and in what sense are they linked together? Right now when I say neuron all I want you to think about is a thing that holds a number, specifically a number between 0 and 1. It's really not more than that. For example the network starts with a bunch of neurons corresponding to each of the 28x28 pixels of the input image, which is 784 neurons in total. Each one of these holds a number that represents the grayscale value of the corresponding pixel, ranging from 0 for black pixels up to 1 for white pixels. This number inside the neuron is called its activation, and the image you might have in mind here is that each neuron is lit up when its activation is a high number. So all of these 784 neurons make up the first layer of our network. Now jumping over to the last layer, this has 10 neurons, each representing one of the digits. The activation in these neurons, again some number that's between 0 and 1, represents how much the system thinks that a given image corresponds with a given digit. There's also a couple layers in between called the hidden layers, which for the time being should just be a giant question mark for how on earth this process of recognizing digits is going to be handled. In this network I chose two hidden layers, each one with 16 neurons, and admittedly that's kind of an arbitrary choice. To be honest I chose two layers based on how I want to motivate the structure in just a moment, and 16, well that was just a nice number to fit on the screen. In practice there is a lot of room for experiment with a specific structure here. The way the network operates, activations in one layer determine the activations of the next layer. And of course the heart of the network as an information processing mechanism comes down to exactly how those activations from one layer bring about activations in the next layer. It's meant to be loosely analogous to how in biological networks of neurons, some groups of neurons firing cause certain others to fire. Now the network I'm showing here has already been trained to recognize digits, and let me show you what I mean by that. It means if you feed in an image, lighting up all 784 neurons of the input layer according to the brightness of each pixel in the image, that pattern of activations causes some very specific pattern in the next layer which causes some pattern in the one after it, which finally gives some pattern in the output layer. And the brightest neuron of that output layer is the network's choice, so to speak, for what digit this image represents. And before jumping into the math for how one layer influences the next, or how training works, let's just talk about why it's even reasonable to expect a layered structure like this to behave intelligently. What are we expecting here? What is the best hope for what those middle layers might be doing? Well, when you or I recognize digits, we piece together various components. A 9 has a loop up top and a line on the right. An 8 also has a loop up top, but it's paired with another loop down low. A 4 basically breaks down into three specific lines, and things like that. Now in a perfect world, we might hope that each neuron in the second to last layer corresponds with one of these subcomponents, that anytime you feed in an image with, say, a loop up top, like a 9 or an 8, there's some specific neuron whose activation is going to be close to 1. And I don't mean this specific loop of pixels, the hope would be that any generally loopy pattern towards the top sets off this neuron. That way, going from the third layer to the last one just requires learning which combination of subcomponents corresponds to which digits. Of course, that just kicks the problem down the road, because how would you recognize these subcomponents, or even learn what the right subcomponents should be? And I still haven't even talked about how one layer influences the next, but run with me on this one for a moment. Recognizing a loop can also break down into subproblems. One reasonable way to do this would be to first recognize the various little edges that make it up. Similarly, a long line, like the kind you might see in the digits 1 or 4 or 7, is really just a long edge, or maybe you think of it as a certain pattern of several smaller edges. So maybe our hope is that each neuron in the second layer of the network corresponds with the various relevant little edges. Maybe when an image like this one comes in, it lights up all of the neurons associated with around 8 to 10 specific little edges, which in turn lights up the neurons associated with the upper loop and a long vertical line, and those light up the neuron associated with a 9. Whether or not this is what our final network actually does is another question, one that I'll come back to once we see how to train the network, but this is a hope that we might have, a sort of goal with the layered structure like this. Moreover, you can imagine how being able to detect edges and patterns like this would be really useful for other image recognition tasks. And even beyond image recognition, there are all sorts of intelligent things you might want to do that break down into layers of abstraction. Parsing speech, for example, involves taking raw audio and picking out distinct sounds, which combine to make certain syllables, which combine to form words, which combine to make up phrases and more abstract thoughts, etc. But getting back to how any of this actually works, picture yourself right now designing how exactly the activations in one layer might determine the activations in the next. The goal is to have some mechanism that could conceivably combine pixels into edges, or edges into patterns, or patterns into digits. And to zoom in on one very specific example, let's say the hope is for one particular neuron in the second layer to pick up on whether or not the image has an edge in this region here. The question at hand is what parameters should the network have? What dials and knobs should you be able to tweak so that it's expressive enough to potentially capture this pattern, or any other pixel pattern, or the pattern that several edges can make a loop, and other such things? Well, what we'll do is assign a weight to each one of the connections between our neuron and the neurons from the first layer. These weights are just numbers. Then take all of those activations from the first layer and compute their weighted sum according to these weights. I find it helpful to think of these weights as being organized into a little grid of their own, and I'm going to use green pixels to indicate positive weights, and red pixels to indicate negative weights, where the brightness of that pixel is some loose depiction of the weight's value. Now if we made the weights associated with almost all of the pixels zero except for some positive weights in this region that we care about, then taking the weighted sum of all the pixel values really just amounts to adding up the values of the pixel just in the region that we care about. And if you really wanted to pick up on whether there's an edge here, what you might do is have some negative weights associated with the surrounding pixels. Then the sum is largest when those middle pixels are bright but the surrounding pixels are darker. When you compute a weighted sum like this, you might come out with any number, but for this network what we want is for activations to be some value between 0 and 1. So a common thing to do is to pump this weighted sum into some function that squishes the real number line into the range between 0 and 1. And a common function that does this is called the sigmoid function, also known as a logistic curve. Basically very negative inputs end up close to 0, positive inputs end up close to 1, and it just steadily increases around the input 0. So the activation of the neuron here is basically a measure of how positive the relevant weighted sum is. But maybe it's not that you want the neuron to light up when the weighted sum is bigger than 0. Maybe you only want it to be active when the sum is bigger than say 10. That is, you want some bias for it to be inactive. What we'll do then is just add in some other number like negative 10 to this weighted sum before plugging it through the sigmoid squishification function. That additional number is called the bias. So the weights tell you what pixel pattern this neuron in the second layer is picking up on, and the bias tells you how high the weighted sum needs to be before the neuron starts getting meaningfully active. And that is just one neuron. Every other neuron in this layer is going to be connected to all 784 pixel neurons from the first layer, and each one of those 784 connections has its own weight associated with it. Also, each one has some bias, some other number that you add on to the weighted sum before squishing it with the sigmoid. And that's a lot to think about! With this hidden layer of 16 neurons, that's a total of 784 times 16 weights, along with 16 biases. And all of that is just the connections from the first layer to the second. The connections between the other layers also have a bunch of weights and biases associated with them. All said and done, this network has almost exactly 13,000 total weights and biases. 13,000 knobs and dials that can be tweaked and turned to make this network behave in different ways. So when we talk about learning, what that's referring to is getting the computer to find a valid setting for all of these many many numbers so that it'll actually solve the problem at hand. One thought experiment that is at once fun and kind of horrifying is to imagine sitting down and setting all of these weights and biases by hand, purposefully tweaking the numbers so that the second layer picks up on edges, the third layer picks up on patterns, etc. I personally find this satisfying rather than just treating the network as a total black box, because when the network doesn't perform the way you anticipate, if you've built up a little bit of a relationship with what those weights and biases actually mean, you have a starting place for experimenting with how to change the structure to improve. Or when the network does work but not for the reasons you might expect, digging into what the weights and biases are doing is a good way to challenge your assumptions and really expose the full space of possible solutions. By the way, the actual function here is a little cumbersome to write down, don't you think? So let me show you a more notationally compact way that these connections are represented. This is how you'd see it if you choose to read up more about neural networks. Organize all of the activations from one layer into a column as a vector. Then organize all of the weights as a matrix, where each row of that matrix corresponds to the connections between one layer and a particular neuron in the next layer. What that means is that taking the weighted sum of the activations in the first layer according to these weights corresponds to one of the terms in the matrix vector product of everything we have on the left here. By the way, so much of machine learning just comes down to having a good grasp of linear algebra, so for any of you who want a nice visual understanding for matrices and what matrix vector multiplication means, take a look at the series I did on linear algebra, especially chapter 3. Back to our expression, instead of talking about adding the bias to each one of these values independently, we represent it by organizing all those biases into a vector, and adding the entire vector to the previous matrix vector product. Then as a final step, I'll wrap a sigmoid around the outside here, and what that's supposed to represent is that you're going to apply the sigmoid function to each specific component of the resulting vector inside. So once you write down this weight matrix and these vectors as their own symbols, you can communicate the full transition of activations from one layer to the next in an extremely tight and neat little expression, and this makes the relevant code both a lot simpler and a lot faster, since many libraries optimize the heck out of matrix multiplication. Remember how earlier I said these neurons are simply things that hold numbers? Well of course the specific numbers that they hold depends on the image you feed in, so it's actually more accurate to think of each neuron as a function, one that takes in the outputs of all the neurons in the previous layer and spits out a number between 0 and 1. Really the entire network is just a function, one that takes in 784 numbers as an input and spits out 10 numbers as an output. It's an absurdly complicated function, one that involves 13,000 parameters in the forms of these weights and biases that pick up on certain patterns, and which involves iterating many matrix vector products and the sigmoid squishification function, but it's just a function nonetheless. And in a way it's kind of reassuring that it looks complicated. I mean if it were any simpler, what hope would we have that it could take on the challenge of recognizing digits? And how does it take on that challenge? How does this network learn the appropriate weights and biases just by looking at data? Well that's what I'll show in the next video, and I'll also dig a little more into what this particular network we're seeing is really doing. Now is the point I suppose I should say subscribe to stay notified about when that video or any new videos come out, but realistically most of you don't actually receive notifications from YouTube, do you? Maybe more honestly I should say subscribe so that the neural networks that underlie YouTube's recommendation algorithm are primed to believe that you want to see content from this channel get recommended to you. Anyway, stay posted for more. Thank you very much to everyone supporting these videos on Patreon. I've been a little slow to progress in the probability series this summer, but I'm jumping back into it after this project, so patrons you can look out for updates there. To close things off here I have with me Lisha Li who did her PhD work on the theoretical side of deep learning and who currently works at a venture capital firm called Amplify Partners who kindly provided some of the funding for this video. So Lisha one thing I think we should quickly bring up is this sigmoid function. As I understand it early networks use this to squish the relevant weighted sum into that interval between zero and one, you know kind of motivated by this biological analogy of neurons either being inactive or active. Exactly.
But relatively few modern networks actually use sigmoid anymore. Yeah.
It's kind of old school right? Yeah or rather ReLU seems to be much easier to train. And ReLU, ReLU stands for rectified linear unit? Yes it's this kind of function where you're just taking a max of zero and a where a is given by what you were explaining in the video and what this was sort of motivated from I think was a partially by a biological analogy with how neurons would either be activated or not. And so if it passes a certain threshold it would be the identity function but if it did not then it would just not be activated so it'd be zero so it's kind of a simplification. Using sigmoids didn't help training or it was very difficult to train at some point and people just tried ReLU and it happened to work very well for these incredibly deep neural networks. All right thank you Lisha.

================================================================================
VIDEO ID: MzRCDLre1b4
TITLE: Some light quantum mechanics (with minutephysics)
URL: https://www.youtube.com/watch?v=MzRCDLre1b4
PUBLISHED: 2017-09-13T14:06:26Z
STATUS: SUCCESS
================================================================================
You guys know Henry from MinutePhysics, right? Well, he and I just made a video on a certain quantum mechanical topic,  Bell's inequalities. It's a really mind-warping topic that not enough people know about,  and even though it's a quantum thing, it's based on some surprisingly simple math,  and you should definitely check it out. For this video, we have in mind those viewers who  actually want to learn some quantum mechanics more deeply. And obviously it's a huge topic, nowhere near the scope of a single video,  but the question we asked was what topic could we present that's not meant  to be some eye-catching piece of quantum weirdness,  but which actually lays down some useful foundations for anyone who wants  to learn this field? What topic would set the right intuitions for someone before they dove into,  say, the Feynman lectures? Well, a natural place to start, where quantum mechanics itself started, is light. Specifically, if you want to learn quantum, you have to have an  understanding of waves and how they're described mathematically. And what we'd like to build to here is the relationship between the energy  in a purely classical wave and the probabilities that govern quantum behavior. In fact, we'll actually spend most of the time talking through the pre-quantum  understanding of light, since that sets up a lot of the relevant wave mechanics. The thing is, a lot of ideas from quantum mechanics,  like describing states as superpositions with various amplitudes and phases,  come up in the context of classical waves in a way that doesn't involve any of the  quantum weirdness people might be familiar with. This also helps to appreciate what's actually different in quantum mechanics,  namely certain restrictions on how much energy these waves can have,  how they behave when measured, and quantum entanglement,  though we won't cover entanglement in this video. So we'll start with the late 1800s understanding  of light as waves in the electromagnetic field. Here, let's break that down a bit. The electric field is a vector field, and that means every point in space has  some arrow attached to it, indicating the direction and strength of the field. Now, the physical meaning of those arrows is that if you have some charged particle in  space, there's going to be a force on that particle in the direction of the arrow,  and it's proportional to the length of the arrow and the specific charge of the particle. Likewise, the magnetic field is another vector field,  where now the physical meaning of each arrow is that when a charged particle is  moving through that space, there's going to be a force perpendicular to both its  direction of motion and to the direction of the magnetic field,  and the strength of that force is proportional to the charge of the particle,  its velocity, and the length of the magnetic field arrow. For example, a wire with a current of moving charges next to  a magnet is either pushed or pulled by that magnetic field. A kind of culmination of the 19th century physics understanding of  how these two fields work are Maxwell's equations,  which among other things describe how each of these fields can cause  a change to the other. Specifically, what Maxwell's equations tell us is that when the electric  field arrows seem to be forming a loop around some region,  the magnetic field will be increasing inside that region perpendicular to  the plane of the loop, and symmetrically, such a loop in the magnetic field  corresponds to a change in the electric field within it perpendicular to  the plane of the loop. Now, the specifics for how exactly these equations work is really beautiful  and worth a full video on its own, but all you need to know for now is that  one natural consequence of this mutual interplay in how changes to one field  cause changes to the other in its neighboring regions is that you get these  propagating waves where the electric field and magnetic fields are oscillating  perpendicular to each other and perpendicular to the direction of propagation. When you hear the term electromagnetic radiation,  which refers to things like radio waves and visible light,  this is what it's talking about, propagating waves in both the  electric and magnetic fields. Of course, it's now almost mainstream to know of light as electromagnetic radiation,  but it's neat to think about just how surprising this was in Maxwell's time,  that these fields that have to do with forces on charged particles and magnets not only  have something to do with light, but that what light is is a propagating wave as these  two fields dance with each other causing this mutual oscillation of increasing and  decreasing field strength. With this as a visual, let's take a moment to lay down the math used to describe waves. It'll still be purely classical, but ideas that are core to quantum mechanics,  like superposition, amplitudes, phases, all of these come up in this context,  and I would argue with a clearer motivation for what they actually mean. Take this wave and think of it as directed straight out of the screen, towards your face. And let's go ahead and ignore the magnetic field right now,  just looking at how the electric field oscillates. And also, we're only going to focus on one of these vectors oscillating  in the plane of the screen, which we'll think of as the xy plane. If it oscillates horizontally, like this, we say that the light is horizontally polarized. So the y component of this electric field is 0 at all times,  and we might write the x component as something like cosine of 2 pi times ft,  where f represents some frequency, and t is time. So if f was 1, for example, that means it takes exactly 1  second for this cosine function to go through a full cycle. For a lower frequency, that would mean it takes more  time for the cosine to go through its full cycle. As the value t increases, the inside of this cosine function increases more slowly. Also we're going to include another term in here, phi, called the phase shift,  which tells us where this vector is in its cycle at time t equals 0. You'll see why that matters in just a moment. By default, cosine only oscillates between negative 1 and 1,  so let's put another term in front, a, that gives us the amplitude of this wave. One more thing, just to make things look a little more like they often do in  quantum mechanics, instead of writing it as a column vector, like this,  I'm going to separate it out into two different components using these symbols  called kets. This ket here indicates a unit vector in the horizontal direction,  and this ket here represents a unit vector in the vertical direction. If the light is vertically polarized, meaning the electric field is  wiggling purely in the up and down direction, its equation might look like this,  where the horizontal component is now 0, and the vertical component  is a cosine with some frequency, amplitude, and phase shift. Now if you have two distinct waves, two ways of wiggling through  space over time that solve Maxwell's equations,  then adding both of these together gives another valid wave, at least in a vacuum. That is, at each point in time, add these two vectors tip to tail to get a new vector. Doing this at all points in space and all points in time gives a new,  valid solution to Maxwell's equations, at least this is all true in a vacuum. This is because Maxwell's equations in a vacuum are what's called linear equations. They're essentially a combination of derivatives acting on the electric and magnetic  fields to give 0, so if one field f1 satisfies this equation and another field f2  satisfies it, then their sum, f1 plus f2, also satisfies it, since derivatives are linear. So the sum of two or more solutions to Maxwell's  equations is also a solution to Maxwell's equations. This new wave is called a superposition of the first two. And here, superposition essentially just means sum, or in some context, weighted sum,  since if you include some kind of amplitude and phase shift in each of these components,  it can still be called a superposition of the two original vectors. Now right now, the resulting superposition is a wave wiggling in the diagonal direction,  but if the horizontal and vertical components were out of phase with each other,  which might happen if you increase the phase shift in one of them,  their sum might instead trace out some sort of ellipse,  and in the case where the phases are exactly 90 degrees out of sync with each other,  and the amplitudes are both equal, this is what we call circularly polarized light. This by the way is why it's important to keep track not just of the amplitude in  each direction but also of the phase, it affects the way the two waves add together. That's also an important idea that carries over to quantum,  and underlies some of the things that look confusing at first. And here's another important idea, we're describing waves by adding  together the horizontal and vertical components,  but we could also choose to describe everything with respect to different directions. I mean, you could describe waves as some superposition  of the diagonal and the anti-diagonal directions. In that case, vertically polarized light would actually be a  superposition of these two diagonal wiggling directions,  at least when both are in phase with each other and have the same magnitude. The choice of which directions you write things in terms of is called a basis,  and which basis is nicest to work with, well that typically  depends on what you're doing with the light. For example, if you have a polarizing filter, like that from a set  of polarized sunglasses, the way these work is by absorbing the  energy from electromagnetic oscillations in some particular direction. A vertically oriented polarizer, for example, would absorb  all of the energy from these waves along the horizontal directions,  at least classically that's how you might think about it. So, if you're analyzing light and it's passing through a filter like this,  it's nice to describe it with respect to the horizontal and vertical directions. That way, what you can say is that whatever light passes through  the filter is just the vertical component of the original wave. But if you had a filter oriented, say, diagonally,  well then it would be convenient to describe things as a superposition  of that diagonal direction and its perpendicular anti-diagonal direction. These ideas will carry over almost word for word to the quantum case. Quantum states, much like this wiggling direction of our wave,  are described as a superposition of multiple base states,  where you have many choices for what base states to use. And just like with classical waves, the components of such a  superposition will have both an amplitude and a phase of some kind. And by the way, for those of you who do read more into quantum mechanics,  you'll find that these components are actually given using a single complex number,  rather than a cosine expression like this one. One way to think of this is that complex numbers are just a very convenient and  natural mathematical way to encode an amplitude and a phase with a single value. That can make things a little confusing because it's hard to visualize a pair of  complex numbers, which is what would describe a superposition of two base states. But you can think about the use of complex numbers throughout  quantum mechanics as a result of its underlying wavy nature,  and this need to encapsulate the amplitude and the phase for each direction. Okay, just one quick point before getting into the quantum. Look at one of these waves, and focus just on  the electric field portion like we were before. Classically, we think about the energy of a wave like  this as being proportional to the square of its amplitude. And I want you to notice how well this lines up with the Pythagorean theorem. If you were to describe this wave as a superposition of a horizontal  component with amplitude Ax, and a vertical component with amplitude Ay,  then its energy density is proportional to Ax2 plus Ay2. And you can think of this in two different ways. Either it's because you're adding up the energies of each component in the superposition,  or it's just that you're figuring out the new amplitude using the  Pythagorean theorem and taking the square. Isn't that nice? In the classical understanding of light, you should be able to dial this energy  up and down continuously however you want by changing the amplitude of the wave. But what physicists started to notice in the late 19th and early 20th  centuries was that this energy actually seems to come in discrete amounts. Specifically, the energy of one of these electromagnetic waves always seems to  come as an integer multiple of a specific constant times the frequency of that wave. We now call this constant Planck's constant, commonly denoting it with the letter h. Physically what this means is that whenever this wave trades its  energy with something else like an electron, the amount of energy  it trades off is always an integer multiple of h times its frequency. Importantly, this means there is some minimal non-zero  energy level for waves of a given frequency, hf. If you have an electromagnetic wave with this frequency and energy,  you cannot make it smaller without eliminating it entirely. That feels weird when the conception of a wave  is a nice continuously oscillating vector field. But that's not how the universe works as late 19th  and early 20th century experiments started to expose. In fact I've done a video about this called the origin of quantum mechanics. However, it's worth noting that this phenomenon is actually  common in waves when they're constrained in certain ways,  like in pipes or instrument strings, and it's called harmonics. What's weird is that electromagnetic waves do this in free space,  even when they're not constrained. And what do we call an electromagnetic wave with this minimal possible energy? A photon. But like I said, the math used to describe classical  electromagnetic waves carries over to describing a photon. It might have, say, a 45 degree diagonal polarization,  which can be described as a superposition of a purely horizontal state  and a purely vertical state, where each one of these components has some  amplitude and phase. And with a different choice in basis, that same state might  be described as a superposition of two other directions. All of this is stuff you'd see if you started reading more into quantum mechanics. But this superposition has a different interpretation than before, and it has to. Let's say you were thinking of this diagonally polarized photon kind of classically,  and you said it has an amplitude of one unit for some appropriate unit system. That would make the hypothetical amplitudes of its horizontal  and vertical components each the square root of one half. And like Henry said, the energy of a photon is  this special constant h times its frequency. And because in a classical setting energy is proportional to the square of the  amplitude of this wave, it's tempting to think of half of the energy as being  in the horizontal component, and half of it as being in the vertical component. But waves of this frequency cannot have half the energy of a photon. I mean, the whole novelty of quantum here is that energy comes in these discrete,  indivisible chunks. So these components, with an imagined amplitude of one over the square root of two,  could not exist in isolation. And you might wonder what exactly they mean. Well, let's get experimental about it. If you were to take a vertically oriented polarizing filter and shoot this  diagonally polarized photon right at it, what do you think would happen? Classically, the way you'd interpret this superposition is that  the half of its energy in the horizontal direction would be absorbed. But because energy comes in these discrete photon packets,  it either has to pass through with all of its energy or get absorbed entirely. And if you actually did this experiment, about half the time the photon  goes through entirely, and about half the time it gets absorbed entirely. And it appears to be random whether a given photon passes through or not. If it does pass through, forcing it to make a decision like this actually  changes it so that its polarization is oriented along the filter's direction. This is analogous to the classic Schrodinger's cat setup. You have something that's in a superposition of two states,  but once you make a measurement of that superposition,  forcing it to interact with an observer in a way where each of those two  states would behave differently, from the perspective of that observer,  this superposition collapses to be entirely in one state or entirely in another,  dead or alive, horizontal or vertical. One pretty neat way to see this in action, which Henry and I talk about in the  other video, is to take several polarized sunglasses,  or some other form of polarizing filters, and start by holding two of them between  you and some light source. If you rotate them to be 90 degrees off from each other,  the light source is blacked out completely, or at least with perfect filters it would be,  because all of the photons passing through that first one are polarized vertically,  so they actually have a 0% chance of passing a filter oriented horizontally. But if you insert a third filter oriented at a 45 degree angle between the two,  it actually lets more light through. What's going on here is that 50% of the photons passing that vertical filter  will also pass through the diagonal filter, and once they do,  they're going to be changed to have a purely diagonal polarization,  and once they're in that state, they have a 50-50 chance of passing through the  filter oriented at 90 degrees. So even though 0% of the photons passing through the first  would pass through that last if nothing was in between,  by introducing another filter, 25% of them now pass through all three. Now that's something you could not explain unless that  middle filter forces the photons to change their states. And that experiment, by the way, becomes all the weirder when you  dig into the specific probabilities for angles between 0 and 45 degrees,  and that's actually what we talk about in the other video. For example, one specific value we focus on there is the probability that a photon whose  polarization is 22.5 degrees off the direction of a filter will pass through that filter. Again, it's helpful to think of this wave as having an amplitude of 1,  and then you'd think of the horizontal component as having an amplitude  sin of 22.5 degrees, which is around 0.38, and the vertical component  would have an amplitude cos of 22.5 degrees, which is around 0.92. Classically, you might think of its horizontal component as  having energy proportional to 0.38 squared, which is around 0.15. Likewise, you might think of the vertical component as having an energy proportional to 0. 92 squared, which comes out to be around 0.85. And like we said before, classically, this would mean if you pass it through  a vertical filter, 15% of its energy is absorbed in the horizontal direction. But because the energy of light comes in these discrete quanta that cannot be subdivided,  instead what you observe is that 85% of the time the photon passes through entirely,  and 15% of the time it gets completely blocked. Now I want to emphasize that the wave equations don't change. The photon is still described as a superposition of two oscillating components,  each with some phase and amplitude, and these are often encoded using a single complex  number. The difference is that classically the squares of the amplitudes of each component tells  you the amount of that wave's energy in each direction,  but with quantized light at this minimal non-zero energy level,  the squares of those amplitudes tell you the probabilities that a given photon is going  to be found to have all of its energy in one direction or not. Also, these components could still have some kind of phase difference. Just like with classical waves, photons can be circularly polarized,  and there exist polarizing filters that only let through photons  that are polarized circularly, say in the clockwise direction. Or rather, they let through all photons probabilistically,  where the probabilities are determined by describing each one of those  photons as a superposition of the clockwise and counterclockwise states,  and then the square of the amplitude of the clockwise component gives you  the desired probability. Photons are, of course, just one quantum phenomenon,  one where we initially understood it as a wave thanks to Maxwell's equations,  and then as individual particles or quanta, hence the name quantum mechanics. But as many of you well know, there's a flip side to this where many  things that were understood to come in discrete little packets,  like electrons, were discovered to be governed by similar, wavy quantum mechanics. In cases way more general than this one-photon polarization example,  quantum mechanical states are described as some superposition of multiple base states,  and the superposition depends on what basis you choose. Each component in this superposition is given with an amplitude and a phase,  often encoded as a single complex number, and the need for this  phase arises from the wave nature of these objects. As with the photon example, the choice of how to measure these objects can determine  a set of base states, where the probability of measuring a particle to be in one of  these base states is proportional to the squares of the amplitudes of these numbers. It's funny to think, though, that if the wavy nature of electrons and other  particles was discovered first, we might instead refer to the whole subject as  harmonic mechanics, or something like that, since the weirdness there is not  that waves come in discrete units, but that particles are governed by wave equations. This video was supported in part by Brilliant,  and as viewers of this channel know, what I like about Brilliant  is that they're a great complement to passively watching educational videos. All of you here want to learn more math, or physics,  or the math that prepares you for physics, and the only way to  actually learn this stuff is to actively grapple with puzzles and problem solving. Brilliant offers many well-curated sequences of problems  that help you to master all sorts of technical subjects. You all like physics, clearly, so I think you would enjoy their  courses on classical mechanics and gravitational physics,  and honestly group theory would give you a really good foundation. But there are many other great courses too, especially in math. If you go to brilliant.org slash 3b1b, that one lets them know that you came from here,  and also the first 200 people that go to that link are going to get  20% off the annual Brilliant Premium subscription. That's the subscription I've been using, and it's actually  really fun to have a bank of these puzzles and problems. But of course, for those of you who want some more passive viewing,  don't forget that Henry and I just put out a video on Bell's inequalities over on  minute physics. If for some reason you haven't been following minute physics these days,  and I don't know why you wouldn't have been, the videos there have been really top notch,  so definitely take a moment to poke around the rest of his channel.

================================================================================
VIDEO ID: zwAD6dRSVyI
TITLE: Thinking outside the 10-dimensional box
URL: https://www.youtube.com/watch?v=zwAD6dRSVyI
PUBLISHED: 2017-08-11T22:41:08Z
STATUS: SUCCESS
================================================================================
Math is sometimes a real tease. It seduces us with the beauty of reasoning geometrically in two and three dimensions where there's this really nice back and forth between pairs or triplets of numbers and spatial stuff that our visual cortex is good at processing. For example, if you think about a circle with radius 1 centered at the origin, you are in effect conceptualizing every possible pair of numbers x and y that satisfy a certain numerical property that x squared plus y squared is 1. And the usefulness here is that a lot of facts that look opaque in a purely analytic context become quite clear geometrically and vice versa. Honestly, this channel has been the direct beneficiary of this back and forth since it offers such a rich library of that special category of cleverness that involves connecting two seemingly disparate ideas. And I don't just mean the general back and forth between pairs or triplets of numbers and spatial reasoning. I mean this specific one between sums of squares and circles and spheres. It's at the heart of the video I made showing how pi is connected to number theory and primes and the one showing how to visualize all possible Pythagorean triples. It also underlies the video on the Borsuk-Ulam theorem being used to solve what was basically a counting puzzle by using topological facts about spheres. There is no doubt that the ability to frame analytic facts geometrically is very useful for math. But it's all a tease because when you start asking questions about quadruplets or quintuplets or 100 tuples of numbers it's frustrating. The constraints on our physical space seem to have constrained our intuitions about geometry and we lose this back and forth. I mean it is completely reasonable to imagine that there are problems out there that would have clever and illuminating solutions if only we knew how to conceptualize say lists of 10 numbers as individual points in some space. For mathematicians or computer scientists or physicists problems that are framed in terms of lists of numbers lists of more than three numbers are a regular part of the job and the standard approach to actually doing math in higher dimensions is to use two and three dimensions for analogy but to fundamentally reason about things just analytically somewhat analogous to a pilot relying primarily on instruments and not sight while flying through the clouds. Now what I want to offer here is a hybrid between the purely geometric and the purely analytic views a method for making the analytic reasoning a little more visual in a way that generalizes to arbitrarily high dimensions and to drive home the value of a tactic like this I want to share with you a very famous example where analogies with two and three dimensions cannot help because of something extremely counterintuitive that only happens in higher dimensions. The hope though is that what I show you here helps to make that phenomenon more intuitive. The focus throughout will be on higher dimensional spheres for example when we talk about a four-dimensional sphere say with radius one centered at the origin what that actually is is the set of all quadruplets of numbers x,y,z,w where the sum of the squares of these numbers is one. What I have pictured here now is multiple three-dimensional slices of a 4d sphere projected back into three dimensions but it's confusing and even if you do wrap your head around it it just pushes the question back to how you would think about a five or six or a seven dimensional sphere and more importantly squinting your eyes to understand a projection like this is not very reflective of what doing math with a 4d sphere actually entails. Instead the basic idea here will be to get very literal about it and to think about four separate numbers. I like to picture four vertical number lines with sliders to represent each number. Each configuration of these sliders is a point in 4d space, a quadruplet of numbers, and what it means to be on a 4d unit sphere centered at the origin is that the sum of the squares of these four values is one. Our goal is to understand which movements of these sliders correspond to movements on the sphere. To do that it helps if we knock things down to two dimensions where we can actually see the circle. So ask yourself what's a nice way to think about this relation that x squared plus y squared is one? Well I like to think of the value of x squared as the real estate belonging to x and likewise the value of y squared is the real estate belonging to y and that they have a total of one unit of real estate to share between them. So moving around on the circle corresponds to a constant exchange of real estate between the two variables. Part of the reason I choose this term is that it lets us make a very useful analogy that real estate is cheap near zero and more expensive away from To see this, consider starting off in a position where x equals 1 and y is 0, meaning x has all of the real estate to itself, which in our usual geometric picture means we're on the rightmost point of the circle. If you move x down just a bit to 0.9 the value of x squared changes to 0.81, so it has in effect given up 0.19 units of real estate. But for y squared to increase by that same amount, y has to move an entire 0.44 units away from 0, more than four times the amount that x moved. In other words, x changed a little to give up expensive real estate so that y could move a lot and gain the same value of cheap real estate. In terms of the usual circle drawing, this corresponds to the steep slope near the right side. A small nudge in x allows for a very big change to y. Moving forward, let's add some tick marks to these lines to indicate what 0.05 units of real estate looks like at each point. That is, how much would x have to change so that the value of x squared changes by 0.05? As you walk around the circle, the trade-off in value between x squared and y squared gives this piston looking dance motion, where the sliders are moving more slowly away from zero because real estate is more expensive in those regions. There are just more tick marks to cover per unit distance. Also, a nice side effect of the term real estate is that it aligns naturally with the fact that it comes in units of distance squared, so the square root of the total real estate among all coordinates gives us the distance from the origin. For a unit sphere in three dimensions, the set of all triplets x, y, z where the sum of their squares is one, all we have to do is add a third slider for z, but these three sliders still only have the one unit of real estate to share between them. To get a feel for this, imagine holding x in place at 0.5, where it occupies 0.25 units of real estate. What this means is that y and z can move around in the same piston dance motion we saw before as they trade off the remaining 0.75 units of real estate. In terms of our typical way of visualizing a sphere, this corresponds to slicing the sphere along the plane where x is 0.5 and looking at the circle formed by all of the choices for y and z on that sphere. As you increase the value of x, the amount of real estate left over for y and z is smaller, and this more constrained piston dance is what it feels like for the circular slice to be smaller. Eventually, once x reaches the value 1, there's no real estate left over, so you reach this singularity point where y and z are both forced to be 0. The feeling here is a bit like being a bug on the surface of the sphere. You are unable to see the whole sphere all at once. Instead, you're just sitting on a single point, and you have some sense for what local movements are allowed. In four dimensions and higher, we lose the crutch of the global view that a spatial visual offers, but the fundamental rules of this real estate exchange remain the same. If you fix one slider in place and watch the other three trade off, this is basically what it means to take a slice of the 4d sphere to get a small 3d sphere, in much the same way that fixing one of the sliders for the three-dimensional case give us a circular slice when the remaining two were free to vary. Now watching these sliders move about and thinking about the real estate exchange is pretty fun, but it runs the risk of being aimless unless we have an actual high-dimensional puzzle to sink our teeth into. So let's set aside the sliders for just a moment and bring in a very classic example of something that seems reasonable and even dull in two and three dimensions, but which is totally out of whack in higher dimensions. To start, take a 2x2 box centered at the origin. Its corners are on the vertices 1,1, 1,-1,-1,1, and 1,-1. Draw four circles, each with radius 1, centered at these four vertices, so each one is tangent to two of its neighbors. Now I want you to think of the circle centered at the origin which is just large enough to be touching those corner circles, tangent to each one of them. What we want to do for this setup and for its analogies in higher dimensions is find the radius of that inner circle. Here in two dimensions we can use the Pythagorean theorem to see that the distance from the origin to the corner of the box is the square root of 2, which is around 1.414. Then you can subtract off this portion here the radius of the corner circle which by definition is 1, and that means the radius of the inner circle is square root of 2 minus 1, or about 0.414. No surprises here, that seems pretty reasonable. Now do something analogous in three dimensions. Draw a 2x2x2 cube whose corners have vertices 1,1,1,1,1,-1, on and on and on, and then we're going to take eight different spheres, each of which has a radius 1, and center them on these vertices so that each one is tangent to three of its neighbors. Now again, think about the sphere centered at the origin which is just large enough to be barely touching those eight corner spheres. As before, we can start by thinking about the distance from the origin to the corner of the box, say the corner at 1,1,1. By the way, I guess I still haven't yet explicitly said that the way distances work in higher dimensions is always to add up the squares of the components in each direction and take the square root. If you've never seen why this follows from the Pythagorean theorem just in the two-dimensional case, it's actually a really fun puzzle to think about, and I've left the relevant image up on the screen for any of you who want to pause and ponder on it. Anyway, in our case the distance between the origin and the corner 1,1,1 is the square root of 1 squared plus 1 squared plus 1 squared, or square root of 3, which is about 1.73. So the radius of that inner sphere is going to be this quantity minus the radius of a corner sphere, which by definition is 1. And again, 0.73 seems like a reasonable radius for that inner sphere. But what happens to that inner radius as you increase dimensions? Obviously the reason I bring this up is that something surprising will happen, and some of you might see where this is going, but I actually don't want it to feel like a surprise. As fun as it is to wow people with counterintuitive facts and math, the goal here is genuine understanding, not shock. For higher dimensions we'll be using sliders to get a gut feel for what's going on, but since it's kind of a different way of viewing things it helps to get a running start by looking back at how to analyze the two and three-dimensional cases in the context of sliders. First things first, how do you think about a circle centered at a corner like 1,-1? Well previously, for a circle centered at the origin, the amount of real estate belonging to both x and y was dependent on their distance from the number 0. And it's the same basic idea here as you move around the center, it's just that the real estate might be dependent on the distance between each coordinate and some other number. So for this circle, centered at 1,-1, the amount of real estate belonging to x is the square of its distance from 1. Likewise, the real estate belonging to y is the square of its distance from negative 1. Other than that, the look and feel with this piston dance trade-off is completely the same. For simplicity, we'll only focus on one of these circles, the one centered at 1,-1. Now ask yourself, what does it mean to find a circle centered at the origin large enough to be tangent to this guy when we're thinking just in terms of sliders? Well notice how this point of tangency happens when the x and y coordinates are both the same. Or phrased differently, at the point of this corner circle closest to the origin, the real estate is shared evenly between x and y. This will be important for later, so let's really dig in and think about why it's true. Imagine perturbing that point slightly, maybe moving x a little closer to 0, which means y would have to move a little away from 0. The change in x would have to be a little smaller than the change in y, since the real estate it gains by moving farther away from 1 is more expensive than the real estate that y loses by getting closer to 1. But from the perspective of the origin point 0,0 that trade-off is reversed. The resulting change to x squared is smaller than the resulting change to y squared, since when real estate is measured with respect to 0,0, that move of y towards 1 is the more expensive one. What this means is that any slight perturbation away from this point where real estate is shared evenly results in an increasing distance from the origin. The reason we care is that this point is tangent to the inner circle, so we can also think about it as being a point of the inner circle. And this will be very useful for higher dimensions. It gives us a reference point to understanding the radius of that inner circle. Specifically, you can ask how much real estate is shared between x and y at this point when real estate measurements are done with respect to the origin 0,0. For example, down here in two dimensions both x and y dip below 0.5 in this configuration, so the total value x squared plus y squared is going to be less than 0.5 squared plus 0.5 squared. Comparing to this halfway point is really going to come in handy for wrapping our mind around what happens in higher dimensions. Taking things one step at a time, let's bump it up to three dimensions. Consider the corner sphere with radius 1 centered at 1,1,1. The point on that sphere that's closest to the origin corresponds to the configuration of sliders where x, y, and z are all reaching down toward 0 and equal to each other. Again, they all have to go a little beyond that halfway point because the position 0.5 only accounts for 0.5 squared, or 0.25 units of real estate. So with all three coordinates getting a third of a unit of real estate, they need to be farther out. And again, since this is a point where the corner sphere is tangent to the inner sphere, it's also a point of the inner sphere. So with reference to the origin 0,0,0, think about the amount of real estate shared between x, y, and z in this position corresponding to the tangent point. It's definitely less than 0.75 since all three of these are smaller than 0.5, so each one has less than 0.25 units of real estate. And again, we sit back and feel comfortable with this result, right? The inner sphere is smaller than the corner spheres. But things get interesting when we move up into four dimensions. Our 2x2x2x2 box is going to have 16 vertices at 1,1,1,1, 1,1,1,-1 and so on with all possible binary combinations of 1 and negative 1. What this means is that there are 16 unit spheres centered at these corners, each one tangent to four of its neighbors. As before, we'll just be focusing on one of them, the one centered at 1,1,1,1. The point of the sphere closest to the origin corresponds to the configuration of sliders where all four coordinates reach exactly halfway between 1 and 0. And that's because when one of the coordinates is 0.5 units away from 1, it has 0.25 units of real estate with respect to the point 1. We do the same trick as before, thinking of this now as a point of the inner sphere and measuring things with respect to the origin, but you can already see what's cool about four dimensions. As you switch to thinking of real estate with respect to 0,0,0,0, it's still the case that each of these four coordinates has 0.25 units of real estate, making for a total of 1 shared between the four coordinates. In other words, that inner sphere is precisely the same size as the corner spheres. This matches with what you see numerically, by the way, where you can compute the distance between the origin and the corner, 1,1,1,1, is the square root of 4, and then when you subtract off the radius of one of the corner spheres, what you get is 1. But there's something much more satisfying about seeing it, rather than just computing it. In particular, here's a cool aspect of the fact that that inner sphere has radius 1. Move things around so that all of the real estate goes to the coordinate x, and you'll end up at the point 1, 0, 0, 0. This point is actually touching the 2x2x2x2 box, and when you're stuck thinking in the two or three dimensional cases, this fact that the inner sphere has radius 1, the same size as the corner spheres, and that it touches the box, well it just seems too big. But it's important to realize this is fundamentally a four-dimensional phenomenon, and you just can't cram it down into smaller dimensions. But things get weirder. Let's knock it up to five dimensions. In this case we have quite a few corner spheres, 32 in total, but again for simplicity we'll only be thinking about the one centered at 1,1,1,1,1. Think about the point of the sphere closest to the origin, where all five coordinates are equally splitting the one unit of shared real estate. This time each coordinate is a little higher than 0.5. If they reach down to 0.5, each one would have 0.25 units of real estate, giving a total of 1.25, which is too much. But the tables are turned when you view this as a point on the inner sphere, because with respect to the origin, this configuration has much more than one unit of real estate. Not only is every coordinate more than 0.5 units away from 0, but the larger number of dimensions means that there's more total real estate when you add it all up. Specifically you can compute that the radius of that inner sphere is about 1.24. The intuitive feel for what that means is that the sliders can roam over more territory than what just a single unit of real estate would allow. One fun way to see what this means is to adjust everything so that all of the real estate goes to just one coordinate. Because this coordinate can reach beyond one, what you are seeing is that this five dimensional inner sphere actually pokes outside the box. But to really get a feel for how strange things become, as a last example I want to jump up into ten dimensions. Remember, all this means is that points have ten coordinates. For a sphere with radius 1, a single unit of real estate must be shared among all ten of those coordinates. As always, the point of this corner sphere closest to the origin is the one where all ten coordinates split the real estate evenly. And here you can really see just how far away this feels from the origin. Or phrased differently, that inner sphere is allowed to have a very large amount of real estate. In fact, you can compute that the radius of the inner sphere is about 2.16. And viewed from this perspective, where you have ten full dimensions to share that real estate, doesn't it actually feel somewhat reasonable that the inner sphere should have a radius more than twice as big as all those corner spheres? To get a sense for just how big this inner sphere is, look back in two dimensions and imagine a 4x4 box bounding all four circles from the outside. Or go to three dimensions and imagine a 4x4x4 box bounding all of those corner spheres from the outside. Way up here in ten dimensions, that quote-unquote inner sphere is actually large enough to poke outside of that outer bounding box, since it has a diameter bigger than four. I know that seems crazy, but you have to realize that the face of the box is always two units away from the origin, no matter how high the dimension is. And fundamentally it's because it only involves moving along a single axis. But the point 1,1,1,1,1,1,1,1,1,1, which determines the inner sphere's radius, is actually really far away from the center, all the way up here in ten dimensions. And it's because all ten of those dimensions add a full unit of real estate for that point. And of course as you keep upping the dimensions, that inner sphere just keeps growing without bound. Not only is it poking outside of these boxes, but the proportion of the inner sphere lying inside the box decreases exponentially towards zero as the dimension keeps increasing. So taking a step back, one of the things I like about using this slider method for teaching is that when I shared it with a few friends, the way they started to talk about higher dimensions became a little less metaphysical and started to sound more like how you would hear a mathematician talk about the topic. Rather than skeptically asking whether or not ten-dimensional space is a real thing, recognizing that it's exactly as real as numbers are, people would actually probe at what other properties high-dimensional spheres have and what other shapes feel like in terms of sliders. This box situation is just one in a number of things that feel very crazy about higher dimensional spheres, and it's really fun to think about these others in the context of sliders and real estate. It's obviously limited, I mean you're a bug on the surface of these objects, only getting a feel for one point at a time and for the rules of movement. Also, geometry can be quite nice when it's coordinate-free, and this is the opposite of that, but it does give a foothold into thinking about high-dimensional shapes a little more concretely. Now you could say that viewing things with sliders is no different from thinking about things purely analytically. I mean, it's honestly little more than representing each coordinate literally, it's kind of the most obvious thing you might do. But this small move makes it much more possible to play with the thought of a high-dimensional point, and even little things like thinking about the squares of coordinates as real estate can shed light on some seemingly strange aspects of high dimensions, like just how far away the corner of a box is from its center. If anything, the fact that it's such a direct representation of a purely analytic description is exactly what makes it such a faithful reflection of what genuinely doing math in higher dimensions entails. We're still flying in the clouds, trusting the instruments of analytic reasoning, but this is a redesign of those instruments, one which better takes advantage of the fact that such a large portion of our brains goes towards image processing. I mean, just because you can't visualize something doesn't mean you can't still think about it visually.

================================================================================
VIDEO ID: 3s7h2MHQtxc
TITLE: Hilbert's Curve: Is infinite math useful?
URL: https://www.youtube.com/watch?v=3s7h2MHQtxc
PUBLISHED: 2017-07-21T15:33:50Z
STATUS: SUCCESS
================================================================================
Let's talk about space-filling curves. They are incredibly fun to animate, and they also give  a chance to address a certain philosophical question. Math often deals with infinite quantities, sometimes so intimately that the  very substance of a result only actually makes sense in an infinite world. So the question is, how can these results ever be useful in a finite context? As with all philosophizing, this is best left to discuss  until after we look at the concrete case and the real math. So I'll begin by laying down an application of something called a Hilbert curve,  followed by a description of some of its origins in infinite math. Let's say you wanted to write some software that  would enable people to see with their ears. It would take in data from a camera, and then somehow  translate that into a sound in a meaningful way. The thought here is that brains are plastic enough to build an intuition  from sight even when the raw data is scrambled into a different format. I've left a few links in the description to studies to this effect. To make initial experiments easier, you might start by treating  incoming images with a low resolution, maybe 256 by 256 pixels. And to make my own animation efforts easier, let's represent one of  these images with a square grid, each cell corresponding with a pixel. One approach to this sound-to-sight software would be to find a nice  way to associate each one of those pixels with a unique frequency value. Then when that pixel is brighter, the frequency associated with it would be  played louder, and if the pixel were darker, the frequency would be quiet. Listening to all of the pixels all at once would then sound like a bunch of  frequencies overlaid on top of one another, with dominant frequencies  corresponding to the brighter regions of the image sounding like some  cacophonous mess until your brain learns to make sense out of the information it contains. Let's temporarily set aside worries about whether or not this would actually work,  and instead think about what function, from pixel space down to frequency space,  gives this software the best chance of working. The tricky part is that pixel space is two-dimensional,  but frequency space is one-dimensional. You could, of course, try doing this with a random mapping. After all, we're hoping that people's brains make sense out of pretty wonky data anyway. However, it might be nice to leverage some of the  intuitions that a given human brain already has about sound. For example, if we think in terms of the reverse mapping from frequency space to pixel  space, frequencies that are close together should stay close together in the pixel space. That way, even if an ear has a hard time distinguishing between two nearby frequencies,  they will at least refer to the same basic point in space. To ensure this happens, you could first describe a  way to weave a line through each one of these pixels. Then if you fix each pixel to a spot on that line and unravel the  whole thread to make it straight, you could interpret this line as a frequency space,  and you have an association from pixels to frequencies. One weaving method would be to just go one row at a time,  alternating between left and right as it moves up that pixel space. This is like a well-played game of Snake, so let's call this a Snake Curve. When you tell your mathematician friend about this idea,  she says, why not use a Hilbert curve? When you ask her what that is, she stumbles for a moment. So it's not a curve, but an infinite family of curves. She starts, well no, it's just one thing, but I need  to tell you about a certain infinite family first. She pulls out a piece of paper and starts explaining what she  decides to call pseudo-Hilbert curves, for lack of a better term. For an order-one pseudo-Hilbert curve, you divide a square into a 2x2 grid,  and connect the center of the lower left quadrant to the center of the upper left,  over to the upper right, and then down in the lower right. For an order-two pseudo-Hilbert curve, rather than just going straight from one quadrant  to another, we let our curve do a little work to fill out each quadrant while it does so. Specifically, subdivide the square further into a 4x4 grid,  and we have our curve trace out a miniature order-one pseudo-Hilbert  curve inside each quadrant before it moves on to the next. If we left those mini-curves oriented as they are,  going from the end of the mini-curve in the lower left to the start of the mini-curve  in the upper left requires an awkward jump, same deal with going from the upper right  down to the lower right, so we flip the curves in the lower left and lower right to  make that connection shorter. Going from an order-two to an order-three pseudo-Hilbert curve is similar. You divide the square into an 8x8 grid, then put an order-two  pseudo-Hilbert curve in each quadrant, flip the lower left and lower right appropriately,  and connect them all tip to tail. And the pattern continues like that for higher orders. For the 256x256 pixel array, your mathematician friend explains,  you would use an order-eight pseudo-Hilbert curve. And remember, defining a curve which weaves through each pixel is  basically the same as defining a function from pixel space to frequency space,  since you're associating each pixel with a point on the line. Now this is nice as a piece of art, but why would these  pseudo-Hilbert curves be any better than just the snake curve? Well here's one very important reason. Imagine that you go through with this project,  you integrate the software with real cameras and headphones, and it works! People around the world are using the device, building intuitions for vision via sound. What happens when you issue an upgrade that increases the  resolution of the camera's image from 256x256 to 512x512? If you were using the snake curve, as you transition to a higher resolution,  many points on this frequency line would have to go to completely different parts of  pixel space. For example, let's follow a point about halfway along the frequency line. It'll end up about halfway up the pixel space, no matter the resolution,  but where it is left to right can differ wildly as you go from 256x256 up to 512x512. This means everyone using your software would have to re-learn  how to see with their ears, since the original intuitions of  which points in space correspond to which frequencies no longer apply. However, with the Hilbert curve technique, as you increase the  order of a pseudo-Hilbert curve, a given point on the line moves around less and less,  it just approaches a more specific point in space. That way, you've given your users the opportunity to fine-tune their intuitions,  rather than re-learning everything. So, for this sound-to-sight application, the Hilbert  curve approach turns out to be exactly what you want. In fact, given how specific the goal is, it seems almost weirdly perfect. So you go back to your mathematician friend and ask her,  what was the original motivation for defining one of these curves? She explains that near the end of the 19th century,  in the aftershock of Cantor's research on infinity,  mathematicians were interested in finding a mapping from a one-dimensional  line into two-dimensional space in such a way that the line runs through  every single point in space. To be clear, we're not talking about a finite bounded grid of pixels,  like we had in the sound-to-sight application. This is continuous space, which is very infinite,  and the goal is to have a line which is as thin as can be and has zero area,  somehow pass through every single one of those infinitely many points that makes  up the infinite area of space. Before 1890, a lot of people thought this was obviously impossible,  but then Peano discovered the first of what would come to be known as space-filling  curves. In 1891, Hilbert followed with his own slightly simpler space-filling curve. Technically, each one fills a square, not all of space,  but I'll show you later on how once you filled a square with a line,  filling all of space is not an issue. By the way, mathematicians use the word curve to talk about  a line running through space even if it has jagged corners. This is especially counterintuitive terminology in the context of a space-filling curve,  which in a sense consists of nothing but sharp corners. A better name might be something like space-filling fractal,  which some people do use, but hey, it's math, so we live with bad terminology. None of the pseudo-Hilbert curves that you use to fill pixelated space  would count as a space-filling curve, no matter how high the order. Just zoom in on one of the pixels. When this pixel is considered part of infinite, continuous space,  the curve only passes through the tiniest zero-area slice of it,  and it certainly doesn't hit every point. Your mathematician friend explains that an actual bonafide  Hilbert curve is not any one of these pseudo-Hilbert curves. Instead it's the limit of all of them. Defining this limit rigorously is delicate. You first have to formalize what these curves are as functions,  specifically functions which take in a single number somewhere  between 0 and 1 as their input, and output a pair of numbers. This input can be thought of as a point on the line,  and the output can be thought of as coordinates in 2D space. But in principle it's just an association between a single number and pairs of numbers. For example, an order-2 pseudo-Hilbert curve as a  function maps the input 0.3 to the output pair 0.125, 0.75. An order-3 pseudo-Hilbert curve maps that same input 0.3 to the output pair 0.0758,  0.6875. Now the core property that makes a function like this a curve,  and not just any ol' association between single numbers and pairs of numbers,  is continuity. The intuition behind continuity is that you don't want the output of your  function to suddenly jump at any point when the input is only changing smoothly. And the way this is made rigorous in math is actually pretty clever,  and fully appreciating space-filling curves requires digesting the formal idea  of continuity, so it's definitely worth taking a brief side-step to go over it now. Consider a particular input point, a, and the corresponding output of the function, b. Draw a circle centered around a, and look at all the other input points inside that  circle, and consider where the function takes all those points in the output space. Now draw the smallest circle you can centered at b that contains those outputs. Different choices for the size of the input circle might  result in larger or smaller circles in the output space. But notice what happens when we go through this process at a point  where the function jumps, drawing a circle around a,  and looking at the input points within the circle, seeing where they map,  and drawing the smallest possible circle centered at b containing those points. No matter how small the circle around a, the corresponding  circle around b just cannot be smaller than that jump. For this reason, we say that the function is discontinuous at a if  there's any lower bound on the size of this circle that surrounds b. If the circle around b can be made as small as you want,  with sufficiently small choices for circles around a,  you say that the function is continuous at a. A function as a whole is called continuous if  it's continuous at every possible input point. Now with that as a formal definition of curves,  you're ready to define what an actual Hilbert curve is. Doing this relies on a wonderful property of the sequence of pseudo-Hilbert curves,  which should feel familiar. Take a given input point, like 0.3, and apply each  successive pseudo-Hilbert curve function to this point. The corresponding outputs, as we increase the order of the curve,  approaches some particular point in space. It doesn't matter what input you start with, this sequence of outputs  you get by applying each successive pseudo-Hilbert curve to this point  always stabilizes and approaches some particular point in 2D space. This is absolutely not true, by the way, for snake curves,  or for that matter most sequences of curves filling pixelated space of higher  and higher resolutions. The outputs associated with a given input become wildly erratic as the resolution  increases, always jumping from left to right, and never actually approaching anything. Now because of this property, we can define a Hilbert curve function like this. For a given input value between 0 and 1, consider the sequence of points in 2D  space you get by applying each successive pseudo-Hilbert curve function at that point. The output of the Hilbert curve function evaluated on  this input is just defined to be the limit of those points. Because the sequence of pseudo-Hilbert curve outputs always converges  no matter what input you start with, this is actually a well-defined  function in a way that it never could have been had we used snake curves. Now I'm not going to go through the proof for why this gives a space-filling curve,  but let's at least see what needs to be proved. First, verify that this is a well-defined function by proving that the outputs of  the pseudo-Hilbert curve functions really do converge the way I'm telling you they do. Second, show that this function gives a curve, meaning it's continuous. Third, and most important, show that it fills space,  in the sense that every single point in the unit square is an output of this function. I really do encourage anyone watching this to take a stab at each one of these. Spoiler alert, all three of these facts turn out to be true. You can extend this to a curve that fills all of space just by tiling  space with squares and then chaining a bunch of Hilbert curves together  in a spiraling pattern of tiles, connecting the end of one tile to the  start of a new tile with an added little stretch of line if you need to. You can think of the first tile as coming from the interval from 0 to 1,  the second tile as coming from the interval from 1 to 2, and so on,  so the entire positive real number line is getting mapped into all of 2D space. Take a moment to let that fact sink in. A line, the platonic form of thinness itself, can wander through an  infinitely extending and richly dense space and hit every single point. Notice, the core property that made pseudo-Hilbert curves useful in both the  sound-to-sight application and in their infinite origins is that points on  the curve move around less and less as you increase the order of those curves. While translating images to sound, this was useful because it means upgrading  to higher resolutions doesn't require retraining your senses all over again. For mathematicians interested in filling continuous space,  this property is what ensured that talking about the limit of a sequence of curves  was a meaningful thing to do. And this connection here between the infinite and finite  worlds seems to be more of a rule in math than an exception. Another example that several astute commenters on the Inventing Math video  pointed out is the connection between the divergent sum of all powers of  2 and the way that the number of 1 is represented in computers with bits. It's not so much that the infinite result is directly useful,  but instead the same patterns and constructs that are used to define and  prove infinite facts have finite analogs, and these finite analogs are directly useful. But the connection is often deeper than a mere analogy. Many theorems about an infinite object are often equivalent  to some theorem regarding a family of finite objects. For example, if during your sound-to-sight project you were to sit down  and really formalize what it means for your curve to stay stable as  you increase camera resolution, you would end up effectively writing  the definition of what it means for a sequence of curves to have a limit. In fact, a statement about some infinite object,  whether that's a sequence or a fractal, can usually be viewed as  a particularly clean way to encapsulate a truth about a family of finite objects. The lesson to take away here is that even when a statement seems  very far removed from reality, you should always be willing to look  under the hood and at the nuts and bolts of what's really being said. Who knows, you might find insights for representing numbers from divergent sums,  or for seeing with your ears from filling space.

================================================================================
VIDEO ID: S9JGmA5_unY
TITLE: How secure is 256 bit security?
URL: https://www.youtube.com/watch?v=S9JGmA5_unY
PUBLISHED: 2017-07-08T14:19:39Z
STATUS: SUCCESS
================================================================================
In the main video on cryptocurrencies, I made two references to situations where in order  to break a given piece of security, you would have to guess a specific string of 256 bits. One of these was in the context of digital signatures,  and the other in the context of a cryptographic hash function. For example, if you want to find a message whose SHA-256 hash is some specific string  of 256 bits, you have no better method than to just guess and check random messages. This would require, on average, 2 to the 256 guesses. This is a number so far removed from anything we ever deal with  that it can be hard to appreciate its size, but let's give it a try. Two to the 256 is the same as 2 to the 32 multiplied by itself 8 times. What's nice about that split is that 2 to the 32 is 4 billion,  which is at least a number we can think about. All we need to do is appreciate what multiplying 4  billion times itself 8 successive times really feels like. As many of you know, the GPU on your computer can let you  run a bunch of computations in parallel incredibly quickly. If you were to specially program a GPU to run a cryptographic hash function over and  over, a really good one might be able to do a little less than a billion hashes per  second. Let's say you just take a bunch of those and cram your computer full  of extra GPUs so that your computer can run 4 billion hashes per second. So the first 4 billion here is going to represent  the number of hashes per second per computer. Now, picture 4 billion of these GPU-packed computers. For comparison, even though Google does not at all make their number of servers public,  estimates have it somewhere in the single-digit millions. In reality, most of those servers are going to be much  less powerful than our imagined GPU-packed machine. But let's say that Google replaced all of its millions of servers with a machine like  this, then 4 billion machines would mean about 1,000 copies of this souped-up Google. Let's call that 1 kilo-Google worth of computing power. There's about 7.3 billion people on Earth. So next, imagine giving a little over half of every  individual on Earth their own personal kilo-Google. Now, imagine 4 billion copies of this Earth. For comparison, the Milky Way has somewhere between 100 and 400 billion stars. We don't really know, but the estimates tend to be in that range. This would be akin to a full 1% of every star in the galaxy having a copy  of Earth where half the people on Earth have their own personal kilo-Google. Next, try to imagine 4 billion copies of the Milky Way. And we're going to call this your giga-galactic supercomputer,  running about 2 to the 160 guesses every second. Now, 4 billion seconds, that's about 126.8 years. Four billion of those, well that's 507 billion years,  which is about 37 times the age of the universe. So even if you were to have your GPU-packed kilo-Google-per-person multiplanetary  giga-galactic computer guessing numbers for 37 times the age of the universe,  it would still only have a 1 in 4 billion chance of finding the correct guess. By the way, the state of Bitcoin hashing these days is that all of the miners put  together guess and check at a rate of about 5 billion billion hashes per second. That corresponds to one third of what I just described as a kilo-Google. This is not because there are billions of GPU-packed machines out there,  but because miners actually use something that's about 1000 times better than a GPU,  application-specific integrated circuits. These are pieces of hardware specifically designed for Bitcoin mining,  for running a bunch of SHA-256 hashes, and nothing else. Turns out, there's a lot of efficiency gains to be had when you throw out the need  for general computation and design your integrated circuits for one and only one task. Also, on the topic of large powers of two that I personally find it hard to  get my mind around, this channel recently surpassed 2 to the 18th subscribers. And to engage a little more with some sub-portion of those 2 to the 18 people,  I'm going to do a Q&A session. I've left a link in the description to a Reddit thread where you can  post questions and upvote the ones you want to hear answers to.  And probably in the next video or on Twitter or something like that  I'll announce the format in which I'd like to give answers. See you then!

================================================================================
VIDEO ID: bBC-nXj3Ng4
TITLE: But how does bitcoin actually work?
URL: https://www.youtube.com/watch?v=bBC-nXj3Ng4
PUBLISHED: 2017-07-07T16:51:37Z
STATUS: SUCCESS
================================================================================
What does it mean to have a Bitcoin? Many people have heard of Bitcoin, that it's a fully digital currency with no government to issue it, that no banks need to manage accounts and verify transactions, and that no one really knows who invented it. And yet many people don't know the answer to this question, at least not in full. To get there, and to make sure that the technical details underlying the answer actually feel motivated, we're going to walk through, step by step, how you might have invented your own version of Bitcoin. We'll start with you keeping track of payments with your friends using a communal ledger, and then as you start to trust your friends and the world around you less and less, and if you're clever enough to bring in a few ideas from cryptography to help circumvent the need for trust, what you end up with is what's called a cryptocurrency. Bitcoin is just the first implemented example of a cryptocurrency, and now there are thousands more on exchanges with traditional currencies. Walking the path of inventing your own can help to set the foundations for understanding some of the more recent players in the game, and recognizing when and why there's room for different design choices. In fact, one of the reasons I chose this topic is that in the last year there's been a huge amount of attention, investment, and hype directed at these currencies. I'm not going to comment or speculate on the current or future exchange rates, but I think we'd all agree that anyone looking to buy a cryptocurrency should really know what it is. And I don't just mean in terms of analogies with vague connections to gold mining, I mean an actual direct description of what the computers are doing when we send, receive, and create cryptocurrencies. One thing worth stressing is that even though you and I are going to dig into the details here, and that takes meaningful time, you don't actually need to know those details if you just want to use the cryptocurrency, just like you don't need to know the details of what happens under the hood when you swipe a credit card. Like any digital payment, there's lots of user-friendly applications that let you just send and receive the currencies without thinking about what's going on. The difference is that the backbone underlying this is not a bank that verifies transactions, instead it's a clever system of decentralized trustless verification based on some of the math born in cryptography. But to start I want you to actually set aside the thought of cryptocurrencies and all that just for a few minutes. We're going to begin the story with something more down to earth, ledgers and digital signatures. If you and your friends exchange money pretty frequently, paying your share of the dinner bill and such, it can be inconvenient to exchange cash all the time. So you might keep a communal ledger that records all the payments you intend to make at some point in the future. Alice pays Bob $20, Bob pays Charlie $40, things like that. This ledger is going to be something public and accessible to everyone, like a website where anyone can go and add new lines. And let's say at the end of every month you all get together, look at the list of transactions, and settle up. If you spent more than you received, you put that money in the pot, and if you received more than you spent, you take that money out. So the protocol for being part of this very simple system might look like this. Anyone can add lines to the ledger, and at the end of every month you all get together and settle up. Now one problem with a public ledger like this is that anyone can add a line. So what's to prevent Bob from going and writing Alice pays Bob $100 without Alice approving? How are we supposed to trust that all of these transactions are what the sender meant them to be? Well this is where the first bit of cryptography comes in, digital signatures. Like handwritten signatures, the idea here is that Alice should be able to add something next to that transaction that proves that she has seen it and that she's approved of it, and it should be infeasible for anyone else to forge that signature. At first, it might seem like a digital signature shouldn't even be possible. I mean, whatever data makes up that signature can just be read and copied by a computer. So how do you prevent forgeries? Well the way this works is that everyone generates what's called a public key-private key pair, each of which looks like some string of bits. The private key is sometimes also called a secret key, so we can abbreviate it as SK while abbreviating the public key as PK. As the name suggests, this secret key is something you want to keep to yourself. In the real world, your handwritten signature looks the same no matter what document you're signing. But a digital signature is actually much stronger, because it changes for different messages. It looks like some string of 1s and 0s, commonly something like 256 bits, and altering the message even slightly completely changes what the signature on that message should look like. Speaking a little more formally, producing a signature involves a function that depends both on the message itself and on your private key. The private key ensures that only you can produce that signature, and the fact that it depends on the message means that no one can just copy one of your signatures and forge it on another message. Hand-in-hand with this is a second function used to verify that a signature is valid, and this is where the public key comes into play. All it does is output true or false to indicate if this was a signature produced by the private key associated with the public key you're using for verification. I won't go into the details of how exactly both these functions work, but the idea is that it should be completely infeasible to find a valid signature if you don't know the secret key. Specifically, there's no strategy better than just guessing and checking random signatures, which you can check using the public key that everyone knows. Now think about how many signatures there are with a length of 256 bits. That's 2 to the power of 256! This is a stupidly large number. To call it astronomically large would be giving way too much credit to astronomy. In fact, I made a supplemental video devoted just to illustrating what a huge number this is. Right here, let's just say that when you verify that a signature against a given message is valid, you can feel extremely confident that the only way someone could have produced it is if they knew the secret key associated with the public key you used for verification. Making sure people sign transactions on the ledger is pretty good, but there's one slight loophole. If Alice signs a transaction like Alice pays Bob $100, even though Bob can't forge Alice's signature on a new message, he could just copy that same line as many times as he wants. I mean, that message-signature combination remains valid. To get around this, we make it so that when you sign a transaction, the message has to include some sort of unique ID associated with that transaction. That way, if Alice pays Bob $100 multiple times, each one of those lines on the ledger requires a completely new signature. Alright, great. Digital signatures remove a huge aspect of trust in this initial protocol. But even still, if you were to really do this, you would be relying on an honor system of sorts. Namely, you're trusting that everyone will actually follow through and settle up in cash at the end of each month. What if, for example, Charlie racks up thousands of dollars in debt and just refuses to show up? The only real reason to revert back to cash to settle up is if some people, I'm looking at you Charlie, owe a lot of money. So maybe you have the clever idea that you never actually have to settle up in cash as long as you have some way to prevent people from spending too much more than they take in. Maybe you start by having everyone pay $100 into the pot, and then have the first few lines of the ledger read Alice gets $100, Bob gets $100, Charlie gets $100, etc. Now, just don't accept any transactions where someone is spending more than they already have on that ledger. For example, if the first two transactions are Charlie pays Alice $50 and Charlie pays Bob $50, if he would have tried to add Charlie pays you $20, that would be invalid, as invalid as if he had never signed it. Notice, this means verifying a transaction requires knowing the full history of transactions up to that point. This is also going to be true in cryptocurrencies, though there is a little room for optimization. What's interesting here is that this step removes the connection between the ledger and actual physical US dollars. In theory, if everyone in the world was using this ledger, you could live your whole life just sending and receiving money on this ledger without ever having to convert to real US dollars. In fact, to emphasize this point, let's start referring to the quantities on the ledger as ledger dollars, or LD for short. You are of course free to exchange ledger dollars for real US dollars. For example, maybe Alice gives Bob a $10 bill in the real world in exchange for him adding and signing the transaction $10 Bob pays Alice $10 to this communal ledger. But exchanges like that are not guaranteed by the protocol. It's now more analogous to how you might exchange dollars for Euros or any other currency on the open market. It's just its own independent thing. This is the first important thing to understand about Bitcoin, or any other cryptocurrency. What it is, is a ledger. The history of transactions is the currency. Of course, with Bitcoin, money doesn't enter the ledger with people buying in using cash. I'll get to how new money enters the ledger in just a few minutes. But before that, there's actually an even more significant difference between our current system of ledger dollars and how cryptocurrencies work. So far, I've said that this ledger is in some public place, like a website where anyone can add new lines. But that would require trusting a central location, namely, who hosts the website, who controls the rules of adding new lines. To remove that bit of trust, we'll have everybody keep their own copy of the ledger. Then when you want to make a transaction, like Alice pays Bob 100 Ledger Dollars, what you do is broadcast that out into the world for people to hear and record on their own private ledgers. But unless you do something more, this system is absurdly bad. How could you get everyone to agree on what the right ledger is? When Bob receives a transaction, like Alice pays Bob 10 Ledger Dollars, how can he be sure that everyone else received and believes that same transaction? That he'll be able to later on go to Charlie and use those same 10 Ledger Dollars to make a transaction? Really, imagine yourself just listening to transactions being broadcast. How can you be sure that everyone else is recording the same transactions and in the same order? This is really the heart of the issue. This is an interesting puzzle. Can you come up with a protocol for how to accept or reject transactions, and in what order, so that you can feel confident that anyone else in the world who's following that same protocol has a personal ledger that looks the same as yours? This is the problem addressed in the original Bitcoin paper. At a high level, the solution that Bitcoin offers is to trust whichever ledger has the most computational work put into it. I'll take a moment to explain exactly what that means. It involves this thing called a cryptographic hash function. The general idea that we'll build to is that if you use computational work as a basis for what to trust, you can make it so that fraudulent transactions and conflicting ledgers would require an infeasible amount of computation to bring about. Again, I'll remind you that this is getting well into the weeds beyond what anyone would need to know just to use a currency like this. But it's a really cool idea, and if you understand it, you understand the heart of Bitcoin and other cryptocurrencies. So first things first, what's a hash function? The inputs for one of these functions can be any kind of message or file, it really doesn't matter. And the output is a string of bits with some kind of fixed length, like 256 bits. This output is called the hash or digest of the message, and the intent is that it looks random. It's not random, it always gives the same output for a given input. But the idea is that if you slightly change the input, maybe editing just one of the characters, the resulting hash changes completely. In fact, for the hash function I'm showing here, called SHA256, the way the output changes as you slightly change that input is entirely unpredictable. You see, this is not just any hash function, it's a cryptographic hash function. That means it's infeasible to compute in the reverse direction. If I show you some string of 1s and 0s, and ask you to find an input so that the SHA256 hash of that input gives this exact string of bits, you will have no better method than to just guess and check. And again, if you want to feel for how much computation would be needed to go through two to the 256 guesses, just take a look at the supplement video. I actually had way too much fun writing that thing. You might think that if you just really dig into the details of how exactly this function works, you could reverse engineer the appropriate input without having to guess and check. But no one has ever figured out a way to do that. Interestingly, there's no cold hard rigorous proof that it's hard to compute in the reverse direction. And yet, a huge amount of modern security depends on cryptographic hash functions and the idea that they have this property. If you were to look at what algorithms underlie the secure connection that your browser is making with YouTube right now, or that it makes with your bank, you'll likely see the name SHA256 show up in there. For right now, our focus will be on how such a function can prove that a particular list of transactions is associated with a large amount of computational effort. Imagine someone shows you a list of transactions, and they say, hey, I found a special number so that when you put that number at the end of this list of transactions, and apply SHA256 to the entire thing, the first 30 bits of that output are all zeros. How hard do you think it was for them to find that number? Well, for a random message, the probability that a hash happens to start with 30 successive zeros is 1 in 2 to the 30, which is about 1 in a billion. And because SHA256 is a cryptographic hash function, the only way to find a special number like that is just guessing and checking. So this person almost certainly had to go through about a billion different numbers before finding this special one. And once you know that number, it's really quick to verify, you just run the hash and see that there are 30 zeros. So in other words, you can verify that they went through a large amount of work, but without having to go through that same effort yourself. This is called a proof of work. And importantly, all of this work is intrinsically tied to the list of transactions. If you change one of those transactions, even slightly, it would completely change the hash. So you'd have to go through another billion guesses to find a new proof of work, a new number that makes it so that the hash of the altered list together with this new number starts with 30 zeros. So now think back to our distributed ledger situation. Everyone is there broadcasting transactions and we want a way for them to agree on what the correct ledger is. As I mentioned, the idea behind the original Bitcoin paper is to have everyone trust whichever ledger has the most work put into it. The way this works is to first organize a given ledger into blocks, where each block consists of a list of transactions together with a proof of work. That is, a special number so that the hash of the whole block starts with a bunch of zeros. For the moment, let's say it has to start with 60 zeros, but later we'll return back to a more systematic way you might want to choose that number. In the same way that a transaction is only considered valid when it's signed by the sender, a block is only considered valid if it has a proof of work. Also, to make sure there's a standard order to these blocks, we'll make it so that a block has to contain the hash of the previous block at its header. That way, if you were to go back and change any one of the blocks, or to swap the order of two blocks, it would change the block that comes after it, which changes that block's hash, which changes the one that comes after it, and so on. That would require redoing all of the work, finding a new special number for each of these blocks that makes their hashes start with 60 zeros. Because blocks are chained together like this, instead of calling it a ledger, it's common to call it a blockchain. As part of our updated protocol, we'll now allow anyone in the world to be a block creator. What that means is that they're going to listen for transactions being broadcast, collect them into some block, and then do a whole bunch of work to find a special number that makes the hash of that block start with 60 zeros. Once they find it, they broadcast out the block they found. To reward a block creator for all this work, when she puts together a block, we'll allow her to include a very special transaction at the top of it, in which she gets, say, 10 ledger dollars out of thin air. This is called the block reward, and it's an exception to our usual rules about whether or not to accept transactions. It doesn't come from anyone, so it doesn't have to be signed. It also means that the total number of ledger dollars in our economy increases with each new block. Creating blocks is often called mining, since it requires doing a lot of work, and it introduces new bits of currency into the economy. But when you hear or read about miners, keep in mind that what they're really doing is listening for transactions, creating blocks, broadcasting those blocks, and getting rewarded with new money for doing so. From the miners' perspective, each block is like a miniature lottery, where everyone is guessing numbers as fast as they can, until one lucky individual finds a special number that makes the hash of the block start with many zeros, and they get the reward. For anyone else who just wants to use this system to make payments, instead of listening for transactions, they all start listening just for blocks being broadcast by miners, and updating their own personal copies of the blockchain. Now the key addition to our protocol is that if you hear two distinct blockchains with conflicting transaction histories, you defer to the longest one, the one with the most work put into it. If there's a tie, just wait until you hear an additional block that makes one of them longer. So even though there's no central authority, and everyone is maintaining their own copy of the blockchain, if everyone agrees to give preference to whichever blockchain has the most work put into it, we have a way to arrive at decentralized consensus. To see why this makes for a trustworthy system, and to understand at what point you should trust that a payment is legit, it's actually really helpful to walk through exactly what it would take to fool someone using this system. Maybe Alice is trying to fool Bob with a fraudulent block, namely she tries to send him one that includes her paying him 100 Ledger dollars, but without broadcasting that block to the rest of the network, that way everyone else still thinks she has those 100 Ledger dollars. To do this, she would have to find a valid proof of work before all the other miners, each working on their own block. And that could definitely happen, maybe Alice just happens to win this miniature lottery before everyone else. But Bob is still going to be hearing the broadcasts made by other miners, so to keep him believing this fraudulent block, Alice would have to do all the work herself to keep adding blocks on this special fork in Bob's blockchain that's different from what he's hearing from the rest of the miners. Remember, as per the protocol, Bob always trusts the longest chain he knows about. Alice might be able to keep this up for a few blocks if just by chance she finds blocks more quickly than the rest of the miners on the network all combined. But unless she has close to 50% of the computing resources among all of the miners, the probability becomes overwhelming that the blockchain that all the other miners are working on grows faster than the single fraudulent blockchain Alice is feeding to Bob. So after enough time, Bob will just reject what he's hearing from Alice in favor of the longer chain that everyone else is working on. Notice, that means you shouldn't necessarily trust a new block you hear immediately. Instead, you should wait for several new blocks to be added on top of it. If you still haven't heard of any longer blockchains, you can trust that this block is part of the same chain that everyone else is using. And with that, we've hit all the main ideas. This distributed ledger system based on a proof of work is more or less how the Bitcoin protocol works, and how many other cryptocurrencies work. There's just a few details to clear up. Earlier I said that the proof of work might be to find a special number so that the hash of the block starts with 60 zeros. Well, the way the actual Bitcoin protocol works is to periodically change that number of zeros so that it should take, on average, 10 minutes to find a new block. So as there are more and more miners added to the network, the challenge gets harder and harder in such a way that this miniature lottery only has about one winner every 10 minutes. Many newer cryptocurrencies have much shorter block times than that. And all of the money in Bitcoin ultimately comes from some block reward. In the beginning, these rewards were 50 Bitcoin per block. There's actually a great website you can go to called Block Explorer that makes it easy to look through the Bitcoin blockchain. And if you look at the very first few blocks on the chain, they contain no transactions other than that 50 Bitcoin reward to the miner. But every 210,000 blocks, which is about every 4 years, that reward gets cut in half. So right now, the reward is 12.5 Bitcoin per block. And because this reward decreases geometrically over time, it means there will never be more than 21 million Bitcoin in existence. However, this doesn't mean miners will stop earning money. In addition to the block reward, miners can also pick up transaction fees. The way this works is that whenever you make a payment, you can purely optionally include a transaction fee with it that will go to the miner of whichever block includes that payment. The reason you might do that is to incentivize miners to actually include the transaction you broadcast into the next block. You see, in Bitcoin, each block is limited to about 2400 transactions, which many critics argue is unnecessarily restrictive. For comparison, Visa processes an average of about 1700 transactions per second, and they're capable of handling more than 24,000 per second. This comparatively slow processing on Bitcoin makes for higher transaction fees, since that's what determines which transactions miners choose to include in a new block. All of this is far from a comprehensive coverage of cryptocurrencies. There are still many nuances and alternate design choices that I haven't even touched. But my hope is that this can provide a stable WaitButWhy-style tree-trunk of understanding for anyone looking to add a few more branches with further reading. Like I said at the start, one of the motives behind this is that a lot of money has started flowing towards cryptocurrencies, and even though I don't want to make any claims about whether that's a good or bad investment, I really do think it's healthy for people getting into the game to at least know the fundamentals of the technology. As always, my sincerest thanks to those of you making this channel possible on Patreon. I understand that not everyone is in a position to contribute, but if you're still interested in helping out, one of the best ways to do that is simply to share videos that you think might be interesting or helpful to others. I know you know that, but it really does help.

================================================================================
VIDEO ID: QJYmyhnaaek
TITLE: All possible pythagorean triples, visualized
URL: https://www.youtube.com/watch?v=QJYmyhnaaek
PUBLISHED: 2017-05-26T17:58:15Z
STATUS: SUCCESS
================================================================================
When you first learned about the Pythagorean theorem, that the sum of the squares of the two shorter sides on a right triangle always equals the square of its hypotenuse, I'm guessing that you came to be pretty familiar with a few examples, like the 3-4-5 triangle, or the 5-12-13 triangle. And I think it's easy to take for granted that these even exist, examples where the sum of two perfect squares happens to be a perfect square. But keep in mind for comparison, if you were to change that exponent to any whole number bigger than 2, you go from having many integer solutions to no solutions whatsoever. This is Fermat's famous last theorem. Now there's a special name for any triplet of whole numbers, a,b,c, where a squared plus b squared equals c squared. It's called a Pythagorean triple. And what we're going to do here is find every single possible example. And moreover, we'll do so in a way where you can visualize how all of these triples fit together. This is an old question, pretty much as old as they come in math. There are some Babylonian clay tablets from 1800 BC, more than a millennium before Pythagoras himself, that just list these triples. And by the way, while we're talking about the Pythagorean theorem, it would be a shame not to share my favorite proof, for anyone who hasn't already seen this. You start off by drawing a square on each side of the triangle, and if you take that c square and add four copies of the original triangle around it, you can get a big square whose side lengths are a plus b. But you can also arrange the a square and the b square together with four copies of the original triangle to get a big square whose side lengths are a plus b. What this means is that the negative space in each of these diagrams, the area of that big square minus four times the area of the triangle, is from one perspective clearly a squared plus b squared, but from another perspective it's c squared. Anyway, back to the question of finding whole number solutions. Start by reframing the question slightly. Among all of the points on the plane with integer coordinates, that is, all of these lattice points where grid lines cross, which ones are a whole number distance away from the origin? For example, the point 3,4 is a distance 5 away from the origin, and the point 12,5 is a distance 13 away from the origin. The question of finding Pythagorean triples is completely equivalent to finding lattice points which are a whole number distance away from the origin. Of course, for most points, like 2,1, the distance from the origin is not a whole number, but it is at least the square root of a whole number. In this case, 2 squared plus 1 squared is 5, so that distance, that hypotenuse there, is the square root of 5. Now, taking what might seem like a strange step, but one which will justify itself in just a moment, think of this as the complex plane, so that every one of these points, like 2,1 here, is actually an individual complex number, in this case 2 plus i. What this gives is a surprisingly simple way to modify it to get a new point whose distance away from the origin is guaranteed to be a whole number. Just square it. Algebraically, when you square a complex number, expanding out this product and matching up all of the like terms, because everything here just involves multiplying and adding integers, each component of the result is guaranteed to be an integer, in this case you get 3 plus 4i. But you can also think of complex multiplication more geometrically. You take this line drawn from the origin to the number, and consider the angle it makes with the horizontal axis, as well as its length, which in this case is the square root of 5. The effect of multiplying anything by this complex number is to rotate it by that angle, and to stretch out by a factor equal to that length. So when you multiply the number by itself, the effect is to double that angle, and importantly, to square its length. Since the length started off as the square root of some whole number, this resulting length is guaranteed to be a whole number, in this case 5. Here, let's try it with another example. Start off with some complex number that has integer coordinates, like 3 plus 2i. In this case, the distance between this number and the origin is the square root of 3 squared plus 2 squared, which is the square root of 13. Now multiply this complex number by itself. The real part comes out to 3 squared plus 2i squared, which is 9 minus 4, and the imaginary part is 3 times 2 plus 2 times 3, so the result is 5 plus 12i, and the magnitude of this new number is 13, the square of the magnitude of our starting number, 3 plus 2i. So simply squaring our randomly chosen lattice point gives us the 5-12-13 triangle. There's something kind of magical about actually watching this work. It almost feels like cheating. You can start with any randomly chosen lattice point, like 4 plus i, and just by taking its square, you generate a pythagorean triple. In this case, 4 plus i squared is 15 plus 8i, which has a distance 17 away from the origin. If you play around with this, which I encourage you to do, you'll find that some of the results are kind of boring. If both the coordinates of your starting point are the same, or if one of them is zero, then the triple at the end is going to include a zero. For example, 2 plus 2i squared gives 8i, and even though technically this is indeed a lattice point a whole number distance away from the origin, the triple that it corresponds to is 0 squared plus 8 squared equals 8 squared, which isn't exactly something to write home about. But for the most part, this method of squaring complex numbers is a surprisingly simple way to generate non-trivial pythagorean triples. And you can even generalize it to get a nice formula. If you write the coordinates of your initial point as u and v, then when you work out u plus vi squared, the real part is u squared minus v squared, and the imaginary part is 2 times uv. The resulting distance from the origin is going to be u squared plus v squared. It's kind of fun to work out this expression algebraically and see that it does indeed check out, and it's also fun to plug in some random integers for u and v and get out a pythagorean triple. Essentially, we've created a machine where you give it any pair of integers, and it gives you back some pythagorean triple. A really nice way to visualize this, which will be familiar to any of you who watched the zeta function video, is to watch every point of z on the plane move over to the point z squared. For example, the point 3 plus 2i is going to move over to 5 plus 12i. The point i is going to rotate 90 degrees to its square, negative 1. The point negative 1 is going to move over to 1, and so on. Now when you do this to every single point on the plane, including the grid lines, which I'll make more colorful so they're easier to follow, here's what it looks like. So the grid lines all get turned into these parabolic arcs, and every point where these arcs intersect is a place where a lattice point landed, so it corresponds to some pythagorean triple. That is, if you draw a triangle whose hypotenuse is the line between any one of these points and the origin, and whose legs are parallel to the axes, all three side lengths of that triangle will be whole numbers. What I love about this is that usually when you view pythagorean triples just on their own, they seem completely random and unconnected, and you'd be tempted to say there's no pattern. But here we have a lot of them sitting together really organized, just sitting on the intersections of these nicely spaced curves. Now you might ask if this accounts for every possible pythagorean triple. Sadly, it does not. For example, you will never get the point 6 plus 8i using this method, even though 6-8-10 is a perfectly valid pythagorean triple. There are simply no integers u and v where u plus vi squared is 6 plus 8i. Likewise, you will never hit 9 plus 12i. But these don't really feel like anything new, do they? Since you can get each one of them by scaling up the familiar triple 3-4-5, which is accounted for in our method. In fact, for reasons that I'll explain shortly, every possible pythagorean triple that we miss is just some multiple of a different triple that we hit. To give another example, we miss the point 4 plus 3i. There are no integers u and v, so that u plus vi squared is 4 plus 3i. In fact, you'll never hit any points whose imaginary component is odd. However, we do hit 8 plus 6i, that's 3 plus i squared. So even though we miss 4 plus 3i, it's just one half times the point we do hit. And by the way, you'll never have to scale down by anything smaller than one half. A nice way to think about these multiples that we miss is to take each point that we get using this squaring method and draw a line from the origin through that point out to infinity. Marking all of the lattice points that this line hits will account for any multiples of these points that we might have missed. Doing this for all possible points, you'll account for every possible Pythagorean triple, Every right triangle that you ever have seen or ever will see that has whole number side lengths is accounted for somewhere in this diagram. To see why, we'll now shift to a different view of the pythagorean triple problem, one that involves finding points on a unit circle that have rational coordinates. If you take the expression a squared plus b squared equals c squared and divide out by that c squared, what you get is a over c squared plus b over c squared equals 1. This gives us some point on the unit circle x squared plus y squared equals 1 whose coordinates are each rational numbers. This is what we call a rational point of the unit circle. And going the other way around, if you find some rational point on the unit circle, when you multiply out by a common denominator for each of those coordinates, what you'll land on is a point that has integer coordinates and whose distance from the origin is also an integer. With that in mind, consider our diagram, where we squared every possible lattice point and then drew these radial lines through each one to account for any multiples that we might have missed. If you project all of these points onto the unit circle, each one moving along its corresponding radial line, what you'll end up with is a whole bunch of rational points on that circle. And keep in mind, by the way, I'm drawing only finitely many of these dots and lines, but if I drew all infinitely many lines corresponding to every possible squared lattice point, it would actually fill every single pixel of the screen. Now if our method was incomplete, if we were missing a Pythagorean triple out there somewhere, it would mean that there's some rational point on this circle that we never hit once we project everything onto the circle. And let me show you why that cannot happen. Take any one of those rational points and draw a line between it and the point at negative 1. When you compute the rise over run slope of this line, the Rise between the two points is rational and the Run is also rational, so the slope itself is just going to be some rational number. So if we can show that our method of squaring complex numbers accounts for every possible rational slope here, it's going to guarantee that we hit every possible rational point of the unit circle, right? Well, let's think through our method. We start off with some point u plus vi that has integer coordinates, and this number makes some angle off of the horizontal, which I'm going to call theta. Squaring this number, the resulting angle off the horizontal, is 2 times theta. And of course, when you project that onto the unit circle, it's along the same radial line, so the corresponding rational point of the unit circle also has that same angle, 2 times theta. And here, I'll bring in a nice little bit of circle geometry, which is that any time you have an angle between two points on the circumference of a circle and its center, that turns out to be exactly two times the angle made by those same points and any other point on the circle's circumference, provided that that other point isn't between the original two points. What this means for our situation is that the line between negative 1 and the rational point on the circle must make an angle theta with the horizontal. In other words, that line has the same slope as the line between the origin and our initial complex number, u plus vi. But look at the rise over run slope of the line defined by our choice of integers, u and v. The slope is v divided by u, and of course, we can choose v and u to be whatever integers we want,
199
00:14:00,420 --> 00:13:59,720
The slope is v divided by u. And of course, we can choose v and u to be whatever integers we want, and therefore we do indeed account for every possible rational slope. So there you go! The radial lines from our method, determined by all possible choices of u and v, must pass through every rational point on this circle. And that means our method must hit every possible Pythagorean triple. If you haven't already watched the video about pi hiding in prime regularities, the topics there are highly related to the ones here. Thank you for watching!

================================================================================
VIDEO ID: NaL_Cb42WyY
TITLE: Pi hiding in prime regularities
URL: https://www.youtube.com/watch?v=NaL_Cb42WyY
PUBLISHED: 2017-05-19T15:41:54Z
STATUS: SUCCESS
================================================================================
This is a video I've been excited to make for a while now. The story here braids together prime numbers, complex numbers,  and pi in a very pleasing trio. Quite often in modern math, especially that which flirts with the Riemann zeta function,  these three seemingly unrelated objects show up in unison,  and I want to give you a little peek at one instance where this happens,  one of the few that doesn't require too heavy a technical background. That's not to say this is easy, in fact this is probably one of the  most intricate videos I've ever done, but the culmination is worth it. What we'll end up with is a formula for pi, a certain alternating infinite sum. This formula is actually written on the mug I'm drinking coffee from right now as  I write this, and a fun but almost certainly apocryphal story is that the beauty of  this formula is what inspired Leibniz to quit being a lawyer and instead pursue math. Whenever you see pi show up in math, there's always going  to be a circle hiding somewhere, sometimes very sneakily. So the goal here is not just to discover this sum,  but to really understand the circle hiding behind it. You see, there is another way you can prove the same result that you and I are going  to spend some meaningful time building up to, but with just a few lines of calculus. And this is one of those proofs that leaves you thinking, okay, I suppose that's true,  but not really getting a sense for why, or where the hidden circle is. On the path you and I will take, though, what you'll see is that the fundamental  truth behind this sum and the circle it hides is a certain regularity in the  way that prime numbers behave when you put them inside the complex numbers. To start the story, imagine yourself with nothing more than a pencil,  some paper, and a desire to find a formula for computing pi. There are countless ways you could approach this,  but as a broad outline for the plotline, you'll start by asking how many lattice points  of the plane sit inside a big circle. That will lead to asking about how to express numbers as the sum of two squares,  which in turn will lead us to factoring integers inside the complex plane. From there we'll bring in a special function called chi,  which will give us a formula for pi that at first seems to involve a crazy  complicated pattern dependent on the distribution of primes,  but a slight shift in perspective will simplify it dramatically and expose  the ultimate gold nugget. It's a lot, but good math takes time, and we'll take it step by step. When I say lattice point, what I mean is a point AB on the plane  where A and B are both integers, a spot where the grid lines cross. If you draw a circle centered at the origin, let's say with radius 10,  how many lattice points would you guess are inside that circle? Well, there's one lattice point for each unit of area,  so the answer should be approximately equal to the area of the circle,  pi r squared, which in this case is pi times 10 squared. And if it was a really big circle, like radius 1 million,  you would expect this to be a much more accurate estimate,  in the sense that the percent error between the estimate pi r squared and the  actual count of lattice points should get smaller. What we're going to try to do is find a second way to answer this same question,  how many lattice points are inside the circle,  because that can lead to another way to express the area of a circle,  and hence another way to express pi. And so you play, and you wonder, and maybe, especially if you  just watched a certain calculus video, you might try looking  through every possible ring that a lattice point could sit on. If you think about it, for each one of these lattice points AB,  its distance from the origin is the square root of a squared plus b squared. And since a and b are both integers, a squared plus b squared is also some integer,  so you only have to consider rings whose radii are the square roots of some whole number. A radius of 0 just gives you that single origin point. If you look at the radius 1, that hits 4 different lattice points. Radius square root of 2, well that also hits 4 lattice points.  Radius square root of 3 doesn't actually hit anything.  Square root of 4 again hits 4 lattice points. A radius square root of 3 doesn't actually hit anything. Square root of 4 again hits 4 lattice points. A radius square root of 5 actually hits 8 lattice points. And what we want is a systematic way to count how many lattice points are on a  given one of these rings, a given distance from the origin, and tally them all up. And if you pause and try this for a moment, what you'll find is that  the pattern seems really chaotic, just very hard to find order under here. And that's a good sign that some very interesting math is about to come into play. In fact, as you'll see, this pattern is rooted in the distribution of primes. As an example, let's look at the ring with radius square root of 25. It hits the point 5,0, since 5 squared plus 0 squared is 25. It also hits 4,3, since 4 squared plus 3 squared gives 25. And likewise it hits 3,4, and also 0,5. And what's really happening here is that you're counting how many pairs of integers,  a,b, have the property that a squared plus b squared equals 25. And looking at this circle, it looks like there's a total of 12 of them. As another example, take a look at the ring with radius square root of 11. It doesn't hit any lattice points. And that corresponds to the fact that you cannot  find two integers whose squares add up to 11. Try it. Now, many times in math, when you see a question that has to do with the 2D plane,  it can be surprisingly fruitful to just ask what it looks like when  you think of this plane as the set of all complex numbers. So instead of thinking of this lattice point here as the pair of integer coordinates,  3,4, instead think of it as the single complex number, 3 plus 4i. That way, another way to think about the sum of the squares of its coordinates,  3 squared plus 4 squared, is to multiply this number by 3 minus 4i. This is called its complex conjugate. It's what you get by reflecting over the real axis, replacing i with negative i. And this might seem like a strange step if you  don't have much of a history with complex numbers. But describing this distance as a product can be unexpectedly useful. It turns our question into a factoring problem,  which is ultimately why patterns among prime numbers are going to come into play. Algebraically, this relation is straightforward enough to verify. You get a 3 squared, and then the 3 times minus 4i cancels out with the 4i times 3. And then you have negative 4i squared, which, because i squared is negative 1,  becomes plus 4 squared. This is also quite nice to see geometrically. And if you're a little rusty with how complex multiplication works,  I do have another video that goes more into detail about why complex multiplication looks  the way that it does. The way you might think about a case like this is that the number  3 plus 4i has a magnitude of 5 and some angle off of the horizontal. And what it means to multiply it by 3 minus 4i is to rotate by that same angle in the  opposite direction, putting it on the positive real axis,  and then to stretch out by a factor of 5, which in this case lands you on the output 25,  the square of the magnitude. The collection of all of these lattice points,  a plus bi, where a and b are integers, has a special name. They're called the Gaussian integers, named after Martin Sheen. Geometrically, you'll still be asking the same question. How many of these lattice points, Gaussian integers,  are a given distance away from the origin, like square root of 25? But we'll be phrasing it in a slightly more algebraic way. How many Gaussian integers have the property that  multiplying by their complex conjugate gives you 25? This might seem needlessly complex, but it's the key to understanding the seemingly  random pattern for how many lattice points are a given distance away from the origin. To see why, we first need to understand how numbers factor inside the Gaussian integers. As a refresher, among ordinary integers, every number  can be factored as some unique collection of prime numbers. For example, 2250 can be factored as 2 times 3 squared times 5 cubed. And there is no other collection of prime numbers that also multiplies to make 2250. Unless you let negative numbers into the picture,  in which case you could just make some of the primes in this factorization negative. So really, within the integers, factorization is not perfectly unique. It's almost unique, with the exception that you can get a different  looking product by multiplying some of the factors by negative 1. The reason I bring that up is that factoring works  very similarly inside the Gaussian integers. Some numbers, like 5, can be factored into smaller Gaussian integers,  which in this case is 2 plus i times 2 minus i. This Gaussian integer here, 2 plus i, cannot be factored into anything smaller,  so we call it a Gaussian prime. Again, this factorization is almost unique, but this time not only  can you multiply each one of those factors by negative 1 to get a  factorization that looks different, you can also be extra sneaky and  multiply one of these factors by i and then the other one by negative i. This will give you a different way to factor 5 into two distinct Gaussian primes. But other than the things that you can get by multiplying some of these factors by  negative 1, or i, or negative i, factorization within the Gaussian integers is unique. And if you can figure out how ordinary prime numbers factor inside the Gaussian integers,  that'll be enough to tell us how any other natural number  factors inside these Gaussian integers. And so here, we pull in a crucial and pretty surprising fact. Prime numbers that are 1 above a multiple of 4, like 5, or 13, or 17,  these guys can always be factored into exactly two distinct Gaussian primes. This corresponds with the fact that rings with a radius equal to the  square root of one of these prime numbers always hit some lattice points. In fact, they always hit exactly 8 lattice points, as you'll see in just a moment. On the other hand, prime numbers that are 3 above a multiple of 4, like 3,  or 7, or 11, these guys cannot be factored further inside the Gaussian integers. Not only are they primes in the normal numbers,  but they're also Gaussian primes, unsplittable even when i is in the picture. And this corresponds with the fact that a ring whose radius is the  square root of one of those primes will never hit any lattice points. And this pattern right here is the regularity within  prime numbers that we're going to ultimately exploit. And in a later video, I might explain why on earth this is true,  why a prime number's remainder when divided by 4 has anything to do  with whether or not it factors inside the Gaussian integers, or,  said differently, whether or not it can be expressed as the sum of two squares. But here, and now, we'll just have to take it as a given. The prime number 2, by the way, is a little special, because it does factor,  you can write it as 1 plus i times 1 minus i, but these two Gaussian primes are a 90  degree rotation away from each other, so you can multiply one of them by i to get  the other. And that fact is going to make us want to treat the prime number 2 a little bit  differently for where all of this stuff is going,  so just keep that in the back of your mind. Remember, our goal here is to count how many lattice points are a  given distance away from the origin, and doing this systematically  for all distances square root of n can lead us to a formula for pi. And counting the number of lattice points with a given magnitude,  like square root of 25, is the same as asking how many Gaussian integers  have the special property that multiplying them by their complex conjugate gives you 25. So here's the recipe for finding all Gaussian integers that have this property. Step 1, factor 25, which inside the ordinary integers looks like 5 squared,  but since 5 factors even further, as 2 plus i times 2 minus i,  25 breaks down as these four Gaussian primes. Step 2, organize these into two different columns,  with conjugate pairs sitting right next to each other. And once you do that, multiply what's in each column,  and you'll come out with two different Gaussian integers on the bottom. And because everything on the right is a conjugate with everything on the left,  what comes out is going to be a complex conjugate pair which multiplies to 25. Picking an arbitrary standard, let's say that the  product from that left column is the output of our recipe. Now notice, there are three choices for how you  can divvy up the primes that can affect this output. Pictured right here, both copies of 2 plus i are in the left column,  and that gives us the product 3 plus 4i. You could also have chosen to have only one copy of 2 plus i in this left column,  in which case the product would be 5. Or you could have both copies of 2 plus i in that right column,  in which case the output of our recipe would have been 3 minus 4i. And those three possible outputs are all different  lattice points on a circle with radius square root of 25. But why does this recipe not yet capture all 12 of the lattice points? Remember how I mentioned that a factorization into Gaussian primes can  look different if you multiply some of them by i or negative 1, negative i? In this case, you could write the factorization of 25 differently,  maybe splitting up one of those fives as negative 1 plus 2i times negative 1 minus 2i. And if you do that, running through the same recipe, it can affect the result. You'll get a different product out of that left column. But the only effect that this is going to have is to multiply that total output by i,  or negative 1, or negative i. So as a final step for our recipe, let's say that you have to make one of four choices. Take that product from the left column and choose to multiply it by 1, i, negative 1,  or negative i, corresponding to rotations that are some multiple of 90 degrees. That will account for all 12 different ways of constructing  a Gaussian integer whose product with its own conjugate is 25. This process is a little complicated, so I think the best way  to get a feel for it is to just try it out with more examples. Let's say instead we were looking at 125, which is 5 cubed. In that case, we would have four different choices for how  to divvy up the prime conjugate pairs into these two columns. You can either have zero copies of 2 plus i in the left column,  one copy in there, two copies in there, or all three of them in that left column. Those four choices multiplied by the final four choices of multiplying the product from  the left column by 1, or by i, or negative 1, or negative i,  would suggest that there are a total of 16 lattice points a distance square root of  125 away from the origin. And indeed, if you draw that circle out and count,  what you'll find is that it hits exactly 16 lattice points. But what if you introduce a factor like 3, which doesn't  break down as the product of two conjugate Gaussian primes? Well that really mucks up the whole system. When you're divvying up the primes between the two columns,  there's no way that you can split up this 3. No matter where you put it, it leaves the columns imbalanced. And what that means is that when you take the product of all of the  numbers in each column, you're not going to end up with a conjugate pair. So for a number like this, 3 times 5 cubed, which is 375,  there's actually no lattice point that you'll hit. No Gaussian integer whose product with its own conjugate gives you 375. However, if you introduce a second factor of 3, then you have an option. You can throw one 3 in the left column, and the other 3 in the right column. Since 3 is its own complex conjugate, this leaves things balanced,  in the sense that the product of the left and right columns will indeed be a complex  conjugate pair. But it doesn't add any new options. There's still going to be a total of 4 choices for how to divvy up those factors of 5,  multiplied by the final 4 choices of multiplying by 1, i, negative 1, or negative i. So just like the square root of 125 circle, this guy is  also going to end up hitting exactly 16 lattice points. Let's just sum up where we are. When you're counting up how many lattice points lie on a circle  with a radius square root of n, the first step is to factor n. And for prime numbers like 5, or 13, or 17, which factor further into a  complex conjugate pair of Gaussian primes, the number of choices they give  you will always be one more than the exponent that shows up with that factor. On the other hand, for prime factors like 3, or 7, or 11,  which are already Gaussian primes and cannot be split,  if they show up with an even power, you have one and only one choice  with what to do with them. But if it's an odd exponent, you're screwed, and you just have zero choices. And always, no matter what, you have those final 4 choices at the end. By the way, I do think that this process right  here is the most complicated part of the video. It took me a couple times to think through that, yes,  this is a valid way to count lattice points, so don't be shy  if you want to pause and scribble things down to get a feel for it. The one last thing to mention about this recipe is how factors of 2 affect the count. If your number is even, then that factor of 2 breaks down as 1 plus i times 1 minus i. So you can divvy up that complex conjugate pair between the two columns. And at first, it might look like this doubles your options,  depending on how you choose to place those two Gaussian primes between the columns. However, since multiplying one of these guys by i gives you the other one,  when you swap them between the columns, the effect that that has on the  output from the left column is to just multiply it by i, or by negative i. So that's actually redundant with the final step,  where we take the product of this left column and choose to multiply it by either 1,  i, negative 1, or negative i. What this means is that a factor of 2, or any power of 2,  doesn't actually change the count at all. It doesn't hurt, but it doesn't help. For example, a circle with radius square root of 5 hits 8 lattice points. And if you grow that radius to square root of 10, then you also hit 8 lattice points. And square root of 20 also hits 8 lattice points, as does square root of 40. Factors of 2 just don't make a difference. Now what's about to happen is number theory at its best. We have this complicated recipe telling us how many lattice points sit on a circle  with radius square root of n, and it depends on the prime factorization of n. To turn this into something simpler, something we can actually deal with,  we're going to exploit the regularity of primes that those which are  1 above a multiple of 4 split into distinct Gaussian prime factors,  while those that are 3 above a multiple of 4 cannot be split. To do this, let's introduce a simple function,  one which I'll label with the Greek letter chi. For inputs that are 1 above a multiple of 4, the output of chi is just 1. If it takes in an input 3 above a multiple of 4, then the output of chi is negative 1. And then on all even numbers, it gives 0. So if you evaluate chi on the natural numbers, it gives this very nice cyclic pattern,  1, 0, negative 1, 0, and then repeat indefinitely. And this cyclic function chi has a very special property. It's what's called a multiplicative function. If you evaluate it on two different numbers and multiply the results,  like chi of 3 times chi of 5, it's the same as if you evaluate  chi on the product of those two numbers, in this case chi of 15. Likewise, chi of 5 times chi of 5 is equal to chi of 25,  and no matter what two natural numbers you put in there, this property will hold. Go ahead, try it if you want. So for our central question of counting lattice points in this way that  involves factoring a number, what I'm going to do is write down the number  of choices we have but using chi in what at first seems like a much more complicated way,  but this has the benefit of treating all prime factors equally. For each prime power, like 5 cubed, what you write down is chi  of 1 plus chi of 5 plus chi of 5 squared plus chi of 5 cubed. You add up the value of chi on all the powers of this  prime up to the one that shows up inside the factorization. In this case, since 5 is 1 above a multiple of 4, all of these are just 1,  so this sum comes out to be 4, which reflects the fact that a factor of 5 cubed  gives you 4 options for how to divvy up the two Gaussian prime factors between the  columns. For a factor like 3 to the 4th, what you write down looks totally similar,  chi of 1 plus chi of 3 on and on up to chi of 3 to the 4th. But in this case, since chi of 3 is negative 1,  this sum oscillates, it goes 1 minus 1 plus 1 minus 1 plus 1. And if it's an even power, like 4 in this case,  the total sum comes out to be 1, which encapsulates the fact  that there is only one choice for what to do with those unsplittable 3's. But if it's an odd power, that sum comes out to 0,  indicating that you're screwed, you can't place that unsplittable 3. When you do this for a power of 2, what it looks like is 1 plus  0 plus 0 plus 0 on and on, since chi is always 0 on even numbers. And this reflects the fact that a factor of 2 doesn't help and it doesn't hurt,  you always have just one option for what to do with it. And as always, we keep a 4 in front to indicate that final choice of multiplying by 1,  i, negative 1, or negative i. We're getting close to the culmination now. Things are starting to look organized, so take a moment,  pause and ponder, make sure everything feels good up to this point. Take the number 45 as an example. This guy factors as 3 squared times 5, so the expression for  the total number of lattice points is 4 times chi of 1 plus  chi of 3 plus chi of 3 squared times chi of 1 plus chi of 5. You can think about this as 4 times the one choice for what to do with the  3's times two choices for how to divvy up the Gaussian prime factors of 5. It might seem like expanding out this sum is really complicated,  because it involves all possible combinations of these prime factors. And it kind of is. However, because chi is multiplicative, each one of  those combinations corresponds to a divisor of 45. In this case, we get 4 times chi of 1 plus chi of 3 plus  chi of 5 plus chi of 9 plus chi of 15 plus chi of 45. What you'll notice is that this covers every number that divides evenly into 45,  once and only once. And it works like this for any number, there's nothing special about 45. And that to me is pretty interesting, and I think wholly unexpected. This question of counting the number of lattice points a distance  square root of n away from the origin, involves adding up the  value of this relatively simple function over all the divisors of n. To bring it all together, remember why we're doing this. The total number of lattice points inside a big circle  with radius r should be about pi times r squared. But on the other hand, we can count those same lattice points by looking  through all of the numbers n between 0 and r squared,  and counting how many lattice points are a distance square root of n from the origin. Let's go ahead and just ignore that origin dot with radius 0,  it doesn't really follow the pattern of the rest,  and one little dot isn't going to make a difference as we let r grow towards infinity. Now from all of this Gaussian integer and factoring and chi function  stuff that we've been doing, the answer for each n looks like adding  up the value of chi on every divisor of n, and then multiplying by 4. And for now let's just take that 4 and put it in the corner,  and remember to bring it back later. At first, adding up the values for each one of these rows seems super random, right? I mean, numbers with a lot of factors have a lot of divisors,  whereas prime numbers will always only have two divisors. So it initially seems like you would have to have perfect knowledge  of the distribution of primes to get anything useful out of this. But if instead you organize these into columns, the puzzle starts to fit together. How many numbers between 1 and r2 have 1 as a divisor? All of them.  So our sum should include r2 times chi of 1. How many of them have 2 as a divisor? Well, all of them. So our sum should include r squared times chi of 1. How many of them have 2 as a divisor? Well, about half of them. So that would account for about r squared over 2 times chi of 2. About a third of these rows have chi of 3, so we  can put in r squared divided by 3 times chi of 3. And keep in mind we're being approximate since r squared might not perfectly  divide 2 or 3, but as r grows towards infinity, this approximation will get better. And when you keep going like this, you get a pretty  organized expression for the total number of lattice points. And if you factor out that r squared and then bring back the 4 that needs  to be multiplied in, what it means is that the total number of lattice points  inside this big circle is approximately 4 times r squared times this sum. And because chi is 0 on every even number, and it oscillates between 1 and negative 1 for  odd numbers, this sum looks like 1 minus 1 third plus a fifth minus 1 seventh and so on. And this is exactly what we wanted. What we have here is an alternate expression for the total number of lattice  points inside a big circle, which we know should be around pi times r squared. And the bigger r is, the more accurate both of these estimates are,  so the percent error between the left-hand side and the right-hand side can get  arbitrarily small. So divide out by that r squared, and this gives  us an infinite sum that should converge to pi. And keep in mind, I just think this is really cool. The reason that this sum came out to be so simple,  requiring relatively low information to describe,  ultimately stems from the regular pattern and how prime numbers  factor inside the Gaussian integers. If you're curious, there are two main branches of number theory,  algebraic number theory and analytic number theory. Very loosely speaking, the former deals with new number systems,  things like these Gaussian integers that you and I looked at, and a lot more. And the latter deals with things like the Riemann zeta function,  or its cousins, called L-functions, which involve multiplicative  functions like this central character chi from our story. And the path that we just walked is a little glimpse at where those two fields intersect. And both of these are pretty heavy-duty fields  with a lot of active research and unsolved problems. So if all this feels like something that takes time to mentally digest,  like there's more patterns to be uncovered and understood, it's because it is,  and there are.

================================================================================
VIDEO ID: 3d6DsjIBzJ4
TITLE: Taylor series | Chapter 11, Essence of calculus
URL: https://www.youtube.com/watch?v=3d6DsjIBzJ4
PUBLISHED: 2017-05-07T14:06:12Z
STATUS: SUCCESS
================================================================================
When I first learned about Taylor series, I definitely  didn't appreciate just how important they are. But time and time again they come up in math, physics,  and many fields of engineering because they're one of the most  powerful tools that math has to offer for approximating functions. I think one of the first times this clicked for me as a  student was not in a calculus class but a physics class. We were studying a certain problem that had to do with the potential energy of a  pendulum, and for that you need an expression for how high the weight of the  pendulum is above its lowest point, and when you work that out it comes out to be  proportional to 1 minus the cosine of the angle between the pendulum and the vertical. The specifics of the problem we were trying to solve are beyond the point here,  but what I'll say is that this cosine function made the problem awkward and unwieldy,  and made it less clear how pendulums relate to other oscillating phenomena. But if you approximate cosine of theta as 1 minus theta squared over 2,  everything just fell into place much more easily. If you've never seen anything like this before,  an approximation like that might seem completely out of left field. If you graph cosine of theta along with this function, 1 minus theta squared over 2,  they do seem rather close to each other, at least for small angles near 0,  but how would you even think to make this approximation,  and how would you find that particular quadratic? The study of Taylor series is largely about taking non-polynomial  functions and finding polynomials that approximate them near some input. The motive here is that polynomials tend to be much easier to deal  with than other functions, they're easier to compute,  easier to take derivatives, easier to integrate, just all around more friendly. So let's take a look at that function, cosine of x,  and really take a moment to think about how you might construct a quadratic  approximation near x equals 0. That is, among all of the possible polynomials that look like c0 plus c1  times x plus c2 times x squared, for some choice of these constants, c0,  c1, and c2, find the one that most resembles cosine of x near x equals 0,  whose graph kind of spoons with the graph of cosine x at that point. Well, first of all, at the input 0, the value of cosine of x is 1,  so if our approximation is going to be any good at all,  it should also equal 1 at the input x equals 0. Plugging in 0 just results in whatever c0 is, so we can set that equal to 1. This leaves us free to choose constants c1 and c2 to make this  approximation as good as we can, but nothing we do with them is  going to change the fact that the polynomial equals 1 at x equals 0. It would also be good if our approximation had the same  tangent slope as cosine x at this point of interest. Otherwise the approximation drifts away from the  cosine graph much faster than it needs to. The derivative of cosine is negative sine, and at x equals 0,  that equals 0, meaning the tangent line is perfectly flat. On the other hand, when you work out the derivative of our quadratic,  you get c1 plus 2 times c2 times x. At x equals 0, this just equals whatever we choose for c1. So this constant c1 has complete control over the  derivative of our approximation around x equals 0. Setting it equal to 0 ensures that our approximation  also has a flat tangent line at this point. This leaves us free to change c2, but the value and the slope of our  polynomial at x equals 0 are locked in place to match that of cosine. The final thing to take advantage of is the fact that the cosine graph  curves downward above x equals 0, it has a negative second derivative. Or in other words, even though the rate of change is 0 at that point,  the rate of change itself is decreasing around that point. Specifically, since its derivative is negative sine of x,  its second derivative is negative cosine of x, and at x equals 0, that equals negative 1. Now in the same way that we wanted the derivative of our approximation to  match that of the cosine so that their values wouldn't drift apart needlessly quickly,  making sure that their second derivatives match will ensure that they  curve at the same rate, that the slope of our polynomial doesn't drift  away from the slope of cosine x any more quickly than it needs to. Pulling up the same derivative we had before, and then taking its derivative,  we see that the second derivative of this polynomial is exactly 2 times c2. So to make sure that this second derivative also equals negative 1 at x equals 0,  2 times c2 has to be negative 1, meaning c2 itself should be negative 1 half. This gives us the approximation 1 plus 0x minus 1 half x squared. To get a feel for how good it is, if you estimate cosine of 0.1 using this polynomial,  you'd estimate it to be 0.995, and this is the true value of cosine of 0.1. It's a really good approximation! Take a moment to reflect on what just happened. You had 3 degrees of freedom with this quadratic approximation,  the constants c0, c1, and c2. c0 was responsible for making sure that the output of the approximation matches that of  cosine x at x equals 0, c1 was in charge of making sure that the derivatives match at  that point, and c2 was responsible for making sure that the second derivatives match up. This ensures that the way your approximation changes as you move away from x equals 0,  and the way that the rate of change itself changes,  is as similar as possible to the behaviour of cosine x,  given the amount of control you have. You could give yourself more control by allowing more terms  in your polynomial and matching higher order derivatives. For example, let's say you added on the term c3 times x cubed for some constant c3. In that case, if you take the third derivative of a cubic polynomial,  anything quadratic or smaller goes to 0. As for that last term, after 3 iterations of the power rule,  it looks like 1 times 2 times 3 times c3. On the other hand, the third derivative of cosine x comes out to sine x,  which equals 0 at x equals 0. So to make sure that the third derivatives match, the constant c3 should be 0. Or in other words, not only is 1 minus Â½ x2 the best possible quadratic  approximation of cosine, it's also the best possible cubic approximation. You can make an improvement by adding on a fourth order term, c4 times x to the fourth. The fourth derivative of cosine is itself, which equals 1 at x equals 0. And what's the fourth derivative of our polynomial with this new term? Well, when you keep applying the power rule over and over,  with those exponents all hopping down in front,  you end up with 1 times 2 times 3 times 4 times c4, which is 24 times c4. So if we want this to match the fourth derivative of cosine x,  which is 1, c4 has to be 1 over 24. And indeed, the polynomial 1 minus Â½ x2 plus 1 24 times x to the fourth,  which looks like this, is a very close approximation for cosine x around x equals 0. In any physics problem involving the cosine of a small angle, for example,  predictions would be almost unnoticeably different if you substituted this polynomial  for cosine of x. Take a step back and notice a few things happening with this process. First of all, factorial terms come up very naturally in this process. When you take n successive derivatives of the function x to the n,  letting the power rule keep cascading on down,  what you'll be left with is 1 times 2 times 3 on and on up to whatever n is. So you don't simply set the coefficients of the polynomial equal to whatever derivative  you want, you have to divide by the appropriate factorial to cancel out this effect. For example, that x to the fourth coefficient was the fourth derivative of cosine,  1, but divided by 4 factorial, 24. The second thing to notice is that adding on new terms,  like this c4 times x to the fourth, doesn't mess up what the old terms should be,  and that's really important. For example, the second derivative of this polynomial at x equals 0 is still equal  to 2 times the second coefficient, even after you introduce higher order terms. And it's because we're plugging in x equals 0,  so the second derivative of any higher order term, which all include an x,  will just wash away. And the same goes for any other derivative, which is why each derivative of a  polynomial at x equals 0 is controlled by one and only one of the coefficients. If instead you were approximating near an input other than 0, like x equals pi,  in order to get the same effect you would have to write your polynomial in  terms of powers of x minus pi, or whatever input you're looking at. This makes it look noticeably more complicated,  but all we're doing is making sure that the point pi looks and behaves like 0,  so that plugging in x equals pi will result in a lot of nice cancellation that  leaves only one constant. And finally, on a more philosophical level, notice how what we're doing here is basically  taking information about higher order derivatives of a function at a single point,  and translating that into information about the value of the function near that point. You can take as many derivatives of cosine as you want. It follows this nice cyclic pattern, cosine of x,  negative sine of x, negative cosine, sine, and then repeat. And the value of each one of these is easy to compute at x equals 0. It gives this cyclic pattern 1, 0, negative 1, 0, and then repeat. And knowing the values of all those higher order derivatives is a lot of information  about cosine of x, even though it only involves plugging in a single number, x equals 0. So what we're doing is leveraging that information to get an approximation around this  input, and you do it by creating a polynomial whose higher order derivatives are designed  to match up with those of cosine, following this same 1, 0, negative 1, 0, cyclic pattern. And to do that, you just make each coefficient of the polynomial follow that  same pattern, but you have to divide each one by the appropriate factorial. Like I mentioned before, this is what cancels out  the cascading effect of many power rule applications. The polynomials you get by stopping this process at  any point are called Taylor polynomials for cosine of x. More generally, and hence more abstractly, if we were dealing with some other function  other than cosine, you would compute its derivative, its second derivative, and so on,  getting as many terms as you'd like, and you would evaluate each one of them at x equals  0. Then for the polynomial approximation, the coefficient of each x to the n term should be  the value of the nth derivative of the function evaluated at 0,  but divided by n factorial. This whole rather abstract formula is something you'll likely  see in any text or course that touches on Taylor polynomials. And when you see it, think to yourself that the constant term ensures that  the value of the polynomial matches with the value of f,  the next term ensures that the slope of the polynomial matches the slope  of the function at x equals 0, the next term ensures that the rate at which  the slope changes is the same at that point, and so on,  depending on how many terms you want. And the more terms you choose, the closer the approximation,  but the tradeoff is that the polynomial you'd get would be more complicated. And to make things even more general, if you wanted to approximate near some input  other than 0, which we'll call a, you would write this polynomial in terms of powers  of x minus a, and you would evaluate all the derivatives of f at that input, a. This is what Taylor polynomials look like in their fullest generality. Changing the value of a changes where this approximation is hugging the original  function, where its higher order derivatives will be equal to those of the original  function. One of the simplest meaningful examples of this is  the function e to the x around the input x equals 0. Computing the derivatives is super nice, as nice as it gets,  because the derivative of e to the x is itself,  so the second derivative is also e to the x, as is its third, and so on. So at the point x equals 0, all of these are equal to 1. And what that means is our polynomial approximation should look like  1 plus 1 times x plus 1 over 2 times x squared plus 1 over 3 factorial times x cubed,  and so on, depending on how many terms you want. These are the Taylor polynomials for e to the x. Ok, so with that as a foundation, in the spirit of showing you just how connected all  the topics of calculus are, let me turn to something kind of fun,  a completely different way to understand this second order term of the Taylor  polynomials, but geometrically. It's related to the fundamental theorem of calculus,  which I talked about in chapters 1 and 8 if you need a quick refresher. Like we did in those videos, consider a function that gives the area  under some graph between a fixed left point and a variable right point. What we're going to do here is think about how to approximate this area function,  not the function for the graph itself, like we've been doing before. Focusing on that area is what's going to make the second order term pop out. Remember, the fundamental theorem of calculus is that this graph itself represents the  derivative of the area function, and it's because a slight nudge dx to the right bound  of the area gives a new bit of area approximately equal to the height of the graph times  dx. And that approximation is increasingly accurate for smaller and smaller choices of dx. But if you wanted to be more accurate about this change in area,  given some change in x that isn't meant to approach 0,  you would have to take into account this portion right here,  which is approximately a triangle. Let's name the starting input a, and the nudged input above it x, so that change is x-a. The base of that little triangle is that change, x-a,  and its height is the slope of the graph times x-a. Since this graph is the derivative of the area function,  its slope is the second derivative of the area function, evaluated at the input a. So the area of this triangle, 1 half base times height,  is 1 half times the second derivative of this area function, evaluated at a,  multiplied by x-a2. And this is exactly what you would see with a Taylor polynomial. If you knew the various derivative information about this area function at the point a,  how would you approximate the area at the point x? Well you have to include all that area up to a, f of a,  plus the area of this rectangle here, which is the first derivative, times x-a,  plus the area of that little triangle, which is 1 half times the second derivative,  times x-a2. I really like this, because even though it looks a bit messy all written out,  each one of the terms has a very clear meaning that you can just point to on the diagram. If you wanted, we could call it an end here, and you would have a  phenomenally useful tool for approximating these Taylor polynomials. But if you're thinking like a mathematician, one question you might ask is  whether or not it makes sense to never stop and just add infinitely many terms. In math, an infinite sum is called a series, so even though one of these  approximations with finitely many terms is called a Taylor polynomial,  adding all infinitely many terms gives what's called a Taylor series. You have to be really careful with the idea of an infinite series,  because it doesn't actually make sense to add infinitely many things,  you can only hit the plus button on the calculator so many times. But if you have a series where adding more and more of the terms,  which makes sense at each step, gets you increasingly close to some specific value,  what you say is that the series converges to that value. Or, if you're comfortable extending the definition of equality to  include this kind of series convergence, you'd say that the series as a whole,  this infinite sum, equals the value it's converging to. For example, look at the Taylor polynomial for e to the x,  and plug in some input, like x equals 1. As you add more and more polynomial terms, the total sum gets closer and  closer to the value e, so you say that this infinite series converges to the number e,  or what's saying the same thing, that it equals the number e. In fact, it turns out that if you plug in any other value of x, like x equals 2,  and look at the value of the higher and higher order Taylor polynomials at this value,  they will converge towards e to the x, which is e squared. This is true for any input, no matter how far away from 0 it is,  even though these Taylor polynomials are constructed only from derivative information  gathered at the input 0. In a case like this, we say that e to the x equals its own Taylor series at all inputs x,  which is kind of a magical thing to have happen. Even though this is also true for a couple other important functions,  like sine and cosine, sometimes these series only converge within a  certain range around the input whose derivative information you're using. If you work out the Taylor series for the natural log of x around the input x equals 1,  which is built by evaluating the higher order derivatives of the natural  log of x at x equals 1, this is what it would look like. When you plug in an input between 0 and 2, adding more and more terms of this  series will indeed get you closer and closer to the natural log of that input. But outside of that range, even by just a little bit,  the series fails to approach anything. As you add on more and more terms, the sum bounces back and forth wildly. It does not, as you might expect, approach the natural log of that value,  even though the natural log of x is perfectly well defined for inputs above 2. In some sense, the derivative information of ln  of x at x equals 1 doesn't propagate out that far. In a case like this, where adding more terms of the series doesn't approach anything,  you say that the series diverges. And that maximum distance between the input you're approximating  near and points where the outputs of these polynomials actually  converge is called the radius of convergence for the Taylor series. There remains more to learn about Taylor series. There are many use cases, tactics for placing bounds on the error of  these approximations, tests for understanding when series do and don't converge,  and for that matter, there remains more to learn about calculus as a whole,  and the countless topics not touched by this series. The goal with these videos is to give you the fundamental intuitions  that make you feel confident and efficient in learning more on your own,  and potentially even rediscovering more of the topic for yourself. In the case of Taylor series, the fundamental intuition to keep in mind  as you explore more of what there is, is that they translate derivative  information at a single point to approximation information around that point. Thank you once again to everybody who supported this series. The next series like it will be on probability,  and if you want early access as those videos are made, you know where to go. Thank you.

================================================================================
VIDEO ID: BLkz5LGWihw
TITLE: Higher order derivatives | Chapter 10, Essence of calculus
URL: https://www.youtube.com/watch?v=BLkz5LGWihw
PUBLISHED: 2017-05-07T14:05:35Z
STATUS: SUCCESS
================================================================================
In the next chapter about Taylor series, I make  frequent reference to higher order derivatives. And if you're already comfortable with second derivatives,  third derivatives, and so on, great! Feel free to just skip ahead to the main event now. You won't hurt my feelings. But somehow, I've managed not to bring up higher  order derivatives at all so far in this series. So for the sake of completeness, I thought I'd give you  this little footnote just to go over them very quickly. I'll focus mainly on the second derivative, showing what it looks like in the context  of graphs and motion, and leave you to think about the analogies for higher orders. Given some function f of x, the derivative can be  interpreted as the slope of this graph above some point, right? A steep slope means a high value for the derivative,  a downward slope means a negative derivative. So the second derivative, whose notation I'll explain in just a moment,  is the derivative of the derivative, meaning it tells you how that slope is changing. The way to see that at a glance is to think about how the graph of f of x curves. At points where it curves upwards, the slope is increasing,  and that means the second derivative is positive. At points where it's curving downwards, the slope is decreasing,  so the second derivative is negative. For example, a graph like this one has a very positive second derivative at the point 4,  since the slope is rapidly increasing around that point,  whereas a graph like this one still has a positive second derivative at the same point,  but it's smaller, the slope only increases slowly. At points where there's not really any curvature, the second derivative is just 0. As far as notation goes, you could try writing it like this,  indicating some small change to the derivative function,  divided by some small change to x, where as always the use of this letter d  suggests that what you really want to consider is what this ratio approaches as dx,  both dx's in this case, approach 0. That's pretty awkward and clunky, so the standard is  to abbreviate this as d squared f divided by dx squared. And even though it's not terribly important for getting an intuition for the second  derivative, I think it might be worth showing you how you can read this notation. To start off, think of some input to your function,  and then take two small steps to the right, each one with a size of dx. I'm choosing rather big steps here so we'll be able to see what's going on,  but in principle keep in the back of your mind that dx should be rather tiny. The first step causes some change to the function, which I'll call df1,  and the second step causes some similar but possibly slightly different change,  which I'll call df2. The difference between these changes, the change in how the function changes,  is what we'll call ddf. You should think of this as really small, typically proportional to the size of dx2. So if, for example, you substituted in 0.01 for dx,  you would expect this ddf to be about proportional to 0.0001. The second derivative is the size of this change to the change,  divided by the size of dx2, or more precisely,  whatever that ratio approaches as dx approaches 0. eleration. Given some movement along a line, suppose you have some function that  records the distance traveled versus time, maybe its graph looks like this,  steadily increasing over time. Then its derivative tells you velocity at each  point in time, for example the graph might look like this bump,  increasing up to some maximum, and decreasing back to zero.  So the second derivative tells you the rate of Maybe the most visceral understanding of the second  derivative is that it represents acceleration. Given some movement along a line, suppose you have some function  that records the distance traveled versus time,  maybe its graph looks something like this, steadily increasing over time. Then its derivative tells you velocity at each point in time,  for example the graph might look like this bump, increasing up to some maximum,  and decreasing back to zero. The third derivative, and this is not a joke, is called jerk. So if the jerk is not zero,  it means that the strength of the acceleration itself is changing.  One of the most useful things about higher order derivatives is how they help us in  approximating functions, In this example, the second derivative is positive for the first half of the journey,  which indicates speeding up, that's the sensation of being pushed back into  your car seat, or rather, having the car seat push you forward. A negative second derivative indicates slowing down, negative acceleration. The third derivative, and this is not a joke, is called jerk. So if the jerk is not zero, it means the strength of the acceleration itself is changing. One of the most useful things about higher order derivatives is  how they help us in approximating functions, which is exactly the  topic of the next chapter on Taylor series, so I'll see you there.

================================================================================
VIDEO ID: FnJqaIESC2s
TITLE: What does area have to do with slope? | Chapter 9, Essence of calculus
URL: https://www.youtube.com/watch?v=FnJqaIESC2s
PUBLISHED: 2017-05-06T13:53:16Z
STATUS: SUCCESS
================================================================================
Here, I want to discuss one common type of problem where integration comes up,  finding the average of a continuous variable. This is a perfectly useful thing to know in its own right,  but what's really neat is that it can give us a completely different  perspective for why integrals and derivatives are inverses of each other. To start, take a look at the graph of sinx between 0 and pi, which is half of its period. What is the average height of this graph on that interval? It's not a useless question. All sorts of cyclic phenomena in the world are modeled using sine waves. For example, the number of hours the sun is up per day as a  function of what day of the year it is follows a sine wave pattern. So if you wanted to predict the average effectiveness of solar panels in summer months vs. winter months, you'd want to be able to answer a question like this,  what is the average value of that sine function over half of its period? Where as a case like this is going to have all sorts of constants mucking up the  function, you and I are going to focus on a pure, unencumbered sinx function,  but the substance of the approach would be totally the same in any other application. It's kind of a weird question to think about though, isn't it? The average of a continuous variable. Usually with averages we think of a finite number of variables,  where you can add them all up and divide that sum by how many there are. But there are infinitely many values of sinx between 0 and pi,  and it's not like we can just add up all those numbers and divide by infinity. This sensation comes up a lot in math, and it's worth remembering,  where you have this vague sense that you want to add together infinitely  many values associated with a continuum, even though that doesn't make sense. And almost always, when you get that sense, the key is to use an integral somehow. And to think through exactly how, a good first step is to  just approximate your situation with some kind of finite sum. In this case, imagine sampling a finite number of points evenly spaced along this range. Since it's a finite sample, you can find the average by just adding up all the heights  sinx at each one of these, and then dividing that sum by the number of points you sampled. And presumably, if the idea of an average height among all infinitely many  points is going to make any sense at all, the more points we sample,  which would involve adding up more and more heights,  the closer the average of that sample should be to the actual average of  the continuous variable. And this should feel at least somewhat related to taking an integral of sinx  between 0 and pi, even if it might not be exactly clear how the two ideas match up. For that integral, remember, you also think of a sample of inputs on this continuum,  but instead of adding the height sinx at each one and dividing by how many there are,  you add up sinx times dx, where dx is the spacing between the samples. That is, you're adding up little areas, not heights. And technically, the integral is not quite this sum,  it's whatever that sum approaches as dx approaches 0. But it is actually quite helpful to reason with respect to one of these finite  iterations, where we're looking at a concrete size for dx and some specific number of  rectangles. So what you want to do here is reframe this expression for the average,  this sum of the heights divided by the number of sampled points,  in terms of dx, the spacing between samples. And now, if I tell you that the spacing between these points is, say, 0.1,  and you know that they range from 0 to pi, can you tell me how many there are? Well, you can take the length of that interval, pi,  and divide it by the length of the space between each sample. If it doesn't go in perfectly evenly, you'd have to round down to the nearest integer,  but as an approximation, this is completely fine. So if we write that spacing between samples as dx,  the number of samples is pi divided by dx. And when we substitute that into our expression up here,  you can rearrange it, putting that dx up top and distributing it into the sum. But think about what it means to distribute that dx up top. It means that the terms you're adding up will look like  sinx times dx for the various inputs x that you're sampling. So that numerator looks exactly like an integral expression. And so for larger and larger samples of points,  this average will approach the actual integral of sinx between 0 and pi,  all divided by the length of that interval, pi. In other words, the average height of this graph is this area divided by its width. On an intuitive level, and just thinking in terms of units,  that feels pretty reasonable, doesn't it? Area divided by width gives you an average height. So with this expression in hand, let's actually solve it. As we saw last video, to compute an integral, you need to find an antiderivative  of the function inside the integral, some other function whose derivative is sinx. And if you're comfortable with derivatives of trig functions,  you know that the derivative of cosine is negative sine. So if you just negate that, negative cosine is the function we want,  the antiderivative of sine. And to gut-check yourself on that, look at this graph of negative cosine. At 0, the slope is 0, and then it increases up to some maximum slope at pi halves,  and then goes back down to 0 at pi. And in general, its slope does indeed seem to  match the height of the sine graph at every point. So what do we have to do to evaluate the integral of sine between 0 and pi? We evaluate this antiderivative at the upper bound,  and subtract off its value at the lower bound. More visually, that's the difference in the height of  this negative cosine graph above pi and its height at 0. And as you can see, that change in height is exactly 2. That's kind of interesting, isn't it? That the area under this sine graph turns out to be exactly 2? So the answer to our average height problem, this integral divided by the width  of the region, evidently turns out to be 2 divided by pi, which is around 0.64. I promised at the start that this question of finding the average of a function offers  an alternate perspective on why integrals and derivatives are inverses of each other,  why the area under one graph has anything to do with the slope of another graph. Notice how finding this average value, 2 divided by pi,  came down to looking at the change in the antiderivative,  negative cosine x, over the input range, divided by the length of that range. And another way to think about that fraction is as the rise over run slope between  the point of the antiderivative graph below 0 and the point of that graph above pi. Think about why it might make sense that this slope would  represent an average value of sine of x on that region. By definition, sine of x is the derivative of this antiderivative graph,  giving us the slope of negative cosine at every point. Another way to think about the average value of sine of x is  as the average slope over all tangent lines between 0 and pi. And when you view things like that, doesn't it make a lot of sense  that the average slope of a graph over all its points in a certain  range should equal the total slope between the start and end points? To digest this idea, it helps to think about what it looks like for a general function. For any function f of x, if you want to find its average value on some interval,  say between a and b, what you do is take the integral of f on that  interval divided by the width of that interval, b minus a. You can think of this as the area under the graph divided by its width,  or more accurately, it is the signed area of that graph,  since any area below the x-axis is counted as negative. And it's worth taking a moment to remember what this area has to do with the usual notion  of a finite average, where you add up many numbers and divide by how many there are. When you take some sample of points spaced out by dx,  the number of samples is about equal to the length of the interval divided by dx. So if you add up the values of f of x at each sample and divide by  the total number of samples, it's the same as adding up the product  f of x times dx and dividing by the width of the entire interval. The only difference between that and the integral is that the integral asks  what happens as dx approaches 0, but that just corresponds with samples of  more and more points that approximate the true average increasingly well. Now for any integral, evaluating it comes down to finding an antiderivative of f of x,  commonly denoted capital F of x. What we want is the change to this antiderivative between a and b,  capital F of b minus capital F of a, which you can think of as  the change in height of this new graph between the two bounds. I've conveniently chosen an antiderivative that passes through 0 at the lower bound here,  but keep in mind you can freely shift this up and down adding whatever  constant you want and it would still be a valid antiderivative. So the solution to the average problem is the change in the height of  this new graph divided by the change to the x value between a and b. In other words, it is the slope of the antiderivative graph between the two endpoints. And again, when you stop to think about it, that should make a lot of sense,  because little gives us the slope of the tangent line to this graph at each point. After all, it is by definition the derivative of capital F. So why are antiderivatives the key to solving integrals? My favorite intuition is still the one I showed last video,  but a second perspective is that when you reframe the question of finding an average of  a continuous value as instead finding the average slope of a bunch of tangent lines,  it lets you see the answer just by comparing endpoints,  rather than having to actually tally up all the points in between. In the last video I described a sensation that should bring integrals to your mind,  namely if you feel like the problem you're solving could be approximated by  breaking it up somehow and adding up a large number of small things. Here I want you to come away recognizing a second  sensation that should also bring integrals to your mind. If ever there's some idea that you understand in a finite context,  and which involves adding up multiple values, like taking the average of a  bunch of numbers, and if you want to generalize that idea to apply to an infinite  continuous range of values, try seeing if you can phrase things in terms of an integral. It's a feeling that comes up all the time, especially in probability,  and it's definitely worth remembering. My thanks, as always, go to those making these videos possible. Thank you.

================================================================================
VIDEO ID: rfG8ce4nNh0
TITLE: Integration and the fundamental theorem of calculus | Chapter 8, Essence of calculus
URL: https://www.youtube.com/watch?v=rfG8ce4nNh0
PUBLISHED: 2017-05-05T15:05:21Z
STATUS: SUCCESS
================================================================================
This guy, Grothendieck, is somewhat of a mathematical idol to me,  and I just love this quote, don't you? Too often in math, we dive into showing that a certain fact is true  with a long series of formulas before stepping back and making sure it feels reasonable,  and preferably obvious, at least at an intuitive level. In this video, I want to talk about integrals,  and the thing that I want to become almost obvious is that they are an  inverse of derivatives. Here we're just going to focus on one example,  which is a kind of dual to the example of a moving car that I talked about in chapter  2 of the series, introducing derivatives. Then in the next video we're going to see how this same idea generalizes,  but to a couple other contexts. Imagine you're sitting in a car, and you can't see out the window,  all you see is the speedometer. At some point the car starts moving, speeds up,  and then slows back down to a stop, all over the course of 8 seconds. The question is, is there a nice way to figure out how far you've  travelled during that time based only on your view of the speedometer? Or better yet, can you find a distance function, s of t,  that tells you how far you've travelled after a given amount of time, t,  somewhere between 0 and 8 seconds? Let's say you take note of the velocity at every second,  and make a plot over time that looks something like this. And maybe you find that a nice function to model that velocity  over time in meters per second is v of t equals t times 8 minus t. You might remember, in chapter 2 of this series we were looking at  the opposite situation, where you knew what a distance function was,  s of t, and you wanted to figure out the velocity function from that. There I showed how the derivative of a distance vs. time function gives you a velocity vs. time function. So in our current situation, where all we know is velocity,  it should make sense that finding a distance vs. time function is going to come down to asking what  function has a derivative of t times 8 minus t. This is often described as finding the antiderivative of a function, and indeed,  that's what we'll end up doing, and you could even pause right now and try that. But first, I want to spend the bulk of this video showing how this question is related  to finding the area bounded by the velocity graph,  because that helps to build an intuition for a whole class of problems,  things called integral problems in math and science. To start off, notice that this question would be a lot easier  if the car was just moving at a constant velocity, right? In that case, you could just multiply the velocity in meters per second times the amount  of time that has passed in seconds, and that would give you the number of meters traveled. And notice, you can visualize that product, that distance, as an area. And if visualizing distance as area seems kind of weird, I'm right there with you. It's just that on this plot, where the horizontal direction has units of seconds,  and the vertical direction has units of meters per second,  units of area just very naturally correspond to meters. But what makes our situation hard is that velocity is not constant,  it's incessantly changing at every single instant. It would even be a lot easier if it only ever changed at a handful of points,  maybe staying static for the first second, and then suddenly discontinuously  jumping to a constant 7 meters per second for the next second, and so on,  with discontinuous jumps to portions of constant velocity. That would make it uncomfortable for the driver,  in fact it's actually physically impossible, but it would make your calculations  a lot more straightforward. You could just compute the distance traveled on each interval by multiplying the constant  velocity on that interval by the change in time, and then just add all of those up. So what we're going to do is approximate the velocity function as if it  was constant on a bunch of intervals, and then, as is common in calculus,  we'll see how refining that approximation leads us to something more precise. Here, let's make this a little more concrete by throwing in some numbers. Chop up the time axis between 0 and 8 seconds into many small intervals,  each with some little width dt, something like 0.25 seconds. Consider one of those intervals, like the one between t equals 1 and 1.25. In reality, the car speeds up from 7 m per second to about 8.4 m per  second during that time, and you could find those numbers just by  plugging in t equals 1 and t equals 1.25 to the equation for velocity. What we want to do is approximate the car's motion  as if its velocity was constant on that interval. Again, the reason for doing that is we don't really know  how to handle situations other than constant velocity ones. You could choose this constant to be anything between 7 and 8.4. It actually doesn't matter. All that matters is that our sequence of approximations,  whatever they are, gets better and better as dt gets smaller and smaller. That treating this car's journey as a bunch of discontinuous jumps  in speed between portions of constant velocity becomes a less-wrong  reflection of reality as we decrease the time between those jumps. So for convenience, on an interval like this, let's just approximate the  speed with whatever the true car's velocity is at the start of that interval,  the height of the graph above the left side, which in this case is 7. In this example interval, according to our approximation,  the car moves 7 m per second times 0.25 seconds. That's 1.75 meters, and it's nicely visualized as the area of this thin rectangle. In truth, that's a little under the real distance traveled, but not by much. The same goes for every other interval. The approximated distance is v of t times dt, it's just that you'd be plugging in a  different value for t at each one of these, giving a different height for each rectangle. I'm going to write out an expression for the sum of  the areas of all those rectangles in kind of a funny way. Take this symbol here, which looks like a stretched s for sum,  and put a 0 at its bottom and an 8 at its top,  to indicate that we'll be ranging over time steps between 0 and 8 seconds. And as I said, the amount we're adding up at each time step is v of t times dt. Two things are implicit in this notation. First of all, that value dt plays two separate roles. Not only is it a factor in each quantity we're adding up,  it also indicates the spacing between each sampled time step. So when you make dt smaller and smaller, even though it decreases the area of  each rectangle, it increases the total number of rectangles whose areas we're adding up,  because if they're thinner, it takes more of them to fill that space. And second, the reason we don't use the usual sigma notation to indicate a sum is that  this expression is technically not any particular sum for any particular choice of dt. It's meant to express whatever that sum approaches as dt approaches 0. And as you can see, what that approaches is the  area bounded by this curve and the horizontal axis. Remember, smaller choices of dt indicate closer approximations for the original question,  how far does the car actually go? So this limiting value for the sum, the area under this curve,  gives us the precise answer to the question in full unapproximated precision. Now tell me that's not surprising. We had this pretty complicated idea of approximations that  can involve adding up a huge number of very tiny things. And yet, the value that those approximations approach can be described so simply,  it's just the area underneath this curve. This expression is called an integral of v of t,  since it brings all of its values together, it integrates them. Now at this point, you could say, how does this help? You've just reframed one hard question, finding how far the car has traveled,  into an equally hard problem, finding the area between this graph and the horizontal axis. And you'd be right. If the velocity-distance duo was the only thing we cared about, most of this video,  with all the area under a curve nonsense, would be a waste of time. We could just skip straight ahead to finding an antiderivative. But finding the area between a function's graph and the horizontal axis  is somewhat of a common language for many disparate problems that can be  broken down and approximated as the sum of a large number of small things. You'll see more in the next video, but for now I'll just say in  the abstract that understanding how to interpret and how to  compute the area under a graph is a very general problem-solving tool. In fact, the first video of this series already covered the basics of how this works,  but now that we have more of a background with derivatives,  we can take this idea to its completion. For a velocity example, think of this right endpoint as a variable, capital T. So we're thinking of this integral of the velocity function between 0 and T,  the area under this curve between those inputs,  as a function where the upper bound is the variable. That area represents the distance the car has travelled after T seconds, right? So in reality, this is a distance vs. time function, s of t. Now ask yourself, what is the derivative of that function? On the one hand, a tiny change in distance over a tiny change in time is velocity,  that is what velocity means. But there's another way to see this, purely in terms of this graph and this area,  which generalizes a lot better to other integral problems. A slight nudge of dt to the input causes that area to increase,  some little ds represented by the area of this sliver. The height of that sliver is the height of the graph at that point,  v of t, and its width is dt. And for small enough dt, we can basically consider that sliver to be a rectangle,  so this little bit of added area, ds, is approximately equal to v of t times dt. And because that's an approximation that gets better and better for smaller dt,  the derivative of that area function, ds, dt, at this point equals vt,  the value of the velocity function at whatever time we started on. And that right there is a super general argument. The derivative of any function giving the area under a  graph like this is equal to the function for the graph itself. So, if our velocity function is t times 8-t, what should s be? What function of t has a derivative of t times 8-t? It's easier to see if we expand this out, writing it as 8t minus t squared,  and then we can just take each part one at a time. What function has a derivative of 8t? We know that the derivative of t squared is 2t,  so if we just scale that up by a factor of 4, we can see that the derivative  of 4t squared is 8t. And for that second part, what kind of function do  you think might have negative t squared as a derivative? Using the power rule again, we know that the derivative of a cubic term,  t cubed, gives us a square term, 3t squared. So if we just scale that down by a third, the  derivative of 1 third t cubed is exactly t squared. And then making that negative, we'd see that negative  1 third t cubed has a derivative of negative t squared. Therefore, the antiderivative of our function,  8t minus t squared, is 4t squared minus 1 third t cubed. But there's a slight issue here. We could add any constant we want to this function,  and its derivative is still 8t minus t squared. The derivative of a constant always goes to zero. And if you were to graph s of t, you could think of this in the sense that moving a  graph of a distance function up and down does nothing to affect its slope at every input. So in reality, there's actually infinitely many different  possible antiderivative functions, and every one of them looks  like 4t squared minus 1 third t cubed plus c, for some constant c. But there is one piece of information we haven't used yet that will let  us zero in on which antiderivative to use, the lower bound of the integral. This integral has to be zero when we drag that right  endpoint all the way to the left endpoint, right? The distance travelled by the car between 0 seconds and 0 seconds isâ€¦ well, zero. So as we found, the area as a function of capital  T is an antiderivative for the stuff inside. And to choose what constant to add to this expression,  you subtract off the value of that antiderivative function at the lower bound. If you think about it for a moment, that ensures that the  integral from the lower bound to itself will indeed be zero. As it so happens, when you evaluate the function we have here at t equals zero,  you get zero. So in this specific case, you don't need to subtract anything off. For example, the total distance travelled during the full 8 seconds  is this expression evaluated at t equals 8, which is 85.33 minus 0. So the answer as a whole is 85.33. But a more typical example would be something like the integral between 1 and 7. That's the area pictured here, and it represents  the distance travelled between 1 second and 7 seconds. What you do is evaluate the antiderivative we found at the top bound,  7, and subtract off its value at the bottom bound, 1. Notice, by the way, it doesn't matter which antiderivative we chose here. If for some reason it had a constant added to it, like 5, that constant would cancel out. More generally, any time you want to integrate some function, and remember,  you think of that as adding up values f of x times dx for inputs in a certain range,  and then asking what is that sum approach as dx approaches 0. The first step to evaluating that integral is to find an antiderivative,  some other function, capital F, whose derivative is the thing inside the integral. Then the integral equals this antiderivative evaluated  at the top bound minus its value at the bottom bound. And this fact right here that you're staring at is the fundamental theorem of calculus. And I want you to appreciate something kind of crazy about this fact. The integral, the limiting value for the sum of all these thin rectangles,  takes into account every single input on the continuum,  from the lower bound to the upper bound. That's why we use the word integrate, it brings them all together. And yet, to actually compute it using an antiderivative,  you only look at two inputs, the top bound and the bottom bound. It almost feels like cheating. Finding the antiderivative implicitly accounts for all the  information needed to add up the values between those two bounds. That's just crazy to me. This idea is deep, and there's a lot packed into this whole concept,  so let's recap everything that just happened, shall we? We wanted to figure out how far a car goes just by looking at the speedometer. And what makes that hard is that velocity is always changing. If you approximate velocity to be constant on multiple different intervals,  you could figure out how far the car goes on each interval with multiplication,  and then add all of those up. Better and better approximations for the original problem correspond to  collections of rectangles whose aggregate area is closer and closer to  being the area under this curve between the start time and the end time. So that area under the curve is actually the precise distance  traveled for the true nowhere constant velocity function. If you think of that area as a function itself,  with a variable right endpoint, you can deduce that the derivative  of that area function must equal the height of the graph at every point. And that's really the key right there. It means that to find a function giving this area,  you ask, what function has v of t as a derivative? There are actually infinitely many antiderivatives of a given function,  since you can always just add some constant without affecting the derivative,  so you account for that by subtracting off the value of whatever antiderivative function  you choose at the bottom bound. By the way, one important thing to bring up before we leave is the idea of negative area. What if the velocity function was negative at some point, meaning the car goes backwards? It's still true that a tiny distance traveled ds on a little time interval is  about equal to the velocity at that time multiplied by the tiny change in time. It's just that the number you'd plug in for velocity would be negative,  so the tiny change in distance is negative. In terms of our thin rectangles, if a rectangle goes below the horizontal axis,  like this, its area represents a bit of distance traveled backwards,  so if what you want in the end is to find a distance between the car's  start point and its end point, this is something you'll want to subtract. And that's generally true of integrals. Whenever a graph dips below the horizontal axis,  the area between that portion of the graph and the horizontal axis is counted as negative. What you'll commonly hear is that integrals don't measure area per se,  they measure the signed area between the graph and the horizontal axis. Next up, I'm going to bring up more context where this idea  of an integral and area under curves comes up,  along with some other intuitions for this fundamental theorem of calculus. Maybe you remember, chapter 2 of this series introducing the derivative  was sponsored by The Art of Problem Solving, so I think there's  something elegant to the fact that this video, which is kind of a duel to that one,  was also supported in part by The Art of Problem Solving. I really can't imagine a better sponsor for this channel,  because it's a company whose books and courses I recommend to people anyway. They were highly influential to me when I was a student developing a love for  creative math, so if you're a parent looking to foster your own child's love  for the subject, or if you're a student who wants to see what math has to offer  beyond rote schoolwork, I cannot recommend The Art of Problem Solving enough. Whether that's their newest development to build the right intuitions in  elementary school kids, called Beast Academy, or their courses in higher-level  topics and contest preparation, going to aops.com slash 3blue1brown,  or clicking on the link in the description, lets them know you came from this channel,  which may encourage them to support future projects like this one. I consider these videos a success not when they teach people a particular bit of math,  which can only ever be a drop in the ocean, but when they encourage people  to go and explore that expanse for themselves,  and The Art of Problem Solving is among the few great places to actually do  that exploration.

================================================================================
VIDEO ID: kfF40MiS7zA
TITLE: Limits, L'HÃ´pital's rule, and epsilon delta definitions | Chapter 7, Essence of calculus
URL: https://www.youtube.com/watch?v=kfF40MiS7zA
PUBLISHED: 2017-05-04T15:05:18Z
STATUS: SUCCESS
================================================================================
The last several videos have been about the idea of a derivative,  and before moving on to integrals I want to take some time to talk about limits. To be honest, the idea of a limit is not really anything new. If you know what the word approach means you pretty much already know what a limit is. You could say it's a matter of assigning fancy notation to  the intuitive idea of one value that gets closer to another. But there are a few reasons to devote a full video to this topic. For one thing, it's worth showing how the way I've been describing  derivatives so far lines up with the formal definition of a  derivative as it's typically presented in most courses and textbooks. I want to give you a little confidence that thinking in terms of dx and df  as concrete non-zero nudges is not just some trick for building intuition,  it's backed up by the formal definition of a derivative in all its rigor. I also want to shed light on what exactly mathematicians mean when  they say approach in terms of the epsilon-delta definition of limits. Then we'll finish off with a clever trick for computing limits called L'Hopital's rule. So, first things first, let's take a look at the formal definition of the derivative. As a reminder, when you have some function f of x,  to think about its derivative at a particular input, maybe x equals 2,  you start by imagining nudging that input some little dx away,  and looking at the resulting change to the output, df. The ratio df divided by dx, which can be nicely thought of  as the rise over run slope between the starting point on the graph and the nudged point,  is almost what the derivative is. The actual derivative is whatever this ratio approaches as dx approaches 0. Just to spell out what's meant there, that nudge to the output  df is the difference between f at the starting input plus dx and f at the starting input,  the change to the output caused by dx. To express that you want to find what this ratio approaches as dx approaches 0,  you write lim for limit, with dx arrow 0 below it. You'll almost never see terms with a lowercase  d like dx inside a limit expression like this. Instead, the standard is to use a different variable,  something like delta x, or commonly h for whatever reason. The way I like to think of it is that terms with this lowercase  d in the typical derivative expression have built into them this idea of a limit,  the idea that dx is supposed to eventually go to 0. In a sense, this left hand side here, df over dx,  the ratio we've been thinking about for the past few videos,  is just shorthand for what the right hand side here spells out in more detail,  writing out exactly what we mean by df, and writing out this limit process explicitly. This right hand side here is the formal definition of a derivative,  as you would commonly see it in any calculus textbook. And if you'll pardon me for a small rant here,  I want to emphasize that nothing about this right hand side references the paradoxical  idea of an infinitely small change. The point of limits is to avoid that. This value h is the exact same thing as the dx  I've been referencing throughout the series. It's a nudge to the input of f with some non-zero, finitely small size, like 0.001. It's just that we're analyzing what happens for arbitrarily small choices of h. In fact, the only reason people introduce a new variable name into this formal  definition, rather than just using dx, is to be extra clear that these changes  to the input are just ordinary numbers that have nothing to do with infinitesimals. There are others who like to interpret this dx as an infinitely small change,  whatever Or to just say that dx and df are nothing more than  symbols that we shouldn't take too seriously. But by now in the series, you know I'm not really a fan of either of those views. I think you can and should interpret dx as a concrete, finitely small nudge,  just so long as you remember to ask what happens when that thing approaches 0. For one thing, and I hope the past few videos have helped convince you of this,  that helps to build stronger intuition for where the rules of calculus actually come from. But it's not just some trick for building intuitions. Everything I've been saying about derivatives with this concrete,  finitely small nudge philosophy is just a translation of this formal definition we're  staring at right now. Long story short, the big fuss about limits is that they let us  avoid talking about infinitely small changes by instead asking what  happens as the size of some small change to our variable approaches 0. And this brings us to goal number 2, understanding  exactly what it means for one value to approach another. For example, consider the function 2 plus h cubed minus 2 cubed all divided by h. This happens to be the expression that pops out when you unravel  the definition of a derivative of x cubed evaluated at x equals 2,  but let's just think of it as any old function with an input h. Its graph is this nice continuous looking parabola,  which would make sense because it's a cubic term divided by a linear term. But actually, if you think about what's going on at h equals 0,  plugging that in you would get 0 divided by 0, which is not defined. So really, this graph has a hole at that point,  and you have to exaggerate to draw that hole, often with an empty circle like this. But keep in mind, the function is perfectly well  defined for inputs as close to 0 as you want. Wouldn't you agree that as h approaches 0, the corresponding output,  the height of this graph, approaches 12? It doesn't matter which side you come at it from. That limit of this ratio as h approaches 0 is equal to 12. But imagine you're a mathematician inventing calculus,  and someone skeptically asks you, well, what exactly do you mean by approach? That would be kind of an annoying question, I mean, come on,  we all know what it means for one value to get closer to another. But let's start thinking about ways you might be able to answer that person,  completely unambiguously. For a given range of inputs within some distance of 0,  excluding the forbidden point 0 itself, look at all of the corresponding outputs,  all possible heights of the graph above that range. As the range of input values closes in more and more tightly around 0,  that range of output values closes in more and more closely around 12. And importantly, the size of that range of output values can be made as small as you want. As a counter example, consider a function that looks like this,  which is also not defined at 0, but kind of jumps up at that point. When you approach h equals 0 from the right, the function approaches the value 2,  but as you come at it from the left, it approaches 1. Since there's not a single clear, unambiguous value that this function  approaches as h approaches 0, the limit is not defined at that point. One way to think of this is that when you look at any range of inputs around 0,  and consider the corresponding range of outputs, as you shrink that input range,  the corresponding outputs don't narrow in on any specific value. Instead, those outputs straddle a range that never shrinks smaller than 1,  even as you make that input range as tiny as you could imagine. This perspective of shrinking an input range around the limiting point,  and seeing whether or not you're restricted in how much that shrinks the output range,  leads to something called the epsilon-delta definition of limits. Now I should tell you, you could argue that this is  needlessly heavy duty for an introduction to calculus. Like I said, if you know what the word approach means,  you already know what a limit means, there's nothing new on the conceptual level here. But this is an interesting glimpse into the field of real analysis,  and gives you a taste for how mathematicians make the intuitive ideas of calculus more  airtight and rigorous. You've already seen the main idea here. When a limit exists, you can make this output range as small as you want,  but when the limit doesn't exist, that output range cannot get smaller than some  particular value, no matter how much you shrink the input range around the limiting input. Let's freeze that same idea a little more precisely,  maybe in the context of this example where the limiting value was 12. Think about any distance away from 12, where for some reason it's  common to use the Greek letter epsilon to denote that distance. The intent here is that this distance epsilon is as small as you want. What it means for the limit to exist is that you will always be able to find a  range of inputs around our limiting point, some distance delta around 0,  so that any input within delta of 0 corresponds to an output within a distance  epsilon of 12. The key point here is that that's true for any epsilon,  no matter how small, you'll always be able to find the corresponding delta. In contrast, when a limit does not exist, as in this example here,  you can find a sufficiently small epsilon, like 0.4,  so that no matter how small you make your range around 0, no matter how tiny delta is,  the corresponding range of outputs is just always too big. There is no limiting output where everything is within a distance epsilon of that output. So far, this is all pretty theory-heavy, don't you think? Limits being used to formally define the derivative,  and epsilons and deltas being used to rigorously define the limit itself. So let's finish things off here with a trick for actually computing limits. For instance, let's say for some reason you were studying  the function sin of pi times x divided by x squared minus 1. Maybe this was modeling some kind of dampened oscillation. When you plot a bunch of points to graph this, it looks pretty continuous. But there's a problematic value at x equals 1. When you plug that in, sin of pi is 0, and the denominator also comes out to 0,  so the function is actually not defined at that input,  and the graph should have a hole there. This also happens at x equals negative 1, but let's just  focus our attention on a single one of these holes for now. The graph certainly does seem to approach a distinct value at that point,  wouldn't you say? So you might ask, how exactly do you find what output this approaches as x approaches 1,  since you can't just plug in 1? Well, one way to approximate it would be to plug in  a number that's just really close to 1, like 1.00001. Doing that, you'd find that this should be a number around negative 1.57. But is there a way to know precisely what it is? Some systematic process to take an expression like this one,  that looks like 0 divided by 0 at some input, and ask what is its limit as x  approaches that input? After limits, so helpfully let us write the definition for derivatives,  derivatives can actually come back here and return the favor to help us evaluate limits. Let me show you what I mean. Here's what the graph of sin of pi times x looks like,  and here's what the graph of x squared minus 1 looks like. That's a lot to have up on the screen, but just  focus on what's happening around x equals 1. The point here is that sin of pi times x and x squared minus 1 are both 0 at that point,  they both cross the x axis. In the same spirit as plugging in a specific value near 1, like 1.00001,  let's zoom in on that point and consider what happens just a tiny nudge dx away from it. The value sin of pi times x is bumped down, and the value of that nudge,  which was caused by the nudge dx to the input, is what we might call d sin of pi x. And from our knowledge of derivatives, using the chain rule,  that should be around cosine of pi times x times pi times dx. Since the starting value was x equals 1, we plug in x equals 1 to that expression. In other words, the amount that this sin of pi times x graph changes is roughly  proportional to dx, with a proportionality constant equal to cosine of pi times pi. And cosine of pi, if we think back to our trig knowledge,  is exactly negative 1, so we can write this whole thing as negative pi times dx. Similarly, the value of the x squared minus 1 graph changes by some dx squared minus 1,  and taking the derivative, the size of that nudge should be 2x times dx. Again, we were starting at x equals 1, so we plug in x equals 1 to that expression,  meaning the size of that output nudge is about 2 times 1 times dx. What this means is that for values of x which are just a tiny nudge dx away from 1,  the ratio sin of pi x divided by x squared minus 1 is approximately  negative pi times dx divided by 2 times dx. The dx's cancel out, so what's left is negative pi over 2. And importantly, those approximations get more and more  accurate for smaller and smaller choices of dx, right? This ratio, negative pi over 2, actually tells  us the precise limiting value as x approaches 1. Remember, what that means is that the limiting height on  our original graph is evidently exactly negative pi over 2. What happened there is a little subtle, so I want to go through it again,  but this time a little more generally. Instead of these two specific functions, which are both equal to 0 at x equals 1,  think of any two functions, f of x and g of x, which are both 0 at some common value,  x equals a. The only constraint is that these have to be functions where you're  able to take a derivative of them at x equals a,  which means they each basically look like a line when you zoom in close  enough to that value. Even though you can't compute f divided by g at this trouble point,  since both of them equal 0, you can ask about this ratio for  values of x really close to a, the limit as x approaches a. It's helpful to think of those nearby inputs as just a tiny nudge, dx, away from a. The value of f at that nudged point is approximately its derivative,  df over dx, evaluated at a times dx. Likewise, the value of g at that nudged point is approximately the derivative of g,  evaluated at a times dx. Near that trouble point, the ratio between the outputs of f and g is actually about the  same as the derivative of f at a times dx, divided by the derivative of g at a times dx. Those dx's cancel out, so the ratio of f and g near a  is about the same as the ratio between their derivatives. Because each of those approximations gets more and more accurate for smaller and  smaller nudges, this ratio of derivatives gives the precise value for the limit. This is a really handy trick for computing a lot of limits. Whenever you come across some expression that seems to equal 0 divided by  0 when you plug in some particular input, just try taking the derivative  of the top and bottom expressions and plugging in that same trouble input. This clever trick is called L'Hopital's Rule. Interestingly, it was actually discovered by Johann Bernoulli,  but L'Hopital was this wealthy dude who essentially paid  Bernoulli for the rights to some of his mathematical discoveries. Academia is weird back then, but in a very literal way,  it pays to understand these tiny nudges. Right now, you might be remembering that the definition of a derivative  for a given function comes down to computing the limit of a certain  fraction that looks like 0 divided by 0, so you might think that  L'Hopital's Rule could give us a handy way to discover new derivative formulas. But that would actually be cheating, since presumably  you don't know what the derivative of the numerator is. When it comes to discovering derivative formulas,  something we've been doing a fair amount this series,  there is no systematic plug-and-chug method. But that's a good thing! Whenever creativity is needed to solve problems like these,  it's a good sign that you're doing something real,  something that might give you a powerful tool to solve future problems. And speaking of powerful tools, up next I'm going to be talking about what an integral  is, as well as the fundamental theorem of calculus,  another example of where limits can be used to give a clear meaning to a pretty delicate  idea that flirts with infinity. As you know, most support for this channel comes through Patreon,  and the primary perk for patrons is early access to future series like this one,  where the next one is going to be on probability. But for those of you who want a more tangible way to flag that  you're part of the community, there is also a small 3blue1brown store. Links on the screen and in the description. I'm still debating whether or not to make a preliminary batch of plushie pie creatures,  it depends on how many viewers seem interested in the store more generally,  but let me know in comments what other kinds of things you'd like to see in there.  Thanks for watching!

================================================================================
VIDEO ID: qb40J4N1fa4
TITLE: Implicit differentiation, what's going on here? | Chapter 6, Essence of calculus
URL: https://www.youtube.com/watch?v=qb40J4N1fa4
PUBLISHED: 2017-05-03T15:38:43Z
STATUS: SUCCESS
================================================================================
Let me share with you something I found particularly weird when I was a student first learning calculus. Let's say you have a circle with radius 5 centered at the origin of the xy plane. This is something defined with the equation x2 plus y2 equals 5 squared, that is, all the points on the circle are a distance 5 from the origin as encapsulated by the Pythagorean theorem, where the sum of the squares of the two legs on this triangle equals the square of the hypotenuse, 5 squared. And suppose you want to find the slope of a tangent line to the circle, maybe at the point xy equals 3,4. Now if you're savvy with geometry, you might already know that this tangent line is perpendicular to the radius touching it at that point. But let's say you don't already know that, or maybe you want a technique that generalizes to curves other than just circles. As with other problems about the slopes of tangent lines to curves, the key thought here is to zoom in close enough that the curve basically looks just like its own tangent line, and then ask about a tiny step along that curve. The y component of that little step is what you might call dy, and the x component is dx, so the slope we want is the rise over run, dy divided by dx. But unlike other tangent slope problems in calculus, this curve is not the graph of a function, so we can't just take a simple derivative, asking about the size of some tiny nudge to the output of a function caused by some tiny nudge to the input. x is not an input, and y is not an output, they're both just interdependent values related by some equation. This is what's called an implicit curve, it's just the set of all points x, y that satisfy some property written in terms of the two variables, x and y. The procedure for how you actually find dy, dx for curves like this is the thing I found very weird as a calculus student. You take the derivative of both sides like this, for x squared you write 2x times dx, and similarly y squared becomes 2y times dy, and then the derivative of that constant 5 squared on the right is just 0. Now you can see why this feels a little strange, right? What does it mean to take the derivative of an expression that has multiple variables in it, and why is it that we're tacking on dy and dx in this way? But if you just blindly move forward with what you get, you can rearrange this equation and find an expression for dy divided by dx, which in this case comes out to be negative x divided by y. So at the point with coordinates x, y equals 3, 4, that slope would be negative 3 divided by 4, evidently. This strange process is called implicit differentiation. Don't worry, I have an explanation for how you can interpret taking a derivative of an expression with two variables like this. But first I want to set aside this particular problem and show how it's connected to a different type of calculus problem, something called a related rates problem. Imagine a 5 meter long ladder held up against a wall where the top of the ladder starts 4 meters above the ground, which by the Pythagorean theorem means that the bottom is 3 meters away from the wall. And let's say it's slipping down in such a way that the top of the ladder is dropping at a rate of 1 meter per second. The question is, in that initial moment, what's the rate at which the bottom of the ladder is moving away from the wall? It's interesting, right? That distance from the bottom of the ladder to the wall is 100% determined by the distance from the top of the ladder to the floor. So we should have enough information to figure out how the rates of change for each of those values actually depend on each other, but it might not be entirely clear how exactly you relate those two. First things first, it's always nice to give names to the quantities that we care about, so let's label that distance from the top of the ladder to the ground y of t, written as a function of time because it's changing. Likewise, label the distance between the bottom of the ladder and the wall x of t. The key equation that relates these terms is the Pythagorean theorem, x of t squared plus y of t squared equals 5 squared. What makes that a powerful equation to use is that it's true at all points of time. One way that you could solve this would be to isolate x of t, and then figure out what y of t has to be based on that 1 m per second drop rate, and you could take the derivative of the resulting function dx dt, the rate at which x is changing with respect to time. That's fine, it involves a couple layers of using the chain rule, and it'll definitely work for you, but I want to show a different way that you can think about the same problem. This left hand side of the equation is a function of time, right? It just so happens to equal a constant, meaning the value evidently doesn't change while time passes, but it's still written as an expression dependent on time, which means we can manipulate it like any other function that has t as an input. In particular, we can take a derivative of this left hand side, which is a way of saying if I let a little bit of time pass, some small dt, which causes y to slightly decrease and x to slightly increase, how much does this expression change? On the one hand, we know that the derivative should be 0, since the expression is a constant, and constants don't care about your tiny nudges in time, they just remain unchanged. But on the other hand, what do you get when you compute this derivative? Well, the derivative of x of t squared is 2 times x of t times the derivative of x. That's the chain rule that I talked about last video. 2x dx represents the size of a change to x squared caused by some change to x, and then we're dividing out by dt. Likewise, the rate at which y of t squared is changing is 2 times y of t times the derivative of y. Now evidently, this whole expression must be 0, and that's an equivalent way of saying that x squared plus y squared must not change while the ladder moves. At the very start, time t equals 0, the height, y of t, is 4 meters, and that distance x of t is 3 meters. And since the top of the ladder is dropping at a rate of 1 meter per second, that derivative, dy dt, is negative 1 meters per second. Now, this gives us enough information to isolate the derivative, dx dt, and when you work it out, it comes out to be 4 thirds meters per second. The reason I bring up this ladder problem is that I want you to compare it to the problem of finding the slope of a tangent line to the circle. In both cases, we had the equation x squared plus y squared equals 5 squared, and in both cases we ended up taking the derivative of each side of this expression. But for the ladder question, these expressions were functions of time, so taking the derivative has a clear meaning, it's the rate at which the expression changes as time changes. But what makes the circle situation strange is that rather than saying that a small amount of time dt has passed, which causes x and y to change, the derivative just has these tiny nudges dx and dy just floating free, not tied to some other common variable, like time. Let me show you a nice way to think about this. Let's give this expression x squared plus y squared a name, maybe s. s is essentially a function of two variables. It takes every point xy on the plane and associates it with a number. For points on the circle, that number happens to be 25. If you stepped off the circle away from the center, that value would be bigger. For other points xy closer to the origin, that value would be smaller. Now what it means to take a derivative of this expression, a derivative of s, is to consider a tiny change to both of these variables, some tiny change dx to x, and some tiny change dy to y, and not necessarily one that keeps you on the circle, by the way, it's just any tiny step in any direction of the xy plane. From there you ask how much does the value of s change? That difference, the difference in the value of s before the nudge and after the nudge, is what I'm writing as ds. For example, in this picture we're starting off at a point where x equals 3 and where y equals 4, and let's just say that the step I drew has dx at negative 0.02 and dy at negative 0.01. Then the decrease in s, the amount that x squared plus y squared changes over that step, would be about 2 times 3 times negative 0.02 plus 2 times 4 times negative 0.01. That's what this derivative expression, 2x dx plus 2y dy, actually means. It's a recipe for telling you how much the value x squared plus y squared changes as determined by the point xy where you start and the tiny step dx dy that you take. And As with all things derivative, this is only an approximation, but it's one that gets truer and truer for smaller and smaller choices of dx and dy. The key point here is that when you restrict yourself to steps along the circle, you're essentially saying you want to ensure that this value of s doesn't change. It starts at a value of 25 and you want to keep it at a value of 25. That is, ds should be 0. So setting the expression 2x dx plus 2y dy equal to 0 is the condition under which one of these tiny steps actually stays on the circle. Again, this is only an approximation. Speaking more precisely, that condition is what keeps you on the tangent line of the circle, not the circle itself. But for tiny enough steps, those are essentially the same thing. Of course, there's nothing special about the expression x squared plus y squared equals 5 squared. It's always nice to think through more examples, so let's consider this expression sin of x times y2 equals x. This corresponds to a whole bunch of u-shaped curves on the plane. And those curves, remember, represent all of the points xy where the value of sine of x times y squared happens to equal the value of x. Now imagine taking some tiny step with components dx and dy, and not necessarily one that keeps you on the curve. Taking the derivative of each side of this equation will tell us how much the value of that side changes during the step. On the left side, the product rule that we talked through last video tells us that this should be left d right plus right d left. That is sine of x times the change to y squared, which is 2y times dy, plus y squared times the change to sine of x, which is cosine of x times dx. The right side is simply x, so the size of a change to that value is exactly dx, right? Now setting these two sides equal to each other is a way of saying whatever your tiny step with coordinates dx and dy is, if it's going to keep us on the curve, the values of both the left hand side and the right hand side must change by the same amount. That's the only way this top equation can remain true. From there, depending on what problem you're trying to solve, you have something to work with algebraically, and maybe the most common goal is to try to figure out what dy divided by dx is. As a final example here, I want to show you how you can use this technique of implicit differentiation to figure out new derivative formulas. I've mentioned that the derivative of e to the x is itself, but what about the derivative of its inverse function, the natural log of x? Well the graph of the natural log of x can be thought of as an implicit curve. It's all of the points xy on the plane where y happens to equal ln of x. It just happens to be the case that the x's and y's of this equation aren't as intermingled as they were in our other examples. The slope of this graph, dy divided by dx, should be the derivative of ln of x, right? Well to find that, first rearrange this equation y equals ln of x to be e to the y equals x. This is exactly what the natural log of x means, it's saying e to the what equals x. Since we know the derivative of e to the y, we can take the derivative of both sides here, effectively asking how a tiny step with components dx and dy changes the value of each one of these sides. To ensure that a step stays on the curve, the change to the left side of the equation, which is e to the y times dy, must equal the change to the right side, which in this case is just dx. Rearranging, that means dy divided by dx, the slope of our graph, equals 1 divided by e to the y. When we're on the curve, e to the y is by definition the same thing as x, so evidently this slope is 1 divided by x. And of course, an expression for the slope of a graph of a function written in terms of x like this is the derivative of that function, so evidently the derivative of ln of x is 1 divided by x. By the way, all of this is a little sneak peek into multivariable calculus, where you consider functions that have multiple inputs and how they change as you tweak those multiple inputs. The key, as always, is to have a clear image in your head of what tiny nudges are at play, and how exactly they depend on each other. Next up, I'm going to be talking about limits, and how they're used to formalize the idea of a derivative. Thank you.

================================================================================
VIDEO ID: m2MIpDrF7Es
TITLE: What's so special about Euler's number e? | Chapter 5, Essence of calculus
URL: https://www.youtube.com/watch?v=m2MIpDrF7Es
PUBLISHED: 2017-05-02T15:09:46Z
STATUS: SUCCESS
================================================================================
I've introduced a few derivative formulas, but a  really important one that I left out was exponentials. So here I want to talk about the derivatives of functions like 2 to the x, 7 to the x,  and also to show why e to the x is arguably the most important of the exponentials. First of all, to get an intuition, let's just focus on the function 2 to the x. Let's think of that input as a time, t, maybe in days, and the output,  2 to the t, as a population size, perhaps of a particularly  fertile band of pie creatures which doubles every single day. And actually, instead of population size, which grows in discrete little jumps with each  new baby pie creature, maybe let's think of 2 to the t as the total mass of the  population. I think that better reflects the continuity of this function, don't you? So for example, at time t equals 0, the total mass is 2 to the 0 equals 1,  for the mass of one creature. At t equals 1 day, the population has grown to 2 to the 1 equals 2 creature masses. At day t equals 2, it's t squared, or 4, and in general it just keeps doubling every day. For the derivative, we want dm dt, the rate at which this population mass is growing,  thought of as a tiny change in the mass, divided by a tiny change in time. Let's start by thinking of the rate of change over a full day,  say between day 3 and day 4. In this case, it grows from 8 to 16, so that's 8  new creature masses added over the course of one day. And notice, that rate of growth equals the population size at the start of the day. Between day 4 and day 5, it grows from 16 to 32,  so that's a rate of 16 new creature masses per day,  which again equals the population size at the start of the day. And in general, this rate of growth over a full day  equals the population size at the start of that day. So it might be tempting to say that this means the derivative  of 2 to the t equals itself, that the rate of change of this  function at a given time t is equal to the value of that function. And this is definitely in the right direction, but it's not quite correct. What we're doing here is making comparisons over a full day,  considering the difference between 2 to the t plus 1 and 2 to the t. But for the derivative, we need to ask what happens for smaller and smaller changes. What's the growth over the course of a tenth of a day,  a hundredth of a day, one one billionth of a day? This is why I had us think of the function as representing population mass,  since it makes sense to ask about a tiny change in mass over a tiny fraction of a day,  but it doesn't make as much sense to ask about the tiny change in a discrete population  size per second. More abstractly, for a tiny change in time, dt,  we want to understand the difference between 2 to the t plus dt and 2 to the t,  all divided by dt. The change in the function per unit time, but now we're looking very narrowly  around a given point in time, rather than over the course of a full day. And here's the thing, I would love if there was some very clear geometric picture  that made everything that's about to follow just pop out,  some diagram where you could point to one value and say, see, that part,  that is the derivative of 2 to the t. And if you know of one, please let me know. And while the goal here, as with the rest of the series,  is to maintain a playful spirit of discovery, the type of play that  follows will have more to do with finding numerical patterns rather than visual ones. So start by just taking a very close look at this term, 2 to the t plus dt. A core property of exponentials is that you can  break this up as 2 to the t times 2 to the dt. That really is the most important property of exponents. If you add two values in that exponent, you can  break up the output as a product of some kind. This is what lets you relate additive ideas, things like tiny steps in time,  to multiplicative ideas, things like rates and ratios. I mean, just look at what happens here. After that move, we can factor out the term 2 to the t,  which is now just multiplied by 2 to the dt minus 1, all divided by dt. And remember, the derivative of 2 to the t is whatever  this whole expression approaches as dt approaches 0. And at first glance, that might seem like an unimportant manipulation. But a tremendously important fact is that this term on the right,  where all of the dt stuff lives, is completely separate from the t term itself. It doesn't depend on the actual time where we started. You can go off to a calculator and plug in very small values for dt here,  for example, maybe typing in 2 to the 0.001 minus 1 divided by 0.001. What you'll find is that for smaller and smaller choices of dt,  this value approaches a very specific number, around 0.6931. Don't worry if that number seems mysterious, the  central point is that this is some kind of constant. Unlike derivatives of other functions, all of the stuff  that depends on dt is separate from the value of t itself. So the derivative of 2 to the t is just itself, but multiplied by some constant. And that should make sense, because earlier it felt like the derivative for 2 to the t  should be itself, at least when we were looking at changes over the course of a full day. And evidently, the rate of change for this function over much smaller  timescales is not quite equal to itself, but it's proportional to itself,  with this very peculiar proportionality constant of 0.6931. And there's not too much special about the number 2 here. If instead we had dealt with the function 3 to the t,  the exponential property would also have led us to the conclusion that the derivative  of 3 to the t is proportional to itself, but this time it would have had a  proportionality constant of 1.0986. And for other bases to your exponent, you can have fun trying to see what the  various proportionality constants are, maybe seeing if you can find a pattern in them. For example, if you plug in 8 to the power of a very tiny number,  minus 1, and divide by that same tiny number, you'd find that  the relevant proportionality constant is around 2.079. And maybe, just maybe, you would notice that this number happens  to be exactly 3 times the constant associated with the base for 2. So these numbers certainly aren't random, there is some kind of pattern, but what is it? What does 2 have to do with the number 0.6931,  and what does 8 have to do with the number 2.079? Well, a second question that is ultimately going to explain these mystery constants is  whether there's some base where that proportionality constant is 1,  where the derivative of a to the power t is not just proportional to itself,  but actually equal to itself. And there is! It's the special constant e around 2.71828. In fact, it's not just that the number e happens to show up here,  this is in a sense what defines the number e. If you ask why does e of all numbers have this property,  it's a little like asking why does pi of all numbers happen  to be the ratio of the circumference of a circle to its diameter. This is at its heart what defines this value. All exponential functions are proportional to their own derivative,  but e alone is the special number so that proportionality constant is 1,  meaning e to the t actually equals its own derivative. One way to think of that is that if you look at the graph of e to the t,  it has the peculiar property that the slope of a tangent line to any point  on this graph equals the height of that point above the horizontal axis. The existence of a function like this answers the question of the mystery constants,  and it's because it gives a different way to think about functions  that are proportional to their own derivative. The key is to use the chain rule. For example, what is the derivative of e to the 3t? Well, you take the derivative of the outermost function,  which due to this special nature of e is just itself,  and multiply by the derivative of that inner function 3t, which is the constant 3. Or rather than just applying a rule blindly, you could take this moment  to practice the intuition for the chain rule that I talked through last video,  thinking about how a slight nudge to t changes the value of 3t,  and how that intermediate change nudges the final value of e to the 3t. Either way, the point is e to the power of some constant  times t is equal to that same constant times itself. And from here, the question of those mystery constants  really just comes down to a certain algebraic manipulation. The number 2 can also be written as e to the natural log of 2. There's nothing fancy here, this is just the definition of the natural log,  it asks the question e to the what equals 2. So the function 2 to the t is the same as the function  e to the power of the natural log of 2 times t. And from what we just saw, combining the fact that e to the t is its own  derivative with the chain rule, the derivative of this function is proportional  to itself, with a proportionality constant equal to the natural log of 2. And indeed, if you go plug in the natural log of 2 to a calculator,  you'll find that it's 0.6931, the mystery constant we ran into earlier. And the same goes for all the other bases. The mystery proportionality constant that pops up when taking derivatives is just  the natural log of the base. The answer to the question e to the what equals that base. In fact, throughout applications of calculus, you rarely  see exponentials written as some base to a power t. Instead, you almost always write the exponential  as e to the power of some constant times t. It's all equivalent, I mean any function like 2 to the t or  3 to the t can also be written as e to some constant times t. At the risk of staying overfocused on the symbols here,  I want to emphasize that there are many ways to write down any particular  exponential function. And when you see something written as e to some constant times t,  that's a choice we make to write it that way, and the number e is not fundamental to  that function itself. What is special about writing exponentials in terms of e like this is  that it gives that constant in the exponent a nice readable meaning. Here, let me show you what I mean. All sorts of natural phenomena involve some rate of  change that's proportional to the thing that's changing. For example, the rate of growth of a population actually does  tend to be proportional to the size of the population itself,  assuming there isn't some limited resource slowing things down. And if you put a cup of hot water in a cool room,  the rate at which the water cools is proportional to the difference in temperature  between the room and the water, or said a little differently,  the rate at which that difference changes is proportional to itself. If you invest your money, the rate at which it grows is  proportional to the amount of money there at any time. In all of these cases, where some variable's rate of change is proportional to itself,  the function describing that variable over time is going to  look like some kind of exponential. And even though there are lots of ways to write any exponential function,  it's very natural to choose to express these functions as e to the power  of some constant times t, since that constant carries a very natural meaning. It's the same as the proportionality constant between  the size of the changing variable and the rate of change. And as always, I want to thank those who have made this series possible. Thank you.

================================================================================
VIDEO ID: YG15m2VwSjA
TITLE: Visualizing the chain rule and product rule | Chapter 4, Essence of calculus
URL: https://www.youtube.com/watch?v=YG15m2VwSjA
PUBLISHED: 2017-05-01T15:19:28Z
STATUS: SUCCESS
================================================================================
In the last videos I talked about the derivatives of simple functions,  and the goal was to have a clear picture or intuition to hold in  your mind that actually explains where these formulas come from. But most of the functions you deal with in modeling the world involve mixing,  combining, or tweaking these simple functions in some other way,  so our next step is to understand how you take derivatives of more complicated  combinations. Again, I don't want these to be something to memorize,  I want you to have a clear picture in mind for where each one comes from. Now, this really boils down into three basic ways to combine functions. You can add them together, you can multiply them,  and you can throw one inside the other, known as composing them. Sure, you could say subtracting them, but really that's just  multiplying the second by negative one and adding them together. Likewise, dividing functions doesn't really add anything,  because that's the same as plugging one inside the function, one over x,  and then multiplying the two together. So really, most functions you come across just involve layering  together these three different types of combinations,  though there's not really a bound on how monstrous things can become. But as long as you know how derivatives play with just those three combination types,  you'll always be able to take it step by step and peel through  the layers for any kind of monstrous expression. So the question is, if you know the derivative of two functions,  what is the derivative of their sum, of their product,  and of the function composition between them? The sum rule is easiest, if somewhat tongue-twisting to say out loud. The derivative of a sum of two functions is the sum of their derivatives. But it's worth warming up with this example by really thinking through  what it means to take a derivative of a sum of two functions,  since the derivative patterns for products and function composition won't  be so straightforward, and they're going to require this kind of deeper thinking. For example, let's think about this function f of x equals sine of x plus x squared. It's a function where, for every input, you add together  the values of sine of x and x squared at that point. For example, let's say at x equals 0.5, the height of the sine  graph is given by this vertical bar, and the height of the x  squared parabola is given by this slightly smaller vertical bar. And their sum is the length you get by just stacking them together. For the derivative, you want to ask what happens as you nudge that input slightly,  maybe increasing it up to 0.5 plus dx. The difference in the value of f between those two places is what we call df. And when you picture it like this, I think you'll agree that the total  change in the height is whatever the change to the sine graph is,  what we might call d sine of x, plus whatever the change to x squared is, dx squared. We know that the derivative of sine is cosine, and remember what that means. It means that this little change, d sine of x, is about cosine of x times dx. It's proportional to the size of our initial nudge dx,  and the proportionality constant equals cosine of whatever input we started at. Likewise, because the derivative of x squared is 2x,  the change in the height of the x squared graph is 2x times whatever dx was. So rearranging df divided by dx, the ratio of the tiny change to  the sum function to the tiny change in x that caused it,  is indeed cosine of x plus 2x, the sum of the derivatives of its parts. But like I said, things are a bit different for products,  and let's think through why in terms of tiny nudges again. In this case, I don't think graphs are our best bet for visualizing things. Pretty commonly in math, at a lot of levels of math really,  if you're dealing with a product of two things,  it helps to understand it as some kind of area. In this case, maybe you try to configure some mental setup  of a box where the side lengths are sine of x and x squared. But what would that mean? Well, since these are functions, you might think of those sides as adjustable,  dependent on the value of x, which maybe you think of as this  number that you can just freely adjust up and down. So getting a feel for what this means, focus on  that top side who changes as the function sine of x. As you change this value of x up from 0, it increases up to  a length of 1 as sine of x moves up towards its peak,  and after that it starts to decrease as sine of x comes down from 1. And in the same way, that height there is always changing as x squared. So f of x, defined as the product of these two functions, is the area of this box. And for the derivative, let's think about how  a tiny change to x by dx influences that area. What is that resulting change in area df? Well, the nudge dx caused that width to change by some small d sine of x,  and it caused that height to change by some dx squared. And this gives us three little snippets of new area,  a thin rectangle on the bottom whose area is its width, sine of x,  times its thin height, dx squared. And there's this thin rectangle on the right, whose area is its height,  x squared, times its thin width, d sine of x. And there's also this little bit in the corner, but we can ignore that. Its area is ultimately proportional to dx squared,  and as we've seen before, that becomes negligible as dx goes to zero. I mean, this whole setup is very similar to what I showed last video,  with the x squared diagram. And just like then, keep in mind that I'm using somewhat beefy  changes here to draw things, just so we can actually see them. But in principle, dx is something very very small,  and that means that dx squared and d sine of x are also very very small. So, applying what we know about the derivative of sine and of x squared,  that tiny change, dx squared, is going to be about 2x times dx. And that tiny change, d sine of x, well that's going to be about cosine of x times dx. As usual, we divide out by that dx to see that the ratio we want, df divided by dx,  is sine of x times the derivative of x squared,  plus x squared times the derivative of sine. And nothing we've done here is specific to sine or to x squared. This same line of reasoning would work for any two functions, g and h. And sometimes people like to remember this pattern with  a certain mnemonic that you kind of sing in your head. Left d right, right d left. In this example, where we have sine of x times x squared, left d right,  means you take that left function, sine of x, times the derivative of the right,  in this case 2x. Then you add on right d left, that right function,  x squared, times the derivative of the left one, cosine of x. Now out of context, presented as a rule to remember,  I think this would feel pretty strange, don't you? But when you actually think of this adjustable box,  you can see what each of those terms represents. Left d right is the area of that little bottom rectangle,  and right d left is the area of that rectangle on the side. By the way, I should mention that if you multiply by a constant,  say 2 times sine of x, things end up a lot simpler. The derivative is just the same as the constant multiplied by  the derivative of the function, in this case 2 times cosine of x. I'll leave it to you to pause and ponder and verify that makes sense. Aside from addition and multiplication, the other common way to combine functions,  and believe me, this one comes up all the time,  is to shove one inside the other, function composition. For example, maybe we take the function x squared and shove it  inside sine of x to get this new function, sine of x squared. What do you think the derivative of that new function is? To think this one through, I'll choose yet another way to visualize things,  just to emphasize that in creative math, we've got lots of options. I'll put up three different number lines, the top one is going to hold the value of x,  the second one is going to hold the x squared,  and the third line is going to hold the value of sine of x squared. That is, the function x squared gets you from line 1 to line 2,  and the function sine gets you from line 2 to line 3. As I shift around this value of x, maybe moving it up to the value 3,  that second value stays pegged to whatever x squared is, in this case moving up to 9. That bottom value, being sine of x squared, is  going to go to whatever sine of 9 happens to be. So, for the derivative, let's again start by nudging that x value by some little dx. I always think that it's helpful to think of x as starting  at some actual concrete number, maybe 1.5 in this case. The resulting nudge to that second value, the change in x squared caused by such a dx,  is dx squared. We could expand this like we have before, as 2x times dx,  which for our specific input would be 2 times 1.5 times dx,  but it helps to keep things written as dx squared, at least for now. In fact, I'm going to go one step further, give a new name to this x squared,  maybe h, so instead of writing dx squared for this nudge, we write dh. This makes it easier to think about that third value, which is now pegged at sine of h. Its change is d sine of h, the tiny change caused by the nudge dh. By the way, the fact that it's moving to the left while the dh bump is going to the right  just means that this change, d sine of h, is going to be some kind of negative number. Once again, we can use our knowledge of the derivative of the sine. This d sine of h is going to be about cosine of h times dh. That's what it means for the derivative of sine to be cosine. Unfolding things, we can replace that h with x squared again,  so we know that the bottom nudge will be a size of cosine of x squared times dx squared. Let's unfold things even further. That intermediate nudge dx squared is going to be about 2x times dx. It's always a good habit to remind yourself of  what an expression like this actually means. In this case, where we started at x equals 1.5 up top,  this whole expression is telling us that the size of the nudge on that third  line is going to be about cosine of 1.5 squared times 2 times 1.5 times whatever  the size of dx was. It's proportional to the size of dx, and this  derivative is giving us that proportionality constant. Notice what we came out with here. We have the derivative of the outside function,  and it's still taking in the unaltered inside function,  and then multiplying it by the derivative of that inside function. Again, there's nothing special about sine of x or x squared. If you have any two functions, g of x and h of x,  the derivative of their composition, g of h of x,  is going to be the derivative of g evaluated on h, multiplied by the derivative of h. This pattern right here is what we usually call the chain rule. Notice for the derivative of g, I'm writing it as dg dh instead of dg dx. On the symbolic level, this is a reminder that the thing you plug  into that derivative is still going to be that intermediary function h. But more than that, it's an important reflection of what  this derivative of the outer function actually represents. Remember, in our three line setup, when we took the derivative of the sine on  that bottom, we expanded the size of that nudge, d sine, as cosine of h times dh. This was because we didn't immediately know how  the size of that bottom nudge depended on x. That's kind of the whole thing we were trying to figure out. But we could take the derivative with respect to that intermediate variable, h. That is, figure out how to express the size of that nudge on the third  line as some multiple of dh, the size of the nudge on the second line. It was only after that that we unfolded further by figuring out what dh was. In this chain rule expression, we're saying, look at the ratio between a tiny change in  g, the final output, to a tiny change in h that caused it,  h being the value we plug into g. Then multiply that by the tiny change in h, divided  by the tiny change in x that caused it. So notice, those dh's cancel out, and they give us a ratio  between the change in that final output and the change to the input that,  through a certain chain of events, brought it about. And that cancellation of dh is not just a notational trick. That is a genuine reflection of what's going on with the  tiny nudges that underpin everything we do with derivatives. So those are the three basic tools to have in your belt to handle  derivatives of functions that combine a lot of smaller things. You've got the sum rule, the product rule, and the chain rule. And I'll be honest with you, there is a big difference between knowing  what the chain rule is and what the product rule is,  and actually being fluent with applying them in even the most hairy of situations. Watching videos, any videos, about the mechanics of calculus is  never going to substitute for practicing those mechanics yourself,  and building up the muscles to do these computations yourself. I really wish I could offer to do that for you,  but I'm afraid the ball is in your court, my friend, to seek out the practice. What I can offer, and what I hope I have offered,  is to show you where these rules actually come from. To show that they're not just something to be memorized and hammered away,  but they're natural patterns, things that you too could have discovered  just by patiently thinking through what a derivative actually means.

================================================================================
VIDEO ID: S0_qX4VJhMQ
TITLE: Derivative formulas through geometry | Chapter 3, Essence of calculus
URL: https://www.youtube.com/watch?v=S0_qX4VJhMQ
PUBLISHED: 2017-04-30T15:24:09Z
STATUS: SUCCESS
================================================================================
Now that we've seen what a derivative means and what it has to do with rates of change,  our next step is to learn how to actually compute these guys. As in, if I give you some kind of function with an explicit formula,  you'd want to be able to find what the formula for its derivative is. Maybe it's obvious, but I think it's worth stating explicitly why this  is an important thing to be able to do, why much of a calculus student's  time ends up going towards grappling with derivatives of abstract  functions rather than thinking about concrete rate of change problems. It's because a lot of real-world phenomena, the sort of things that  we want to use calculus to analyze, are modeled using polynomials,  trigonometric functions, exponentials, and other pure functions like that. So if you build up some fluency with the ideas of rates of change for those kinds of  pure abstract functions, it gives you a language to more readily talk about the rates  at which things change in concrete situations that you might be using calculus to model. But it is way too easy for this process to feel like just memorizing a list of rules,  and if that happens, if you get that feeling, it's also easy to lose sight of the  fact that derivatives are fundamentally about just looking at tiny changes to some  quantity and how that relates to a resulting tiny change in another quantity. So in this video and in the next one, my aim is to show you how you can think  about a few of these rules intuitively and geometrically,  and I really want to encourage you to never forget that tiny nudges are at the  heart of derivatives. Let's start with a simple function like f of x equals x squared. What if I asked you its derivative? That is, if you were to look at some value x, like x equals 2,  and compare it to a value slightly bigger, just dx bigger,  what's the corresponding change in the value of the function? dF. And in particular, what's dF divided by dx, the rate  at which this function is changing per unit change in x. As a first step for intuition, we know that you can think of this ratio  dF dx as the slope of a tangent line to the graph of x squared,  and from that you can see that the slope generally increases as x increases. At zero, the tangent line is flat, and the slope is zero. At x equals 1, it's something a bit steeper. At x equals 2, it's steeper still. But looking at graphs isn't generally the best way  to understand the precise formula for a derivative. For that, it's best to take a more literal look at what x squared actually means,  and in this case let's go ahead and picture a square whose side length is x. If you increase x by some tiny nudge, some little dx,  what's the resulting change in the area of that square? That slight change in area is what dF means in this context. It's the tiny increase to the value of f of x equals x squared,  caused by increasing x by that tiny nudge dx. Now you can see that there's three new bits of area in this diagram,  two thin rectangles and a minuscule square. The two thin rectangles each have side lengths of x and dx,  so they account for 2 times x times dx units of new area. For example, let's say x was 3 and dx was 0.01,  then that new area from these two thin rectangles would be 2 times 3 times 0.01,  which is 0.06, about 6 times the size of dx. That little square there has an area of dx squared,  but you should think of that as being really tiny, negligibly tiny. For example, if dx was 0.01, that would be only 0.0001,  and keep in mind I'm drawing dx with a fair bit of width here just so we  can actually see it, but always remember in principle,  dx should be thought of as a truly tiny amount, and for those truly tiny amounts,  a good rule of thumb is that you can ignore anything that includes a dx  raised to a power greater than 1. That is, a tiny change squared is a negligible change. What this leaves us with is that dF is just some multiple of dx, and that multiple 2x,  which you could also write as dF divided by dx, is the derivative of x squared. For example, if you were starting at x equals 3, then as you slightly increase x,  the rate of change in the area per unit change in length added, dx squared over dx,  would be 2 times 3, or 6, and if instead you were starting at x equals 5,  then the rate of change would be 10 units of area per unit change in x. Let's go ahead and try a different simple function, f of x equals x cubed. This is going to be the geometric view of the stuff  that I went through algebraically in the last video. What's nice here is that we can think of x cubed as the volume of an actual  cube whose side lengths are x, and when you increase x by a tiny nudge,  a tiny dx, the resulting increase in volume is what I have here in yellow. That represents all the volume in a cube with side lengths x plus dx  that's not already in the original cube, the one with side length x. It's nice to think of this new volume as broken up into multiple components,  but almost all of it comes from these three square faces,  or said a little more precisely, as dx approaches 0,  those three squares comprise a portion closer and closer to 100% of  that new yellow volume. Each of those thin squares has a volume of x squared times dx,  the area of the face times that little thickness dx. So in total this gives us 3x squared dx of volume change. And to be sure there are other slivers of volume here along the edges  and that tiny one in the corner, but all of that volume is going to be  proportional to dx squared, or dx cubed, so we can safely ignore them. Again this is ultimately because they're going to be divided by dx,  and if there's still any dx remaining then those terms aren't  going to survive the process of letting dx approach 0. What this means is that the derivative of x cubed,  the rate at which x cubed changes per unit change of x, is 3 times x squared. What that means in terms of graphical intuition is that the slope of  the graph of x cubed at every single point x is exactly 3x squared. And reasoning about that slope, it should make sense that this derivative is high on the  left and then 0 at the origin and then high again as you move to the right,  but just thinking in terms of the graph would never have landed us on the precise  quantity 3x squared. For that we had to take a much more direct look at what x cubed actually means. Now in practice you wouldn't necessarily think of the square every  time you're taking the derivative of x squared,  nor would you necessarily think of this cube whenever you're taking  the derivative of x cubed. Both of them fall under a pretty recognizable pattern for polynomial terms. The derivative of x to the fourth turns out to be 4x cubed,  the derivative of x to the fifth is 5x to the fourth, and so on. Abstractly you'd write this as the derivative of x to  the n for any power n is n times x to the n minus 1. This right here is what's known in the business as the power rule. In practice we all quickly just get jaded and think about this symbolically as  the exponent hopping down in front, leaving behind one less than itself,  rarely pausing to think about the geometric delights that underlie these derivatives. That's the kind of thing that happens when these tend  to fall in the middle of much longer computations. But rather than tracking it all off to symbolic patterns,  let's just take a moment and think about why this works for powers beyond just 2 and 3. When you nudge that input x, increasing it slightly to x plus dx,  working out the exact value of that nudged output would involve  multiplying together these n separate x plus dx terms. The full expansion would be really complicated,  but part of the point of derivatives is that most of that complication can be ignored. The first term in your expansion is x to the n. This is analogous to the area of the original square,  or the volume of the original cube from our previous examples. For the next terms in the expansion you can choose mostly x's with a single dx. Since there are n different parentheticals from which you could have chosen  that single dx, this gives us n separate terms,  all of which include n minus 1 x's times a dx,  giving a value of x to the power n minus 1 times dx. This is analogous to how the majority of the new area in the square came from those  two bars, each with area x times dx, or how the bulk of the new volume in the cube  came from those three thin squares, each of which had a volume of x squared times dx. There will be many other terms of this expansion,  but all of them are just going to be some multiple of dx squared,  so we can safely ignore them, and what that means is that all but a  negligible portion of the increase in the output comes from n copies of  this x to the n minus 1 times dx. That's what it means for the derivative of x to the n to be n times x to the n minus 1. And even though, like I said in practice, you'll find yourself performing this  derivative quickly and symbolically, imagining the exponent hopping down to the front,  every now and then it's nice to just step back and remember why these rules work. Not just because it's pretty, and not just because it helps remind us that math  actually makes sense and isn't just a pile of formulas to memorize,  but because it flexes that very important muscle of thinking about derivatives in  terms of tiny nudges. As another example, think of the function f of x equals 1 divided by x. Now on the hand you could just blindly try applying the power rule,  since 1 divided by x is the same as writing x to the negative 1. That would involve letting the negative 1 hop down in front,  leaving behind 1 less than itself, which is negative 2. But let's have some fun and see if we can reason about this geometrically,  rather than just plugging it through some formula. The value 1 over x is asking what number multiplied by x equals 1. So here's how I'd like to visualize it. Imagine a little rectangular puddle of water sitting in two dimensions whose area is 1. And let's say that its width is x, which means that the height has to be 1 over x,  since the total area of it is 1. So if x was stretched out to 2, then that height is forced down to 1 half. And if you increased x up to 3, then the other side has to be squished down to 1 third. This is a nice way to think about the graph of 1 over x, by the way. If you think of this width x of the puddle as being in the xy-plane,  then that corresponding output 1 divided by x, the height of the graph above that point,  is whatever the height of your puddle has to be to maintain an area of 1. So with this visual in mind, for the derivative,  imagine nudging up that value of x by some tiny amount, some tiny dx. How must the height of this rectangle change so  that the area of the puddle remains constant at 1? That is, increasing the width by dx adds some new area to the right here. So the puddle has to decrease in height by some d 1 over x,  so that the area lost off of that top cancels out the area gained. You should think of that d 1 over x as being a negative amount,  by the way, since it's decreasing the height of the rectangle. And you know what? I'm going to leave the last few steps here for you,  for you to pause and ponder and work out an ultimate expression. And once you reason out what d of 1 over x divided by dx should be,  I want you to compare it to what you would have gotten if you had just  blindly applied the power rule, purely symbolically, to x to the negative 1. And while I'm encouraging you to pause and ponder,  here's another fun challenge if you're feeling up to it. See if you can reason through what the derivative of the square root of x should be. To finish things off, I want to tackle one more type of function,  trigonometric functions, and in particular let's focus on the sine function. So for this section I'm going to assume that you're already  familiar with how to think about trig functions using the unit circle,  the circle with a radius 1 centered at the origin. For a given value of theta, like say 0.8, you imagine yourself  walking around the circle starting from the rightmost point  until you've traversed that distance of 0.8 in arc length. This is the same thing as saying that the angle right here is exactly theta radians,  since the circle has a radius of 1. Then what sine of theta means is the height of that point above the x-axis,  and as your theta value increases and you walk around the circle  your height bobs up and down between negative 1 and 1. So when you graph sine of theta versus theta you get this wave pattern,  the quintessential wave pattern. And just from looking at this graph we can start to  get a feel for the shape of the derivative of the sine. The slope at 0 is something positive since sine of theta is increasing there,  and as we move to the right and sine of theta approaches its peak that slope goes down  to 0. Then the slope is negative for a little while,  while the sine is decreasing before coming back up to 0 as the sine graph levels out. And as you continue thinking this through and drawing it out,  if you're familiar with the graph of trig functions you might guess that this  derivative graph should be exactly cosine of theta,  since all the peaks and valleys line up perfectly with where the peaks and  valleys for the cosine function should be. And spoiler alert, the derivative is in fact the cosine of theta,  but aren't you a little curious about why it's precisely cosine of theta? I mean you could have all sorts of functions with peaks and valleys at the same points  that have roughly the same shape, but who knows,  maybe the derivative of sine could have turned out to be some entirely new type of  function that just happens to have a similar shape. Well just like the previous examples, a more exact understanding  of the derivative requires looking at what the function actually represents,  rather than looking at the graph of the function. So think back to that walk around the unit circle,  having traversed an arc with length theta and thinking about sine of theta as  the height of that point. Now zoom into that point on the circle and consider a slight nudge of d theta  along their circumference, a tiny step in your walk around the unit circle. How much does that tiny step change the sine of theta? How much does this increase d theta of arc length increase the height above the x-axis? Well zoomed in close enough, the circle basically looks like a straight line in this  neighborhood, so let's go ahead and think of this right triangle where the hypotenuse  of that right triangle represents the nudge d theta along the circumference,  and that left side here represents the change in height, the resulting d sine of theta. Now this tiny triangle is actually similar to this larger triangle here,  with the defining angle theta and whose hypotenuse is the radius of the circle with  length 1. Specifically this little angle right here is precisely equal to theta radians. Now think about what the derivative of sine is supposed to mean. It's the ratio between that d sine of theta, the tiny change to the height,  divided by d theta, the tiny change to the input of the function. And from the picture we can see that that's the ratio between the  length of the side adjacent to the angle theta divided by the hypotenuse. Well let's see, adjacent divided by hypotenuse,  that's exactly what the cosine of theta means, that's the definition of the cosine. So this gives us two different really nice ways of  thinking about how the derivative of sine is cosine. One of them is looking at the graph and getting a loose feel for the shape of  things based on thinking about the slope of the sine graph at every single point. And the other is a more precise line of reasoning looking at the unit circle itself. For those of you that like to pause and ponder,  see if you can try a similar line of reasoning to find what the derivative of  the cosine of theta should be. In the next video I'll talk about how you can take derivatives  of functions who combine simple functions like these ones,  either as sums or products or function compositions, things like that. And similar to this video the goal is going to be to understand each one  geometrically in a way that makes it intuitively reasonable and somewhat more memorable.

================================================================================
VIDEO ID: 9vKqVkMQHKk
TITLE: The paradox of the derivative | Chapter 2, Essence of calculus
URL: https://www.youtube.com/watch?v=9vKqVkMQHKk
PUBLISHED: 2017-04-29T16:24:03Z
STATUS: SUCCESS
================================================================================
The goal here is simple, explain what a derivative is. The thing is though, there's some subtlety to this topic,  and a lot of potential for paradoxes if you're not careful. So a secondary goal is that you have an appreciation  for what those paradoxes are and how to avoid them. You see, it's common for people to say that the derivative measures an instantaneous  rate of change, but when you think about it, that phrase is actually an oxymoron. Change is something that happens between separate points in time,  and when you blind yourself to all but just a single instant,  there's not really any room for change. You'll see what I mean more as we get into it,  but when you appreciate that a phrase like instantaneous rate of change is actually  nonsense, I think it makes you appreciate just how clever the fathers of calculus  were in capturing the idea that phrase is meant to evoke,  but with a perfectly sensible piece of math, the derivative. As our central example, I want you to imagine a car that starts at some point A,  speeds up, and then slows down to a stop at some point B 100 meters away,  and let's say it all happens over the course of 10 seconds. That's the setup to have in mind as we lay out what the derivative is. Well, we could graph this motion, letting the vertical axis represent the  distance traveled, and the horizontal axis represent time, so at each time t,  represented with a point somewhere on the horizontal axis,  the height of the graph tells us how far the car has traveled in total after  that amount of time. It's pretty common to name a distance function like this s of t. I would use the letter d for distance, but that  guy already has another full time job in calculus. Initially, the curve is quite shallow, since the car is slow to start. During that first second, the distance it travels doesn't change that much. For the next few seconds, as the car speeds up,  the distance traveled in a given second gets larger,  which corresponds to a steeper slope in this graph. Then towards the end, when it slows down, that curve shallows out again. If we were to plot the car's velocity in meters per second as a function of time,  it might look like this bump. At early times, the velocity is very small. Up to the middle of the journey, the car builds up to some maximum velocity,  covering a relatively large distance each second. Then it slows back down towards a speed of zero. These two curves are definitely related to each other. If you change the specific distance vs. time function, you'll have some different velocity vs. time function. What we want to understand is the specifics of that relationship. Exactly how does velocity depend on a distance vs. time function? To do that, it's worth taking a moment to think  critically about what exactly velocity means here. Intuitively, we all might know what velocity at a given moment means,  it's just whatever the car's speedometer shows in that moment. Intuitively, it might make sense that the car's velocity should be higher at times when  this distance function is steeper, when the car traverses more distance per unit time. But the funny thing is, velocity at a single moment makes no sense. If I show you a picture of a car, just a snapshot in an instant,  and I ask you how fast it's going, you'd have no way of telling me. What you'd need are two separate points in time to compare. That way you can compute whatever the change in distance across those times is,  divided by the change in time. Right? I mean, that's what velocity is, it's the distance traveled per unit time. So how is it that we're looking at a function for velocity that  only takes in a single value of t, a single snapshot in time? It's weird, isn't it? We want to associate individual points in time with a velocity,  but actually computing velocity requires comparing two separate points in time. If that feels strange and paradoxical, good! You're grappling with the same conflicts that the fathers of calculus did. And if you want a deep understanding for rates of change, not just for a moving car,  but for all sorts of things in science, you're going to need to resolve this apparent  paradox. First, I think it's best to talk about the real world,  and then we'll go into a purely mathematical one. Let's think about what the car's speedometer is probably doing. At some point, say 3 seconds into the journey,  the speedometer might measure how far the car goes in a very small amount of time,  maybe the distance traveled between 3 seconds and 3.01 seconds. Then it could compute the speed in meters per second as that tiny  distance traversed in meters divided by that tiny time, 0.01 seconds. That is, a physical car just side-steps the paradox and  doesn't actually compute speed at a single point in time. It computes speed during a very small amount of time. So let's call that difference in time dt, which you might think of as 0.01 seconds,  and let's call that resulting difference in distance ds. So the velocity at some point in time is ds divided by dt,  the tiny change in distance over the tiny change in time. Graphically, you can imagine zooming in on some point of this distance vs. time graph above t equals 3. That dt is a small step to the right, since time is on the horizontal axis,  and that ds is the resulting change in the height of the graph,  since the vertical axis represents the distance traveled. So ds divided by dt is something you can think of as the rise  over run slope between two very close points on this graph. Of course, there's nothing special about the value t equals 3. We could apply this to any other point in time,  so we consider this expression ds over dt to be a function of t,  something where I can give you a time t and you can give me back the value of this  ratio at that time, the velocity as a function of time. For example, when I had the computer draw this bump curve here,  the one representing the velocity function, here's what I had the computer actually do. First, I chose a small value for dt, I think in this case it was 0.01. Then I had the computer look at a whole bunch of times t between 0 and 10,  and compute the distance function s at t plus dt,  and then subtract off the value of that function at t. In other words, that's the difference in the distance traveled between the given time,  t, and the time 0.01 seconds after that. Then you can just divide that difference by the change in time, dt,  and that gives you velocity in meters per second around each point in time. So with a formula like this, you could give the computer any curve representing any  distance function s of t, and it could figure out the curve representing velocity. Now would be a good time to pause, reflect, and make sure this idea  of relating distance to velocity by looking at tiny changes makes sense,  because we're going to tackle the paradox of the derivative head on. This idea of ds over dt, a tiny change in the value of the function s divided by  the tiny change in the input that caused it, that's almost what a derivative is. And even though a car's speedometer will actually look at a concrete change in time,  like 0.01 seconds, and even though the drawing program here is looking at an actual  concrete change in time, in pure math the derivative is not this ratio ds over dt for a  specific choice of dt. Instead, it's whatever that ratio approaches as your choice for dt  approaches 0. Luckily there is a really nice visual understanding for what it means to ask what  this ratio approaches, Remember, for any specific choice of dt,  this ratio ds over dt is the slope of a line passing through two separate points  on the graph, right? Well as dt approaches 0, and as those two points approach each other,  the slope of the line approaches the slope of a line that's  tangent to the graph at whatever point t we're looking at. So the true honest-to-goodness pure math derivative is not the  rise over run slope between two nearby points on the graph,  it's equal to the slope of a line tangent to the graph at a single point. Now notice what I'm not saying, I'm not saying that the derivative is  whatever happens when dt is infinitely small, whatever that would mean. Nor am I saying that you plug in 0 for dt. This dt is always a finitely small non-zero value, it's just that it approaches 0 is all. I think that's really clever. Even though change in an instant makes no sense,  this idea of letting dt approach 0 is a really sneaky backdoor  way to talk reasonably about the rate of change at a single point in time. Isn't that neat? It's kind of flirting with the paradox of change in  an instant without ever needing to actually touch it. And it comes with such a nice visual intuition too,  as the slope of a tangent line to a single point on the graph. And because change in an instant still makes no sense,  I think it's healthiest for you to think of this slope not as some instantaneous  rate of change, but instead as the best constant approximation for a rate of  change around a point. By the way, it's worth saying a couple words on notation here. Throughout this video I've been using dt to refer to a tiny change in t with  some actual size, and ds to refer to the resulting change in s,  which again has an actual size, and this is because that's how I want you to  think about them. But the convention in calculus is that whenever you're using the letter d like this,  you're kind of announcing your intention that eventually you're  going to see what happens as dt approaches 0. For example, the honest-to-goodness pure math derivative is written as ds divided by dt,  even though it's technically not a fraction per se,  but whatever that fraction approaches for smaller and smaller nudges in t. I think a specific example should help here. You might think that asking about what this ratio approaches  for smaller and smaller values would make it much more difficult to compute,  but weirdly it kind of makes things easier. Let's say you have a given distance vs time function that happens to be exactly t cubed. So after 1 second the car has traveled 1 cubed equals 1 meters,  after 2 seconds it's traveled 2 cubed, or 8 meters, and so on. Now what I'm about to do might seem somewhat complicated,  but once the dust settles it really is simpler,  and more importantly it's the kind of thing you only ever have to do once in calculus. Let's say you wanted to compute the velocity, ds divided by dt,  at some specific time, like t equals 2. For right now let's think of dt as having an actual size,  some concrete nudge, we'll let it go to 0 in just a bit. The tiny change in distance between 2 seconds and 2 plus dt  seconds is s of 2 plus dt minus s of 2, and we divide that by dt. Since our function is t cubed, that numerator looks like 2 plus dt cubed minus 2 cubed. And this is something we can work out algebraically. Again, bear with me, there's a reason I'm showing you the details here. When you expand that top, what you get is 2 cubed plus 3 times 2 squared dt  plus 3 times 2 times dt squared plus dt cubed, and all of that is minus 2 cubed. Now there's a lot of terms, and I want you to remember that it looks like a mess,  but it does simplify. Those 2 cubed terms cancel out. Everything remaining here has a dt in it, and since there's a dt on the bottom there,  many of those cancel out as well. What this means is that the ratio ds divided by dt has boiled down into  3 times 2 squared plus 2 different terms that each have a dt in them. So if we ask what happens as dt approaches 0, representing the idea of looking at a  smaller and smaller change in time, we can just completely ignore those other terms. By eliminating the need to think about a specific dt,  we've eliminated a lot of the complication in the full expression. So what we're left with is this nice clean 3 times 2 squared. You can think of that as meaning that the slope of a line tangent to  the point at t equals 2 of this graph is exactly 3 times 2 squared, or 12. And of course, there's nothing special about the time t equals 2. We could more generally say that the derivative  of t cubed as a function of t is 3 times t squared. Now take a step back, because that's beautiful. The derivative is this crazy complicated idea. We've got tiny changes in distance over tiny changes in time,  but instead of looking at any specific one of those,  we're talking about what that thing approaches. I mean, that's a lot to think about. And yet what we've come out with is such a simple expression, 3 times t squared. And in practice, you wouldn't go through all this algebra each time. Knowing that the derivative of t cubed is 3t squared is one of those things that all  calculus students learn how to do immediately without having to re-derive it each time. And in the next video, I'm going to show you a nice way to think about  this and a couple other derivative formulas in really nice geometric ways. But the point I want to make by showing you all of the algebraic guts  here is that when you consider the tiny change in distance caused by a  tiny change in time for some specific value of dt, you'd have kind of a mess. But when you consider what that ratio approaches as dt approaches 0,  it lets you ignore much of that mess, and it really does simplify the problem. That right there is kind of the heart of why calculus becomes useful. Another reason to show you a concrete derivative like this is that it  sets the stage for an example of the kind of paradoxes that come about  if you believe too much in the illusion of instantaneous rate of change. So think about the actual car traveling according to this t cubed distance function,  and consider its motion at the moment t equals 0, right at the start. Now ask yourself whether or not the car is moving at that time. On the one hand, we can compute its speed at that point using the derivative,  3t squared, which for time t equals 0 works out to be 0. Visually, this means that the tangent line to the graph at that point is perfectly flat,  so the car's quote-unquote instantaneous velocity is 0,  and that suggests that obviously it's not moving. But on the other hand, if it doesn't start moving at time 0, when does it start moving? Really, pause and ponder that for a moment. Is the car moving at time t equals 0? Do you see the paradox? The issue is that the question makes no sense. It references the idea of change in a moment, but that doesn't actually exist. That's just not what the derivative measures. What it means for the derivative of a distance function to be 0 is that the best  constant approximation for the car's velocity around that point is 0 m per second. For example, if you look at an actual change in time,  say between time 0 and 0.1 seconds, the car does move. It moves 0.001 m. That's very small, and importantly, it's very small compared to the change in time,  giving an average speed of only 0.01 m per second. And remember, what it means for the derivative of this motion to be 0 is that  for smaller and smaller nudges in time, this ratio of m per second approaches 0. But that's not to say that the car is static. Approximating its movement with a constant velocity of 0 is,  after all, just an approximation. So whenever you hear people refer to the derivative as an instantaneous rate of change,  a phrase which is intrinsically oxymoronic, I want you to think of that as a  conceptual shorthand for the best constant approximation for rate of change. In the next couple videos, I'll be talking more about the derivative,  what it looks like in different contexts, how do you actually compute it,  why is it useful, things like that, focusing on visual intuition as always.

================================================================================
VIDEO ID: WUvTyaaNkzM
TITLE: The essence of calculus
URL: https://www.youtube.com/watch?v=WUvTyaaNkzM
PUBLISHED: 2017-04-28T15:58:48Z
STATUS: SUCCESS
================================================================================
Hey everyone, Grant here. This is the first video in a series on the essence of calculus, and I'll be publishing the following videos once per day for the next 10 days. The goal here, as the name suggests, is to really get the heart of the subject out in one binge-watchable set. But with a topic that's as broad as calculus, there's a lot of things that can mean, so here's what I have in mind specifically. Calculus has a lot of rules and formulas which are often presented as things to be memorized. Lots of derivative formulas, the product rule, the chain rule, implicit differentiation, the fact that integrals and derivatives are opposite, Taylor series, just a lot of things like that. And my goal is for you to come away feeling like you could have invented calculus yourself. That is, cover all those core ideas, but in a way that makes clear where they actually come from, and what they really mean, using an all-around visual approach. Inventing math is no joke, and there is a difference between being told why something's true, and actually generating it from scratch. But at all points, I want you to think to yourself, if you were an early mathematician, pondering these ideas and drawing out the right diagrams, does it feel reasonable that you could have stumbled across these truths yourself? In this initial video, I want to show how you might stumble into the core ideas of calculus by thinking very deeply about one specific bit of geometry, the area of a circle. Maybe you know that this is pi times its radius squared, but why? Is there a nice way to think about where this formula comes from? Well, contemplating this problem and leaving yourself open to exploring the interesting thoughts that come about can actually lead you to a glimpse of three big ideas in calculus, integrals, derivatives, and the fact that they're opposites. But the story starts more simply, just you and a circle, let's say with radius 3. You're trying to figure out its area, and after going through a lot of paper trying different ways to chop up and rearrange the pieces of that area, many of which might lead to their own interesting observations, maybe you try out the idea of slicing up the circle into many concentric rings. This should seem promising because it respects the symmetry of the circle, and math has a tendency to reward you when you respect its symmetries. Let's take one of those rings, which has some inner radius r that's between 0 and 3. If we can find a nice expression for the area of each ring like this one, and if we have a nice way to add them all up, it might lead us to an understanding of the full circle's area. Maybe you start by imagining straightening out this ring. And you could try thinking through exactly what this new shape is and what its area should be, but for simplicity, let's just approximate it as a rectangle. The width of that rectangle is the circumference of the original ring, which is 2 pi times r, right? I mean, that's essentially the definition of pi. And its thickness? Well, that depends on how finely you chopped up the circle in the first place, which was kind of arbitrary. In the spirit of using what will come to be standard calculus notation, let's call that thickness dr for a tiny difference in the radius from one ring to the next. Maybe you think of it as something like 0.1. So approximating this unwrapped ring as a thin rectangle, its area is 2 pi times r, the radius, times dr, the little thickness. And even though that's not perfect, for smaller and smaller choices of dr, this is actually going to be a better and better approximation for that area, since the top and the bottom sides of this shape are going to get closer and closer to being exactly the same length. So let's just move forward with this approximation, keeping in the back of our minds that it's slightly wrong, but it's going to become more accurate for smaller and smaller choices of dr. That is, if we slice up the circle into thinner and thinner rings. So just to sum up where we are, you've broken up the area of the circle into all of these rings, and you're approximating the area of each one of those as 2 pi times its radius times dr, where the specific value for that inner radius ranges from 0 for the smallest ring up to just under 3 for the biggest ring, spaced out by whatever the thickness is that you choose for dr, something like 0.1. And notice that the spacing between the values here corresponds to the thickness dr of each ring, the difference in radius from one ring to the next. In fact, a nice way to think about the rectangles approximating each ring's area is to fit them all upright side by side along this axis. Each one has a thickness dr, which is why they fit so snugly right there together, and the height of any one of these rectangles sitting above some specific value of r, like 0.6, is exactly 2 pi times that value. That's the circumference of the corresponding ring that this rectangle approximates. Pictures like this 2 pi r can get tall for the screen, I mean 2 times pi times 3 is around 19, so let's just throw up a y axis that's scaled a little differently so that we can actually fit all of these rectangles on the screen. A nice way to think about this setup is to draw the graph of 2 pi r, which is a straight line that has a slope 2 pi. Each of these rectangles extends up to the point where it just barely touches that graph. Again, we're being approximate here. Each of these rectangles only approximates the area of the corresponding ring from the circle. But remember, that approximation, 2 pi r times dr, gets less and less wrong as the size of dr gets smaller and smaller. And this has a very beautiful meaning when we're looking at the sum of the areas of all those rectangles. For smaller and smaller choices of dr, you might at first think that turns the problem into a monstrously large sum. I mean, there's many many rectangles to consider, and the decimal precision of each one of their areas is going to be an absolute nightmare. But notice, all of their areas in aggregate just looks like the area under a graph. And that portion under the graph is just a triangle, a triangle with a base of 3 and a height that's 2 pi times 3. So its area, 1 half base times height, works out to be exactly pi times 3 squared. Or if the radius of our original circle was some other value, capital R, that area comes out to be pi times r squared. And that's the formula for the area of a circle. It doesn't matter who you are or what you typically think of math, that right there is a beautiful argument. But if you want to think like a mathematician here, you don't just care about finding the answer, you care about developing general problem-solving tools and techniques. So take a moment to meditate on what exactly just happened and why it worked, because the way we transitioned from something approximate to something precise is actually pretty subtle and cuts deep to what calculus is all about. You had this problem that could be approximated with the sum of many small numbers, each of which looked like 2 pi r times dr, for values of r ranging between 0 and 3. Remember, the small number dr here represents our choice for the thickness of each ring, for example 0.1. And there are two important things to note here. First of all, not only is dr a factor in the quantities we're adding up, 2 pi r times dr, it also gives the spacing between the different values of r. And secondly, the smaller our choice for dr, the better the approximation. Adding all of those numbers could be seen in a different, pretty clever way as adding the areas of many thin rectangles sitting underneath a graph, the graph of the function 2 pi r in this case. Then, and this is key, by considering smaller and smaller choices for dr, corresponding to better and better approximations of the original problem, the sum, thought of as the aggregate area of those rectangles, approaches the area under the graph. And because of that, you can conclude that the answer to the original question, in full unapproximated precision, is exactly the same as the area underneath this graph. A lot of other hard problems in math and science can be broken down and approximated as the sum of many small quantities, like figuring out how far a car has traveled based on its velocity at each point in time. In a case like that, you might range through many different points in time, and at each one multiply the velocity at that time times a tiny change in time, dt, which would give the corresponding little bit of distance traveled during that little time. I'll talk through the details of examples like this later in the series, but at a high level many of these types of problems turn out to be equivalent to finding the area under some graph, in much the same way that our circle problem did. This happens whenever the quantities you're adding up, the one whose sum approximates the original problem, can be thought of as the areas of many thin rectangles sitting side by side. If finer and finer approximations of the original problem correspond to thinner and thinner rings, then the original problem is equivalent to finding the area under some graph. Again, this is an idea we'll see in more detail later in the series, so don't worry if it's not 100% clear right now. The point now is that you, as the mathematician having just solved a problem by reframing it as the area under a graph, might start thinking about how to find the areas under other graphs. We were lucky in the circle problem that the relevant area turned out to be a triangle, but imagine instead something like a parabola, the graph of x2. What's the area underneath that curve, say between the values of x equals 0 and x equals 3? Well, it's hard to think about, right? And let me reframe that question in a slightly different way. We'll fix that left endpoint in place at 0, and let the right endpoint vary. Are you able to find a function, a of x, that gives you the area under this parabola between 0 and x? A function a of x like this is called an integral of x2. Calculus holds within it the tools to figure out what an integral like this is, but right now it's just a mystery function to us. We know it gives the area under the graph of x2 between some fixed left point and some variable right point, but we don't know what it is. And again, the reason we care about this kind of question is not just for the sake of asking hard geometry questions, it's because many practical problems that can be approximated by adding up a large number of small things can be reframed as a question about an area under a certain graph. I'll tell you right now that finding this area, this integral function, is genuinely hard, and whenever you come across a genuinely hard question in math, a good policy is to not try too hard to get at the answer directly, since usually you just end up banging your head against a wall. Instead, play around with the idea, with no particular goal in mind. Spend some time building up familiarity with the interplay between the function defining the graph, in this case x2, and the function giving the area. In that playful spirit, if you're lucky, here's something you might notice. When you slightly increase x by some tiny nudge dx, look at the resulting change in area, represented with this sliver I'm going to call da for a tiny difference in area. That sliver can be pretty well approximated with a rectangle, one whose height is x2 and whose width is dx. And the smaller the size of that nudge dx, the more that sliver actually looks like a rectangle. This gives us an interesting way to think about how a of x is related to x2. A change to the output of a, this little da, is about equal to x2, where x is whatever input you started at, times dx, the little nudge to the input that caused a to change. Or rearranged, da divided by dx, the ratio of a tiny change in a to the tiny change in x that caused it, is approximately whatever x2 is at that point. And that's an approximation that should get better and better for smaller and smaller choices of dx. In other words, we don't know what a of x is, that remains a mystery. But we do know a property that this mystery function must have. When you look at two nearby points, for example 3 and 3.001, consider the change to the output of a between those two points, the difference between the mystery function evaluated at 3.001 and 3.001. That change, divided by the difference in the input values, which in this case is 0.001, should be about equal to the value of x2 for the starting input, in this case 3 squared. And this relationship between tiny changes to the mystery function and the values of x2 itself is true at all inputs, not just 3. That doesn't immediately tell us how to find a of x, but it provides a very strong clue that we can work with. And there's nothing special about the graph x2 here. Any function defined as the area under some graph has this property, that da divided by dx, a slight nudge to the output of a divided by a slight nudge to the input that caused it, is about equal to the height of the graph at that point. Again, that's an approximation that gets better and better for smaller choices of dx. And here, we're stumbling into another big idea from calculus, derivatives. This ratio da divided by dx is called the derivative of a, or more technically, the derivative is whatever this ratio approaches as dx gets smaller and smaller. I'll dive much more deeply into the idea of a derivative in the next video, but loosely speaking it's a measure of how sensitive a function is to small changes in its input. You'll see as the series goes on that there are many ways you can visualize a derivative, depending on what function you're looking at and how you think about tiny nudges to its output. We care about derivatives because they help us solve problems, and in our little exploration here, we already have a glimpse of one way they're used. They are the key to solving integral questions, problems that require finding the area under a curve. Once you gain enough familiarity with computing derivatives, you'll be able to look at a situation like this one where you don't know what a function is, but you do know that its derivative should be x2, and from that reverse engineer what the function must be. This back and forth between integrals and derivatives, where the derivative of a function for the area under a graph gives you back the function defining the graph itself, is called the fundamental theorem of calculus. It ties together the two big ideas of integrals and derivatives, and shows how each one is an inverse of the other. All of this is only a high-level view, just a peek at some of the core ideas that emerge in calculus. And what follows in this series are the details, for derivatives and integrals and more. At all points, I want you to feel that you could have invented calculus yourself, that if you drew the right pictures and played with each idea in just the right way, these formulas and rules and constructs that are presented could have just as easily popped out naturally from your own explorations. And before you go, it would feel wrong not to give the people who supported this series on Patreon a well-deserved thanks, both for their financial backing as well as for the suggestions they gave while the series was being developed. You see, supporters got early access to the videos as I made them, and they'll continue to get early access for future essence-of type series. And as a thanks to the community, I keep ads off of new videos for their first month. I'm still astounded that I can spend time working on videos like these, and in a very direct way, you are the one to thank for that.

================================================================================
VIDEO ID: mvmuCPvRoWQ
TITLE: Euler's formula with introductory group theory
URL: https://www.youtube.com/watch?v=mvmuCPvRoWQ
PUBLISHED: 2017-03-03T22:07:09Z
STATUS: SUCCESS
================================================================================
Two years ago, almost to the day actually, I put up the first video on this channel,  about Euler's formula, e to the pi i equals negative one. As an anniversary of sorts, I want to revisit that same idea. For one thing, I've always wanted to improve on the presentation,  but I wouldn't rehash an old topic if there wasn't something new to teach. You see, the idea underlying that video was to take certain concepts from  a field in math called group theory, and show how they give Euler's formula  a much richer interpretation than a mere association between numbers. And two years ago, I thought it might be fun to use those ideas without  referencing group theory itself, or any of the technical terms within it. But I've come to see that you all actually quite like getting into the math itself,  even if it takes some time. So here, two years later, lets you and me go through an introduction to the basics  of group theory, building up to how Euler's formula comes to life under this light. If all you want is a quick explanation of Euler's formula,  and if you're comfortable with vector calculus,  I'll go ahead and put up a particularly short explanation on the screen  that you can pause and ponder on. If it doesn't make sense, don't worry about it, it's not needed for where we're going. The reason I want to put out this group theory view,  though, is not because I think it's a better explanation. Heck, it's not even a complete proof, it's just an intuition really. It's because it has the chance to change how you think about numbers,  and how you think about algebra. You see, group theory is all about studying the nature of symmetry. For example, a square is a very symmetric shape, but what do we actually mean by that? One way to answer that is to ask about what are all the actions you can take  on the square that leave it looking indistinguishable from how it started. For example, you could rotate it 90 degrees counterclockwise,  and it looks totally the same to how it started. You could also flip it around this vertical line, and again, it still looks identical. In fact, the thing about such perfect symmetry is that it's  hard to keep track of what action has actually been taken,  so to help out I'm going to stick on an asymmetric image here. We call each one of these actions a symmetry of the square,  and all of the symmetries together make up a group of symmetries, or just group for short. This particular group consists of 8 symmetries. There's the action of doing nothing, which is one we count,  plus 3 different rotations, and then there's 4 ways you can flip it over. In fact, this group of 8 symmetries has a special name,  it's called the dihedral group of order 8. And that's an example of a finite group, consisting of only 8 actions,  but a lot of other groups consist of infinitely many actions. Think of all possible rotations, for example, of any angle. Maybe you think of this as a group that acts on a circle,  capturing all of the symmetries of that circle that don't involve flipping it. Here, every action from this group of rotation lies  somewhere on the infinite continuum between 0 and 2 pi radians. One nice aspect of these actions is that we can associate each one of  them with a single point on the circle itself, the thing being acted on. You start by choosing some arbitrary point, maybe the one on the right here. Then every circle symmetry, every possible rotation,  takes this marked point to some unique spot on the circle,  and the action itself is completely determined by where it takes that spot. Now, this doesn't always happen with groups, but it's nice when it does happen,  because it gives us a way to label the actions themselves,  which can otherwise be pretty tricky to think about. The study of groups is not just about what a particular set of symmetries is,  whether that's the 8 symmetries of a square, the infinite continuum  of symmetries of the circle, or anything else you dream up. The real heart and soul of the study is knowing how these symmetries play with each other. On the square, if I rotate 90 degrees and then flip around the vertical axis,  the overall effect is the same as if I had just flipped over this diagonal line. So in some sense, that rotation plus the vertical flip equals that diagonal flip. On the circle, if I rotate 270 degrees and then follow it with a rotation of 120 degrees,  the overall effect is the same as if I had just rotated 30 degrees to start with. So in this circle group, a 270 degree rotation plus  a 120 degree rotation equals a 30 degree rotation. And in general, with any group, any collection of these sorts of symmetric actions,  there's a kind of arithmetic, where you can always take two actions and add  them together to get a third one, by applying one after the other. Or maybe you think of it as multiplying actions, it doesn't really matter. The point is that there is some way to combine the two actions to get out another one. That collection of underlying relations, all associations between  pairs of actions and the single action that's equivalent to applying one after the other,  that's really what makes a group a group. It's actually crazy how much of modern math is rooted in, well, this,  in understanding how a collection of actions is organized by this relation,  this relation between pairs of actions and the single action you get by composing them. Groups are extremely general. A lot of different ideas can be framed in terms of symmetries and composing symmetries. And maybe the most familiar example is numbers, just ordinary numbers. And there are actually two separate ways to think about numbers as a group. One where composing actions is going to look like addition,  and another where composing actions will look like multiplication. It's a little weird, because we don't usually think of numbers as actions,  we usually think of them as counting things. But let me show you what I mean. Think of all of the ways that you can slide a number line left or right along itself. This collection of all sliding actions is a group,  what you might think of as the group of symmetries on an infinite line. And in the same way that actions from the circle group could be associated with  individual points on that circle, this is another one of those special groups where  we can associate each action with a unique point on the thing that it's actually acting  on. You just follow where the point that starts at zero ends up. For example, the number 3 is associated with the action of sliding right by 3 units. The number negative 2 is associated with the action of sliding 2 units to the left,  since that's the unique action that drags the point at zero over to the point at negative  2. The number zero itself, well, that's associated with the action of just doing nothing. This group of sliding actions, each one of which is associated with a unique real number,  has a special name, the additive group of real numbers. The reason the word additive is in there is because of what the  group operation of applying one action followed by another looks like. If I slide right by 3 units and then I slide right by 2 units,  the overall effect is the same as if I slid right by 3 plus 2, or 5 units. Simple enough, we're just adding the distances of each slide. But the point here is that this gives an alternate view for what numbers even are. They are one example in a much larger category of groups,  groups of symmetries acting on some object, and the arithmetic of adding  numbers is just one example of the arithmetic that any group of symmetries has within it. We could also extend this idea, instead asking  about the sliding actions on the complex plane. The newly introduced numbers i, 2i, 3i, and so on on this vertical line would  all be associated with vertical sliding motions,  since those are the actions that drag the point at zero up to the relevant  point on that vertical line. The point over here at 3 plus 2i would be associated with the action of sliding  the plane in such a way that drags zero up and to the right to that point. And it should make sense why we call this 3 plus 2i. That diagonal sliding action is the same as first sliding by 3 to the right,  and then following it with a slide that corresponds to 2i, which is 2 units vertically. Similarly, let's get a feel for how composing  any two of these actions generally breaks down. Consider this slide by 3 plus 2i action, as well as this slide by 1 minus 3i action,  and imagine applying one of them right after the other. The overall effect, the composition of these two sliding actions,  is the same as if we had slid 3 plus 1 to the right and 2 minus 3 vertically. Notice how that involves adding together each component. So composing sliding actions is another way to think  about what adding complex numbers actually means. This collection of all sliding actions on the 2d complex  plane goes by the name the additive group of complex numbers. Again, the upshot here is that numbers, even complex numbers,  are just one example of a group, and the idea of addition can be thought of in terms of  successively applying actions. But numbers, schizophrenic as they are, also lead a completely different life,  as a completely different kind of group. Consider a new group of actions on the number line,  all ways that you can stretch or squish it, keeping everything evenly spaced,  and keeping that number 0 fixed in place. Yet again, this group of actions has that nice property,  where we can associate each action in the group with a specific point on the  thing that it's acting on. In this case, follow where the point that starts at the number 1 goes. There is one and only one stretching action that brings that point at  1 to the point at 3, for instance, namely stretching by a factor of 3. Likewise, there is one and only one action that brings that point  at 1 to the point at 1 half, namely squishing by a factor of 1 half. I like to imagine using one hand to fix the number 0 in place,  and using the other to drag the number 1 wherever I like,  while the rest of the number line just does whatever it takes to stay evenly spaced. In this way, every single positive number is associated  with a unique stretching or squishing action. Now, notice what composing actions looks like in this group. If I apply the stretch by 3 action, and then follow it with the stretch by 2 action,  the overall effect is the same as if I had just applied the stretch by 6 action,  the product of the two original numbers. And in general, applying one of these actions followed by another  corresponds with multiplying the numbers that they're associated with. In fact, the name for this group is the multiplicative group of positive real numbers. So, multiplication, ordinary familiar multiplication,  is one more example of this very general and very far-reaching idea of groups,  and the arithmetic within groups. And we can also extend this idea to the complex plane. Again, I like to think of fixing 0 in place with one hand,  and dragging around the point at 1, keeping everything else evenly spaced while I do so. But this time, as we drag the number 1 to places that are off the real number line,  we see that our group includes not only stretching and squishing actions,  but actions that have some rotational component as well. The quintessential example of this is the action associated with that point at i,  one unit above 0. What it takes to drag the point at 1 to that point at i is a 90 degree rotation. So, the multiplicative action associated with i is a 90 degree rotation. And notice, if I apply that action twice in a row,  the overall effect is to flip the plane 180 degrees. And that is the unique action that brings the point at 1 over to negative 1. So, in this sense, i times i equals negative 1,  meaning the action associated with i, followed by that same action associated with i,  has the same overall effect as the action associated with negative 1. As another example, here's the action associated with 2 plus i,  dragging 1 up to that point. If you want, you could think of this as broken down as a rotation by 30 degrees,  followed by a stretch by a factor of square root of 5. And in general, every one of these multiplicative actions is some  combination of a stretch or a squish, an action associated with some  point on the positive real number line, followed by a pure rotation,  where pure rotations are associated with points on this circle, the one with radius 1. This is very similar to how the sliding actions in the additive group could be broken  down as some pure horizontal slide, represented with points on the real number line,  plus some purely vertical slide, represented with points on that vertical line. That comparison of how actions in each group breaks down is going to be important,  so remember it. In each one, you can break down any action as some purely real number action,  followed by something that's specific to complex numbers,  whether that's vertical slides for the additive group,  or pure rotations for the multiplicative group. So that's our quick introduction to groups. A group is a collection of symmetric actions on some mathematical object,  whether that's a square, a circle, the real number line, or anything else you dream up. And every group has a certain arithmetic, where you can combine  two actions by applying one after the other, and asking what  other action from the group gives the same overall effect. Numbers, both real and complex numbers, can be  thought of in two different ways as a group. They can act by sliding, in which case the group arithmetic just looks like  ordinary addition, or they can act by these stretching-squishing-rotating actions,  in which case the group arithmetic looks just like multiplication. And with that, let's talk about exponentiation. Our first introduction to exponents is to think  of them in terms of repeated multiplication, right? I mean, the meaning of something like 2 cubed is to take 2 times 2 times 2,  and the meaning of something like 2 to the fifth is 2 times 2 times 2 times 2 times 2. And a consequence of this, something you might call the exponential property,  is that if I add two numbers in the exponent, say 2 to the 3 plus 5,  this can be broken down as the product of 2 to the third times 2 to the 5. And when you expand things, this seems reasonable enough, right? But expressions like 2 to the 1 half, or 2 to the negative 1, and much less 2 to the i,  don't really make sense when you think of exponents as repeated multiplication. I mean, what does it mean to multiply 2 by itself half of a time, or negative 1 of a time? So we do something very common throughout math,  and extend beyond the original definition, which only makes sense for counting numbers,  to something that applies to all sorts of numbers. But we don't just do this randomly. If you think back to how fractional and negative exponents are defined,  it's always motivated by trying to make sure that this property,  2 to the x plus y equals 2 to the x times 2 to the y, still holds. To see what this might mean for complex exponents,  think about what this property is saying from a group theory light. It's saying that adding the inputs corresponds with multiplying the outputs,  and that makes it very tempting to think of the inputs not merely as numbers,  but as members of the additive group of sliding actions. And to think of the outputs not merely as numbers,  but as members of this multiplicative group of stretching and squishing actions. Now, it is weird and strange to think about functions that take in one kind of action,  and spit out another kind of action. But this is something that actually comes up all the time throughout group theory. And this exponential property is very important for this association between groups. It guarantees that if I compose two sliding actions, maybe a slide by negative 1,  and then a slide by positive 2, it corresponds to composing the two output actions,  in this case, squishing by 2 to the negative 1, and then stretching by 2 squared. Mathematicians would describe a property like this by saying that the function preserves  the group structure, in the sense that the arithmetic within a group is what gives it  its structure, and a function like this exponential plays nicely with that arithmetic. Functions between groups that preserve the arithmetic like  this are really important throughout group theory,  enough so that they've earned themselves a nice fancy name, homomorphisms. Now, think about what all of this means for associating the additive group  in the complex plane with the multiplicative group in the complex plane. We already know that when you plug in a real number to 2 to the x,  you get out a real number, a positive real number, in fact. So this exponential function takes any purely horizontal slide,  and turns it into some pure stretching or squishing action. So wouldn't you agree that it would be reasonable for this new  dimension of additive actions, slides up and down,  to map directly into this new dimension of multiplicative actions, pure rotations? Those vertical sliding actions correspond to points on this vertical axis,  and those rotating multiplicative actions correspond to points on the circle with  radius 1. So what it would mean for an exponential function like 2 to the x to map purely  vertical slides into pure rotations would be that complex numbers on this vertical line,  multiples of i, get mapped to complex numbers on this unit circle. In fact, for the function 2 to the x, the input i, a vertical slide of one unit,  happens to map to a rotation of about 0.693 radians, that is,  a walk around the unit circle that covers 0.693 units of distance. With a different exponential function, say 5 to the x, that input i,  a vertical slide of one unit, would map to a rotation of about 1.609 radians,  a walk around the unit circle covering exactly 1.609 units of distance. What makes the number e special is that when the exponential e to the x maps vertical  slides to rotations, a vertical slide of one unit, corresponding to i,  maps to a rotation of exactly one radian, a walk around the unit circle covering a  distance of exactly one. And so, a vertical slide of two units would map to a rotation of two radians. A three unit slide up corresponds to a rotation of three radians. And a vertical slide of exactly pi units up, corresponding to the input pi times i,  maps to a rotation of exactly pi radians, halfway around the circle. And that's the multiplicative action associated with the number negative one. Now you might ask, why e? Why not some other base? Well, the full answer resides in calculus. I mean, that's the birthplace of e and where it's even defined. Again, I'll leave up another explanation on the screen if you're hungry  for a fuller description and if you're comfortable with the calculus. But at a high level, I'll say that it has to do with the fact that  all exponential functions are proportional to their own derivative. But e to the x alone is the one that's actually equal to its own derivative. The important point that I want to make here, though,  is that if you view things from the lens of group theory,  thinking of the inputs to an exponential function as sliding actions,  and thinking of the outputs as stretching and rotating actions,  it gives a very vivid way to read what a formula like this is even saying. When you read it, you can think that exponentials in general map purely vertical slides,  the additive actions that are perpendicular to the real number line, into pure rotations,  which are in some sense perpendicular to the real number stretching actions. And moreover, e to the x does this in the very special way that ensures  that a vertical slide of pi units corresponds to a rotation of exactly pi radians,  the 180 degree rotation associated with the number negative 1. To finish things off here, I want to show a way that you can think  about this function e to the x as a transformation of the complex plane. But before that, just two quick messages. I've mentioned before just how thankful I am to you, the community,  for making these videos possible through Patreon,  but in much the same way that numbers become more meaningful when you think of them as  actions, gratitude is also best expressed as an action. So I've decided to turn off ads on new videos for their first month,  in the hopes of giving you all a better viewing experience. This video was sponsored by Emerald Cloud Lab,  and actually I was the one to reach out to them on this one,  since it's a company I find particularly inspiring. Emerald is a very unusual startup, half software, half biotech. The Cloud Lab that they're building essentially enables biologists and chemists  to conduct research through a software platform, instead of working in a lab. Scientists can program experiments, which are then executed remotely and robotically,  in Emerald's industrialized research lab. I know some of the people at the company, and the software  challenges they're working on are really interesting. Currently, they're looking to hire software engineers and web  developers for their engineering team, as well as applied  mathematicians and computer scientists for their scientific computing team. If you're interested in applying, whether that's now or a few months from now,  there are a couple special links in the description of this video,  and if you apply through those, it lets Emerald know that you heard about them  through this channel. Alright, so e to the x transforming the plane. I like to imagine first rolling that plane into a cylinder,  wrapping all those vertical lines into circles,  and then taking that cylinder and kind of smooshing it onto the plane around zero,  where each of those concentric circles, spaced out exponentially,  correspond with what started off as vertical lines.

================================================================================
VIDEO ID: gB9n2gHsHN4
TITLE: Fractals are typically not self-similar
URL: https://www.youtube.com/watch?v=gB9n2gHsHN4
PUBLISHED: 2017-01-27T17:29:08Z
STATUS: SUCCESS
================================================================================
Who doesn't like fractals? They're a beautiful blend of simplicity and complexity,  often including these infinitely repeating patterns. Programmers in particular tend to be especially fond of them,  because it takes a shockingly small amount of code to produce images  that are way more intricate than any human hand ever could hope to draw. But a lot of people don't actually know the definition of a fractal,  at least not the one Benoit Mandelbrot, the father of fractal geometry, had in mind. A common misconception is that fractals are shapes that are perfectly self-similar. For example, this snowflake-looking shape right here, called the Von Koch snowflake,  consists of three different segments, and each one of these is perfectly self-similar,  in that when you zoom in on it, you get a perfectly identical copy of the original. Likewise, the famous Sierpinski triangle consists  of three smaller identical copies of itself. And don't get me wrong, self-similar shapes are definitely beautiful,  and they're a good toy model for what fractals really are. But Mandelbrot had a much broader conception in mind, one motivated not by beauty,  but more by a pragmatic desire to model nature in a way that actually captures roughness. In some ways, fractal geometry is a rebellion against calculus,  whose central assumption is that things tend to look smooth if you zoom in far enough. But Mandelbrot saw this as overly idealized, or at least needlessly idealized,  resulting in models that neglect the finer details of the thing  they're actually modeling, which can matter. What he observed is that self-similar shapes give a basis for modeling the  regularity in some forms of roughness, but the popular perception that fractals  only include perfectly self-similar shapes is another over-idealization,  one that ironically goes against the pragmatic spirit of fractal geometry's origins. The real definition of fractals has to do with this idea of fractal dimension,  the main topic of this video. You see, there is a sense, a certain way to define the word dimension,  in which the Sierpinski triangle is approximately 1.585D,  that the Von Koch curve is approximately 1.262D. The coastline of Britain turns out to be around 1.21D,  and in general it's possible to have shapes whose dimension is any positive real number,  not just whole numbers. I think when I first heard someone reference fractional dimension like this,  I just thought it was nonsense, right? I mean, mathematicians are clearly just making stuff up. Dimension is something that usually only makes sense for natural numbers, right? A line is one-dimensional, a plane that's two-dimensional,  the space that we live in that's three-dimensional, and so on. And in fact, any linear algebra student who just learned the formal definition of  dimension in that context would agree, it only makes sense for counting numbers. And of course, the idea of fractal dimension is just made up. I mean, this is math, everything's made up. But the question is whether or not it turns out  to be a useful construct for modeling the world. And I think you'll agree, once you learn how fractal dimension is defined,  it's something that you start seeing almost everywhere that you look. It actually helps to start the discussion here  by only looking at perfectly self-similar shapes. In fact, I'm going to start with four shapes,  the first three of which aren't even fractals. A line, a square, a cube, and a Sierpinski triangle. All of these shapes are self-similar. A line can be broken up into two smaller lines,  each of which is a perfect copy of the original, just scaled down by a half. A square can be broken down into four smaller squares,  each of which is a perfect copy of the original, just scaled down by a half. Likewise, a cube can be broken down into eight smaller cubes,  again, each one is a scaled down version by one half. And the core characteristic of the Sierpinski triangle is that it's made  of three smaller copies of itself, and the length of the side of one of  those smaller copies is one half the side length of the original triangle. Now, it's fun to compare how we measure these things. We'd say that the smaller line is one half the length of the original line,  the smaller square is one quarter the area of the original square,  the smaller cube is one eighth the volume of the original cube,  and that smaller Sierpinski triangle? Well, we'll talk about how to measure that in just a moment. What I want is a word that generalizes the idea of length, area,  and volume, but that I can apply to all of those shapes and more. And typically in math, the word that you'd use for this is measure,  but I think it might be more intuitive to talk about mass, as in,  imagine that each of these shapes is made out of metal, a thin wire, a flat sheet,  a solid cube, and some kind of Sierpinski mesh. Fractal dimension has everything to do with understanding  how the mass of these shapes changes as you scale them. The benefit of starting the discussion with self-similar shapes  is that it gives us a nice clear-cut way to compare masses. When you scale down that line by one half, the mass is also scaled down by one half,  which you can viscerally see because it takes two copies of that smaller one to form the  whole. When you scale down a square by one half, its mass is scaled down by one fourth,  where again you can see this by piecing together four of the smaller copies to get the  original. Likewise, when you scale down that cube by one half,  the mass is scaled down by one eighth, or one half cubed,  because it takes eight copies of that smaller cube to rebuild the original. And when you scale down the Sierpinski triangle by a factor of a half,  wouldn't you agree that it makes sense to say that its mass goes down by a factor  of one third? I mean, it takes exactly three of those smaller ones to form the original. But notice that for the line, the square, and the cube,  the factor by which the mass changed is this nice clean integer power of one half. In fact, that exponent is the dimension of each shape. And what's more, you could say that what it means for a shape to be, for example,  two-dimensional, what puts the two in two-dimensional,  is that when you scale it by some factor, its mass is scaled by that factor raised  to the second power. And maybe what it means for a shape to be three-dimensional is that when you  scale it by some factor, the mass is scaled by the third power of that factor. So if this is our conception of dimension, what  should the dimensionality of a Sierpinski triangle be? You'd want to say that when you scale it down by a factor of one half,  its mass goes down by one half to the power of whatever its dimension is. And because it's self-similar, we know that we  want its mass to go down by a factor of one third. So what's the number d such that raising one half to the power of d gives you one third? Well, that's the same as asking two to the what equals three,  the quintessential type of question that logarithms are meant to answer. And when you go and plug in log base two of three to a calculator,  what you'll find is that it's about 1.585. So in this way, the Sierpinski triangle is not one-dimensional,  even though you could define a curve that passes through all its points,  and nor is it two-dimensional, even though it lives in the plane. Instead, it's 1.585 dimensional. And if you want to describe its mass, neither  length nor area seem like the fitting notions. If you tried, its length would turn out to be infinite,  and its area would turn out to be zero. Instead, what you want is whatever the 1.585 dimensional analog of length is. Here, let's look at another self-similar fractal, the von Koch curve. This one is composed of four smaller identical copies of itself,  each of which is a copy of the original scaled down by one third. So the scaling factor is one third, and the mass has gone down by a factor of one fourth. So that means the dimension should be some number D,  so that when we raise one third to the power of D, it gives us one fourth. Well, that's the same as saying three to the what equals four,  so you can go and plug into a calculator log base three of four,  and that comes out to be around 1.262. So in a sense, the von Koch curve is a 1.262 dimensional shape. Here's another fun one. This is kind of the right angled version of the Koch curve. It's built up of eight scaled down copies of itself,  where the scaling factor here is one fourth. So if you want to know its dimension, it should be some number D,  such that one fourth to the power of D equals one eighth,  the factor by which the mass just decreased. And in this case, the value we want is log base four of eight,  and that's exactly three halves. So evidently, this fractal is precisely 1.5 dimensional. Does that kind of make sense? It's weird, but it's all just about scaling and comparing masses while you scale. And what I've described so far, everything up to this  point is what you might call self-similarity dimension. It does a good job making the idea of fractional dimension  seem at least somewhat reasonable, but there's a problem. It's not really a general notion. I mean, when we were reasoning about how a mass's shape should change,  it relied on the self-similarity of the shapes,  that you could build them up from smaller copies of themselves. But that seems unnecessarily restrictive. After all, most two-dimensional shapes are not at all self-similar. Consider the disk, the interior of a circle. We know that's two-dimensional, and you could say that this is because  when you scale it up by a factor of two, its mass, proportional to the area,  gets scaled by the square of that factor, in this case four. But it's not like there's some way to piece together four  copies of that smaller circle to rebuild the original. So how do we know that that bigger disk is exactly four times the mass of the original? Answering that requires a way to make this idea of mass a little more mathematically  rigorous, since we're not dealing with physical objects made of matter, are we? We're dealing with purely geometric ones living in an abstract space. And there's a couple ways to think about this, but here's a common one. Cover the plane with a grid, and highlight all of the grid squares  that are touching the disk, and now count how many there are. In the back of our minds, we already know that a disk is two-dimensional,  and the number of grid squares that it touches should be proportional to its area. A clever way to verify this empirically is to scale up that disk by some factor,  like two, and count how many grid squares touch this new scaled-up version. What you should find is that that number has increased approximately in proportion to  the square of our scaling factor, which in this case means about four times as many boxes. Well, admittedly what's on the screen here might not look that convincing,  but it's just because the grid is really coarse. If instead you took a much finer grid, one that more tightly captures  the intent we're going for here by measuring the size of the circle,  that relationship of quadrupling the number of boxes touched when you  scale the disk by a factor of two should shine through more clearly. I'll admit though that when I was animating this,  I was surprised by just how slowly this value converges to four. Here's one example. For larger and larger scaling values, which is actually equivalent to just  looking at a finer grid, that data is going to more perfectly fit that parabola. Now getting back to fractals, let's play this game with the Sierpinski triangle,  counting how many boxes are touching points in that shape. How would you imagine that number compares to scaling up the triangle  by a factor of two and counting the new number of boxes touched? Well, the proportion of boxes touched by the big one to the  number of boxes touched by the small one should be about three. After all, that bigger version is just built up of three copies of the smaller version. You could also think about this as two raised to the dimension of the fractal,  which we just saw is about 1.585. And so if you were to go and plot the scaling factor in this case against the number of  boxes touched by the Sierpinski triangle, the data would closely fit a curve with the  shape of y equals x to the power 1.585, just multiplied by some proportionality constant. But importantly, the whole reason that I'm talking about this is that we can play  the same game with non-self-similar shapes that still have some kind of roughness. And the classic example here is the coastline of Britain. If you plop that coastline into the plane and count how many boxes are touching it,  and then scale it by some amount, and count how many boxes are touching that new  scaled version, what you'd find is that the number of boxes touching the coastline  increases approximately in proportion to the scaling factor raised to the power of 1.21. Here, it's kind of fun to think about how you  would actually compute that number empirically. As in, imagine I give you some shape, and you're a savvy programmer. How would you find this number? So what I'm saying here is that if you scale this shape by some factor,  which I'll call S, the number of boxes touching that shape should equal some constant  multiplied by that scaling factor raised to whatever the dimension is,  the value that we're looking for. Now, if you have some data plot that closely fits a curve that looks like the  input raised to some power, it can be hard to see exactly what that power should be. So a common trick is to take the logarithm of both sides. That way, the dimension is going to drop down from the exponent,  and we'll have a nice clean linear relationship. What this suggests is that if you were to plot the log of the scaling factor  against the log of the number of boxes touching the coastline,  the relationship should look like a line, and that line should have a slope  equal to the dimension. So what that means is that if you tried out a whole bunch of scaling factors,  counted the number of boxes touching the coast in each instant,  and then plotted the points on the log-log plot,  you could then do some kind of linear regression to find the best fit line to your  data set, and when you look at the slope of that line,  that tells you the empirical measurement for the dimension of what you're examining. I just think that makes this idea of fractal dimension so much more  real and visceral compared to abstract, artificially perfect shapes. And once you're comfortable thinking about dimension like this, you,  my friend, have become ready to hear the definition of a fractal. Essentially, fractals are shapes whose dimension is not an integer,  but instead some fractional amount. What's cool about that is that it's a quantitative way to say that  they're shapes that are rough, and that they stay rough even as you zoom in. Technically, there's a slightly more accurate definition,  and I've included it in the video description,  but this idea here of a non-integer dimension almost entirely captures  the idea of roughness that we're going for. There is one nuance though that I haven't brought up yet, but it's worth pointing out,  which is that this dimension, at least as I've described it so far using the box  counting method, can sometimes change based on how far zoomed in you are. For example, here's a shape sitting in three dimensions  which at a distance looks like a line. In 3D, by the way, when you do a box counting you have a 3D grid full  of little cubes instead of little squares, but it works the same way. At this scale, where the shape's thickness is smaller than the size of the boxes,  it looks one-dimensional, meaning the number of boxes it touches is proportional to its  length. But when you scale it up, it starts behaving a lot more like a tube,  touching the boxes on the surface of that tube, and so it'll look two-dimensional,  with the number of boxes touched being proportional to the square of the scaling factor. But it's not really a tube, it's made of these rapidly winding little curves,  so once you scale it up even more, to the point where the boxes can pick up  on the details of those curves, it looks one-dimensional again,  with the number of boxes touched scaling directly in proportion to the scaling constant. So actually assigning a number to a shape for its dimension can be tricky,  and it leaves room for differing definitions and differing conventions. In a pure math setting, there are indeed numerous definitions for dimension,  but all of them focus on what the limit of this dimension is at closer and closer zoom  levels. You can think of that in terms of the plot as the limit  of this slope as you move farther and farther to the right. So for a purely geometric shape to be a genuine fractal,  it has to continue looking rough, even as you zoom in infinitely far. But in a more applied setting, like looking at the coastline of Britain,  it doesn't really make sense to talk about the limit as you zoom in more and more. I mean, at some point you'd just be hitting atoms. Instead what you do is you look at a sufficiently wide range of scales from  very zoomed out up to very zoomed in, and compute the dimension at each one. And in this more applied setting, a shape is typically  considered to be a fractal only when the measured dimension  stays approximately constant even across multiple different scales. For example, the coastline of Britain doesn't just look 1.21 dimensional at a distance. Even if you zoom in by a factor of a thousand,  the level of roughness is still around 1.21. That right there is the sense in which many shapes from nature actually are self-similar,  albeit not perfect self-similarity. Perfectly self-similar shapes do play an important role in fractal geometry. What they give us are simple to describe, low-information  examples of this phenomenon of roughness, roughness that  persists at many different scales and at arbitrarily close scales. And that's important, it gives us the primitive  tools for modeling these fractal phenomena. But I think it's also important not to view them as the prototypical example of fractals,  since fractals in general actually have a lot more character to them. I really do think that this is one of those ideas where once you learn it,  it makes you start looking at the world completely differently. What this number is, what this fractional dimension  gives us is a quantitative way to describe roughness. For example, the coastline of Norway is about 1.52 dimensional,  which is a numerical way to communicate the fact that it's way more jaggedy than  Britain's coastline. The surface of a calm ocean might have a fractal dimension only barely above 2,  while a stormy one might have a dimension closer to 2.3. In fact, fractal dimension doesn't just arise frequently in nature,  it seems to be the core differentiator between objects that arise naturally and those  that are just man-made.

================================================================================
VIDEO ID: IxNb1WG_Ido
TITLE: Tattoos on Math
URL: https://www.youtube.com/watch?v=IxNb1WG_Ido
PUBLISHED: 2017-01-06T18:05:41Z
STATUS: SUCCESS
================================================================================
Hey folks, just a short, out of the ordinary video for you today. A friend of mine, Cam, recently got a math tattoo. It's not something I'd recommend, but he told his team at work  that if they reached a certain stretch goal, it's something he'd do. And well, the incentive worked. Cam's initials are CSC, which happens to be the  shorthand for the cosecant function in trigonometry. So what he decided to do is make his tattoo a certain  geometric representation of what that function means. It's kind of like a wordless signature written in pure math. It got me thinking, though, about why on earth we teach students about  the trigonometric functions cosecant, secant, and cotangent,  and it occurred to me that there's something kind of poetic about this particular tattoo. Just as tattoos are artificially painted on, but become  permanent as if they were a core part of the recipient's flesh. The fact that the cosecant is a named function is kind of an artificial construct on math. Trigonometry could just as well have existed intact without the cosecant  ever being named, but because it was, it has this strange and artificial  permanence in our conventions, and to some extent in our education system. In other words, the cosecant is not just a tattoo on Cam's chest,  it's a tattoo on math itself, something which seemed reasonable and even worthy  of immortality at its inception, but which doesn't necessarily hold up as time goes on. Here, let me show you a picture of the tattoo he chose,  because not a lot of people know the geometric representation of the cosecant. Whenever you have an angle, typically represented with the Greek letter theta,  it's common in trigonometry to relate it to a corresponding point on the unit circle,  the circle with the radius 1 centered at the origin in the xy plane. Most trigonometry students learn that the distance between this point  here on the circle and the x-axis is the sine of the angle,  and the distance between that point and the y-axis is the cosine of the angle. And these links give a really wonderful understanding  for what cosine and sine are all about. People might learn that the tangent of an angle is sine divided by cosine,  and that relatively few learn that there's also a nice geometric  interpretation for each of those quantities. If you draw a line tangent to the circle at this point,  the distance from that point to the x-axis along that tangent is the tangent of the angle. And the distance along that line to the point where  it hits the y-axis is the cotangent of the angle. Again, this gives a really intuitive feel for what those quantities mean. You can imagine tweaking that theta and seeing when cotangent gets smaller and when  tangent gets larger, and it's a good gut check for any students working with them. Likewise, secant, which is defined as 1 divided by the cosine, and cosecant,  which is defined as 1 divided by the sine of theta,  each have their own places on this diagram. If you look at that point where this tangent line crosses the x-axis,  the distance from that point to the origin is the secant of the angle,  that is 1 divided by the cosine. Likewise, the distance between where this tangent line crosses the y-axis  and the origin is the cosecant of the angle, that is 1 divided by the sine. If you're wondering why on earth that's true, notice that we have  two similar right triangles here, one small one inside the circle,  and this larger triangle whose hypotenuse is resting on the y-axis. I'll leave it to you to check that the interior angle up at the tip there is theta,  the angle that we originally started with over inside the circle. For each one of those triangles, I want you to think about the ratio of  the length of the side opposite theta to the length of the hypotenuse. For the small triangle, the length of the opposite side is sine of theta,  and the hypotenuse is that radius, the one we defined to have length 1,  so the ratio is just sine of theta divided by 1. Now, when we look at the larger triangle, the side opposite  theta is that radial line of length 1, and the hypotenuse is  now this length on the y-axis, the one I'm claiming is the cosecant. If you take the reciprocal of each side here, you see that this  matches up with the fact that the cosecant of theta is 1 divided by sine. Kinda cool, right? It's also kind of nice that sine, tangent, and secant all correspond to lengths of  lines that somehow go to the x-axis, and then the corresponding cosine, cotangent,  and cosecant are all then lengths of lines going to the corresponding spots on the y-axis. And on a diagram like this, it might be pleasing  that all six of these are separately named functions. But in any practical use of trigonometry, you can get by just using sine,  cosine, and tangent. In fact, if you really wanted, you could define all six of these in terms of sine alone. But the sort of things that cosine and tangent correspond to come up  frequently enough that it's more convenient to give them their own names. But cosecant, secant, and cotangent never really come up in problem solving in a  way that's not just as convenient to write in terms of sine, cosine, and tangent. At that point, it's really just adding more words for students to learn,  with not that much added utility. And if anything, if you only introduce secant as 1 over cosine,  and cosecant as 1 over sine, the mismatch of this co-prefix is probably just an  added point of confusion in a class that's prone enough to confusion for many  of its students. The reason that all six of these functions have separate names, by the way,  is that before computers and calculators, if you were doing trigonometry,  maybe because you're a sailor, or an astronomer, or some kind of engineer,  you'd find the values for these functions using large charts that just recorded  known input-output pairs. And when you can't easily plug in something like 1 divided by the  sine of 30 degrees into a calculator, it might actually make sense  to have a dedicated column to this value, with a dedicated name. And if you have a diagram like this one in mind when you're taking measurements,  with sine, tangent, and secant having nicely mirrored meanings to cosine, cotangent,  and cosecant, calling this cosecant instead of 1 divided by sine might actually make  some sense, and it might actually make it easier to remember what it means geometrically. But times have changed, and most use cases for trig just  don't involve charts of values and diagrams like this. Hence, the cosecant and its brothers are tattoos on math,  ideas whose permanence in our conventions is our own doing,  not the result of nature itself. And in general, I actually think this is a good lesson for  any student learning a new piece of math, at whatever level. You just gotta take a moment and ask yourself whether what you're  learning is core to the flesh of math itself, and to nature itself,  or if what you're looking at is actually just inked on to the subject,  and could just as easily have been inked on in some completely other way.

================================================================================
VIDEO ID: sD0NjbwqlYw
TITLE: But what is the Riemann zeta function? Visualizing analytic continuation
URL: https://www.youtube.com/watch?v=sD0NjbwqlYw
PUBLISHED: 2016-12-09T17:50:56Z
STATUS: SUCCESS
================================================================================
The Riemann zeta function. This is one of those objects in modern math that a lot of you might have heard of,  but which can be really difficult to understand. Don't worry, I'll explain that animation that you just saw in a few minutes. A lot of people know about this function because there's a one  million dollar prize out for anyone who can figure out when it equals zero,  an open problem known as the Riemann hypothesis. Some of you may have heard of it in the context of the  divergent sum 1 plus 2 plus 3 plus 4 on and on up to infinity. You see, there's a sense in which this sum equals negative 1 twelfth,  which seems nonsensical if not obviously wrong. But a common way to define what this equation is  actually saying uses the Riemann zeta function. But as any casual math enthusiast who started to read into this knows,  its definition references this one idea called analytic continuation,  which has to do with complex valued functions. And this idea can be frustratingly opaque and unintuitive. So what I'd like to do here is just show you all what this zeta  function actually looks like, and to explain what this idea of  analytic continuation is in a visual and more intuitive way. I'm assuming that you know about complex numbers,  and that you're comfortable working with them. And I'm tempted to say that you should know calculus,  since analytic continuation is all about derivatives,  but for the way I'm planning to present things I think you might  actually be fine without that. So to jump right into it, let's just define what this zeta function is. For a given input, where we commonly use the variable s,  the function is 1 over 1 to the s, which is always 1, plus 1 over 2 to the s,  plus 1 over 3 to the s, plus 1 over 4 to the s, on and on and on,  summing up over all natural numbers. So for example, let's say you plug in a value like s equals 2. You'd get 1 plus 1 over 4 plus 1 over 9 plus 1 sixteenth,  and as you keep adding more and more reciprocals of squares,  this just so happens to approach pi squared over 6, which is around 1.645. There's a very beautiful reason for why pi shows up here,  and I might do a video on it at a later date, but that's just the tip of the iceberg for  why this function is beautiful. You could do the same thing for other inputs s,  like 3 or 4, and sometimes you get other interesting values. And so far, everything feels pretty reasonable. You're adding up smaller and smaller amounts, and these sums approach some number. Great, no craziness here. Yet, if you were to read about it, you might see some  people say that zeta of negative 1 equals negative 1 twelfth. But looking at this infinite sum, that doesn't make any sense. When you raise each term to the negative 1, flipping each fraction,  you get 1 plus 2 plus 3 plus 4 on and on over all natural numbers. And obviously that doesn't approach anything, certainly not negative 1 twelfth, right? And, as any mercenary looking into the Riemann hypothesis knows,  this function is said to have trivial zeros at negative even numbers. So for example, that would mean that zeta of negative 2 equals 0. But when you plug in negative 2, it gives you 1 plus 4 plus 9 plus 16 on and on,  which again obviously doesn't approach anything, much less 0, right? Well, we'll get to negative values in a few minutes,  but for right now, let's just say the only thing that seems reasonable. This function only makes sense when s is greater than 1, which is when this sum converges. So far, it's simply not defined for other values. Now, with that said, Bernard Riemann was somewhat of a father to complex analysis,  which is the study of functions that have complex numbers as inputs and outputs. So rather than just thinking about how this sum takes a number s on the  real number line to another number on the real number line,  his main focus was on understanding what happens when you plug in a complex value for s. So for example, maybe instead of plugging in 2, you would plug in 2 plus i. Now, if you've never seen the idea of raising a number to the power of a complex value,  it can feel kind of strange at first, because it no longer has  anything to do with repeated multiplication. But mathematicians found that there is a very nice and very natural  way to extend the definition of exponents beyond their familiar  territory of real numbers and into the realm of complex values. It's not super crucial to understand complex exponents for where I'm going with  this video, but I think it'll still be nice if we just summarize the gist of it here. The basic idea is that when you write something like 1 half to the power of a complex  number, you split it up as 1 half to the real part times 1 half to the pure imaginary  part. We're good on 1 half to the real part, there's no issues there. But what about raising something to a pure imaginary number? Well, the result is going to be some complex number  on the unit circle in the complex plane. As you let that pure imaginary input walk up and down the imaginary line,  the resulting output walks around that unit circle. For a base like 1 half, the output walks around the unit circle somewhat slowly. But for a base that's farther away from 1, like 1 ninth,  then as you let this input walk up and down the imaginary axis,  the corresponding output is going to walk around the unit circle more quickly. If you've never seen this and you're wondering why on earth this happens,  I've left a few links to good resources in the description. For here, I'm just going to move forward with the what without the why. The main takeaway is that when you raise something like 1 half to the power of 2 plus i,  which is 1 half squared times 1 half to the i,  that 1 half to the i part is going to be on the unit circle,  meaning it has an absolute value of 1. So when you multiply it, it doesn't change the size of the number,  it just takes that 1 fourth and rotates it somewhat. So, if you were to plug in 2 plus i to the zeta function,  one way to think about what it does is to take the 1 half to the i part and  think about what it does is to start off with all of the terms raised to the power of 2,  which you can think of as piecing together lines whose lengths are the  reciprocals of squares of numbers, which, like I said before,  converges to pi squared over 6. Then when you change that input from 2 up to 2 plus i,  each of these lines gets rotated by some amount. But importantly, the lengths of those lines won't change, so the sum still converges,  it just does so in a spiral to some specific point on the complex plane. Here, let me show what it looks like when I vary the input s,  represented with this yellow dot on the complex plane,  where this spiral sum is always going to be showing the converging value for zeta of s. What this means is that zeta of s, defined as this infinite sum,  is a perfectly reasonable complex function as long as the real part of the input  is greater than 1, meaning the input s sits somewhere on this right half of the  complex plane. Again, this is because it's the real part of s that determines the size of each number,  while the imaginary part just dictates some rotation. So now what I want to do is visualize this function. It takes in inputs on the right half of the complex plane  and spits out outputs somewhere else in the complex plane. A super nice way to understand complex functions is to visualize them as transformations,  meaning you look at every possible input to the function and just  let it move over to the corresponding output. For example, let's take a moment and try to visualize  something a little bit easier than the zeta function. Say f of s is equal to s squared. When you plug in s equals 2, you get 4, so we'll  end up moving that point at 2 over to the point at 4. When you plug in negative 1, you get 1, so the point over here  at negative 1 is going to end up moving over to the point at 1. When you plug in i, by definition its square is negative 1,  so it's going to move over here to negative 1. Now I'm going to add on a more colorful grid, and this is just  because things are about to start moving, and it's kind of nice  to have something to distinguish grid lines during that movement. From here, I'll tell the computer to move every single point on this grid  over to its corresponding output under the function f of s equals s squared. Here's what it looks like. That can be a lot to take in, so I'll go ahead and play it again. And this time, focus on one of the marked points,  and notice how it moves over to the point corresponding to its square. It can be a little complicated to see all of the points moving all at once,  but the reward is that this gives us a very rich picture for what the  complex function is actually doing, and it all happens in just two dimensions. So, back to the zeta function. We have this infinite sum, which is a function of some complex number s,  and we feel good and happy about plugging in values of s whose real part is  greater than 1, and getting some meaningful output via the converging spiral sum. So to visualize this function, I'm going to take the portion of the grid sitting on the  right side of the complex plane here, where the real part of numbers is greater than 1,  and I'm going to tell the computer to move each point of this grid to the appropriate  output. It actually helps if I add a few more grid lines around the number 1,  since that region gets stretched out by quite a bit. Alright, so first of all, let's all just appreciate how beautiful that is. I mean, damn, if that doesn't make you want to learn more about complex functions,  you have no heart. But also, this transformed grid is just begging to be extended a little bit. For example, let's highlight these lines here,  which represent all of the complex numbers with imaginary part i, or negative i. After the transformation, these lines make such  lovely arcs before they just abruptly stop. Don't you want to just, you know, continue those arcs? In fact, you can imagine how some altered version of the function,  with a definition that extends into this left half of the plane,  might be able to complete this picture with something that's quite pretty. Well, this is exactly what mathematicians working with complex functions do. They continue the function beyond the original domain where it was defined. Now, as soon as we branch over into inputs where the real part is less than 1,  this infinite sum that we originally used to define the function doesn't make sense  anymore. You'll get nonsense, like adding 1 plus 2 plus 3 plus 4 on and on up to infinity. But just looking at this transformed version of the right half of the plane,  where the sum does make sense, it's just begging us to extend  the set of points that we're considering as inputs. Even if that means defining the extended function  in some way that doesn't necessarily use that sum. Of course, that leaves us with the question, how  would you define that function on the rest of the plane? You might think that you could extend it any number of ways. Maybe you define an extension that makes it so the point at,  say, s equals negative 1 moves over to negative 1 twelfth. But maybe you squiggle on some extension that makes it land on any other value. I mean, as soon as you open yourself up to the idea of defining the function differently  for values outside that domain of convergence, that is, not based on this infinite sum,  the world is your oyster, and you can have any number of extensions, right? Well, not exactly. I mean, yes, you can give any child a marker and have them extend these lines any  which way, but if you add on the restriction that this new extended function has to  have a derivative everywhere, it locks us into one and only one possible extension. I know, I know, I said that you wouldn't need to know about derivatives for this video,  and even if you do know calculus, maybe you have yet to learn how  to interpret derivatives for complex functions. But luckily for us, there is a very nice geometric intuition that you  can keep in mind for when I say a phrase like, has a derivative everywhere. Here, to show you what I mean, let's look back at that f of s equals s squared example. Again, we think of this function as a transformation,  moving every point s of the complex plane over to the point s squared. For those of you who know calculus, you know that you can take the derivative  of this function at any given input, but there's an interesting property of that  transformation that turns out to be related and almost equivalent to that fact. If you look at any two lines in the input space that intersect at some angle,  and consider what they turn into after the transformation,  they will still intersect each other at that same angle. The lines might get curved, and that's okay, but the important  part is that the angle at which they intersect remains unchanged,  and this is true for any pair of lines that you choose. So when I say a function has a derivative everywhere,  I want you to think about this angle-preserving property,  that any time two lines intersect, the angle between them remains  unchanged after the transformation. At a glance, this is easiest to appreciate by noticing how all of the curves  that the grid lines turn into still intersect each other at right angles. Complex functions that have a derivative everywhere are called analytic,  so you can think of this term analytic as meaning angle-preserving. Admittedly, I'm lying to you a little here, but only a little bit. A slight caveat for those of you who want the full details is  that at inputs where the derivative of a function is zero,  instead of angles being preserved, they get multiplied by some integer. But those points are by far the minority, and for almost  all inputs to an analytic function, angles are preserved. So if when I say analytic, you think angle-preserving,  I think that's a fine intuition to have. Now, if you think about it for a moment, and this is a point that  I really want you to appreciate, this is a very restrictive property. The angle between any pair of intersecting lines has to remain unchanged. And yet, pretty much any function out there that has a name turns out to be analytic. The field of complex analysis, which Riemann helped to establish in its modern form,  is almost entirely about leveraging the properties of analytic functions to  understand results and patterns in other fields of math and science. The zeta function, defined by this infinite sum on the right half of the plane,  is an analytic function. Notice how all of these curves that the grid lines  turn into still intersect each other at right angles. So the surprising fact about complex functions is that if you want to extend an  analytic function beyond the domain where it was originally defined, for example,  extending this zeta function into the left half of the plane,  then if you require that the new extended function still be analytic, that is,  that it still preserves angles everywhere, it forces you into only one possible  extension, if one exists at all. It's kind of like an infinite continuous jigsaw puzzle,  where this requirement of preserving angles locks you into one and only one choice  for how to extend it. This process of extending an analytic function in the only way possible that's  still analytic is called, as you may have guessed, analytic continuation. So that's how the full Riemann zeta function is defined. For values of s on the right half of the plane, where the real part is greater than 1,  we can plug them into this sum and see where it converges. And that convergence might look like some kind of spiral,  since raising each of these terms to a complex power has the effect of rotating each one. Then for the rest of the plane, we know that there exists one and only  one way to extend this definition so that the function will still be analytic,  that is, so that it still preserves angles at every single point. So we just say that by definition, the zeta function on the  left half of the plane is whatever that extension happens to be. And that's a valid definition because there's only one possible analytic continuation. Notice, that's a very implicit definition. It just says, use the solution of this jigsaw puzzle,  which through more abstract derivation we know must exist,  but it doesn't specify exactly how to solve it. Mathematicians have a pretty good grasp on what this extension looks like,  but some important parts of it remain a mystery. A million dollar mystery, in fact. Let's actually take a moment and talk about the Riemann hypothesis,  which is a million dollar problem. The places where this function equals zero turn out to be quite important,  that is, which points get mapped onto the origin after the transformation. One thing we know about this extension is that  the negative even numbers get mapped to zero. These are commonly called the trivial zeros. The naming here stems from a long-standing tradition of mathematicians  to call things trivial when they understand it quite well,  even when it's a fact that is not at all obvious from the outset. We also know that the rest of the points that get mapped to zero sit somewhere  in this vertical strip, called the critical strip,  and the specific placement of those non-trivial zeros encodes a surprising  information about prime numbers. It's actually pretty interesting why this function carries so much information  about primes, and I definitely think I'll make a video about that later on,  but right now things are long enough, so I'll leave it unexplained. Riemann hypothesized that all of these non-trivial zeros sit right in the  middle of the strip, on the line of numbers s, whose real part is one half. This is called the critical line. If that's true, it gives us a remarkably tight grasp on the pattern of prime numbers,  as well as many other patterns in math that stem from this. Now, so far, when I've shown what the zeta function looks like,  I've only shown what it does to the portion of the grid on the screen,  and that kind of undersells its complexity. So if I were to highlight this critical line and apply the transformation,  it might not seem to cross the origin at all. However, here's what the transformed version of more and more of that line looks like. Notice how it's passing through the number zero many, many times. If you can prove that all of the non-trivial zeros sit somewhere on this line,  the Clay Math Institute gives you one million dollars. And you'd also be proving hundreds, if not thousands,  of modern math results that have already been shown contingent on this  hypothesis being true. Another thing we know about this extended function is that  it maps the point negative one over to negative one twelfth. And if you plug this into the original sum, it looks like we're saying one plus  two plus three plus four, on and on up to infinity, equals negative one twelfth. Now, it might seem disingenuous to still call this a sum,  since the definition of the zeta function on the left half of the plane is not defined  directly from this sum. Instead, it comes from analytically continuing  the sum beyond the domain where it converges. That is, solving the jigsaw puzzle that began on the first line of the line,  solving the jigsaw puzzle that began on the right half of the plane. That said, you have to admit that the uniqueness of this analytic continuation,  the fact that the jigsaw puzzle has only one solution,  is very suggestive of some intrinsic connection between these extended values  and the original sum.

================================================================================
VIDEO ID: bdMfjfT0lKk
TITLE: Binary, Hanoi, and Sierpinski, part 2
URL: https://www.youtube.com/watch?v=bdMfjfT0lKk
PUBLISHED: 2016-11-25T17:30:46Z
STATUS: SUCCESS
================================================================================
Today, I want to share with you a neat way to solve the Towers  of Hanoi puzzle just by counting in a different number system. And surprisingly, this stuff relates to finding a curve that fills Sierpinski's triangle. I learned about this from a former CS lecturer of mine, his name's Keith Schwartz,  and I've gotta say, this man is one of the best educators I've ever met. I actually recorded a bit of the conversation where he showed me this stuff,  so you guys can hear some of what he described directly. In case you're unfamiliar, let's just lay down  what the Towers of Hanoi puzzle actually is. So you have a collection of three pegs, and you have these disks of descending size. You think of these disks as having a hole in the  middle so that you can fit them onto a peg. The setup pictured here has five disks, which I'll label 0, 1, 2,  3, 4, but in principle, you could have as many disks as you want. So they all start up stacked up from biggest to smallest on one spindle,  and the goal is to move the entire tower from one spindle to another. The rule is you can only move one disk at a time,  and you can't move a bigger disk on top of a smaller disk. For example, your first move must involve moving disk 0,  since any other disk has stuff on top of it that needs to get out of the way  before it can move. After that, you can move disk 1, but it has to go on whatever  peg doesn't currently have disk 0, since otherwise you'd be  putting a bigger disk on a smaller one, which isn't allowed. If you've never seen this before, I highly encourage you to pause  and pull out some books of varying sizes and try it out for yourself. Just kind of get a feel for what the puzzle is, if it's hard,  why it's hard, if it's not, why it's not, that kind of stuff. Now Keith showed me something truly surprising about this puzzle,  which is that you can solve it just by counting up in binary and  associating the rhythm of that counting with a certain rhythm of disk movements. For anyone unfamiliar with binary, I'm going to  take a moment to do a quick overview here first. Actually, even if you are familiar with binary,  I want to explain it with a focus on the rhythm of counting,  which you may or may not have thought about before. Any description of binary typically starts off with an introspection  about our usual way to represent numbers, what we call base 10,  since we use 10 separate digits, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9. The rhythm of counting begins by walking through all 10 of these digits. Then, having run out of new digits, you express the next number,  10, with two digits, 1, 0. You say that 1 is in the tens place, since it's meant to encapsulate the group of 10  that you've already counted up to so far, while freeing the ones place to reset to 0. The rhythm of counting repeats like this, counting up 9,  rolling over to the tens place, counting up 9 more, rolling over to the tens place, etc. Until, after repeating that process 9 times, you roll over to a hundreds place,  a digit that keeps track of how many groups of 100 you've hit,  freeing up the other two digits to reset to 0. In this way, the rhythm of counting is kind of self-similar. Even if you zoom out to a larger scale, the process looks like doing something,  rolling over, doing that same thing, rolling over,  and repeating 9 times before an even larger rollover. In binary, also known as base-2, you limit yourself to two digits,  0 and 1, commonly called bits, which is short for binary digits. The result is that when you're counting, you have to roll over all the time. After counting 01, you've already run out of bits,  so you need to roll over to a twos place, writing 10,  and resisting every urge in your base-10 trained brain to read this as 10,  and instead understand it to mean 1 group of 2 plus 0. Then increment up to 11, which represents 3, and already you have to roll over again,  and since there's a 1 in that twos place, that has to roll over as well,  giving you 100, which represents 1 group of 4 plus 0 groups of 2 plus 0. In the same way that digits in base-10 represent powers of 10,  bits in base-2 represent different powers of 2, so instead of a tens place,  a hundreds place, a thousands place, you talk about a twos place, a fours place,  and an eights place. The rhythm of counting is now a lot faster, but that almost makes it more noticeable. Again, there's a certain self-similarity to this pattern. At every scale, the process is to do something, roll over, then do that same thing again. At the small scale, say counting up to 3, which is 11 in binary,  this means flip the last bit, roll over to the twos, then flip the last bit. At a larger scale, like counting up to 15, which is 1111 in binary,  the process is to let the last 3 count up to 7,  roll over to the eights place, then let the last 3 bits count up again. Counting up to 255, which is 8 successive ones,  this looks like letting the last 7 bits count up till they're full,  rolling over to the 128th place, then letting the last 7 bits count up again. Alright, so with that mini-introduction, the surprising fact that Keith  showed me is that we can use this rhythm to solve the towers of Hanoi. You start by counting from 0. Whenever you're only flipping that last bit, from a 0 to a 1,  move disk 0 one peg to the right. If it was already on the right-most peg, you just loop it back to the first peg. If, in your binary counting, you roll over once to the twos place,  meaning you flip the last two bits, you move disk number 1. Where do you move it, you might ask? Well, you have no choice. You can't put it on top of disk 0, and there's only one other peg,  so you move it where you're forced to move it. So after this, counting up to 1,1, that involves just flipping the last bit,  so you move disk 0 again. Then when your binary counting rolls over twice to the fours place,  move disk number 2, and the pattern continues like this. Flip the last, move disk 0. Flip the last two, move disk 1. Flip the last, move disk 0. And here, we're going to have to roll over three times to the eights place,  and that corresponds to moving disk number 3. There's something magical about it. When I first saw this, I was like, this can't work. I don't know how this works, I don't know why this works. Now I know, but it's just magical when you see it. I remember putting together an animation for this when I was teaching this,  and just like, I know how this works. I know all the things in it. It's still fun to just sit and just watch it play out. Oh yeah. I mean, it's not even clear at first that this is always going to give legal moves. For example, how do you know that every time you're rolling over to the eights place,  that disk 3 is necessarily going to be freed up to move? At the same time, the solution just immediately raises these questions like,  where does this come from, why does this work,  and is there a better way of doing this than having to do 2 to the n minus 1 steps? It turns out, not only does this solve Towers of Hanoi,  but it does it in the most efficient way possible. Understanding why this works and how it works and what the heck is going on comes down  to a certain perspective on the puzzle, what CS folk might call a recursive perspective. Disk 3 is thinking, okay, 2, 1, and 0, you have to get off of me. I can't really function under this much weight and pressure. And so just from disk 3's perspective, if you want to figure out how is disk 3 going  to get over here, somehow, I don't care how, disk 2, 1, and 0 have to get to spindle B. That's the only way it can move. If any of these disks are on top of 3, it can't move. If any of them are in spindle C, it can't move there. So somehow we have to get 2, 1, and 0 off. Having done that, then we can move disk 3 over there. And then disk 3 says, I'm set. You never need to move me again. Everyone else just figure out how to get here. And in a sense, you now have a smaller version of the same problem. Now you've got disk 0, 1, and 2 sitting on spindle B, you've got to get them to C. So the idea is that if I just focus on one disk and I think  about what am I going to have to do to get this disk to work,  I can turn my bigger problem into something slightly smaller. And then how do I solve that? Well, it's exactly the same thing. Disk 2 is going to say, disk 1, disk 0, it's not you, it's me. I just need some space. Get off. They need to move somewhere. Then disk 2 can move to where it needs to go. Then disk 1 and 0 can do this. But the interesting point is that every single  disk pretty much has the exact same strategy. They all say, everybody above me, get off. Then I'm going to move, OK, everyone pile back on. When you know that insight, you can code up something that will solve Towers of Hanoi,  like five or six lines of code, which probably has the highest ratio  of intellectual investment to lines of code ever. And if you think about it for a bit, it becomes  clear that this has to be the most efficient solution. At every step, you're only doing what's forced upon you. You have to get disk 0 through 2 off before you can move disk 3. And you have to move disk 3. And then you have to move disk 0 through 2 back onto it. There's just not any room for inefficiency from this perspective. So why does counting in binary capture this algorithm? Well, what's going on here is that this pattern of solving a subproblem,  moving a big disk, then solving a subproblem again,  is perfectly paralleled by the pattern of binary counting. Count up some amount, roll over, count up to that same amount again. And this Towers of Hanoi algorithm and binary counting are both self-similar processes,  in the sense that if you zoom out and count up to a larger power of 2,  or solve Towers of Hanoi with more disks, they both still have that same structure. Subproblem, do a thing, subproblem. For example, at a pretty small scale, solving Towers of Hanoi for two disks,  move disk 0, move disk 1, move disk 0, is reflected by counting up to 3 in binary. Flip the last bit, roll over once, flip the last bit. At a slightly larger scale, solving Towers of Hanoi for three  disks looks like doing whatever it takes to solve two disks,  move disk number 2, then do whatever it takes to solve two disks again. Analogously, counting up to 111 in binary involves counting up to 3,  rolling over all three bits, and counting up three more. At all scales, both processes have this same breakdown. So in a sense, the reason that this binary solution works, or at least an explanation,  I feel like there's no one explanation, but I think the most natural one is that  the pattern you would use to generate these binary numbers has exactly the same  structure as the pattern you would use for Towers of Hanoi,  which is why if you look at the bits flipping, you're effectively reversing this process. You're saying, what process generated these? If I were trying to understand how these bits were flipped to give me this thing,  you're effectively reverse engineering the recursive algorithm for Towers of Hanoi,  which is why it works out. That's pretty cool, right? But it actually gets cooler. I haven't even gotten to how this relates to Sierpinski's triangle. And that's exactly what I'm going to do in the follow-on video, part 2. Many thanks to everybody who's supporting these videos on Patreon. I just finished the first chapter of Essence of Calculus,  and I'm working on the second one right now, and Patreon supporters are  getting early access to these videos before I publish the full series in a few months. This video and the next one are also supported in part by Desmos,  and before the next video I just want to take a moment and share with  you guys a little about who they are and the fact that they're hiring. So Desmos is actually really cool. They make a lot of these interactive math activities  for classrooms and tools for teachers. The real meat of their offering is in their classroom activities. For my part, I'm super impressed by just how well-thought-out  these activities are from a pedagogical standpoint. The team clearly knows their stuff, and they know where they  stand to make a difference in students' and teachers' lives. And like I said, they're hiring. They are always looking to bring in more good talent, whether that's engineering talent,  designers, teachers, or whatever other skill sets line up with what they want to do. If any of you out there are interested in joining them,  helping them make some of these great tools for teachers and students,  you can check out the careers page I've linked in the description. Personally, I think they're doing some really meaningful stuff. I think their activities are building genuinely good math intuitions for students,  and the world could use a few more talented people pointing  their efforts towards education the way they do. Alright so with that, I'll see you guys next video,  and I think you're really going to like where this is going.

================================================================================
VIDEO ID: 2SUvWfNJSsM
TITLE: Binary, Hanoi and Sierpinski, part 1
URL: https://www.youtube.com/watch?v=2SUvWfNJSsM
PUBLISHED: 2016-11-25T17:30:20Z
STATUS: SUCCESS
================================================================================
Today, I want to share with you a neat way to solve the Towers  of Hanoi puzzle just by counting in a different number system. And surprisingly, this stuff relates to finding a curve that fills Sierpinski's triangle. I learned about this from a former CS lecturer of mine, his name's Keith Schwartz,  and I've gotta say, this man is one of the best educators I've ever met. I actually recorded a bit of the conversation where he showed me this stuff,  so you guys can hear some of what he described directly. In case you're unfamiliar, let's just lay down  what the Towers of Hanoi puzzle actually is. So you have a collection of three pegs, and you have these disks of descending size. You think of these disks as having a hole in the  middle so that you can fit them onto a peg. The setup pictured here has five disks, which I'll label 0, 1, 2,  3, 4, but in principle, you could have as many disks as you want. So they all start up stacked up from biggest to smallest on one spindle,  and the goal is to move the entire tower from one spindle to another. The rule is you can only move one disk at a time,  and you can't move a bigger disk on top of a smaller disk. For example, your first move must involve moving disk 0,  since any other disk has stuff on top of it that needs to get out of the way  before it can move. After that, you can move disk 1, but it has to go on whatever  peg doesn't currently have disk 0, since otherwise you'd be  putting a bigger disk on a smaller one, which isn't allowed. If you've never seen this before, I highly encourage you to pause  and pull out some books of varying sizes and try it out for yourself. Just kind of get a feel for what the puzzle is, if it's hard,  why it's hard, if it's not, why it's not, that kind of stuff. Now Keith showed me something truly surprising about this puzzle,  which is that you can solve it just by counting up in binary and  associating the rhythm of that counting with a certain rhythm of disk movements. For anyone unfamiliar with binary, I'm going to  take a moment to do a quick overview here first. Actually, even if you are familiar with binary,  I want to explain it with a focus on the rhythm of counting,  which you may or may not have thought about before. Any description of binary typically starts off with an introspection  about our usual way to represent numbers, what we call base 10,  since we use 10 separate digits, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9. The rhythm of counting begins by walking through all 10 of these digits. Then, having run out of new digits, you express the next number,  10, with two digits, 1, 0. You say that 1 is in the tens place, since it's meant to encapsulate the group of 10  that you've already counted up to so far, while freeing the ones place to reset to 0. The rhythm of counting repeats like this, counting up 9,  rolling over to the tens place, counting up 9 more, rolling over to the tens place, etc. Until, after repeating that process 9 times, you roll over to a hundreds place,  a digit that keeps track of how many groups of 100 you've hit,  freeing up the other two digits to reset to 0. In this way, the rhythm of counting is kind of self-similar. Even if you zoom out to a larger scale, the process looks like doing something,  rolling over, doing that same thing, rolling over,  and repeating 9 times before an even larger rollover. In binary, also known as base-2, you limit yourself to two digits,  0 and 1, commonly called bits, which is short for binary digits. The result is that when you're counting, you have to roll over all the time. After counting 01, you've already run out of bits,  so you need to roll over to a twos place, writing 10,  and resisting every urge in your base-10 trained brain to read this as 10,  and instead understand it to mean 1 group of 2 plus 0. Then increment up to 11, which represents 3, and already you have to roll over again,  and since there's a 1 in that twos place, that has to roll over as well,  giving you 100, which represents 1 group of 4 plus 0 groups of 2 plus 0. In the same way that digits in base-10 represent powers of 10,  bits in base-2 represent different powers of 2, so instead of a tens place,  a hundreds place, a thousands place, you talk about a twos place, a fours place,  and an eights place. The rhythm of counting is now a lot faster, but that almost makes it more noticeable. Again, there's a certain self-similarity to this pattern. At every scale, the process is to do something, roll over, then do that same thing again. At the small scale, say counting up to 3, which is 11 in binary,  this means flip the last bit, roll over to the twos, then flip the last bit. At a larger scale, like counting up to 15, which is 1111 in binary,  the process is to let the last 3 count up to 7,  roll over to the eights place, then let the last 3 bits count up again. Counting up to 255, which is 8 successive ones,  this looks like letting the last 7 bits count up till they're full,  rolling over to the 128th place, then letting the last 7 bits count up again. Alright, so with that mini-introduction, the surprising fact that Keith  showed me is that we can use this rhythm to solve the towers of Hanoi. You start by counting from 0. Whenever you're only flipping that last bit, from a 0 to a 1,  move disk 0 one peg to the right. If it was already on the right-most peg, you just loop it back to the first peg. If, in your binary counting, you roll over once to the twos place,  meaning you flip the last two bits, you move disk number 1. Where do you move it, you might ask? Well, you have no choice. You can't put it on top of disk 0, and there's only one other peg,  so you move it where you're forced to move it. So after this, counting up to 1,1, that involves just flipping the last bit,  so you move disk 0 again. Then when your binary counting rolls over twice to the fours place,  move disk number 2, and the pattern continues like this. Flip the last, move disk 0. Flip the last two, move disk 1. Flip the last, move disk 0. And here, we're going to have to roll over three times to the eights place,  and that corresponds to moving disk number 3. There's something magical about it. When I first saw this, I was like, this can't work. I don't know how this works, I don't know why this works. Now I know, but it's just magical when you see it. I remember putting together an animation for this when I was teaching this,  and just like, I know how this works. I know all the things in it. It's still fun to just sit and just watch it play out. Oh yeah. I mean, it's not even clear at first that this is always going to give legal moves. For example, how do you know that every time you're rolling over to the eights place,  that disk 3 is necessarily going to be freed up to move? At the same time, the solution just immediately raises these questions like,  where does this come from, why does this work,  and is there a better way of doing this than having to do 2 to the n minus 1 steps? It turns out, not only does this solve Towers of Hanoi,  but it does it in the most efficient way possible. Understanding why this works and how it works and what the heck is going on comes down  to a certain perspective on the puzzle, what CS folk might call a recursive perspective. Disk 3 is thinking, okay, 2, 1, and 0, you have to get off of me. I can't really function under this much weight and pressure. And so just from disk 3's perspective, if you want to figure out how is disk 3 going  to get over here, somehow, I don't care how, disk 2, 1, and 0 have to get to spindle B. That's the only way it can move. If any of these disks are on top of 3, it can't move. If any of them are in spindle C, it can't move there. So somehow we have to get 2, 1, and 0 off. Having done that, then we can move disk 3 over there. And then disk 3 says, I'm set. You never need to move me again. Everyone else just figure out how to get here. And in a sense, you now have a smaller version of the same problem. Now you've got disk 0, 1, and 2 sitting on spindle B, you've got to get them to C. So the idea is that if I just focus on one disk and I think  about what am I going to have to do to get this disk to work,  I can turn my bigger problem into something slightly smaller. And then how do I solve that? Well, it's exactly the same thing. Disk 2 is going to say, disk 1, disk 0, it's not you, it's me. I just need some space. Get off. They need to move somewhere. Then disk 2 can move to where it needs to go. Then disk 1 and 0 can do this. But the interesting point is that every single  disk pretty much has the exact same strategy. They all say, everybody above me, get off. Then I'm going to move, OK, everyone pile back on. When you know that insight, you can code up something that will solve Towers of Hanoi,  like five or six lines of code, which probably has the highest ratio  of intellectual investment to lines of code ever. And if you think about it for a bit, it becomes  clear that this has to be the most efficient solution. At every step, you're only doing what's forced upon you. You have to get disk 0 through 2 off before you can move disk 3. And you have to move disk 3. And then you have to move disk 0 through 2 back onto it. There's just not any room for inefficiency from this perspective. So why does counting in binary capture this algorithm? Well, what's going on here is that this pattern of solving a subproblem,  moving a big disk, then solving a subproblem again,  is perfectly paralleled by the pattern of binary counting. Count up some amount, roll over, count up to that same amount again. And this Towers of Hanoi algorithm and binary counting are both self-similar processes,  in the sense that if you zoom out and count up to a larger power of 2,  or solve Towers of Hanoi with more disks, they both still have that same structure. Subproblem, do a thing, subproblem. For example, at a pretty small scale, solving Towers of Hanoi for two disks,  move disk 0, move disk 1, move disk 0, is reflected by counting up to 3 in binary. Flip the last bit, roll over once, flip the last bit. At a slightly larger scale, solving Towers of Hanoi for three  disks looks like doing whatever it takes to solve two disks,  move disk number 2, then do whatever it takes to solve two disks again. Analogously, counting up to 111 in binary involves counting up to 3,  rolling over all three bits, and counting up three more. At all scales, both processes have this same breakdown. So in a sense, the reason that this binary solution works, or at least an explanation,  I feel like there's no one explanation, but I think the most natural one is that  the pattern you would use to generate these binary numbers has exactly the same  structure as the pattern you would use for Towers of Hanoi,  which is why if you look at the bits flipping, you're effectively reversing this process. You're saying, what process generated these? If I were trying to understand how these bits were flipped to give me this thing,  you're effectively reverse engineering the recursive algorithm for Towers of Hanoi,  which is why it works out. That's pretty cool, right? But it actually gets cooler. I haven't even gotten to how this relates to Sierpinski's triangle. And that's exactly what I'm going to do in the follow-on video, part 2. Many thanks to everybody who's supporting these videos on Patreon. I just finished the first chapter of Essence of Calculus,  and I'm working on the second one right now, and Patreon supporters are  getting early access to these videos before I publish the full series in a few months. This video and the next one are also supported in part by Desmos,  and before the next video I just want to take a moment and share with  you guys a little about who they are and the fact that they're hiring. So Desmos is actually really cool. They make a lot of these interactive math activities  for classrooms and tools for teachers. The real meat of their offering is in their classroom activities. For my part, I'm super impressed by just how well-thought-out  these activities are from a pedagogical standpoint. The team clearly knows their stuff, and they know where they  stand to make a difference in students' and teachers' lives. And like I said, they're hiring. They are always looking to bring in more good talent, whether that's engineering talent,  designers, teachers, or whatever other skill sets line up with what they want to do. If any of you out there are interested in joining them,  helping them make some of these great tools for teachers and students,  you can check out the careers page I've linked in the description. Personally, I think they're doing some really meaningful stuff. I think their activities are building genuinely good math intuitions for students,  and the world could use a few more talented people pointing  their efforts towards education the way they do. Alright so with that, I'll see you guys next video,  and I think you're really going to like where this is going.

================================================================================
VIDEO ID: R7p-nPg8t_g
TITLE: 3blue1brown channel trailer
URL: https://www.youtube.com/watch?v=R7p-nPg8t_g
PUBLISHED: 2016-11-25T17:29:36Z
STATUS: SUCCESS
================================================================================
Hey there, welcome to 3Blue1Brown. So, I make videos that animate math. For a lot of them, I just try to find something kinda interesting or thought provoking, not necessarily in the typical progression of subjects that a student would see in school. To see what I mean there, check out some of the Recommended playlist. Some of the channel, though, is more directly targeted at people actually trying to learn a commonly taught subject. For an example of what I mean there, check out the Essence of Linear Algebra series that I did. I'll always be working on some other 'Essence of' series like this, so stay posted for more. Now, when I say that these videos animate math, on the one hand, I mean that very directly; things are explained with moving visuals and anthropomorphic kinda-cartoonish pi creatures, but my hope here is that they animate math in another, more literal sense of giving life to the subject. Math kinda gets a bad rap for being abstruse and inhuman, and let's face it, a lot of it is symbol heavy and can be introduced in a pretty unmotivated way. But the fact is, good math is nothing less than art. I'm guessing a lot of you out there know that feeling when you wrap your mind around a really clever argument and it's got that very unique flavour of satisfaction. And same goes for re-understanding something familiar, but in a novel or unexpected light. Here, I'm just trying to do my part to share feelings like those with more people. So take a look at some of the videos here, and if you want to stay posted about new stuff, or to just see new videos rather than this trailer whenever you come back to the page, consider subscribing.

================================================================================
VIDEO ID: AmgkSdhK4K8
TITLE: Who cares about topology?   (Old version)
URL: https://www.youtube.com/watch?v=AmgkSdhK4K8
PUBLISHED: 2016-11-04T21:48:23Z
STATUS: SUCCESS
================================================================================
I've got several fun things for you this video. An unsolved problem, a very elegant solution to a weaker version of the problem,  and a little bit about what topology is and why people care. But before I jump into it, it's worth saying a  few words on why I'm excited to share this solution. When I was a kid, since I loved math and sought out various mathy things,  I would occasionally find myself in some talk or a seminar where people  wanted to get the youth excited about things that mathematicians care about. A very common go-to topic to excite our imaginations was topology. We might be shown something like a mobius strip,  maybe building it out of construction paper by twisting a rectangle and gluing its ends. Look, we'd be told, as we were asked to draw a line along the surface. It's a surface with just one side. Or we might be told that topologists view coffee mugs and donuts as the same thing,  since each has just one hole. But these kinds of demos always left a lurking question. How is this math? How does any of this actually help to solve problems? It wasn't until I saw the problem that I'm about to show you,  with its elegant and surprising solution, that I started to understand why  mathematicians actually care about some of these shapes and the properties they have. So, there's this unsolved problem called the inscribed square problem. If you have a closed loop, meaning you squiggle some line through space in a  potentially crazy way and you end up back where you started,  the question is whether or not you'll always be able to find four points on this  loop that make up a square. If your closed loop was a circle, for example,  it's quite easy to find an inscribed square. Infinitely many, in fact. If your loop was instead an ellipse, it's still pretty easy to find an inscribed square. The question is whether or not every possible closed loop,  no matter how crazy, has at least one inscribed square. Pretty interesting, right? I mean, just the fact that this is unsolved is interesting,  that the current tools of math can neither confirm nor deny that there's some loop with  no inscribed square in it. Now, if we weaken the question a bit and ask about inscribed rectangles  instead of inscribed squares, it's still pretty hard, but there is a beautiful,  video-worthy solution that might actually be my favorite piece of math. The idea is to shift the focus away from individual  points on the loop and instead onto pairs of points. We'll use the following fact about rectangles. Let's label the vertices of some rectangle ABCD. Then the pair of points AC has a few things in common with the pair of points BD. The distance between A and C equals the distance between B and D,  and the midpoint of A and C is the same as the midpoint of B and D. In fact, any time you have two separate pairs of points in space, AC and BD,  if you can guarantee that they share a midpoint and that the distance between AC equals  the distance between B and D, it's enough to guarantee that those four points make up  a rectangle. So what we're going to do is try to prove that for any closed loop,  it's always possible to find two distinct pairs of points on that  loop that share a midpoint and which are the same distance apart. Take a moment to make sure that's clear. We're finding two distinct pairs of points that share  a common midpoint and which are the same distance apart. The way we'll go about this is to define a function that takes  in pairs of points on the loop and outputs a single point in 3D space,  which kind of encodes the midpoint and distance information. It will be sort of like a graph. Consider the closed loop to be sitting on the xy-plane in 3D space. For a given pair of points, label their midpoint m,  which will be some point on the xy-plane, and label the distance between them d. Plot the point, which is exactly d units above that midpoint m in the z-direction. As you do this for many possible pairs of points,  you'll effectively be drawing through 3D space. And if you do it for all possible pairs of points on the loop,  you'll draw out some kind of surface above the plane. Now look at the surface, and notice how it seems to hug the loop itself. This is actually going to be important later, so let's think about why it happens. As the pair of points on the loop gets closer and closer, the plotted point gets lower,  since its height is by definition equal to the distance between the points. Also, the midpoint gets closer and closer to the loop as the points approach each other. Once the pair of points coincides, meaning the input of our  function looks like xx for some point x on the loop,  the plotted point of the surface will be exactly on the loop at the point x. Okay, so remember that. Another important fact is that this function is continuous,  and all that really means is that if you slightly adjust a given pair of points,  then the corresponding output in 3D is only slightly adjusted as well. There's never a sudden discontinuous jump. Our goal, then, is to show that this function has a collision,  that two distinct pairs of points each map to the same spot in 3D space. Because the only way for that to happen is if they share a common midpoint,  and if their distance d apart from each other is the same. So in some sense, finding an inscribed rectangle comes  down to showing that this surface has to intersect itself. To move forward from here, we need to build up a  relationship with the idea of pairs of points on a loop. Think about how we represent pairs of real numbers  using a two-dimensional coordinate plane. Analogous to this, we're going to seek out a certain 2D surface  which naturally represents all pairs of points on the loop. Understanding the properties of this surface will help to show  why the graph that we just defined has to intersect itself. Now, when I say pair of points, there are two things that I could be talking about. The first is ordered pairs of points, which would mean a  pair like AB would be considered distinct from the pair BA. That is, there's some notion of which point is the first one. The second idea is unordered points, where AB and BA would be considered the same thing,  where all that really matters is what the points are,  and there's no meaning to which one is first. Ultimately, we want to understand unordered pairs of points,  but to get there, we need to take a path of thought through ordered pairs. We'll start out by straightening out the loop,  cutting it at some point, and deforming it into an interval. For the sake of having some labels, let's say that  this is the interval on the number line from 0 to 1. By following where each point ends up, every point on the loop corresponds with a  unique number on this interval, except for the point where the cut happened,  which corresponds simultaneously to both endpoints of the interval,  meaning the numbers 0 and 1. Now, the benefit of straightening out this loop like this is that we can start  thinking about pairs of points the same way we think about pairs of numbers. Make a y-axis using a second interval, then associate each pair of values  on the interval with a single point in this 1x1 square that they span out. Every individual point of this square naturally corresponds to a pair of  points on the loop, since its x and y coordinates are each numbers between 0 and 1,  which are in turn associated to some unique point on the loop. Remember, we're trying to find a surface that naturally represents the set of  all pairs of points on the loop, and this square is the first step to doing that. The problem is that there's some ambiguity when it comes to the edges of the square. Remember, the endpoints 0 and 1 on the interval really correspond to  the same point of the loop, as if to say that those endpoints need to  be glued together if we're going to faithfully map back to the loop. So all of the points on the left edge of the square, like 0, 0, 0.1, 0, 0.2,  on and on and on, really represent the same pair of points on the loop as the  corresponding coordinates on the right edge of the square, 1, 0.1, 1, 0.2,  on and on and on. So for this square to represent the pairs of points on the loop in a unique way,  we need to glue this left edge to the right edge. I'll mark each edge with some arrows to remember how the edges need to be lined up. Likewise, the bottom edge needs to be glued to the top edge,  since y-coordinates of 0 and 1 really represent the same second point in a given pair  of points on the loop. If you bend this square to perform the gluing,  first rolling it into a cylinder to glue the left and right edges,  then gluing the ends of that cylinder, which represent the top and bottom edges,  we get a torus, better known as the surface of a doughnut. Every individual point on this torus corresponds to a unique pair of points on the loop,  and likewise, every pair of points on the loop corresponds to  some unique point on this torus. The torus is to pair of points on the loop what the  xy-plane is to pairs of points on the real number line. The key property of this association is that it's continuous both ways,  meaning if you nudge any point on the torus by just a tiny amount,  it corresponds to only a very slight nudge to the pair of points on the loop,  and vice versa. So if the torus is the natural shape for ordered pairs of points on the loop,  what's the natural shape for unordered pairs? After all, the whole reason we're doing this is to show that two distinct pairs  of pairs of points on the loop share a midpoint and are the same distance apart. But if we consider a pair AB to be distinct from BA,  then that would trivially give us two separate pairs which have the same  midpoint and distance apart. That's like saying you can always find a rectangle so  long as you consider any pair of points to be a rectangle. Not helpful. So let's think about this. Let's think about how to represent unordered pairs  of points looking back at our unit square. We need to say that the coordinates 0.2, 0.3 represent the same pair as 0.3, 0.2. Or that 0.5, 0.7 really represents the same thing as 0.7, 0.5. And in general, any coordinates x, y has to represent the same thing as y, x. Once again, we capture this idea by gluing points together when they're supposed to  represent the same pair, which in this case requires folding the square over diagonally. Now notice this diagonal line, the crease of the fold. It represents all pairs of points that look like xx,  meaning the pairs which are really just a single point written twice. Right now, it's marked with a red line. And you should remember it. It will become important to know where all of these pairs like xx live. But we still have some arrows to glue together here. We need to glue that bottom edge to the right edge. And the orientation with which we do this is going to be important. Points towards the left of the bottom edge have to be  glued to points towards the bottom of the right edge. And points towards the right of the bottom edge have  to be glued to points towards the top of the right edge. It's weird to think about, right? Go ahead, pause and ponder this for a moment. The trick, which is kind of clever, is to make a diagonal cut,  which we need to remember to glue back in just a moment. After that, we can glue the bottom and the right like so. But notice the orientation of the arrows here. To glue back what we just cut, we don't simply  connect the edges of this rectangle to get a cylinder. We have to make a twist. Doing this in 3D space, the shape we get is a MÃ¶bius strip. Isn't that awesome? Evidently, the surface which represents all pairs  of unordered points on the loop is the MÃ¶bius strip. And notice, the edge of this strip, shown here in red,  represents the pairs of points that look like xx,  those which are really just a single point listed twice. The MÃ¶bius strip is to unordered pairs of points on  the loop what the xy-plane is to pairs of real numbers. That totally blew my mind when I first saw it. Now, with this fact that there is a continuous one-to-one association  between unordered pairs of points on the loop and individual points on this MÃ¶bius strip,  we can solve the inscribed rectangle problem. Remember, we had defined this special kind of graph in 3D space,  where the loop was sitting in the xy-plane. For each pair of points, you consider their midpoint m, which lives on the xy-plane,  and their distance d apart, and you plot a point which is exactly d units above m. Because of the continuous one-to-one association between pairs  of points on the loop and the MÃ¶bius strip, this gives us a  natural map from the MÃ¶bius strip onto this surface in 3D space. For every point on the MÃ¶bius strip, consider the pair of points on the loop  that it represents, then plug that pair of points into the special function. And here's the key point. When pairs of points on the loop are extremely close together,  the output of the function is right above the loop itself,  and in the extreme case of pairs of points like xx,  the output of the function is exactly on the loop. Since points on this red edge of the MÃ¶bius strip correspond to pairs like xx,  when the MÃ¶bius strip is mapped onto this surface,  it must be done in such a way that the edge of the strip gets mapped right onto  that loop in the xy-plane. But if you stand back and think about it for a moment,  considering the strange shape of the MÃ¶bius strip,  there is no way to glue its edge to something two-dimensional without  forcing the strip to intersect itself. Since points of the MÃ¶bius strip represent pairs of points on the loop,  if the strip intersects itself during this mapping,  it means that there are at least two distinct pairs of points that correspond to the same  output on this surface, which means they share a midpoint and are the same distance  apart, which in turn means that they form a rectangle. And that's the proof! Or at least, if you're willing to trust me in saying that you can't glue the edge of  the MÃ¶bius strip to a plane without forcing it to intersect itself, then that's the proof. This fact is intuitively clear looking at the MÃ¶bius strip,  but in order to make it rigorous, you basically need to start developing the  field of topology. In fact, for any of you who have a topology class in your future,  going through the exercise of trying to justify this is a good way to  gain an appreciation for why topologists choose to make certain definitions. And I want you to take note of something here. The reason for talking about the torus and the MÃ¶bius strip  was not because we were playing around with construction paper,  or because we were daydreaming about deforming a coffee mug. They came up as a natural way to understand pairs of points on a loop,  and that's something that we needed to solve a concrete problem. Thank you.

================================================================================
VIDEO ID: TgKwz5Ikpc8
TITLE: Abstract vector spaces | Chapter 16, Essence of linear algebra
URL: https://www.youtube.com/watch?v=TgKwz5Ikpc8
PUBLISHED: 2016-09-24T19:29:09Z
STATUS: SUCCESS
================================================================================
I'd like to revisit a deceptively simple question  that I asked in the very first video of this series. What are vectors? Is a two-dimensional vector, for example, fundamentally an arrow on  a flat plane that we can describe with coordinates for convenience? Or is it fundamentally that pair of real numbers which  is just nicely visualized as an arrow on a flat plane? Or are both of these just manifestations of something deeper? On the one hand, defining vectors as primarily being  a list of numbers feels clear-cut and unambiguous. It makes things like four-dimensional vectors or 100-dimensional vectors sound like real,  concrete ideas that you can actually work with. When otherwise, an idea like four dimensions is just a vague geometric  notion that's difficult to describe without waving your hands a bit. But on the other hand, a common sensation for those who actually work with  linear algebra, especially as you get more fluent with changing your basis,  is that you're dealing with a space that exists independently from the  coordinates that you give it, and that coordinates are actually somewhat arbitrary,  depending on what you happen to choose as your basis vectors. Core topics in linear algebra, like determinants and eigenvectors,  seem indifferent to your choice of coordinate systems. The determinant tells you how much a transformation scales areas,  and eigenvectors are the ones that stay on their own span during a transformation. But both of these properties are inherently spatial,  and you can freely change your coordinate system without changing the underlying  values of either one. But if vectors are not fundamentally lists of real numbers,  and if their underlying essence is something more spatial,  that just begs the question of what mathematicians mean when they use a  word like space or spatial. To build up to where this is going, I'd actually like to spend the  bulk of this video talking about something which is neither an arrow  nor a list of numbers, but also has vector-ish qualities â€“ functions. You see, there's a sense in which functions are actually just another type of vector. In the same way that you can add two vectors together,  there's also a sensible notion for adding two functions, f and g,  to get a new function, f plus g. It's one of those things where you kind of already know what it's going to be,  but actually phrasing it is a mouthful. The output of this new function at any given input, like negative four,  is the sum of the outputs of f and g when you evaluate them each at that same input,  negative four. Or more generally, the value of the sum function at any  given input x is the sum of the values f of x plus g of x. This is pretty similar to adding vectors coordinate by coordinate,  it's just that there are, in a sense, infinitely many coordinates to deal with. Similarly, there's a sensible notion for scaling a function by a real number,  just scale all of the outputs by that number. And again, this is analogous to scaling a vector coordinate by coordinate,  it just feels like there's infinitely many coordinates. Now, given that the only thing vectors can really do is get added together or scaled,  it feels like we should be able to take the same useful constructs and problem  solving techniques of linear algebra that were originally thought about in  the context of arrows and space and apply them to functions as well. For example, there's a perfectly reasonable notion of a linear transformation  for functions, something that takes in one function and turns it into another. One familiar example comes from calculus, the derivative. It's something which transforms one function into another function. Sometimes in this context you'll hear these called operators instead of transformations,  but the meaning is the same. A natural question you might want to ask is what it  means for a transformation of functions to be linear. The formal definition of linearity is relatively abstract and symbolically driven  compared to the way that I first talked about it in chapter 3 of this series. But the reward of abstractness is that we'll get something  general enough to apply to functions as well as arrows. A transformation is linear if it satisfies two properties,  commonly called additivity and scaling. Additivity means that if you add two vectors, v and w,  then apply a transformation to their sum, you get the same result as if you added the  transformed versions of v and w. The scaling property is that when you scale a vector v by some number,  then apply the transformation, you get the same ultimate vector as  if you scaled the transformed version of v by that same amount. The way you'll often hear this described is that linear transformations  preserve the operations of vector addition and scalar multiplication. The idea of gridlines remaining parallel and evenly spaced that I've  talked about in past videos is really just an illustration of what  these two properties mean in the specific case of points in 2D space. One of the most important consequences of these properties,  which makes matrix vector multiplication possible,  is that a linear transformation is completely described by where it  takes the basis vectors. Since any vector can be expressed by scaling and adding the basis vectors in some way,  finding the transformed version of a vector comes down to scaling and adding  the transformed versions of the basis vectors in that same way. As you'll see in just a moment, this is as true for functions as it is for arrows. For example, calculus students are always using the fact that the derivative is  additive and has the scaling property, even if they haven't heard it phrased that way. If you add two functions, then take the derivative,  it's the same as first taking the derivative of each one separately,  then adding the result. Similarly, if you scale a function, then take the derivative,  it's the same as first taking the derivative, then scaling the result. To really drill in the parallel, let's see what it  might look like to describe the derivative with a matrix. This will be a little tricky, since function spaces have a tendency to be  infinite dimensional, but I think this exercise is actually quite satisfying. Let's limit ourselves to polynomials, things like x squared plus 3x plus 5,  or 4x to the seventh minus 5x squared. Each of the polynomials in our space will only have finitely many terms,  but the full space is going to include polynomials with arbitrarily large degree. The first thing we need to do is give coordinates to this space,  which requires choosing a basis. Since polynomials are already written down as the sum of scaled powers of the variable x,  it's pretty natural to just choose pure powers of x as the basis function. In other words, our first basis function will be the constant function, b0 of x equals 1. The second basis function will be b1 of x equals x,  then b2 of x equals x squared, then b3 of x equals x cubed, and so on. The role that these basis functions serve will be similar to the roles of i-hat,  j-hat, and k-hat in the world of vectors as arrows. Since our polynomials can have arbitrarily large degree,  this set of basis functions is infinite. But that's okay, it just means that when we treat our polynomials as vectors,  they're going to have infinitely many coordinates. A polynomial like x squared plus 3x plus 5, for example,  would be described with the coordinates 5, 3, 1, then infinitely many zeros. You'd read this as saying that it's 5 times the first basis function,  plus 3 times that second basis function, plus 1 times the third basis function,  and then none of the other basis functions should be added from that point on. The polynomial 4x to the seventh minus 5x squared would have the coordinates 0,  0, negative 5, 0, 0, 0, 0, 4, then an infinite string of zeros. In general, since every individual polynomial has only finitely many terms,  its coordinates will be some finite string of numbers with an infinite tail of zeros. In this coordinate system, the derivative is described with  an infinite matrix that's mostly full of zeros,  but which has the positive integers counting down on this offset diagonal. I'll talk about how you could find this matrix in just a moment,  but the best way to get a feel for it is to just watch it in action. Take the coordinates representing the polynomial x cubed plus 5x squared plus 4x plus 5,  then put those coordinates on the right of the matrix. The only term that contributes to the first coordinate of the result is 1 times 4,  which means the constant term in the result will be 4. This corresponds to the fact that the derivative of 4x is the constant 4. The only term contributing to the second coordinate of the matrix vector product  is 2 times 5, which means the coefficient in front of x in the derivative is 10. That one corresponds to the derivative of 5x squared. Similarly, the third coordinate in the matrix  vector product comes down to taking 3 times 1. This one corresponds to the derivative of x cubed being 3x squared. And after that, it'll be nothing but zeros. What makes this possible is that the derivative is linear. And for those of you who like to pause and ponder,  you could construct this matrix by taking the derivative of each  basis function and putting the coordinates of the results in each column. So, surprisingly, matrix vector multiplication and taking a derivative,  which at first seem like completely different animals,  are both just really members of the same family. In fact, most of the concepts I've talked about in this series with  respect to vectors as arrows in space, things like the dot product or eigenvectors,  have direct analogs in the world of functions,  though sometimes they go by different names, things like inner product or eigenfunction. So back to the question of what is a vector. The point I want to make here is that there are lots of vectorish things in math. As long as you're dealing with a set of objects where there's a reasonable notion of  scaling and adding, whether that's a set of arrows in space, lists of numbers, functions,  or whatever other crazy thing you choose to define,  all of the tools developed in linear algebra regarding vectors,  linear transformations and all that stuff, should be able to apply. Take a moment to imagine yourself right now as a  mathematician developing the theory of linear algebra. You want all of the definitions and discoveries of your work to apply to  all of the vectorish things in full generality, not just to one specific case. These sets of vectorish things, like arrows or lists of numbers or functions,  are called vector spaces. And what you as the mathematician might want to do is say,  hey everyone, I don't want to have to think about all the  different types of crazy vector spaces that you all might come up with. So what you do is establish a list of rules that  vector addition and scaling have to abide by. These rules are called axioms, and in the modern theory of linear algebra,  there are eight axioms that any vector space must satisfy if all of  the theory and constructs that we've discovered are going to apply. I'll leave them on the screen here for anyone who wants to pause and ponder,  but basically it's just a checklist to make sure that the notions of vector  addition and scalar multiplication do the things that you'd expect them to do. These axioms are not so much fundamental rules of nature as they are an  interface between you, the mathematician, discovering results,  and other people who might want to apply those results to new sorts of vector spaces. If, for example, someone defines some crazy type of vector space,  like the set of all pi creatures with some definition of adding and scaling pi creatures,  these axioms are like a checklist of things that they need to verify about  their definitions before they can start applying the results of linear algebra. And you, as the mathematician, never have to think about  all the possible crazy vector spaces people might define. You just have to prove your results in terms of these axioms so  anyone whose definitions satisfy those axioms can happily apply your results,  even if you never thought about their situation. As a consequence, you'd tend to phrase all of your results pretty abstractly,  which is to say, only in terms of these axioms,  rather than centering on a specific type of vector, like arrows in space or functions. For example, this is why just about every textbook you'll find will  define linear transformations in terms of additivity and scaling,  rather than talking about gridlines remaining parallel and evenly spaced. Even though the latter is more intuitive, and at least in my view,  more helpful for first-time learners, even if it is specific to one situation. So the mathematician's answer to what are vectors is to just ignore the question. In the modern theory, the form that vectors take doesn't really matter. Arrows, lists of numbers, functions, pi creatures, really, it can be anything,  so long as there's some notion of adding and scaling vectors that follows these rules. It's like asking what the number 3 really is. Whenever it comes up concretely, it's in the context of some triplet of things,  but in math, it's treated as an abstraction for all possible triplets of things,  and lets you reason about all possible triplets using a single idea. Same goes with vectors, which have many embodiments,  but math abstracts them all into a single, intangible notion of a vector space. But, as anyone watching this series knows, I think it's better  to begin reasoning about vectors in a concrete, visualizable setting,  like 2D space, with arrows rooted at the origin. But as you learn more linear algebra, know that these tools apply much more generally,  and that this is the underlying reason why textbooks and lectures tend to be phrased,  well, abstractly. So with that, folks, I think I'll call it an in to this essence of linear algebra series. If you've watched and understood the videos, I really do believe that  you have a solid foundation in the underlying intuitions of linear algebra. This is not the same thing as learning the full topic, of course,  that's something that can only really come from working through problems,  but the learning you do moving forward could be substantially more efficient if you have  all the right intuitions in place. So, have fun applying those intuitions, and best of luck with your future learning.

================================================================================
VIDEO ID: PFDu9oVAE-g
TITLE: Eigenvectors and eigenvalues | Chapter 14, Essence of linear algebra
URL: https://www.youtube.com/watch?v=PFDu9oVAE-g
PUBLISHED: 2016-09-15T18:22:14Z
STATUS: SUCCESS
================================================================================
Eigenvectors and eigenvalues is one of those topics  that a lot of students find particularly unintuitive. Questions like, why are we doing this and what does this actually mean,  are too often left just floating away in an unanswered sea of computations. And as I've put out the videos of this series,  a lot of you have commented about looking forward to visualizing this topic in particular. I suspect that the reason for this is not so much that  eigenthings are particularly complicated or poorly explained. In fact, it's comparatively straightforward, and  I think most books do a fine job explaining it. The issue is that it only really makes sense if you have a  solid visual understanding for many of the topics that precede it. Most important here is that you know how to think about matrices as  linear transformations, but you also need to be comfortable with things  like determinants, linear systems of equations, and change of basis. Confusion about eigenstuffs usually has more to do with a shaky foundation in  one of these topics than it does with eigenvectors and eigenvalues themselves. To start, consider some linear transformation in two dimensions, like the one shown here. It moves the basis vector i-hat to the coordinates 3, 0, and j-hat to 1, 2. So it's represented with a matrix whose columns are 3, 0, and 1, 2. Focus in on what it does to one particular vector,  and think about the span of that vector, the line passing through its origin and its tip. Most vectors are going to get knocked off their span during the transformation. I mean, it would seem pretty coincidental if the place where  the vector landed also happened to be somewhere on that line. But some special vectors do remain on their own span,  meaning the effect that the matrix has on such a vector is just to stretch it or  squish it, like a scalar. For this specific example, the basis vector i-hat is one such special vector. The span of i-hat is the x-axis, and from the first column of the matrix,  we can see that i-hat moves over to 3 times itself, still on that x-axis. What's more, because of the way linear transformations work,  any other vector on the x-axis is also just stretched by a factor of 3,  and hence remains on its own span. A slightly sneakier vector that remains on its own  span during this transformation is negative 1, 1. It ends up getting stretched by a factor of 2. And again, linearity is going to imply that any other vector on the diagonal  line spanned by this guy is just going to get stretched out by a factor of 2. And for this transformation, those are all the vectors  with this special property of staying on their span. Those on the x-axis getting stretched out by a factor of 3,  and those on this diagonal line getting stretched by a factor of 2. Any other vector is going to get rotated somewhat during the transformation,  knocked off the line that it spans. As you might have guessed by now, these special vectors are called the eigenvectors of  the transformation, and each eigenvector has associated with it what's called an  eigenvalue, which is just the factor by which it's stretched or squished during the  transformation. Of course, there's nothing special about stretching versus squishing,  or the fact that these eigenvalues happen to be positive. In another example, you could have an eigenvector with eigenvalue negative 1 half,  meaning that the vector gets flipped and squished by a factor of 1 half. But the important part here is that it stays on the  line that it spans out without getting rotated off of it. For a glimpse of why this might be a useful thing to think about,  consider some three-dimensional rotation. If you can find an eigenvector for that rotation,  a vector that remains on its own span, what you have found is the axis of rotation. And it's much easier to think about a 3D rotation in terms of some  axis of rotation and an angle by which it's rotating,  rather than thinking about the full 3x3 matrix associated with that transformation. In this case, by the way, the corresponding eigenvalue would have to be 1,  since rotations never stretch or squish anything,  so the length of the vector would remain the same. This pattern shows up a lot in linear algebra. With any linear transformation described by a matrix,  you could understand what it's doing by reading off the columns of this matrix as the  landing spots for basis vectors. But often, a better way to get at the heart of what the linear  transformation actually does, less dependent on your particular coordinate system,  is to find the eigenvectors and eigenvalues. I won't cover the full details on methods for computing eigenvectors  and eigenvalues here, but I'll try to give an overview of the  computational ideas that are most important for a conceptual understanding. Symbolically, here's what the idea of an eigenvector looks like. A is the matrix representing some transformation, with v as the eigenvector,  and lambda is a number, namely the corresponding eigenvalue. What this expression is saying is that the matrix-vector product, A times v,  gives the same result as just scaling the eigenvector v by some value lambda. So finding the eigenvectors and their eigenvalues of a matrix A comes  down to finding the values of v and lambda that make this expression true. It's a little awkward to work with at first, because that left-hand side represents  matrix-vector multiplication, but the right-hand side here is scalar-vector  multiplication. So let's start by rewriting that right-hand side as some kind of matrix-vector  multiplication, using a matrix which has the effect of scaling any vector by a factor  of lambda. The columns of such a matrix will represent what happens to each basis vector,  and each basis vector is simply multiplied by lambda,  so this matrix will have the number lambda down the diagonal, with zeros everywhere else. The common way to write this guy is to factor that lambda out and write it  as lambda times i, where i is the identity matrix with 1s down the diagonal. With both sides looking like matrix-vector multiplication,  we can subtract off that right-hand side and factor out the v. So what we now have is a new matrix, A minus lambda times the identity,  and we're looking for a vector v such that this new matrix times v gives the zero vector. Now, this will always be true if v itself is the zero vector, but that's boring. What we want is a non-zero eigenvector. And if you watch chapter 5 and 6, you'll know that the only way it's possible  for the product of a matrix with a non-zero vector to become zero is if the  transformation associated with that matrix squishes space into a lower dimension. And that squishification corresponds to a zero determinant for the matrix. To be concrete, let's say your matrix A has columns 2, 1 and 2, 3,  and think about subtracting off a variable amount, lambda, from each diagonal entry. Now imagine tweaking lambda, turning a knob to change its value. As that value of lambda changes, the matrix itself changes,  and so the determinant of the matrix changes. The goal here is to find a value of lambda that will make this determinant zero,  meaning the tweaked transformation squishes space into a lower dimension. In this case, the sweet spot comes when lambda equals 1. Of course, if we had chosen some other matrix, the eigenvalue might not necessarily be 1. The sweet spot might be hit at some other value of lambda. So this is kind of a lot, but let's unravel what this is saying. When lambda equals 1, the matrix A minus lambda  times the identity squishes space onto a line. That means there's a non-zero vector v such that A minus  lambda times the identity times v equals the zero vector. And remember, the reason we care about that is because it means A times v  equals lambda times v, which you can read off as saying that the vector v  is an eigenvector of A, staying on its own span during the transformation A. In this example, the corresponding eigenvalue is 1,  so v would actually just stay fixed in place. Pause and ponder if you need to make sure that that line of reasoning feels good. This is the kind of thing I mentioned in the introduction. If you didn't have a solid grasp of determinants and why they  relate to linear systems of equations having non-zero solutions,  an expression like this would feel completely out of the blue. To see this in action, let's revisit the example from the start,  with a matrix whose columns are 3, 0 and 1, 2. To find if a value lambda is an eigenvalue, subtract it from  the diagonals of this matrix and compute the determinant. Doing this, we get a certain quadratic polynomial in lambda,  3 minus lambda times 2 minus lambda. Since lambda can only be an eigenvalue if this determinant happens to be zero,  you can conclude that the only possible eigenvalues are lambda equals 2 and lambda  equals 3. To figure out what the eigenvectors are that actually have one of these eigenvalues,  say lambda equals 2, plug in that value of lambda to the matrix and then  solve for which vectors this diagonally altered matrix sends to zero. If you computed this the way you would any other linear system,  you'd see that the solutions are all the vectors on the diagonal line spanned  by negative 1, 1. This corresponds to the fact that the unaltered matrix, 3, 0, 1,  2, has the effect of stretching all those vectors by a factor of 2. Now, a 2D transformation doesn't have to have eigenvectors. For example, consider a rotation by 90 degrees. This doesn't have any eigenvectors since it rotates every vector off of its own span. If you actually try computing the eigenvalues of a rotation like this,  notice what happens. Its matrix has columns 0, 1 and negative 1, 0. Subtract off lambda from the diagonal elements and look for when the determinant is zero. In this case, you get the polynomial lambda squared plus 1. The only roots of that polynomial are the imaginary numbers, i and negative i. The fact that there are no real number solutions indicates that there are no eigenvectors. Another pretty interesting example worth holding in the back of your mind is a shear. This fixes i-hat in place and moves j-hat 1 over, so its matrix has columns 1, 0 and 1, 1. All of the vectors on the x-axis are eigenvectors  with eigenvalue 1 since they remain fixed in place. In fact, these are the only eigenvectors. When you subtract off lambda from the diagonals and compute the determinant,  what you get is 1 minus lambda squared. And the only root of this expression is lambda equals 1. This lines up with what we see geometrically,  that all of the eigenvectors have eigenvalue 1. Keep in mind though, it's also possible to have just one eigenvalue,  but with more than just a line full of eigenvectors. A simple example is a matrix that scales everything by 2. The only eigenvalue is 2, but every vector in the  plane gets to be an eigenvector with that eigenvalue. Now is another good time to pause and ponder some  of this before I move on to the last topic. I want to finish off here with the idea of an eigenbasis,  which relies heavily on ideas from the last video. Take a look at what happens if our basis vectors just so happen to be eigenvectors. For example, maybe i-hat is scaled by negative 1 and j-hat is scaled by 2. Writing their new coordinates as the columns of a matrix,  notice that those scalar multiples, negative 1 and 2,  which are the eigenvalues of i-hat and j-hat, sit on the diagonal of our matrix,  and every other entry is a 0. Any time a matrix has zeros everywhere other than the diagonal,  it's called, reasonably enough, a diagonal matrix. And the way to interpret this is that all the basis vectors are eigenvectors,  with the diagonal entries of this matrix being their eigenvalues. There are a lot of things that make diagonal matrices much nicer to work with. One big one is that it's easier to compute what will happen  if you multiply this matrix by itself a whole bunch of times. Since all one of these matrices does is scale each basis vector by some eigenvalue,  applying that matrix many times, say 100 times,  is just going to correspond to scaling each basis vector by the 100th power of  the corresponding eigenvalue. In contrast, try computing the 100th power of a non-diagonal matrix. Really, try it for a moment. It's a nightmare. Of course, you'll rarely be so lucky as to have your basis vectors also be eigenvectors. But if your transformation has a lot of eigenvectors,  like the one from the start of this video, enough so that you can choose a set that  spans the full space, then you could change your coordinate system so that these  eigenvectors are your basis vectors. I talked about change of basis last video, but I'll go through  a super quick reminder here of how to express a transformation  currently written in our coordinate system into a different system. Take the coordinates of the vectors that you want to use as a new basis,  which in this case means our two eigenvectors,  then make those coordinates the columns of a matrix, known as the change of basis matrix. When you sandwich the original transformation,  putting the change of basis matrix on its right and the inverse of the  change of basis matrix on its left, the result will be a matrix representing  that same transformation, but from the perspective of the new basis  vectors coordinate system. The whole point of doing this with eigenvectors is that this new matrix is  guaranteed to be diagonal with its corresponding eigenvalues down that diagonal. This is because it represents working in a coordinate system where what  happens to the basis vectors is that they get scaled during the transformation. A set of basis vectors which are also eigenvectors is called,  again, reasonably enough, an eigenbasis. So if, for example, you needed to compute the 100th power of this matrix,  it would be much easier to change to an eigenbasis,  compute the 100th power in that system, then convert back to our standard system. You can't do this with all transformations. A shear, for example, doesn't have enough eigenvectors to span the full space. But if you can find an eigenbasis, it makes matrix operations really lovely. For those of you willing to work through a pretty neat puzzle to  see what this looks like in action and how it can be used to produce  some surprising results, I'll leave up a prompt here on the screen. It takes a bit of work, but I think you'll enjoy it. The next and final video of this series is going to be on abstract vector spaces.  See you then!

================================================================================
VIDEO ID: P2LTAUO1TdA
TITLE: Change of basis | Chapter 13, Essence of linear algebra
URL: https://www.youtube.com/watch?v=P2LTAUO1TdA
PUBLISHED: 2016-09-11T17:56:20Z
STATUS: SUCCESS
================================================================================
If I have a vector sitting here in 2D space, we  have a standard way to describe it with coordinates. In this case, the vector has coordinates 3, 2,  which means going from its tail to its tip involves moving three units to  the right and two units up. Now, the more linear algebra-oriented way to describe coordinates is to think  of each of these numbers as a scalar, a thing that stretches or squishes vectors. You think of that first coordinate as scaling i-hat,  the vector with length 1 pointing to the right,  while the second coordinate scales j-hat, the vector with length 1 pointing straight up. The tip-to-tail sum of those two scaled vectors  is what the coordinates are meant to describe. You can think of these two special vectors as encapsulating  all of the implicit assumptions of our coordinate system. The fact that the first number indicates rightward motion,  that the second one indicates upward motion, exactly how far a unit of distance is,  all of that is tied up in the choice of i-hat and j-hat as the  vectors which are scalar coordinates are meant to actually scale. Any way to translate between vectors and sets of numbers is called a coordinate system,  and the two special vectors i-hat and j-hat are called the basis  vectors of our standard coordinate system. What I'd like to talk about here is the idea of using a different set of basis vectors. For example, let's say you have a friend, Jennifer,  who uses a different set of basis vectors, which I'll call b1 and b2. Her first basis vector, b1, points up and to the right a little bit,  and her second vector, b2, points left and up. Now take another look at that vector that I showed earlier,  the one that you and I would describe using the coordinates 3,2,  using our basis vectors i-hat and j-hat. Jennifer would actually describe this vector with the coordinates 5 thirds and 1 third. What this means is that the particular way to get to that vector using her two basis  vectors is to scale b1 by 5 thirds, scale b2 by 1 third, then add them both together. In a little bit, I'll show you how you could have figured out those two numbers,  5 thirds and 1 third. In general, whenever Jennifer uses coordinates to describe a vector,  she thinks of her first coordinate as scaling b1,  the second coordinate as scaling b2, and she adds the results. What she gets will typically be completely different from the  vector that you and I would think of as having those coordinates. To be a little more precise about the setup here, her first basis vector,  b1, is something that we would describe with the coordinates 2,1,  and her second basis vector, b2, is something that we would describe as negative 1,1. But it's important to realize from her perspective in her system,  those vectors have coordinates 1,0 and 0,1. They are what define the meaning of the coordinates 1,0 and 0,1 in her world. So in effect, we're speaking different languages. We're all looking at the same vectors in space,  but Jennifer uses different words and numbers to describe them. Let me say a quick word about how I'm representing things here. When I animate 2D space, I typically use this square grid. But that grid is just a construct, a way to visualize our coordinate system,  and so it depends on our choice of basis. Space itself has no intrinsic grid. Jennifer might draw her own grid, which would be an equally made up construct meant  as nothing more than a visual tool to help follow the meaning of her coordinates. Her origin though would actually line up with ours,  since everybody agrees on what the coordinates 0,0 should mean. It's the thing that you get when you scale any vector by 0. But the direction of her axes and the spacing of her grid lines will be different,  depending on her choice of basis vectors. So after all this is set up, a pretty natural question  to ask is how we translate between coordinate systems. If for example, Jennifer describes a vector with coordinates negative 1,2,  what would that be in our coordinate system? How do you translate from her language to ours? Well, what her coordinates are saying is that  this vector is negative 1 times b1 plus 2 times b2. And from our perspective, b1 has coordinates 2,1, and b2 has coordinates negative 1,1. So we can actually compute negative 1 times b1 plus 2  times b2 as they're represented in our coordinate system. And working this out, you get a vector with coordinates negative 4,1. So that's how we would describe the vector that she thinks of as negative 1,2. This process here of scaling each of her basis vectors by the corresponding  coordinates of some vector, then adding them together, might feel somewhat familiar. It's matrix-vector multiplication, with a matrix whose  columns represent Jennifer's basis vectors in our language. In fact, once you understand matrix-vector multiplication as applying a certain linear  transformation, say by watching what I view to be the most important video in this  series, chapter 3, there's a pretty intuitive way to think about what's going on here. A matrix whose columns represent Jennifer's basis vectors can be  thought of as a transformation that moves our basis vectors,  i-hat and j-hat, the things we think of when we say 1,0 and 0,1,  to Jennifer's basis vectors, the things she thinks of when she says 1,0 and 0,1. To show how this works, let's walk through what it would mean to take the vector  that we think of as having coordinates negative 1,2 and applying that transformation. Before the linear transformation, we're thinking of this vector as a certain  linear combination of our basis vectors, negative 1 times i-hat plus 2 times j-hat. And the key feature of a linear transformation is that the resulting vector  will be that same linear combination but of the new basis vectors,  negative 1 times the place where i-hat lands plus 2 times the place where j-hat lands. So what this matrix does is transform our misconception of what  Jennifer means into the actual vector that she's referring to. I remember that when I was first learning this, it always felt kind of backwards to me. Geometrically, this matrix transforms our grid into Jennifer's grid,  but numerically, it's translating a vector described in her language to our language. What made it finally click for me was thinking about how it takes our  misconception of what Jennifer means, the vector we get using the same  coordinates but in our system, then it transforms it into the vector that she  really meant. What about going the other way around? In the example I used earlier this video, when I had the vector with coordinates 3,  2 in our system, how did I compute that it would have coordinates  5 thirds and 1 third in Jennifer's system? You start with that change of basis matrix that translates Jennifer's language into ours,  then you take its inverse. Remember, the inverse of a transformation is a new transformation  that corresponds to playing that first one backwards. In practice, especially when you're working in more than two dimensions,  you'd use a computer to compute the matrix that actually represents this inverse. In this case, the inverse of the change of basis matrix that  has Jennifer's basis as its columns ends up working out to have columns 1 third,  negative 1 third, and 1 third, 2 thirds. So, for example, to see what the vector 3, 2 looks like in Jennifer's system,  we multiply this inverse change of basis matrix by the vector 3,  2, which works out to be 5 thirds, 1 third. So that, in a nutshell, is how to translate the description of  individual vectors back and forth between coordinate systems. The matrix whose columns represent Jennifer's basis vectors but written  in our coordinates translates vectors from her language into our language. And the inverse matrix does the opposite. But vectors aren't the only thing that we describe using coordinates. For this next part, it's important that you're all comfortable  representing transformations with matrices and that you know how  matrix multiplication corresponds to composing successive transformations. Definitely pause and take a look at chapters 3 and 4 if any of that feels uneasy. Consider some linear transformation, like a 90 degree counterclockwise rotation. When you and I represent this with a matrix, we  follow where the basis vectors i-hat and j-hat each go. i-hat ends up at the spot with coordinates 0, 1,  and j-hat ends up at the spot with coordinates negative 1, 0. So those coordinates become the columns of our matrix. But this representation is heavily tied up in our choice of basis vectors,  from the fact that we're following i-hat and j-hat in the first place to  the fact that we're recording their landing spots in our own coordinate system. How would Jennifer describe this same 90 degree rotation of space? You might be tempted to just translate the columns  of our rotation matrix into Jennifer's language. But that's not quite right. Those columns represent where our basis vectors i-hat and j-hat go. But the matrix that Jennifer wants should represent where her basis vectors land,  and it needs to describe those landing spots in her language. Here's a common way to think of how this is done. Start with any vector written in Jennifer's language. Rather than trying to follow what happens to it in terms of her language,  first we're going to translate it into our language using the change of basis matrix,  the one whose columns represent her basis vectors in our language. This gives us the same vector but now written in our language. Then apply the transformation matrix to what you get by multiplying it on the left. This tells us where that vector lands, but still in our language. So as a last step, apply the inverse change of basis matrix,  multiplied on the left as usual, to get the transformed vector but now in  Jennifer's language. Since we could do this with any vector written in her language,  first applying the change of basis, then the transformation,  then the inverse change of basis, that composition of three matrices gives us the  transformation matrix in Jennifer's language. It takes in a vector of her language and spits out  the transformed version of that vector in her language. For this specific example, when Jennifer's basis vectors look like 2,  1 and negative 1, 1 in our language, and when the transformation is a 90 degree rotation,  the product of these three matrices, if you work through it, has columns 1 third,  5 thirds, and negative 2 thirds, negative 1 third. So if Jennifer multiplies that matrix by the coordinates of a vector in her system,  it will return the 90 degree rotated version of that vector expressed in her coordinate  system. In general, whenever you see an expression like A inverse times M times A,  it suggests a mathematical sort of empathy. That middle matrix represents a transformation of some kind as you see it,  and the outer two matrices represent the empathy, the shift in perspective. And the full matrix product represents that same  transformation but as someone else sees it. For those of you wondering why we care about alternate coordinate systems,  the next video on eigenvectors and eigenvalues will give a really important example  of this.

================================================================================
VIDEO ID: BaM7OCEm3G0
TITLE: Cross products in the light of linear transformations | Chapter 11, Essence of linear algebra
URL: https://www.youtube.com/watch?v=BaM7OCEm3G0
PUBLISHED: 2016-09-01T03:54:15Z
STATUS: SUCCESS
================================================================================
Hey folks, where we left off I was talking about how to compute  a three-dimensional cross product between two vectors, v cross w. It's this funny thing where you write a matrix whose second column has the  coordinates of v, whose third column has the coordinates of w,  but the entries of that first column, weirdly, are the symbols i-hat, j-hat,  and k-hat, where you just pretend like those guys are numbers for the sake  of computations. Then with that funky matrix in hand, you compute its determinant. If you just chug along with those computations, ignoring the weirdness,  you get some constant times i-hat, plus some constant times j-hat,  plus some constant times k-hat. How specifically you think about computing that determinant is kind of beside the point. All that really matters here is that you'll end up with three different  numbers that are interpreted as the coordinates of some resulting vector. From here, students are typically told to just believe that  the resulting vector has the following geometric properties. Its length equals the area of the parallelogram defined by v and w. It points in a direction perpendicular to both v and w,  and this direction obeys the right-hand rule, in the sense that if  you point your forefinger along v and your middle finger along w,  then when you stick up your thumb, it'll point in the direction of the new vector. There are some brute force computations that you could do to confirm these facts,  but I want to share with you a really elegant line of reasoning. It leverages a bit of background, though, so for this video  I'm assuming that everybody has watched chapter 5 on the determinant and chapter 7,  where I introduced the idea of duality. As a quick reminder, the idea of duality is that any time you have a  linear transformation from some space to the number line,  it's associated with a unique vector in that space,  in the sense that performing the linear transformation is the same as  taking a dot product with that vector. Numerically, this is because one of those transformations is described by a matrix with  just one row, where each column tells you the number that each basis vector lands on. And multiplying this matrix by some vector v is computationally identical to taking  the dot product between v and the vector you get by turning that matrix on its side. The takeaway is that whenever you're out in the mathematical wild and you find  a linear transformation to the number line, you will be able to match it to some vector,  which is called the dual vector of that transformation,  so that performing the linear transformation is the same as taking a dot product  with that vector. The cross product gives us a really slick example of this process in action. It takes some effort, but it's definitely worth it. What I'm going to do is define a certain linear transformation from three dimensions  to the number line, and it'll be defined in terms of the two vectors v and w. Then when we associate that transformation with its dual vector in 3D space,  that dual vector is going to be the cross product of v and w. The reason for doing this will be that understanding that transformation is going to  make clear the connection between the computation and the geometry of the cross product. So to back up a bit, remember in two dimensions what  it meant to compute the 2D version of the cross product? When you have two vectors v and w, you put the coordinates of v as the first  column of a matrix and the coordinates of w as the second column of a matrix. Then you just compute the determinant. There's no nonsense with basis vectors stuck in a matrix or anything like that,  just an ordinary determinant returning a number. Geometrically, this gives us the area of a parallelogram spanned out by those two  vectors, with the possibility of being negative depending on the orientation of the  vectors. Now, if you didn't already know the 3D cross product and you're trying to extrapolate,  you might imagine that it involves taking three separate 3D vectors,  u, v, and w, and making their coordinates the columns of a 3x3 matrix,  then computing the determinant of that matrix. And as you know from chapter 5, geometrically this would give you the volume  of a parallelepiped spanned out by those three vectors,  with a plus or minus sign depending on the right hand rule orientation of  those three vectors. Of course, you all know that this is not the 3D cross product. The actual 3D cross product takes in two vectors and spits out a vector. It doesn't take in three vectors and spit out a number. But this idea actually gets us really close to what the real cross product is. Consider that first vector u to be a variable,  say with variable entries x, y, and z, while v and w remain fixed. What we have then is a function from three dimensions to the number line. You input some vector x, y, z and you get out a number by taking  the determinant of a matrix whose first column is x, y,  z and whose other two columns are the coordinates of the constant vectors v and w. Geometrically, the meaning of this function is that for any input vector x,  y, z, you consider the parallelepiped defined by this vector v and w. Then you return its volume with a plus or minus sign depending on orientation. Now, this might feel like kind of a random thing to do. I mean, where does this function come from? Why are we defining it this way? And I'll admit, at this stage it might kind of feel like it's coming out of the blue. But if you're willing to go along with it and play around with the  properties that this guy has, it's the key to understanding the cross product. One really important fact about this function is that it's linear. I'll actually leave it to you to work through the details  of why this is true based on properties of the determinant. But once you know that it's linear, we can start bringing in the idea of duality. Once you know that it's linear, you know that there's some  way to describe this function as matrix multiplication. Specifically, since it's a function that goes from three dimensions to one dimension,  there will be a one by three matrix that encodes this transformation. And the whole idea of duality is that the special thing about transformations from  several dimensions to one dimension is that you can turn that matrix on its side and  instead interpret the entire transformation as the dot product with a certain vector. What we're looking for is the special 3D vector that I'll call p such that taking  the dot product between p and any other vector x, y,  z gives the same result as plugging in x, y, z as the first column of a three  by three matrix whose other two columns have the coordinates of v and w,  then computing the determinant. I'll get to the geometry of this in just a moment,  but right now let's dig in and think about what this means computationally. Taking the dot product between p and x, y, z will give us something times x plus  something times y plus something times z, where those somethings are the coordinates of p. But on the right side here, when you compute the determinant,  you can organize it to look like some constant times x plus some constant times y  plus some constant times z, where those constants involve certain combinations of  the components of v and w. So those constants, those particular combinations of the coordinates of v  and w are going to be the coordinates of the vector p that we're looking for. But what's going on on the right here should feel very familiar to  anyone who's actually worked through a cross product computation. Collecting the constant terms that are multiplied by x, y,  and by z like this is no different from plugging in the symbols i-hat, j-hat,  and k-hat to that first column, and seeing which coefficients aggregate on each  one of those terms. It's just that plugging in i-hat, j-hat, and k-hat is a way of signaling  that we should interpret those coefficients as the coordinates of a vector. So what all of this is saying is that this funky computation  can be thought of as a way to answer the following question. What vector p has the special property that when you take a dot  product between p and some vector x, y, z, it gives the same result as plugging in x,  y, z to the first column of a matrix whose other two columns have  the coordinates of v and w, then computing the determinant. That's a bit of a mouthful, but it's an important question to digest for this video. Now for the cool part, which ties all this together with the geometric  understanding of the cross product that I introduced last video. I'm going to ask the same question again, but this time we're  going to try to answer it geometrically instead of computationally. What 3D vector p has the special property that when you take a dot product between  p and some other vector x, y, z, it gives the same result as if you took the signed  volume of a parallelepiped defined by this vector x, y, z along with v and w. Remember, the geometric interpretation of a dot product between a  vector p and some other vector is to project that other vector onto p,  then to multiply the length of that projection by the length of p. With that in mind, let me show a certain way to think  about the volume of the parallelepiped that we care about. Start by taking the area of the parallelogram defined by v and w,  then multiply it not by the length of x, y, z, but by the component of x,  y, z that's perpendicular to that parallelogram. In other words, the way our linear function works on a given vector is to project  that vector onto a line that's perpendicular to both v and w,  then to multiply the length of that projection by the area of the parallelogram  spanned by v and w. But this is the same thing as taking a dot product between x, y,  z and a vector that's perpendicular to v and w with a length equal to the area of  that parallelogram. What's more, if you choose the appropriate direction for that vector,  the cases where the dot product is negative will line up with the cases  where the right hand rule for the orientation of x, y, z, v and w is negative. This means that we just found a vector p so that taking a dot product  between p and some vector x, y, z is the same thing as computing that  determinant of a 3x3 matrix whose columns are x, y, z, the coordinates of v and w. So the answer that we found earlier computationally using that  special notational trick must correspond geometrically to this vector. This is the fundamental reason why the computation and the  geometric interpretation of the cross product are related. Just to sum up what happened here, I started by defining a linear transformation  from 3D space to the number line, and it was defined in terms of the vectors v and w. Then I went through two separate ways to think about the dual vector  of this transformation, the vector such that applying the transformation  is the same thing as taking a dot product with that vector. On the one hand, a computational approach will lead you to  the trick of plugging in the symbols i-hat, j-hat,  and k-hat to the first column of a matrix and computing the determinant. But thinking geometrically, we can deduce that this dual vector  must be perpendicular to v and w with a length equal to the  area of the parallelogram spanned out by those two vectors. Since both of these approaches give us a dual vector to the same transformation,  they must be the same vector. So that wraps up dot products and cross products,  and the next video will be a really important concept for linear algebra, change of basis.

================================================================================
VIDEO ID: eu6i7WJeinw
TITLE: Cross products | Chapter 10, Essence of linear algebra
URL: https://www.youtube.com/watch?v=eu6i7WJeinw
PUBLISHED: 2016-09-01T03:54:15Z
STATUS: SUCCESS
================================================================================
Last video I talked about the dot product, showing both the standard introduction  to the topic, as well as a deeper view of how it relates to linear transformations. I'd like to do the same thing for cross products,  which also have a standard introduction, along with a deeper understanding  in the light of linear transformations, but this time I'm dividing it into  two separate videos. Here, I'll try to hit the main points that students are usually shown  about the cross product, and in the next video I'll be showing a view  which is less commonly taught, but really satisfying when you learn it. We'll start in two dimensions. If you have two vectors, v and w, think about the parallelogram that they span out. What I mean by that is that if you take a copy of v and move its tail to the tip of w,  and you take a copy of w and move its tail to the tip of v,  the four vectors now on the screen enclose a certain parallelogram. The cross product of v and w, written with the x-shaped multiplication symbol,  is the area of this parallelogram. Well, almost. We also need to consider orientation. Basically, if v is on the right of w, then v cross w  is positive and equal to the area of the parallelogram. But if v is on the left of w, then the cross product is negative,  namely the negative area of that parallelogram. Notice this means that order matters. If you swapped v and w, instead taking w cross v,  the cross product would become the negative of whatever it was before. The way I always remember the ordering here is that when you take the cross product  of the two basis vectors in order, i-hat cross j-hat, the result should be positive. In fact, the order of your basis vectors is what defines orientation. So since i-hat is on the right of j-hat, I remember that v  cross w has to be positive whenever v is on the right of w. So for example, with the vectors shown here, I'll just  tell you that the area of that parallelogram is seven. And since v is on the left of w, the cross product should be negative. So v cross w is negative seven. But of course, you want to be able to compute this without someone telling you the area. This is where the determinant comes in. So if you didn't see chapter five of this series,  where I talk about the determinant, now would be a really good time to go take a look. Even if you did see it, but it was a while ago,  I'd recommend taking another look just to make sure those ideas are fresh in your mind. For the 2D cross product, v cross w, what you do is you write the coordinates  of v as the first column of a matrix, and you take the coordinates of w  and make them the second column, then you just compute the determinant. This is because a matrix whose columns represent v and w corresponds with a  linear transformation that moves the basis vectors i-hat and j-hat to v and w. The determinant is all about measuring how areas change due to a transformation,  and the prototypical area that we look at is the unit square resting on i-hat and j-hat. After the transformation, that square gets turned  into the parallelogram that we care about. So the determinant, which generally measures the factor by which areas are changed,  gives the area of this parallelogram, since it evolved from a square that started with  area one. What's more, if v is on the left of w, it means that orientation was flipped during  that transformation, which is what it means for the determinant to be negative. As an example, let's say v has coordinates negative 3, 1, and w has coordinates 2, 1. The determinant of the matrix with those coordinates as columns  is negative 3 times 1 minus 2 times 1, which is negative 5. So evidently, the area of the parallelogram they define is 5,  and since v is on the left of w, it should make sense that this value is negative. As with any new operation you learn, I'd recommend playing  around with this notion a bit in your head, just to get kind  of an intuitive feel for what the cross product is all about. For example, you might notice that when two vectors are perpendicular,  or at least close to being perpendicular, their cross product is larger than  it would be if they were pointing in very similar directions,  because the area of that parallelogram is larger when the sides are closer to  being perpendicular. Something else you might notice is that if you were to scale up one of those vectors,  perhaps multiplying v by 3, then the area of that parallelogram  is also scaled up by a factor of 3. So what this means for the operation is that 3v  cross w will be exactly 3 times the value of v cross w. Now, even though all of this is a perfectly fine mathematical operation,  what I just described is technically not the cross product. The true cross product is something that combines  two different 3d vectors to get a new 3d vector. Just as before, we're still going to consider the parallelogram  defined by the two vectors that we're crossing together,  and the area of this parallelogram is still going to play a big role. To be concrete, let's say that the area is 2.5 for the vectors shown here. But as I said, the cross product is not a number, it's a vector. This new vector's length will be the area of that parallelogram,  which in this case is 2.5, and the direction of that new vector is going to be  perpendicular to the parallelogram. But which way, right? I mean, there are two possible vectors with length  2.5 that are perpendicular to a given plane. This is where the right hand rule comes in. Point the forefinger of your right hand in the direction of v,  then stick out your middle finger in the direction of w. Then, when you point up your thumb, that's the direction of the cross product. For example, let's say that v was a vector with length 2 pointing straight up in  the z direction, and w is a vector with length 2 pointing in the pure y direction. The parallelogram that they define in this simple example is actually a square,  since they're perpendicular and have the same length, and the area of that square is 4. So their cross product should be a vector with length 4. Using the right hand rule, their cross product should point in the negative x direction. So the cross product of these two vectors is negative 4 times i-hat. For more general computations, there is a formula that you could memorize if you wanted,  but it's common and easier to instead remember a certain  process involving the 3D determinant. Now, this process looks truly strange at first. You write down a 3D matrix where the second and  third columns contain the coordinates of v and w. But for that first column, you write the basis vectors i-hat, j-hat, and k-hat. Then you compute the determinant of this matrix. The silliness is probably clear here. What on earth does it mean to put in a vector as the entry of a matrix? Students are often told that this is just a notational trick. When you carry out the computations as if i-hat, j-hat, and k-hat were numbers,  then you get some linear combination of those basis vectors. And the vector defined by that linear combination, students are told to just believe,  is the unique vector perpendicular to v and w,  whose magnitude is the area of the appropriate parallelogram,  and whose direction obeys the right hand rule. And sure, in some sense this is just a notational trick,  but there is a reason for doing it. It's not just a coincidence that the determinant is once again important. And putting the basis vectors in those slots is not just a random thing to do. To understand where all of this comes from, it helps to  use the idea of duality that I introduced in the last video. This concept is a little bit heavy though, so I'm putting it in a  separate follow-on video for any of you who are curious to learn more. Arguably, it falls outside the essence of linear algebra. The important part here is to know what that cross  product vector geometrically represents. So if you want to skip that next video, feel free. But for those of you who are willing to go a bit deeper,  and who are curious about the connection between this computation and the underlying  geometry, the ideas that I'll talk about in the next video are just a really  elegant piece of math.

================================================================================
VIDEO ID: LyGKycYT2v0
TITLE: Dot products and duality | Chapter 9, Essence of linear algebra
URL: https://www.youtube.com/watch?v=LyGKycYT2v0
PUBLISHED: 2016-08-24T19:20:58Z
STATUS: SUCCESS
================================================================================
["Ode to Joy", by Beethoven, plays to the end of the piano.] Traditionally,  dot products are something that's introduced really early on in a linear algebra course,  typically right at the start. So it might seem strange that I've pushed them back this far in the series. I did this because there's a standard way to introduce the topic,  which requires nothing more than a basic understanding of vectors,  but a fuller understanding of the role that dot products play in math can only really be  found under the light of linear transformations. Before that, though, let me just briefly cover the standard way that dot products are  introduced, which I'm assuming is at least partially review for a number of viewers. Numerically, if you have two vectors of the same dimension,  two lists of numbers with the same lengths, taking their dot product means  pairing up all of the coordinates, multiplying those pairs together,  and adding the result. So the vector 1, 2 dotted with 3, 4 would be 1 times 3 plus 2 times 4. The vector 6, 2, 8, 3 dotted with 1, 8, 5, 3 would be  6 times 1 plus 2 times 8 plus 8 times 5 plus 3 times 3. Luckily, this computation has a really nice geometric interpretation. To think about the dot product between two vectors, v and w,  imagine projecting w onto the line that passes through the origin and the tip of v. Multiplying the length of this projection by the length of v,  you have the dot product v dot w. Except when this projection of w is pointing in the opposite direction from v,  that dot product will actually be negative. So when two vectors are generally pointing in the same direction,  their dot product is positive. When they're perpendicular, meaning the projection of one  onto the other is the zero vector, their dot product is zero. And if they point in generally the opposite direction, their dot product is negative. Now, this interpretation is weirdly asymmetric. It treats the two vectors very differently. So when I first learned this, I was surprised that order doesn't matter. You could instead project v onto w, multiply the length of  the projected v by the length of w, and get the same result. I mean, doesn't that feel like a really different process? Here's the intuition for why order doesn't matter. If v and w happened to have the same length, we could leverage some symmetry. Since projecting w onto v, then multiplying the length of that projection  by the length of v, is a complete mirror image of projecting v onto w,  then multiplying the length of that projection by the length of w. Now, if you scale one of them, say v, by some constant like 2,  so that they don't have equal length, the symmetry is broken. But let's think through how to interpret the dot product between this new vector,  2 times v, and w. If you think of w as getting projected onto v,  then the dot product 2v dot w will be exactly twice the dot product v dot w. This is because when you scale v by 2, it doesn't change the length of the  projection of w, but it doubles the length of the vector that you're projecting onto. But on the other hand, let's say you were thinking about v getting projected onto w. Well, in that case, the length of the projection is the thing that gets scaled when we  multiply v by 2, but the length of the vector that you're projecting onto stays constant. So the overall effect is still to just double the dot product. So even though symmetry is broken in this case,  the effect that this scaling has on the value of the dot product is the same  under both interpretations. There's also one other big question that confused me when I first learned this stuff. Why on earth does this numerical process of matching coordinates,  multiplying pairs, and adding them together have anything to do with projection? Well, to give a satisfactory answer, and also to do full justice to  the significance of the dot product, we need to unearth something a  little bit deeper going on here, which often goes by the name duality. But before getting into that, I need to spend some time talking about linear  transformations from multiple dimensions to one dimension, which is just the number line. These are functions that take in a 2D vector and spit out some number,  but linear transformations are of course much more restricted than  your run-of-the-mill function with a 2D input and a 1D output. As with transformations in higher dimensions, like the ones I talked about in chapter 3,  there are some formal properties that make these functions linear,  but I'm going to purposefully ignore those here so as to not distract from our end goal,  and instead focus on a certain visual property that's equivalent to all the formal stuff. If you take a line of evenly spaced dots and apply a transformation,  a linear transformation will keep those dots evenly spaced once  they land in the output space, which is the number line. Otherwise, if there's some line of dots that gets unevenly spaced,  then your transformation is not linear. As with the cases we've seen before, one of these linear transformations is  completely determined by where it takes i-hat and j-hat,  but this time each one of those basis vectors just lands on a number,  so when we record where they land as the columns of a matrix,  each of those columns just has a single number. This is a 1x2 matrix. Let's walk through an example of what it means  to apply one of these transformations to a vector. Let's say you have a linear transformation that takes i-hat to 1 and j-hat to negative 2. To follow where a vector with coordinates, say, 4, 3 ends up,  think of breaking up this vector as 4 times i-hat plus 3 times j-hat. A consequence of linearity is that after the transformation,  the vector will be 4 times the place where i-hat lands, 1,  plus 3 times the place where j-hat lands, negative 2,  which in this case implies that it lands on negative 2. When you do this calculation purely numerically, it's matrix vector multiplication. Now, this numerical operation of multiplying a 1x2 matrix by  a vector feels just like taking the dot product of two vectors. Doesn't that 1x2 matrix just look like a vector that we tipped on its side? In fact, we could say right now that there's a nice association between 1x2 matrices  and 2D vectors, defined by tilting the numerical representation of a vector on its side  to get the associated matrix, or to tip the matrix back up to get the associated vector. Since we're just looking at numerical expressions right now,  going back and forth between vectors and 1x2 matrices might feel like a silly thing to do. But this suggests something that's truly awesome from the geometric view. There's some kind of connection between linear transformations  that take vectors to numbers and vectors themselves. Let me show an example that clarifies the significance,  and which just so happens to also answer the dot product puzzle from earlier. Unlearn what you have learned, and imagine that you don't  already know that the dot product relates to projection. What I'm going to do here is take a copy of the number line and place  it diagonally in space somehow, with the number 0 sitting at the origin. Now think of the two-dimensional unit vector whose  tip sits where the number 1 on the number is. I want to give that guy a name, u-hat. This little guy plays an important role in what's about to happen,  so just keep him in the back of your mind. If we project 2d vectors straight onto this diagonal number line,  in effect, we've just defined a function that takes 2d vectors to numbers. What's more, this function is actually linear,  since it passes our visual test that any line of evenly spaced dots remains evenly  spaced once it lands on the number line. Just to be clear, even though I've embedded the number line in 2d space like this,  the outputs of the function are numbers, not 2d vectors. You should think of a function that takes in two  coordinates and outputs a single coordinate. But that vector u-hat is a two-dimensional vector, living in the input space. It's just situated in such a way that overlaps with the embedding of the number line. With this projection, we just defined a linear transformation from 2d vectors to numbers,  so we're going to be able to find some kind of 1x2 matrix that  describes that transformation. To find that 1x2 matrix, let's zoom in on this diagonal number  line setup and think about where i-hat and j-hat each land,  since those landing spots are going to be the columns of the matrix. This part's super cool. We can reason through it with a really elegant piece of symmetry. Since i-hat and u-hat are both unit vectors, projecting i-hat onto the line  passing through u-hat looks totally symmetric to projecting u-hat onto the x-axis. So when we ask what number does i-hat land on when it gets projected,  the answer is going to be the same as whatever u-hat lands on when it's projected  onto the x-axis. But projecting u-hat onto the x-axis just means taking the x-coordinate of u-hat. So by symmetry, the number where i-hat lands when it's projected onto  that diagonal number line is going to be the x-coordinate of u-hat. Isn't that cool? The reasoning is almost identical for the j-hat case. Think about it for a moment. For all the same reasons, the y-coordinate of u-hat gives us the  number where j-hat lands when it's projected onto the number line copy. Pause and ponder that for a moment. I just think that's really cool. So the entries of the 1x2 matrix describing the projection  transformation are going to be the coordinates of u-hat. And computing this projection transformation for arbitrary vectors in space,  which requires multiplying that matrix by those vectors,  is computationally identical to taking a dot product with u-hat. This is why taking the dot product with a unit vector can be interpreted as  projecting a vector onto the span of that unit vector and taking the length. So what about non-unit vectors? For example, let's say we take that unit vector u-hat,  but we scale it up by a factor of 3. Numerically, each of its components gets multiplied by 3. So looking at the matrix associated with that vector,  it takes i-hat and j-hat to three times the values where they landed before. Since this is all linear, it implies more generally that the new matrix can be  interpreted as projecting any vector onto the number line copy and multiplying where it  lands by 3. This is why the dot product with a non-unit vector can be  interpreted as first projecting onto that vector,  then scaling up the length of that projection by the length of the vector. Take a moment to think about what happened here. We had a linear transformation from 2D space to the number line,  which was not defined in terms of numerical vectors or numerical dot products,  it was just defined by projecting space onto a diagonal copy of the number line. But because the transformation is linear, it was necessarily described by some 1x2 matrix. And since multiplying a 1x2 matrix by a 2D vector is the same  as turning that matrix on its side and taking a dot product,  this transformation was inescapably related to some 2D vector. The lesson here is that any time you have one of these linear transformations whose  output space is the number line, no matter how it was defined,  there's going to be some unique vector v corresponding to that transformation,  in the sense that applying the transformation is the same thing as taking a dot  product with that vector. To me, this is utterly beautiful. It's an example of something in math called duality. Duality shows up in many different ways and forms throughout math,  and it's super tricky to actually define. Loosely speaking, it refers to situations where you have a natural  but surprising correspondence between two types of mathematical thing. For the linear algebra case that you just learned about,  you'd say that the dual of a vector is the linear transformation that it encodes,  and the dual of a linear transformation from some space to one dimension is a  certain vector in that space. So to sum up, on the surface, the dot product is a very useful  geometric tool for understanding projections and for testing  whether or not vectors tend to point in the same direction. And that's probably the most important thing for you to remember about the dot product. But at a deeper level, dotting two vectors together is a way  to translate one of them into the world of transformations. Again, numerically, this might feel like a silly point to emphasize. It's just two computations that happen to look similar. But the reason I find this so important is that throughout math,  when you're dealing with a vector, once you really get to know its personality,  sometimes you realize that it's easier to understand it not as an arrow in space,  but as the physical embodiment of a linear transformation. It's as if the vector is really just a conceptual shorthand for a certain transformation,  since it's easier for us to think about arrows in space rather than  moving all of that space to the number line. In the next video, you'll see another really cool example of this duality in action,  as I talk about the cross product.

================================================================================
VIDEO ID: v8VSDg_WQlA
TITLE: Nonsquare matrices as transformations between dimensions | Chapter 8, Essence of linear algebra
URL: https://www.youtube.com/watch?v=v8VSDg_WQlA
PUBLISHED: 2016-08-16T21:59:23Z
STATUS: SUCCESS
================================================================================
Hey everyone, I've got another quick footnote for you between chapters today. When I've talked about linear transformations so far,  I've only really talked about transformations from 2D vectors to other 2D vectors,  represented with 2x2 matrices, or from 3D vectors to other 3D vectors,  represented with 3x3 matrices. But several commenters have asked about non-square matrices,  so I thought I'd take a moment to just show what those mean geometrically. By now in the series, you actually have most of the background  you need to start pondering a question like this on your own,  but I'll start talking through it just to give a little mental momentum. It's perfectly reasonable to talk about transformations between dimensions,  such as one that takes 2D vectors to 3D vectors. Again, what makes one of these linear is that gridlines remain  parallel and evenly spaced, and that the origin maps to the origin. What I have pictured here is the input space on the left,  which is just 2D space, and the output of the transformation shown on the right. The reason I'm not showing the inputs move over to the outputs like I usually do is not  just animation laziness, it's worth emphasizing that 2D vector inputs are very different  animals from these 3D vector outputs, living in a completely separate, unconnected space. Encoding one of these transformations with a matrix is  really just the same thing as what we've done before. You look at where each basis vector lands, and write the  coordinates of the landing spots as the columns of a matrix. For example, what you're looking at here is an output of a transformation that takes  i-hat to the coordinates 2, negative 1, negative 2, and j-hat to the coordinates 0, 1, 1. Notice, this means the matrix encoding our transformation has three rows and two columns,  which, to use standard terminology, makes it a 3x2 matrix. In the language of last video, the column space of this matrix,  the place where all the vectors land, is a 2D plane slicing through the origin  of 3D space. But the matrix is still full rank, since the number of dimensions in this  column space is the same as the number of dimensions of the input space. So if you see a 3x2 matrix out in the wild, you can know that it has the geometric  interpretation of mapping two dimensions to three dimensions,  since the two columns indicate that the input space has two basis vectors,  and the three rows indicate that the landing spots for each of those basis vectors is  described with three separate coordinates. Likewise, if you see a 2x3 matrix with two rows and three columns,  what do you think that means? Well, the three columns indicate that you're starting in a space that has  three basis vectors, so we're starting in three dimensions,  and the two rows indicate that the landing spot for each of those three  basis vectors is described with only two coordinates,  so they must be landing in two dimensions. So it's a transformation from 3D space onto the 2D plane,  a transformation that should feel very uncomfortable if you imagine going through it. You could also have a transformation from two dimensions to one dimension. One-dimensional space is really just the number line,  so a transformation like this takes in 2D vectors and spits out numbers. Thinking about grid lines remaining parallel and evenly spaced is a little bit  messy due to all of the squishification happening here, so in this case,  the visual understanding for what linearity means is that if you have a line of  evenly spaced dots, it would remain evenly spaced once they're mapped onto the  number line. One of these transformations is encoded with a 1x2 matrix,  each of whose two columns has just a single entry. The two columns represent where the basis vectors land,  and each one of those columns requires just one number,  the number that that basis vector landed on. This is actually a surprisingly meaningful type of transformation with  close ties to the dot product, and I'll be talking about that next video. Until then, I encourage you to play around with this idea on your own,  contemplating the meanings of things like matrix multiplication and linear systems  of equations in the context of transformations between different dimensions. Have fun!

================================================================================
VIDEO ID: uQhTuRlWMxw
TITLE: Inverse matrices, column space and null space | Chapter 7, Essence of linear algebra
URL: https://www.youtube.com/watch?v=uQhTuRlWMxw
PUBLISHED: 2016-08-15T22:00:22Z
STATUS: SUCCESS
================================================================================
As you can probably tell by now, the bulk of this series is on understanding matrix  and vector operations through that more visual lens of linear transformations. This video is no exception, describing the concepts of inverse matrices,  column space, rank, and null space through that lens. A forewarning though, I'm not going to talk about the methods for actually  computing these things, and some would argue that that's pretty important. There are a lot of very good resources for learning those methods outside this series,  keywords Gaussian elimination and row echelon form. I think most of the value that I actually have to add here is on the intuition half. Plus, in practice, we usually get software to compute this stuff for us anyway. First, a few words on the usefulness of linear algebra. By now, you already have a hint for how it's used in describing the manipulation  of space, which is useful for things like computer graphics and robotics. But one of the main reasons that linear algebra is more  broadly applicable and required for just about any technical  discipline is that it lets us solve certain systems of equations. When I say system of equations, I mean you have a list of variables,  things you don't know, and a list of equations relating them. In a lot of situations, those equations can get very complicated. But, if you're lucky, they might take on a certain special form. Within each equation, the only thing happening to each variable is  that it's scaled by some constant, and the only thing happening to  each of those scaled variables is that they're added to each other. So no exponents or fancy functions or multiplying two variables together,  things like that. The typical way to organize this sort of special system of equations is to  throw all the variables on the left and put any lingering constants on the right. It's also nice to vertically line up the common variables,  and to do that, you might need to throw in some zero coefficients  whenever the variable doesn't show up in one of the equations. This is called a linear system of equations. You might notice that this looks a lot like matrix-vector multiplication. In fact, you can package all of the equations together into a single  vector equation where you have the matrix containing all of the  constant coefficients and a vector containing all of the variables,  and their matrix-vector product equals some different constant vector. Let's name that constant matrix A, denote the vector holding the variables  with a bold-faced X, and call the constant vector on the right-hand side V. This is more than just a notational trick to get  our system of equations written on one line. It sheds light on a pretty cool geometric interpretation for the problem. The matrix A corresponds with some linear transformation,  so solving Ax equals V means we're looking for a vector X, which,  after applying the transformation, lands on V. Think about what's happening here for a moment. You can hold in your head this really complicated idea of multiple  variables all intermingling with each other just by thinking about  squishing and morphing space and trying to figure out which vector lands on another. Cool, right? To start simple, let's say you have a system with two equations and two unknowns. This means the matrix A is a 2x2 matrix, and V and X are each two-dimensional vectors. Now, how we think about the solutions to this equation depends on whether the  transformation associated with A squishes all of space into a lower dimension,  like a line or a point, or if it leaves everything spanning the full two dimensions  where it started. In the language of the last video, we subdivide into the cases where  A has zero determinant and the case where A has non-zero determinant. Let's start with the most likely case, where the determinant is non-zero,  meaning space does not get squished into a zero-area region. In this case, there will always be one and only one vector that lands on V,  and you can find it by playing the transformation in reverse. Following where V goes as we rewind the tape like this,  you'll find the vector x such that A times x equals V. When you play the transformation in reverse, it actually corresponds to a separate  linear transformation, commonly called the inverse of A, denoted A to the negative one. For example, if A was a counterclockwise rotation by 90 degrees,  then the inverse of A would be a clockwise rotation by 90 degrees. If A was a rightward shear that pushes j-hat one unit to the right,  the inverse of A would be a leftward shear that pushes j-hat one unit to the left. In general, A inverse is the unique transformation with the property that if you first  apply A, then follow it with the transformation A inverse,  you end up back where you started. Applying one transformation after another is captured algebraically with  matrix multiplication, so the core property of this transformation A inverse  is that A inverse times A equals the matrix that corresponds to doing nothing. The transformation that does nothing is called the identity transformation. It leaves i-hat and j-hat each where they are, unmoved, so its columns are 1,0 and 0,1. Once you find this inverse, which in practice you'd do with a computer,  you can solve your equation by multiplying this inverse matrix by v. And again, what this means geometrically is that you're  playing the transformation in reverse and following v. This non-zero determinant case, which for a random choice of matrix is by far the  most likely one, corresponds with the idea that if you have two unknowns and two  equations, it's almost certainly the case that there's a single unique solution. This idea also makes sense in higher dimensions,  when the number of equations equals the number of unknowns. Again, the system of equations can be translated to the geometric  interpretation where you have some transformation A and some vector v,  and you're looking for the vector x that lands on v. As long as the transformation A doesn't squish all of space into a lower dimension,  meaning its determinant is non-zero, there will be an inverse transformation A inverse,  with the property that if you first do A, then you do A inverse,  it's the same as doing nothing. And to solve your equation, you just have to multiply  that reverse transformation matrix by the vector v. But when the determinant is zero, and the transformation associated with the  system of equations squishes space into a smaller dimension, there is no inverse. You cannot unsquish a line to turn it into a plane. At least that's not something that a function can do. That would require transforming each individual vector into a whole line full of vectors. But functions can only take a single input to a single output. Similarly, for three equations and three unknowns,  there will be no inverse if the corresponding transformation  squishes 3D space onto the plane, or even if it squishes it onto a line or a point. Those all correspond to a determinant of zero,  since any region is squished into something with zero volume. It's still possible that a solution exists even when there is no inverse. It's just that when your transformation squishes space onto, say, a line,  you have to be lucky enough that the vector v lives somewhere on that line. You might notice that some of these zero determinant  cases feel a lot more restrictive than others. Given a 3x3 matrix, for example, it seems a lot harder for a solution  to exist when it squishes space onto a line compared to when it squishes  things onto a plane, even though both of those are zero determinant. We have some language that's a bit more specific than just saying zero determinant. When the output of a transformation is a line,  meaning it's one-dimensional, we say the transformation has a rank of one. If all the vectors land on some two-dimensional plane,  we say the transformation has a rank of two. So the word rank means the number of dimensions in the output of a transformation. For instance, in the case of 2x2 matrices, rank two is the best that it can be. It means the basis vectors continue to span the full two dimensions of space,  and the determinant is not zero. But for 3x3 matrices, rank two means that we've collapsed,  but not as much as they would have collapsed for a rank one situation. If a 3D transformation has a non-zero determinant and its output fills all of 3D space,  it has a rank of three. This set of all possible outputs for your matrix, whether it's a line,  a plane, 3D space, whatever, is called the column space of your matrix. You can probably guess where that name comes from. The columns of your matrix tell you where the basis vectors land,  and the span of those transformed basis vectors gives you all possible outputs. In other words, the column space is the span of the columns of your matrix. So a more precise definition of rank would be that  it's the number of dimensions in the column space. When this rank is as high as it can be, meaning it equals the number of columns,  we call the matrix full rank. Notice the zero vector will always be included in the column space,  since linear transformations must keep the origin fixed in place. For a full rank transformation, the only vector  that lands at the origin is the zero vector itself. But for matrices that aren't full rank, which squish to a smaller dimension,  you can have a whole bunch of vectors that land on zero. If a 2D transformation squishes space onto a line, for example,  there is a separate line in a different direction full of vectors that get squished  onto the origin. If a 3D transformation squishes space onto a plane,  there's also a full line of vectors that land on the origin. If a 3D transformation squishes all of space onto a line,  then there's a whole plane full of vectors that land on the origin. This set of vectors that lands on the origin is called the null space,  or the kernel of your matrix. It's the space of all vectors that become null,  in the sense that they land on the zero vector. In terms of the linear system of equations, when v happens to be the zero vector,  the null space gives you all of the possible solutions to the equation. So that's a very high level overview of how to  think about linear systems of equations geometrically. Each system has some kind of linear transformation associated with it,  and when that transformation has an inverse, you can use that inverse to solve  your system. Otherwise, the idea of column space lets us understand when a solution even exists,  and the idea of a null space helps us to understand what the  set of all possible solutions can look like. Again, there's a lot that I haven't covered here,  most notably how to compute these things. I also had to limit my scope to examples where the  number of equations equals the number of unknowns. But the goal here is not to try to teach everything,  it's that you come away with a strong intuition for inverse matrices,  column space, and null space, and that those intuitions make any future  learning that you do more fruitful. Next video, by popular request, will be a brief footnote about non-square matrices. Then after that, I'm going to give you my take on dot products,  and something pretty cool that happens when you view them under the light of linear  transformations. See you then!

================================================================================
VIDEO ID: Ip3X9LOh2dk
TITLE: The determinant | Chapter 6, Essence of linear algebra
URL: https://www.youtube.com/watch?v=Ip3X9LOh2dk
PUBLISHED: 2016-08-10T22:31:18Z
STATUS: SUCCESS
================================================================================
Hello, hello again. So moving forward, I'll be assuming that you have a visual understanding  of linear transformations and how they're represented with matrices,  the way that I've been talking about in the last few videos. If you think about a couple of these linear transformations,  you might notice how some of them seem to stretch space out, while others squish it on in. One thing that turns out to be pretty useful for understanding one of these  transformations is to measure exactly how much it stretches or squishes things. More specifically, to measure the factor by which  the area of a given region increases or decreases. For example, look at the matrix with columns 3, 0 and 0, 2. It scales i-hat by a factor of 3 and scales j-hat by a factor of 2. Now, if we focus our attention on the 1 by 1 square whose bottom sits on i-hat and whose  left side sits on j-hat, after the transformation, this turns into a 2 by 3 rectangle. Since this region started out with area 1 and ended up with area 6,  we can say the linear transformation has scaled its area by a factor of 6. Compare that to a shear, whose matrix has columns 1, 0 and 1,  1, meaning i-hat stays in place and j-hat moves over to 1, 1. That same unit square determined by i-hat and j-hat gets slanted  and turned into a parallelogram, but the area of that parallelogram is still 1,  since its base and height each continue to have length 1. So even though this transformation smushes things about,  it seems to leave areas unchanged, at least in the case of that 1 unit square. Actually though, if you know how much the area of that one single unit square changes,  it can tell you how the area of any possible region in space changes. For starters, notice that whatever happens to one square in the grid  has to happen to any other square in the grid, no matter the size. This follows from the fact that grid lines remain parallel and evenly spaced. Then, any shape that's not a grid square can be approximated by grid squares pretty well,  with arbitrarily good approximations if you use small enough grid squares. So, since the areas of all those tiny grid squares are being scaled by some single  amount, the area of the blob as a whole will also be scaled by that same single amount. This very special scaling factor, the factor by which a linear transformation  changes any area, is called the determinant of that transformation. I'll show how to compute the determinant of a transformation  using its matrix later on in this video, but understanding what it represents is,  trust me, much more important than the computation. For example, the determinant of a transformation would be 3 if  that transformation increases the area of a region by a factor of 3.
40
00:02:57,610 --> 00:02:57,040
The determinant of a transformation would be Â½ 
41
00:02:58,180 --> 00:02:57,610
if it squishes down all areas by a factor of Â½. The determinant of a transformation would be 1 half if it squishes down  all areas by a factor of 1 half. And the determinant of a 2D transformation  is 0 if it squishes all of space onto a line, or even onto a single point. Since then, the area of any region would become zero. That last example will prove to be pretty important. It means that checking if the determinant of a given matrix is zero  will give a way of computing whether or not the transformation  associated with that matrix squishes everything into a smaller dimension. You'll see in the next few videos why this is even a useful thing to think about,  but for now, I just want to lay down all of the visual intuition,  which, in and of itself, is a beautiful thing to think about. Okay, I need to confess that what I've said so far is not quite right. The full concept of the determinant allows for negative values. But what would the idea of scaling an area by a negative amount even mean? This has to do with the idea of orientation. For example, notice how this transformation gives the sensation of flipping space over. If you were thinking of 2D space as a sheet of paper,  a transformation like that one seems to turn over that sheet onto the other side. Any transformations that do this are said to invert the orientation of space. Another way to think about it is in terms of i-hat and j-hat. Notice that in their starting positions, j-hat is to the left of i-hat. If, after a transformation, j-hat is now on the right of i-hat,  the orientation of space has been inverted. Whenever this happens, whenever the orientation of space is inverted,  the determinant will be negative. The absolute value of the determinant, though,  still tells you the factor by which areas have been scaled. For example, the matrix with columns 1, 1 and 2,  negative 1 encodes a transformation that has determinant, I'll just tell you, negative 3. And what this means is that space gets flipped over and areas are scaled by a factor of 3. So why would this idea of a negative area scaling  factor be a natural way to describe orientation flipping? Think about the series of transformations you get by  slowly letting i-hat get closer and closer to j-hat. As i-hat gets closer, all of the areas in space are getting squished more and more,  meaning the determinant approaches 0. Once i-hat lines up perfectly with j-hat, the determinant is 0. Then, if i-hat continues the way that it was going,  doesn't it kind of feel natural for the determinant to keep decreasing into  the negative numbers? So that's the understanding of determinants in two dimensions. What do you think it should mean for three dimensions? It also tells you how much a transformation scales things,  but this time, it tells you how much volumes get scaled. Just as in two dimensions, where this is easiest to think about by focusing  on one particular square with an area 1 and watching only what happens to it,  in three dimensions, it helps to focus your attention on the specific 1 by 1  by 1 cube whose edges are resting on the basis vectors, i-hat, j-hat and k-hat. After the transformation, that cube might get warped into some kind of slanty slanty cube. This shape, by the way, has the best name ever, parallelipiped,  a name that's made even more delightful when your professor has a nice thick  Russian accent. Since this cube starts out with a volume of 1,  and the determinant gives the factor by which any volume is scaled,  you can think of the determinant simply as being the volume of that  parallelipiped that the cube turns into. A determinant of 0 would mean that all of space is squished onto something with 0 volume,  meaning either a flat plane, a line, or, in the most extreme case, onto a single point. Those of you who watched chapter 2 will recognize this as  meaning that the columns of the matrix are linearly dependent. Can you see why? What about negative determinants? What should that mean for three dimensions? One way to describe orientation in 3D is with the right hand rule. Point the forefinger of your right hand in the direction of i-hat,  stick out your middle finger in the direction of j-hat,  and notice how when you point your thumb up, it's in the direction of k-hat. If you can still do that after the transformation,  orientation has not changed, and the determinant is positive. Otherwise, if after the transformation it only makes sense to do that with  your left hand, orientation has been flipped, and the determinant is negative. So, if you haven't seen it before, you're probably wondering by now,  how do you actually compute the determinant? For a 2x2 matrix with entries a, b, c, d, the formula is a times d minus b times c. Here's part of an intuition for where this formula comes from. Let's say that the terms b and c both happened to be 0. Then, the term a tells you how much i-hat is stretched in the x direction,  and the term d tells you how much j-hat is stretched in the y direction. So, since those other terms are 0, it should make sense that a  times d gives the area of the rectangle that our favorite unit square turns into,  kind of like the 3, 0, 0, 2 example from earlier. Even if only one of b or c are 0, you'll have  a parallelogram with a base a and a height d. So, the area should still be a times d. Loosely speaking, if both b and c are non-zero,  then that b times c term tells you how much this parallelogram is stretched or  squished in the diagonal direction. For those of you hungry for a more precise description of this b times c term,  here's a helpful diagram if you'd like to pause and ponder. Now, if you feel like computing determinants by hand is something that you need to know,  the only way to get it down is to just practice it with a few. There's really not that much I can say or animate  that's going to drill in the computation. This is all triply true for three-dimensional determinants. There is a formula, and if you feel like that's something you need to know,  you should practice with a few matrices, or, you know,  go watch Sal Khan work through a few. Honestly, though, I don't think that those computations fall within  the essence of linear algebra, but I definitely think that  understanding what the determinant represents falls within that essence. Here's kind of a fun question to think about before the next video. If you multiply two matrices together, the determinant of the resulting matrix  is the same as the product of the determinants of the original two matrices. If you tried to justify this with numbers, it would take a really long time,  but see if you can explain why this makes sense in just one sentence. Next up, I'll be relating the idea of linear transformations covered so far to one of  the areas where linear algebra is most useful, linear systems of equations. See you then!

================================================================================
VIDEO ID: rHLEWRxRGiM
TITLE: Three-dimensional linear transformations | Chapter 5, Essence of linear algebra
URL: https://www.youtube.com/watch?v=rHLEWRxRGiM
PUBLISHED: 2016-08-09T22:01:39Z
STATUS: SUCCESS
================================================================================
Hey folks, I've got a relatively quick video for you today,  just sort of a footnote between chapters. In the last two videos I talked about linear transformations and matrices,  but I only showed the specific case of transformations that take  two-dimensional vectors to other two-dimensional vectors. In general throughout the series we'll work mainly in two dimensions,  mostly because it's easier to actually see on the screen and wrap your mind around. But more importantly than that, once you get all the core ideas in two dimensions,  they carry over pretty seamlessly to higher dimensions. Nevertheless, it's good to peek our heads outside of flatland now and then to,  you know, see what it means to apply these ideas in more than just those two dimensions. For example, consider a linear transformation with three-dimensional  vectors as inputs and three-dimensional vectors as outputs. We can visualize this by smooshing around all the points in three-dimensional space,  as represented by a grid, in such a way that keeps the grid lines parallel  and evenly spaced, and which fixes the origin in place. And just as with two dimensions, every point of space that we see moving around is  really just a proxy for a vector who has its tip at that point,  and what we're really doing is thinking about input vectors moving over to their  corresponding outputs. And just as with two dimensions, one of these transformations  is completely described by where the basis vectors go. But now, there are three standard basis vectors that we typically use. The unit vector in the x direction, i-hat, the unit vector in the y direction,  j-hat, and a new guy, the unit vector in the z direction, called k-hat. In fact, I think it's easier to think about these transformations by only following  those basis vectors, since the full 3D grid representing all points can get kind of messy. By leaving a copy of the original axes in the background,  we can think about the coordinates of where each of these three basis vectors lands. Record the coordinates of these three vectors as the columns of a 3x3 matrix. This gives a matrix that completely describes the transformation using only nine numbers. As a simple example, consider the transformation  that rotates space 90 degrees around the y-axis. So that would mean that it takes i-hat to the coordinates 0,0, negative 1 on the z-axis. It doesn't move j-hat, so it stays at the coordinates 0,1,0. And then k-hat moves over to the x-axis at 1,0,0. Those three sets of coordinates become the columns of  a matrix that describes that rotation transformation. To see where a vector with coordinates x,y,z lands,  the reasoning is almost identical to what it was for two dimensions. Each of those coordinates can be thought of as instructions for how to  scale each basis vector so that they add together to get your vector. And the important part, just like the 2D case,  is that this scaling and adding process works both before and after the transformation. So to see where your vector lands, you multiply those coordinates by the  corresponding columns of the matrix, and then you add together the three results. Multiplying two matrices is also similar. Whenever you see two 3x3 matrices getting multiplied together,  you should imagine first applying the transformation encoded by the right one,  then applying the transformation encoded by the left one. It turns out that 3D matrix multiplication is actually pretty important for fields  like computer graphics and robotics, since things like rotations and three dimensions  can be pretty hard to describe, but they're easier to wrap your mind around if you  can break them down as the composition of separate, easier-to-think-about rotations. Performing this matrix multiplication numerically is,  once again, pretty similar to the two-dimensional case. In fact, a good way to test your understanding of the last video would be to try to  reason through what specifically this matrix multiplication should look like,  thinking closely about how it relates to the idea of applying two successive  transformations in space. In the next video, I'll start getting into the determinant.

================================================================================
VIDEO ID: XkY2DOUCWMU
TITLE: Matrix multiplication as composition | Chapter 4, Essence of linear algebra
URL: https://www.youtube.com/watch?v=XkY2DOUCWMU
PUBLISHED: 2016-08-08T22:20:43Z
STATUS: SUCCESS
================================================================================
Hey everyone, where we last left off, I showed what linear  transformations look like and how to represent them using matrices. This is worth a quick recap because it's just really important,  but of course if this feels like more than just a recap, go back and watch the full video. Technically speaking, linear transformations are functions with vectors  as inputs and vectors as outputs, but I showed last time how we can think  about them visually as smooshing around space in such a way that grid  lines stay parallel and evenly spaced, and so that the origin remains fixed. The key takeaway was that a linear transformation is completely determined by where it  takes the basis vectors of the space, which for two dimensions means i-hat and j-hat. This is because any other vector could be described  as a linear combination of those basis vectors. A vector with coordinates x, y is x times i-hat plus y times j-hat. After going through the transformation, this property that grid  lines remain parallel and evenly spaced has a wonderful consequence. The place where your vector lands will be x times the transformed  version of i-hat plus y times the transformed version of j-hat. This means if you keep a record of the coordinates where i-hat lands and the  coordinates where j-hat lands, you can compute that a vector which starts at x,  y must land on x times the new coordinates of i-hat plus y times the new coordinates  of j-hat. The convention is to record the coordinates of where i-hat and j-hat  land as the columns of a matrix, and to define this sum of the scaled  versions of those columns by x and y to be matrix-vector multiplication. In this way, a matrix represents a specific linear transformation,  and multiplying a matrix by a vector is what it means  computationally to apply that transformation to that vector. Alright, recap over, on to the new stuff. Oftentimes, you find yourself wanting to describe the  effects of applying one transformation and then another. For example, maybe you want to describe what happens when you first  rotate the plane 90 degrees counterclockwise, then apply a shear. The overall effect here, from start to finish,  is another linear transformation, distinct from the rotation and the shear. This new linear transformation is commonly called the  composition of the two separate transformations we applied. And like any linear transformation, it can be described  with a matrix all of its own by following i-hat and j-hat. In this example, the ultimate landing spot for i-hat after both transformations is 1,1,  so let's make that the first column of a matrix. Likewise, j-hat ultimately ends up at the location negative 1,0,  so we make that the second column of the matrix. This new matrix captures the overall effect of applying a rotation then a shear,  but as one single action, rather than two successive ones. Here's one way to think about that new matrix. If you were to take some vector and pump it through the rotation, then the shear,  the long way to compute where it ends up is to first multiply it on the left by the  rotation matrix, then take whatever you get and multiply that on the left by the shear  matrix. This is, numerically speaking, what it means to  apply a rotation then a shear to a given vector. But whatever you get should be the same as just applying this new composition matrix  that we just found by that same vector, no matter what vector you chose,  since this new matrix is supposed to capture the same overall effect as the rotation  then shear action. Based on how things are written down here, I think it's reasonable to  call this new matrix the product of the original two matrices, don't you? We can think about how to compute that product more generally in just a moment,  but it's way too easy to get lost in the forest of numbers. Always remember that multiplying two matrices like this has the  geometric meaning of applying one transformation then another. One thing that's kind of weird here is that this has us reading from right to left. You first apply the transformation represented by the matrix on the right,  then you apply the transformation represented by the matrix on the left. This stems from function notation, since we write functions on the left of variables,  so every time you compose two functions, you always have to read it right to left. Good news for the Hebrew readers, bad news for the rest of us. Let's look at another example. Take the matrix with columns 1,1 and negative 2,0, whose transformation looks like this. And let's call it M1. Next, take the matrix with columns 0,1 and 2,0, whose transformation looks like this. And let's call that guy M2. The total effect of applying M1 then M2 gives us a new transformation,  so let's find its matrix. But this time, let's see if we can do it without watching the animations,  and instead just using the numerical entries in each matrix. First, we need to figure out where i-hat goes. After applying M1, the new coordinates of i-hat,  by definition, are given by that first column of M1, namely 1,1. To see what happens after applying M2, multiply the matrix for M2 by that vector 1,1. Working it out, the way I described last video, you'll get the vector 2,1. This will be the first column of the composition matrix. Likewise, to follow j-hat, the second column of  M1 tells us that it first lands on negative 2,0. Then, when we apply M2 to that vector, you can work out the matrix-vector product  to get 0, negative 2, which becomes the second column of our composition matrix. Let me talk through that same process again, but this time I'll show variable entries  in each matrix, just to show that the same line of reasoning works for any matrices. This is more symbol-heavy and will require some more room,  but it should be pretty satisfying for anyone who has previously been taught matrix  multiplication the more rote way. To follow where i-hat goes, start by looking at the first column of  the matrix on the right, since this is where i-hat initially lands. Multiplying that column by the matrix on the left is how you can tell where the  intermediate version of i-hat ends up after applying the second transformation. So the first column of the composition matrix will always  equal the left matrix times the first column of the right matrix. Likewise, j-hat will always initially land on the second column of the right matrix. So multiplying the left matrix by this second column will give its final location,  and hence that's the second column of the composition matrix. Notice there's a lot of symbols here, and it's common to be taught this formula as  something to memorize, along with a certain algorithmic process to help remember it. But I really do think that before memorizing that process,  you should get in the habit of thinking about what matrix  multiplication really represents, applying one transformation after another. Trust me, this will give you a much better conceptual framework that  makes the properties of matrix multiplication much easier to understand. For example, here's a question. Does it matter what order we put the two matrices in when we multiply them? Well, let's think through a simple example, like the one from earlier. Take a shear, which fixes i-hat and smooshes j-hat over to the right,  and a 90 degree rotation. If you first do the shear, then rotate, we can see that  i-hat ends up at 0,1 and j-hat ends up at negative 1,1. Both are generally pointing close together. If you first rotate, then do the shear, i-hat ends up over at 1,1,  and j-hat is off in a different direction at negative 1,0, and they're pointing,  you know, farther apart. The overall effect here is clearly different, so evidently, order totally does matter. Notice, by thinking in terms of transformations,  that's the kind of thing that you can do in your head by visualizing. No matrix multiplication necessary. I remember when I first took linear algebra, there was this one homework  problem that asked us to prove that matrix multiplication is associative. This means that if you have three matrices, A, B, and C,  and you multiply them all together, it shouldn't matter if you first compute A times B,  then multiply the result by C, or if you first multiply B times C,  then multiply that result by A on the left. In other words, it doesn't matter where you put the parentheses. Now, if you try to work through this numerically, like I did back then,  it's horrible, just horrible, and unenlightening for that matter. But when you think about matrix multiplication as applying  one transformation after another, this property is just trivial. Can you see why? What it's saying is that if you first apply C, then B,  then A, it's the same as applying C, then B, then A. I mean, there's nothing to prove. You're just applying the same three things one after the other, all in the same order. This might feel like cheating, but it's not. This is an honest-to-goodness proof that matrix multiplication is associative,  and even better than that, it's a good explanation for why that property should be true. I really do encourage you to play around more with this idea,  imagining two different transformations, thinking about what happens when  you apply one after the other, and then working out the matrix product numerically. Trust me, this is the kind of playtime that really makes the idea sink in. In the next video, I'll start talking about extending  these ideas beyond just two dimensions. See you then!

================================================================================
VIDEO ID: kYB8IZa5AuE
TITLE: Linear transformations and matrices | Chapter 3, Essence of linear algebra
URL: https://www.youtube.com/watch?v=kYB8IZa5AuE
PUBLISHED: 2016-08-07T21:39:19Z
STATUS: SUCCESS
================================================================================
Hey everyone! If I had to choose just one topic that makes all of the others in  linear algebra start to click, and which too often goes unlearned  the first time a student takes linear algebra, it would be this one. The idea of a linear transformation and its relation to matrices. For this video, I'm just going to focus on what these transformations look like in the  case of two dimensions, and how they relate to the idea of matrix vector multiplication. In particular, I want to show you a way to think about matrix  vector multiplication that doesn't rely on memorization. To start, let's just parse this term, linear transformation. Transformation is essentially a fancy word for function. It's something that takes in inputs and spits out an output for each one. Specifically, in the context of linear algebra,  we like to think about transformations that take in some vector and  spit out another vector. So why use the word transformation instead of function if they mean the same thing? Well, it's to be suggestive of a certain way to visualize this input-output relation. You see, a great way to understand functions of vectors is to use movement. If a transformation takes some input vector to some output vector,  we imagine that input vector moving over to the output vector. Then to understand the transformation as a whole,  we might imagine watching every possible input vector move over to its  corresponding output vector. It gets really crowded to think about all of the vectors all at once,  each one as an arrow. So as I mentioned last video, a nice trick is to conceptualize each vector  not as an arrow, but as a single point, the point where its tip sits. That way, to think about a transformation taking every possible input vector  to some output vector, we watch every point in space moving to some other point. In the case of transformations in two dimensions,  to get a better feel for the whole shape of the transformation,  I like to do this with all of the points on an infinite grid. I also sometimes like to keep a copy of the grid in the background,  just to help keep track of where everything ends up relative to where it starts. The effect for various transformations moving around all of the points in space is,  you've got to admit, beautiful. It gives the feeling of squishing and morphing space itself. As you can imagine though, arbitrary transformations can look pretty complicated. But luckily, linear algebra limits itself to a special type of transformation,  ones that are easier to understand, called linear transformations. Visually speaking, a transformation is linear if it has two properties. All lines must remain lines without getting curved,  and the origin must remain fixed in place. For example, this right here would not be a linear transformation,  since the lines get all curvy. And this one right here, although it keeps the lines straight,  is not a linear transformation, because it moves the origin. This one here fixes the origin, and it might look like it keeps lines straight,  but that's just because I'm only showing the horizontal and vertical grid lines. When you see what it does to a diagonal line, it becomes clear  that it's not at all linear, since it turns that line all curvy. In general, you should think of linear transformations  as keeping grid lines parallel and evenly spaced. Some linear transformations are simple to think about, like rotations about the origin. Others are a little trickier to describe with words. So, how do you think you could describe these transformations numerically? If you were, say, programming some animations to make a video teaching the topic,  what formula do you give the computer so that if you give it the coordinates of a vector,  it can give you the coordinates of where that vector lands? It turns out that you only need to record where the two basis vectors,  i-hat and j-hat, each land, and everything else will follow from that. For example, consider the vector v with coordinates negative 1, 2,  meaning that it equals negative 1 times i-hat plus 2 times j-hat. If we play some transformation and follow where all three of these vectors go,  the property that grid lines remain parallel and evenly spaced has a really important  consequence. The place where v lands will be negative 1 times the vector  where i-hat landed plus 2 times the vector where j-hat landed. In other words, it started off as a certain linear combination of i-hat and j-hat,  and it ends up as that same linear combination of where those two vectors landed. This means you can deduce where v must go based only on where i-hat and j-hat each land. This is why I like keeping a copy of the original grid in the background. For the transformation shown here, we can read off that i-hat lands on the coordinates 1,  negative 2, and j-hat lands on the x-axis over at the coordinates 3, 0. This means that the vector represented by negative 1 i-hat plus 2 times j-hat  ends up at negative 1 times the vector 1, negative 2 plus 2 times the vector 3, 0. Adding that all together, you can deduce that it has to land on the vector 5, 2. This is a good point to pause and ponder, because it's pretty important. Now, given that I'm actually showing you the full transformation,  you could have just looked to see that v has the coordinates 5, 2. But the cool part here is that this gives us a technique to deduce  where any vectors land so long as we have a record of where i-hat  and j-hat each land without needing to watch the transformation itself. Write the vector with more general coordinates, x and y,  and it will land on x times the vector where i-hat lands, 1, negative 2,  plus y times the vector where j-hat lands, 3, 0. Carrying out that sum, you see that it lands at 1x plus 3y, negative 2x plus 0y. I give you any vector, and you can tell me where that vector lands using this formula. What all of this is saying is that a two-dimensional linear transformation  is completely described by just four numbers, the two coordinates for  where i-hat lands and the two coordinates for where j-hat lands. Isn't that cool? It's common to package these coordinates into a 2x2 grid of numbers called a 2x2 matrix,  where you can interpret the columns as the two special vectors  where i-hat and j-hat each land. If you're given a 2x2 matrix describing a linear transformation and some specific vector,  and you want to know where that linear transformation takes that vector,  you can take the coordinates of the vector, multiply them by the corresponding  columns of the matrix, then add together what you get. This corresponds with the idea of adding the scaled versions of our new basis vectors. Let's see what this looks like in the most general case,  where your matrix has entries A, B, C, D. And remember, this matrix is just a way of packaging the  information needed to describe a linear transformation. Always remember to interpret that first column, AC,  as the place where the first basis vector lands, and that second column, BD,  as the place where the second basis vector lands. When we apply this transformation to some vector xy, what do you get? Well, it'll be x times AC plus y times BD. Putting this together, you get a vector Ax plus By, Cx plus Dy. You could even define this as matrix vector multiplication,  when you put the matrix on the left of the vector like it's a function. Then, you could make high schoolers memorize this without  showing them the crucial part that makes it feel intuitive. But, isn't it more fun to think about these columns as the  transformed versions of your basis vectors, and to think about  the result as the appropriate linear combination of those vectors? Let's practice describing a few linear transformations with matrices. For example, if we rotate all of space 90 degrees counterclockwise,  then i-hat lands on the coordinates 0, 1. And j-hat lands on the coordinates negative 1, 0. So the matrix we end up with has columns 0, 1, negative 1, 0. To figure out what happens to any vector after a 90-degree rotation,  you could just multiply its coordinates by this matrix. Here's a fun transformation with a special name, called a shear. In it, i-hat remains fixed, so the first column of the matrix is 1, 0. But j-hat moves over to the coordinates 1, 1,  which become the second column of the matrix. And at the risk of being redundant here, figuring out how a shear transforms  a given vector comes down to multiplying this matrix by that vector. Let's say we want to go the other way around, starting with a matrix,  say with columns 1, 2 and 3, 1, and we want to deduce what its transformation looks like. Pause and take a moment to see if you can imagine it. One way to do this is to first move i-hat to 1, 2, then move j-hat to 3, 1. Always moving the rest of space in such a way  that keeps gridlines parallel and evenly spaced. If the vectors that i-hat and j-hat land on are linearly dependent, which,  if you recall from last video, means that one is a scaled version of the other,  it means that the linear transformation squishes all of 2D space onto the line where  those two vectors sit, also known as the one-dimensional span of those two linearly  dependent vectors. To sum up, linear transformations are a way to move around space such that  gridlines remain parallel and evenly spaced, and such that the origin remains fixed. Delightfully, these transformations can be described using only a handful of numbers,  the coordinates of where each basis vector lands. Matrices give us a language to describe these transformations,  where the columns represent those coordinates,  and matrix-vector multiplication is just a way to compute what that  transformation does to a given vector. The important takeaway here is that every time you see a matrix,  you can interpret it as a certain transformation of space. Once you really digest this idea, you're in a  great position to understand linear algebra deeply. Almost all of the topics coming up, from matrix multiplication to determinants,  change of basis, eigenvalues, all of these will become easier to understand  once you start thinking about matrices as transformations of space. Most immediately, in the next video, I'll be talking about  multiplying two matrices together. See you then! Thank you for watching!

================================================================================
VIDEO ID: k7RM-ot2NWY
TITLE: Linear combinations, span, and basis vectors | Chapter 2, Essence of linear algebra
URL: https://www.youtube.com/watch?v=k7RM-ot2NWY
PUBLISHED: 2016-08-06T23:49:28Z
STATUS: SUCCESS
================================================================================
In the last video, along with the ideas of vector addition and scalar multiplication,  I described vector coordinates, where there's this back and forth between,  for example, pairs of numbers and two-dimensional vectors. Now, I imagine the vector coordinates were already familiar to a lot of you,  but there's another kind of interesting way to think about these coordinates,  which is pretty central to linear algebra. When you have a pair of numbers that's meant to describe a vector,  like 3, negative 2, I want you to think about each coordinate as a scalar,  meaning, think about how each one stretches or squishes vectors. In the xy coordinate system, there are two very special vectors,  the one pointing to the right with length 1, commonly called i-hat,  or the unit vector in the x direction, and the one pointing straight up with length 1,  commonly called j-hat, or the unit vector in the y direction. Now, think of the x coordinate of our vector as a scalar that scales i-hat,  stretching it by a factor of 3, and the y coordinate as a scalar that scales j-hat,  flipping it and stretching it by a factor of 2. In this sense, the vector that these coordinates  describe is the sum of two scaled vectors. That's a surprisingly important concept, this idea of adding together two scaled vectors. Those two vectors, i-hat and j-hat, have a special name, by the way. Together, they're called the basis of a coordinate system. What this means, basically, is that when you think about coordinates as scalars,  the basis vectors are what those scalars actually, you know, scale. There's also a more technical definition, but I'll get to that later. By framing our coordinate system in terms of these two special basis vectors,  it raises a pretty interesting and subtle point. We could have chosen different basis vectors and  gotten a completely reasonable new coordinate system. For example, take some vector pointing up and to the right,  along with some other vector pointing down and to the right in some way. Take a moment to think about all the different vectors that you can get by choosing two  scalars, using each one to scale one of the vectors, then adding together what you get. Which two-dimensional vectors can you reach by altering the choices of scalars? The answer is that you can reach every possible two-dimensional vector,  and I think it's a good puzzle to contemplate why. A new pair of basis vectors like this still gives us a valid way to go back and forth  between pairs of numbers and two-dimensional vectors,  but the association is definitely different from the one that you get using the more  standard basis of i-hat and j-hat. This is something I'll go into much more detail on later,  describing the exact relationship between different coordinate systems,  but for right now, I just want you to appreciate the fact that any time we  describe vectors numerically, it depends on an implicit choice of what basis  vectors we're using. So any time that you're scaling two vectors and adding them like this,  it's called a linear combination of those two vectors. Where does this word linear come from? Why does this have anything to do with lines? Well, this isn't the etymology, but one way I like to think about it  is that if you fix one of those scalars and let the other one change its value freely,  the tip of the resulting vector draws a straight line. Now, if you let both scalars range freely and consider every possible  vector that you can get, there are two things that can happen. For most pairs of vectors, you'll be able to reach every possible point in the plane. Every two-dimensional vector is within your grasp. However, in the unlucky case where your two original vectors happen to line up,  the tip of the resulting vector is limited to just this single line passing through the  origin. Actually, technically there's a third possibility too. Both your vectors could be zero, in which case you'd just be stuck at the origin. Here's some more terminology. The set of all possible vectors that you can reach with a linear combination  of a given pair of vectors is called the span of those two vectors. So restating what we just saw in this lingo, the span of most  pairs of 2D vectors is all vectors of 2D space, but when they line up,  their span is all vectors whose tip sit on a certain line. Remember how I said that linear algebra revolves  around vector addition and scalar multiplication? Well, the span of two vectors is basically a way of asking what  are all the possible vectors you can reach using only these two fundamental operations,  vector addition and scalar multiplication. This is a good time to talk about how people commonly think about vectors as points. It gets really crowded to think about a whole collection of vectors sitting on a line,  and more crowded still to think about all two-dimensional vectors all at once,  filling up the plane. So when dealing with collections of vectors like this,  it's common to represent each one with just a point in space,  the point at the tip of that vector where, as usual,  I want you thinking about that vector with its tail on the origin. That way, if you want to think about every possible vector whose  tip sits on a certain line, just think about the line itself. Likewise, to think about all possible two-dimensional vectors all at once,  conceptualize each one as the point where its tip sits. So in effect, what you'll be thinking about is the infinite flat  sheet of two-dimensional space itself, leaving the arrows out of it. In general, if you're thinking about a vector on its own, think of it as an arrow. And if you're dealing with a collection of vectors,  it's convenient to think of them all as points. So for our span example, the span of most pairs of vectors ends  up being the entire infinite sheet of two-dimensional space. But if they line up, their span is just a line. The idea of span gets a lot more interesting if we  start thinking about vectors in three-dimensional space. For example, if you take two vectors in 3D space that are not  pointing in the same direction, what does it mean to take their span? Well, their span is the collection of all possible linear combinations  of those two vectors, meaning all possible vectors you get by scaling  each of the two of them in some way and then adding them together. You can kind of imagine turning two different knobs to change  the two scalars defining the linear combination,  adding the scaled vectors and following the tip of the resulting vector. That tip will trace out some kind of flat sheet  cutting through the origin of three-dimensional space. This flat sheet is the span of the two vectors. Or more precisely, the set of all possible vectors whose  tips sit on that flat sheet is the span of your two vectors. Isn't that a beautiful mental image? So, what happens if we add a third vector and  consider the span of all three of those guys? A linear combination of three vectors is defined  pretty much the same way as it is for two. You'll choose three different scalars, scale each of those vectors,  and then add them all together. And again, the span of these vectors is the set of all possible linear combinations. Two different things could happen here. If your third vector happens to be sitting on the span of the first two,  then the span doesn't change. You're sort of trapped on that same flat sheet. In other words, adding a scaled version of that third vector to the  linear combination doesn't really give you access to any new vectors. But if you just randomly choose a third vector,  it's almost certainly not sitting on the span of those first two. Then, since it's pointing in a separate direction,  it unlocks access to every possible three-dimensional vector. One way I like to think about this is that as you scale that new third vector,  it moves around that span sheet of the first two, sweeping it through all of space. Another way to think about it is that you're making full use of the three freely changing  scalars that you have at your disposal to access the full three dimensions of space. Now, in the case where the third vector was already sitting on the span of the first two,  or the case where two vectors happen to line up,  we want some terminology to describe the fact that at least one of these vectors is  redundant, not adding anything to our span. Whenever this happens, where you have multiple vectors and you could remove one without  reducing the span, the relevant terminology is to say that they are linearly dependent. Another way of phrasing that would be to say that one of the vectors can be expressed  as a linear combination of the others, since it's already in the span of the others. On the other hand, if each vector really does add another dimension to the span,  they're said to be linearly independent. So with all of that terminology, and hopefully with some good mental  images to go with it, let me leave you with a puzzle before we go. The technical definition of a basis of a space is a  set of linearly independent vectors that span that space. Now, given how I described a basis earlier, and given your current understanding of the  words span and linearly independent, think about why this definition would make sense. In the next video, I'll get into matrices in transforming space. See you then!

================================================================================
VIDEO ID: fNk_zzaMoSs
TITLE: Vectors | Chapter 1, Essence of linear algebra
URL: https://www.youtube.com/watch?v=fNk_zzaMoSs
PUBLISHED: 2016-08-06T00:05:49Z
STATUS: SUCCESS
================================================================================
The fundamental, root-of-it-all building block for linear algebra is the vector. So it's worth making sure that we're all on the same page about what exactly a vector is. You see, broadly speaking, there are three distinct but related ideas about vectors,  which I'll call the physics student perspective,  the computer science student perspective, and the mathematician's perspective. The physics student perspective is that vectors are arrows pointing in space. What defines a given vector is its length and the direction it's pointing,  but as long as those two facts are the same, you can move it all around,  and it's still the same vector. Vectors that live in the flat plane are two-dimensional,  and those sitting in broader space that you and I live in are three-dimensional. The computer science perspective is that vectors are ordered lists of numbers. For example, let's say you were doing some analytics about house prices,  and the only features you cared about were square footage and price. You might model each house with a pair of numbers,  the first indicating square footage and the second indicating price. Notice the order matters here. In the lingo, you'd be modeling houses as two-dimensional vectors,  where in this context, vector is pretty much just a fancy word for list,  and what makes it two-dimensional is the fact that the length of that list is two. The mathematician, on the other hand, seeks to generalize both these views,  basically saying that a vector can be anything where there's a sensible notion of adding  two vectors and multiplying a vector by a number,  operations that I'll talk about later on in this video. The details of this view are rather abstract, and I actually think it's healthy to ignore  it until the last video of this series, favoring a more concrete setting in the interim. But the reason I bring it up here is that it hints at the  fact that the ideas of vector addition and multiplication by  numbers will play an important role throughout linear algebra. But before I talk about those operations, let's just settle in  on a specific thought to have in mind when I say the word vector. Given the geometric focus that I'm shooting for here,  whenever I introduce a new topic involving vectors,  I want you to first think about an arrow, and specifically,  think about that arrow inside a coordinate system, like the xy-plane,  with its tail sitting at the origin. This is a little bit different from the physics student perspective,  where vectors can freely sit anywhere they want in space. In linear algebra, it's almost always the case  that your vector will be rooted at the origin. Then, once you understand a new concept in the context of arrows in space,  we'll translate it over to the list of numbers point of view,  which we can do by considering the coordinates of the vector. Now, while I'm sure that many of you are already familiar with this coordinate system,  it's worth walking through explicitly, since this is where all of the important  back and forth happens between the two perspectives of linear algebra. Focusing our attention on two dimensions for the moment,  you have a horizontal line, called the x-axis, and a vertical line, called the y-axis. The place where they intersect is called the origin,  which you should think of as the center of space and the root of all vectors. After choosing an arbitrary length to represent one,  you make tick marks on each axis to represent this distance. When I want to convey the idea of 2D space as a whole,  which you'll see comes up a lot in these videos,  I'll extend these tick marks to make grid lines, but right now,  they'll actually get a little bit in the way. The coordinates of a vector is a pair of numbers that basically gives  instructions for how to get from the tail of that vector at the origin to its tip. The first number tells you how far to walk along the x-axis,  positive numbers indicating rightward motion, negative numbers indicating leftward  motion, and the second number tells you how far to walk parallel to the y-axis  after that, positive numbers indicating upward motion,  and negative numbers indicating downward motion. To distinguish vectors from points, the convention is to write  this pair of numbers vertically with square brackets around them. Every pair of numbers gives you one and only one vector,  and every vector is associated with one and only one pair of numbers. What about in three dimensions? Well, you add a third axis, called the z-axis,  which is perpendicular to both the x and y-axes, and in this case,  each vector is associated with ordered triplet of numbers. The first tells you how far to move along the x-axis,  the second tells you how far to move parallel to the y-axis,  and the third one tells you how far to then move parallel to this new z-axis. Every triplet of numbers gives you one unique vector in space,  and every vector in space gives you exactly one triplet of numbers. All right, so back to vector addition and multiplication by numbers. After all, every topic in linear algebra is going to center around these two operations. Luckily, each one's pretty straightforward to define. Let's say we have two vectors, one pointing up and a little to the right,  and the other one pointing right and down a bit. To add these two vectors, move the second one so  that its tail sits at the tip of the first one. Then, if you draw a new vector from the tail of the first one to  where the tip of the second one sits, that new vector is their sum. This definition of addition, by the way, is pretty much the only time  in linear algebra where we let vectors stray away from the origin. Now, why is this a reasonable thing to do? Why this definition of addition and not some other one? Well, the way I like to think about it is that each vector represents a certain movement,  a step with a certain distance and direction in space. If you take a step along the first vector, then take a step in the direction  and distance described by the second vector, the overall effect is just  the same as if you moved along the sum of those two vectors to start with. You could think about this as an extension of  how we think about adding numbers on a number line. One way that we teach kids to think about this, say with 2 plus 5,  is to think of moving two steps to the right followed by another five steps to the right. The overall effect is the same as if you just took seven steps to the right. In fact, let's see how vector addition looks numerically. The first vector here has coordinates 1, 2, and the second one has coordinates 3,  negative 1. When you take the vector sum using this tip-to-tail method,  you can think of a four-step path from the origin to the tip of the second vector. Walk 1 to the right, then 2 up, then 3 to the right, then 1 down. Reorganizing these steps so that you first do all of the rightward motion,  then do all the vertical motion, you can read it as saying first  move 1 plus 3 to the right, then move 2 minus 1 up. So the new vector has coordinates 1 plus 3 and 2 plus negative 1. In general, vector addition in this list of numbers conception  looks like matching up their terms and adding each one together. The other fundamental vector operation is multiplication by a number. Now this is best understood just by looking at a few examples. If you take the number 2 and multiply it by a given vector,  it means you stretch out that vector so that it's two times as long as when you started. If you multiply that vector by, say, one-third,  it means you squish it down so that it's one-third the original length. When you multiply it by a negative number, like negative 1.8,  then the vector first gets flipped around, then stretched out by that factor of 1.8. This process of stretching or squishing or sometimes reversing the direction of  a vector is called scaling, and whenever you catch a number like two or one-third  or negative 1.8 acting like this, scaling some vector, you call it a scalar. In fact, throughout linear algebra, one of the main things that numbers do is scale  vectors, so it's common to use the word scalar pretty much interchangeably with the word  number. Numerically, stretching out a vector by a factor of, say, 2,  corresponds with multiplying each of its components by that factor, 2. So in the conception of vectors as lists of numbers,  multiplying a given vector by a scalar means multiplying each one of those  components by that scalar. You'll see in the following videos what I mean when I say linear algebra topics tend to  revolve around these two fundamental operations,  vector addition and scalar multiplication. And I'll talk more in the last video about how and why the  mathematician thinks only about these operations,  independent and abstracted away from however you choose to represent vectors. In truth, it doesn't matter whether you think about vectors as fundamentally being arrows  in space, like I'm suggesting you do, that happen to have a nice numerical  representation, or fundamentally as lists of numbers that happen to have a nice geometric  interpretation. The usefulness of linear algebra has less to do with either one of these  views than it does with the ability to translate back and forth between them. It gives the data analyst a nice way to conceptualize many lists  of numbers in a visual way, which can seriously clarify patterns  in data and give a global view of what certain operations do. And on the flip side, it gives people like physicists and computer  graphics programmers a language to describe space and the manipulation  of space using numbers that can be crunched and run through a computer. When I do math-y animations, for example, I start by thinking about what's  actually going on in space, and then get the computer to represent things numerically,  thereby figuring out where to place the pixels on the screen. And doing that usually relies on a lot of linear algebra understanding. So there are your vector basics, and in the next video I'll  start getting into some pretty neat concepts surrounding vectors like span,  bases, and linear dependence. See you then! you

================================================================================
VIDEO ID: kjBOesZCoqc
TITLE: Essence of linear algebra preview
URL: https://www.youtube.com/watch?v=kjBOesZCoqc
PUBLISHED: 2016-08-05T01:01:44Z
STATUS: SUCCESS
================================================================================
Hey everyone! So I'm pretty excited about the next sequence of videos that I'm doing. They'll be about linear algebra, which, as a lot of you know,  is one of those subjects that's required knowledge for just about any technical  discipline, but it's also, I've noticed, generally poorly understood by students  taking it for the first time. A student might go through a class and learn how to compute lots of things,  like matrix multiplication, or the determinant, or cross products,  which use the determinant, or eigenvalues, but they might come out without really  understanding why matrix multiplication is defined the way that it is,  why the cross product has anything to do with the determinant,  or what an eigenvalue really represents. Oftentimes, students end up well practiced in the numerical operations of matrices,  but are only vaguely aware of the geometric intuitions underlying it all. But there's a fundamental difference between understanding linear  algebra on a numeric level and understanding it on a geometric level. Each has its place, but, roughly speaking, the geometric understanding is  what lets you judge what tools to use to solve specific problems,  feel why they work, and know how to interpret the results,  and the numeric understanding is what lets you actually carry through the  application of those tools. Now, if you learn linear algebra without getting a solid foundation in that  geometric understanding, the problems can go unnoticed for a while until  you've gone deeper into whatever field you happen to pursue,  whether that's computer science, engineering, statistics, economics, or even math itself. Once you're in a class, or a job for that matter,  that assumes fluency with linear algebra, the way that your  professors or your co-workers apply that field could seem like utter magic. They'll very quickly know what the right tool to use is and what the answer  roughly looks like in a way that would seem like computational wizardry if  you assume that they're actually crunching all the numbers in their head. Here, as an analogy, imagine that when you first learned about the  sine function in trigonometry, you were shown this infinite polynomial. This, by the way, is how your calculator evaluates the sine function. For homework, you might be asked to practice computing approximations of the sine  function by plugging in various numbers to the formula and cutting it off at a reasonable  point. And in fairness, let's say you had a vague idea that this was  supposed to be related to triangles, but exactly how had never  really been clear and was just not the focus of the course. Later on, if you took a physics course where sines and cosines are thrown around left  and right and people are able to tell pretty immediately how to apply them and roughly  what the sign of a certain value will be, it would be pretty intimidating, wouldn't it? It would make it seem like the only people who are cut out  for physics are those with computers for brains,  and you would feel unduly slow or dumb for taking so long on each problem. It's not that different with linear algebra, and luckily, just as with trigonometry,  there are a handful of intuitions, visual intuitions, underlying much of the subject. And unlike the trig example, the connection between the computation  and these visual intuitions is typically pretty straightforward. And when you digest these and really understand the relationship  between the geometry and the numbers, the details of the subject,  as well as how it's used in practice, start to feel a lot more reasonable. In fairness, most professors do make an effort to convey that geometric understanding. The sine example is a little extreme. But I do think that a lot of courses have students spending a  disproportionate amount of time on the numerical side of things,  especially given that in this day and age, we almost always get computers  to handle that half, while in practice, humans worry about the conceptual half. So this brings me to the upcoming videos. The goal is to create a short, binge-watchable series animating those intuitions from the  basics of vectors up through the core topics that make up the essence of linear algebra. I'll put out one video per day for the next five days,  then after that put out a new chapter every one to two weeks. I think it should go without saying that you cannot learn a full  subject with a short series of videos, and that's just not the goal here. But what you can do, especially with this subject,  is lay down all the right intuitions so the learning that you do moving forward is as  productive and fruitful as it can be. I also hope this can be a resource for educators who are  teaching courses that assume fluency with linear algebra,  giving them a place to direct students that need a quick brush up. I'll do what I can to keep things well paced throughout,  but it's hard to simultaneously account for different people's different backgrounds  and levels of comfort, so I do encourage you to readily pause and ponder if you  feel that it's necessary. Actually, I'd give that same advice for watching any math video,  even if it doesn't feel too quick, since the thinking that you do on  your own time is where all the learning really happens, don't you think? So with that as an introduction, I'll see you next video.

================================================================================
VIDEO ID: sULa9Lc4pck
TITLE: Triangle of Power
URL: https://www.youtube.com/watch?v=sULa9Lc4pck
PUBLISHED: 2016-06-26T05:51:12Z
STATUS: SUCCESS
================================================================================
Usually, I don't think notation and math matters that much. Don't get me wrong, I enjoy a bad notation rant as much as the next guy,  and there are clearly a few simple changes to our conventions  that could speed up learning for math students everywhere. But at the end of the day, notation, good or bad, is just not the point of math. Even the most carefully designed symbols and syntax will fail to capture the underlying  visual that constitutes understanding, so I figure it's better to just spend time  focusing on that underlying essence and let the symbols just be what they are in peace. But that said, when unintuitive notation actively stalls the gears of learning,  my disposition on the matter hardens up a little bit. In particular, I'm thinking of one threesome of syntax which,  when you stop and think about it, is an egregious source of friction in math  education everywhere. If you take the fact that 2 multiplied by itself 3 times equals 8,  for example, we have three separate ways to explain that relationship. 2 cubed equals 8, with a superscript. The cube root of 8 is 2, with a squaggly radical symbol. And the log base 2 of 8 equals 3, which we write using the word log itself. What the hell do these three ways of writing the same fact have to do with each other? Making up syntax for a concept is fine, but don't do it in three  completely different ways for the same concept and force students  to learn every rule about that concept three separate times. It's like it's a different language. This way of writing things isn't just counterintuitive,  it's counter-mathematical, since rather than making seemingly different  facts look the same, which is what math should do,  it takes three facts which should obviously be the same and makes them  look artificially different. Just think about how confusing logarithms were the first time you learned about them. This is, of course, a known issue, and the internet has no shortage of  people raising the same concern with suggestions for a better notation. But recently, I stumbled across a math exchange post with a suggestion so lovely,  so symmetrical, so utterly reasonable, that I just have to share it. For a relationship like 2 cubed equals 8, take a triangle and write 2 in the lower left,  3 on the top, and 8 on the lower right. To express the operation 2 cubed, remove that bottom right corner. The symbol as a whole represents the value that should go in the missing corner. To express log base 2 of 8, which is asking the question 2 to the what equals 8,  remove the top number. The symbol as a whole represents the value that should go in the missing corner. To express the cube root of 8, which is saying what number to the third power equals 8,  remove the bottom left corner. The symbol as a whole represents the value that should go in the missing corner. In other words, all three operations are completely symmetrically represented. This triangle deserves a name, and a friend of mine at Khan  Academy decided that we should call it the triangle of power. The definition alone is mildly pleasing, but where it gets fun is  when you see how much smoother all of the different operations become. In our current notation, there are 6 different  ways to express the various inverse operations. Most of these are memorized as separate entities, some are rarely even talked about,  and there's no discernible pattern even though all of them describe the same basic idea. But students still have to spend 6 times the effort to memorize each one,  are 6 times more likely to make a mistake, and have 6 separate opportunities to decide  math is dumb and boring and conducive to failure and why don't I just go study art  instead? With the triangle of power, all these operations follow the same pattern. Our brains are really good at picking up on patterns like this,  and you can much more easily imagine a smooth mental image associated with the property. There's even kind of an aesthetic pleasure to this, and who knows,  maybe more of the artistically inclined students would look favorably upon  math long enough to see just how valuable their intuitions really are in the science. Let's take another property, like the idea that a  to the x times a to the y equals a to the x plus y. The corresponding fact for logarithms is that  log of x times y equals log of x plus log of y. When you write this with the triangle of power,  it's a little easier to see that both of these expressions are really  saying the same thing. Remember, the symbol as a whole represents the number at the missing corner,  so the top expression is saying that when you multiply two numbers that belong on the  bottom right of the triangle, it corresponds with adding the numbers that belong to  the top. But that's also what the lower expression is saying,  when you multiply the numbers at the bottom right,  it corresponds with adding numbers that belong to the top. To help students with this, you could draw inside of the triangle,  saying that when the lower left is constant, the numbers at the top like to add,  while the bottom right numbers like to multiply. What about when a different corner stays constant, like the top? Well in this case, you'd write a multiplication sign in both the bottom corners,  because with exponents and radicals, multiplication turns into multiplication. The natural question that a student might ask from here is if  there's an analogous rule for when the lower right stays constant. There is! You have to introduce a new operation, which for the sake of this video,  I'll call O+, where A O plus B equals one over one over A plus one over B. This is not actually a ridiculous thing to introduce,  since it comes up in physics all the time, like when you're computing parallel resistance. With that symbol, you could say that when the lower right number stays constant,  the top numbers like to get O-plussed together,  and the bottom left numbers like to get multiplied. This is actually a really nice connection between logarithms and roots,  and it never gets discussed, probably because the notation isn't really conducive to  asking the question. I could go on and on here, showing a lot of other properties, but honestly,  I think the best case I can make here is to encourage you to explore it for yourself,  and notice that just about everything involving exponents, logs,  or radicals becomes nicer when you use the triangle of power. By the way, I hope that it goes without saying that in this perfect world,  students wouldn't learn these operations purely from the symbols. They should still ask why it's true, and why it doesn't follow a different pattern. But the point is that when the notation actually reflects the math,  the questions that students are most naturally asking tend to be  the ones that cut right into the essence of what's going on. The asymmetries in the notation correspond with actual  asymmetries in the numerical relationship a to the b equals c itself,  not in the artificial asymmetries of squiggles and words. When a student asks why the top likes to get added in one context but O-plussed  in another, the teacher can point out the property that reflecting the triangle  reciprocates the top, and then they can start addressing where that fact comes from. My sincere hope is that students don't learn by symbolic patterns,  but by substantive reasoning and re-derivation within their own heads. But the fact is, most of us do first learn things by symbolic manipulation,  so when there's an opportunity to significantly speed up that process, we should take it! And if you agree with me that the triangle of power is clearly better than what  we have already, start actually using it in your notes to see what it feels like. Spread the word! And, if you're a teacher, maybe start teaching this to your  students so that we can get them hooked while they're young.

================================================================================
VIDEO ID: Cld0p3a43fU
TITLE: The Brachistochrone, with Steven Strogatz
URL: https://www.youtube.com/watch?v=Cld0p3a43fU
PUBLISHED: 2016-04-01T20:27:08Z
STATUS: SUCCESS
================================================================================
For this video, I'm doing something a little different. I got the chance to sit down with Steven Strogatz and record a conversation. For those of you who don't know, Steve is a mathematician at Cornell. He's the author of several popular math books, and a frequent contributor to,  among other things, Radiolab and the New York Times. To put it shortly, he's one of the great mass communicators of math in our time. In our conversation, we talked about a lot of things,  but it was all centering around this one very famous problem in the history of math,  the brachistochrone. And for the first two thirds or so of the video,  I'm just going to play some of that conversation. We lay out the problem, talk about some of its history,  and go through this solution by Johann Bernoulli from the 17th century. After that, I'm going to show this proof that Steve showed me. It's by a modern mathematician, Mark Levy, and it gives a  certain geometric insight to Johann Bernoulli's original solution. And at the very end, I have a little challenge for you. We should probably start off by just defining the problem itself. Okay. All right. You want me to take a crack at that? Yeah, go for it. Okay. Yeah. So it's this complicated word, first of all, brachistochrone, that comes from two... Gee, I have to check. Are those Latin or Greek words? I think... I'm pretty sure they're Greek. Okay. So Greek words for the shortest time. And it refers to a question that was posed by one of their Bernoulli brothers,  by Johann Bernoulli. If you imagine like a chute and there's a particle moving down a chute  being pulled by gravity, what's the path of the chute that connects two  points so that it goes from point A to point B in the shortest amount of time? I think what I like most about this problem is that it's  relatively easy to describe qualitatively what you're going for. You want the path to be short, something like a straight line,  but you want the object to get going fast, which requires starting steeply,  and that adds length to your line. But making this quantitative and actually finding the balance with a specific curve,  it's not at all obvious and makes for a really interesting problem. It is. It's a really interesting thing. Most people when they first hear it assume that the shortest path  will give the shortest time, that the straight line is the best. But as you say, it can help to build up some steam by rolling straight down at first,  or not necessarily rolling. You could picture it sliding. That doesn't really matter how we phrase it. So Galileo had thought about this himself much earlier than Johann Bernoulli in 1638. And Galileo thought that an arc of a circle would be the best thing. So he had the idea that a bit of curvature might help. And it turns out that the arc of the circle is not the right answer. It's good, but there are better solutions. And the history of real solutions starts with Johann Bernoulli posing this as a challenge. So that's then in June of 1696. And he posed it as a challenge really to the mathematical world at that time. For him, that meant the mathematicians of Europe. And in particular, he was very concerned to show off that he was smarter than his brother. So he had a brother, Jacob, and the two of them were quite bitter rivals,  actually, both tremendous mathematicians. But Johann Bernoulli fancied himself the greatest mathematician of his era,  not just better than his brother. But I think he thought that he might be better than Leibniz,  who was alive at the time, and Isaac Newton, who was by then sort of an old man. I mean, more or less retired from doing math. Newton was the warden of the mint, be something like secretary of the treasury nowadays. And Newton shows him up, right? He stays up all night and solves it, even though  it took Johann Bernoulli two weeks to solve it. That's right. That's the great story that Newton was shown the problem,  wasn't really pleased to be challenged, especially by somebody that he  considered beneath him. I mean, he considered pretty much everybody beneath him. But yeah, Newton stayed up all night, solved it,  and then sent it in anonymously to the Philosophical Transactions,  the journal at the time. And it was published anonymously. And so Newton complained in a letter to a friend of his. He said, I do not love to be done and teased by foreigners about mathematical things. So he didn't enjoy this challenge, but he did solve it. The famous legend is that Johann Bernoulli, on seeing this anonymous solution,  said, I recognize the lion by his claw. I don't know if that's true, but it's a great story. Everyone loves to tell that story. And I suspect part of the reason that Johann was so eager to challenge other  mathematicians like Newton is he secretly knew that his own solution was unusually clever. Maybe we should start going into what he does. Yes, he imagines that to solve the problem, you let light take care of it for you,  because Fermat in the early 1600s had shown that you could state the  way that light travels, whether bouncing off of a mirror or refracting  from air into water, where it bends or going through a lens. All the motion of light could be understood by saying that light takes  whatever path gets it from point A to point B in the shortest time. Which is a really awesome perspective when you think about it,  because usually you think very locally in terms of what happens to a particle at  each specific point. This steps back and looks at all possible paths and says nature chooses the best one. Yes, it is. It's a beautiful and as you say, really an awe-inspiring mental shift. For some people, literally awe-inspiring in the sense that it had religious overtones,  that somehow nature is imbued with this property of doing the most efficient thing. Oh, interesting. But leaving that aside, you could just say it's  an empirical fact that that is how light behaves. And so Johann Bernoulli's idea was to then use Fermat's principle of least time  and say let's pretend that instead of a particle sliding down a chute,  it's light traveling through media of different index of refraction,  meaning that the light would go at different speeds as it successively went sort  of down the chute. And I think before we dive into that case, we should look at something simpler. So at this point in the conversation, we talked for a while about Snell's law. This is a result in physics that describes how light bends when  it goes from one material into another where its speed changes. I made a separate video out of this talking about how you can prove it using Fermat's  law's principle together with a very neat argument using imaginary constant tension  springs. But for now, all you need to know is the statement of Snell's law itself. When a beam of light passes from one medium into another,  and you consider the angle that it makes with a line perpendicular to  the boundary between those two materials, the sine of that angle  divided by the speed of light stays constant as you move from one medium to the next. So what Johann Bernoulli does is find a neat way to take advantage of that fact,  this sine of theta over v stays constant fact, for the brachistochrone problem. When he thinks about what's happening with the particle sliding down the chute,  he notices that by conservation of energy, the velocity that the particle  has will be proportional to the square root of the distance from the top. And just to spell that out a little bit more, the loss in potential energy is  its mass times the gravitational constant times y, that distance from the top. And when you set that equal to the kinetic energy, one half times mv squared,  and you rearrange, the velocity v will indeed end up being proportional to the square  root of y. Mm-hmm, yes. So that then gives him the idea about, let's imagine glass of many different layers,  each with a different velocity characteristic for the light in it. The velocity in the first one is v1, and the next one is v2, and the next one is v3,  and these are all going to be proportional to the square root of y1 or y2 or y3. And in principle, you should be thinking about a limiting  process where you have infinitely many infinitely thin layers,  and this is kind of a continuous change for the speed of light. And so then his question is, if light is always instantaneously obeying Snell's  law as it goes from one medium to the next, so that v over sine theta is always  a constant as I move from one layer to the next, what is that path where, you know,  such that these tangent lines are always instantaneously obeying Snell's law? And for the record, we should probably just state exactly what that property is. Okay. So the conclusion that Johan made was that if you look at whatever the  time-minimizing curve is, and you take any point on that curve,  the sine of the angle between the tangent line at that point and the vertical  divided by the square root of the vertical distance between that point and  the start of the curve, that's going to be some constant independent of the  point that you chose. Mm-hmm. And when Johan Bernoulli first saw this, correct me if I'm wrong,  he just recognized it as the differential equation for a cycloid,  the shape traced by the point on the rim of a rolling wheel. But it's not obvious, certainly not obvious to me,  why this sine of theta over square root y property has anything to do with rolling wheels. It's not at all obvious, but this is again the genius of Mark Levy to the rescue. You want to say a few words about Mark Levy? Yeah, well, Mark Levy is a very clever, as well as a very nice guy who is  a friend of mine and a terrific mathematician at Penn State who has written  a book called The Mathematical Mechanic in which he uses principles of  mechanics and more generally physics to solve all kinds of math problems. That is, rather than math in the service of science, it's science in the service of math. And as an example of the kinds of clever things that he does,  he recently published a little note, very short,  showing that if you look at the geometry of a cycloid,  just drawing the correct lines in the right places,  that this principle of velocity over sine theta being constant is built in to the  motion of the cycloid itself. So, in that conversation, we never actually talked about the details of the proof itself. It's kind of a hard thing to do without visuals. But I think a lot of you out there enjoy seeing  the math and not just talking about the math. It's also a really elegant little piece of geometry, so I'm going to go through it here. Imagine a wheel rolling on the ceiling, and picture a point P on the rim of that wheel. Mark Levy's first insight was that the point where the wheel touches the ceiling,  that I'll call C, acts as this instantaneous center of rotation for the trajectory of P. It's as if, for that moment, P is on the end of a pendulum whose base is at C. Since the tangent line of any circle is always perpendicular to the radius,  the tangent line of the cycloid path of P is perpendicular to the line Pc. This gives us a right angle inside of the circle,  and any right triangle inscribed in a circle must have the diameter as its hypotenuse. So from that, you can conclude that the tangent  line always intersects the bottom of the circle. Now, let theta be the angle between this tangent line and the vertical. We get a pair of similar triangles, which I'll just show on the screen. You can see that the length of Pc is the diameter times sine of theta. Using the second similar triangle, this length times sine of theta again gives  the distance between P and the ceiling, the distance we were calling y earlier. Rearranging this, we see that sine of theta divided by the square  root of y is equal to 1 divided by the square root of the diameter. Since the diameter of a circle stays constant throughout the rotation,  this implies that the sine of theta divided by the square root of y is  constant on a cycloid, and that's exactly the Snell's law property we're looking for. So when you combine Johan Bernoulli's insight with this geometry proof,  that's the cleverest solution of the brachistochrome I've ever seen. And I could call it done here, but given that the whole history  of this problem started with a challenge that Johan Bernoulli posed,  I want to finish things off with a little challenge of my own. When I was playing around with the equations of a cycloid,  something interesting popped out. Consider an object sliding down the cycloid due to gravity,  and think about where it is along the curve as a function of time. Now think about how the curve is defined, as this  trajectory of the point on a rim of a rotating wheel. How might you tweak the rate at which the wheel rotates so that when the object starts  sliding, the marked point on the rim of the wheel always stays fixed to that sliding  object? Do you start rotating it slowly and increase its speed? If so, according to what function? It turns out, the wheel will rotate at a constant rate, which is surprising. This means that gravity pulls you along a cycloid in  precisely the same way that a constantly rotating wheel would. The warm-up part of this challenge is just confirm this for yourself,  it's kind of fun to see how it falls out of the equations. But this got me thinking, if we look back at our original brachistochrone problem,  asking about the path of fastest descent between two given points,  maybe there's a slick way to reframe our thinking. How would it look if instead of describing the trajectory of a sliding  object in terms of its x and y coordinates, we described it in terms  of the angle that the velocity vector makes as a function of time? I mean, you can imagine defining a curve by having an object start sliding,  then turning a knob to determine the angle at which it's sliding at each point in time,  always being pulled by gravity. If you describe the angle of the knob as a function of time,  you are in fact uniquely describing a curve. You're basically using a differential equation,  since what's given is the slope as a function of some other parameter, in this case time. So what's interesting here is that when you look at the solution of the  brachistochrone problem not in the xy-plane, but in the t-theta plane,  where t is time, theta is the angle of the path,  all of the brachistochrone solutions are straight lines,  that is to say theta increases at a constant rate with respect to t. When the solution of a curve minimization problem is a straight line,  it's highly suggestive that there's some way to view it as a shortest path problem. Here, it's not so straightforward, since the boundary conditions that  your objects start at a point a and end at a point b in the xy-space  doesn't just look like going from one point to another in the theta-t space. Nevertheless, my challenge to you is this.

================================================================================
VIDEO ID: Iq1a_KJTWJ8
TITLE: Snell's law proof using springs
URL: https://www.youtube.com/watch?v=Iq1a_KJTWJ8
PUBLISHED: 2016-04-01T20:27:08Z
STATUS: SUCCESS
================================================================================
So, in my video with Steve Strogatz about the brachistochrone, we reference this thing called Snell's Law. It's the principle in physics that tells you how light bends as it travels from one medium into another where its speed changes. Our conversation did talk about this in detail, but it was a little bit too much detail, so I ended up cutting it out of the video. So what I want to do here is just show you a condensed version of that, because it references a pretty clever argument by Mark Levy, and it also gives a sense of completion to the brachistochrone solution as a whole. Consider when light travels from air into water. The speed of light is a little bit slower in water than it is in air, and this results in the beam of light bending as it enters the water. Why? There are many ways that you can think about this, but a pretty neat one is to use Fermat's Principle. We talked about this in detail in the brachistochrone video, but in short, it tells you that if light goes from some point to another, it will always do it in the fastest way possible. Consider some point A in its trajectory in the air, and some point B on its trajectory in the water. First you might think that the straight line between them is the fastest path. The only problem with that strategy though, even though it's the shortest path, is that you may be spending a long time in the water. The light is slower in the water, so the path can become faster if we shift things to favor spending more time in the air. You might even try to minimize the time spent in the water by shifting it all the way to the right. However, it's not actually the best thing to do either. As with the brachistochrone problem, we find ourselves trying to balance these two competing factors. It's a problem that you can write down with geometry. And if this was a calculus class, we would set up the appropriate equation with a single variable x, and find where its derivative is zero. But we've got something better than calculus, a Mark-Levy solution. He recognized that optics is not the only time that nature seeks out a minimum. It does so with energy as well. Any mechanical setup will stabilize when the potential energy is at a minimum. So for this light-into-media problem, he imagines putting a rod on the border between the air and the water, and placing a ring on the rod, which is free to slide left and right. Now attach a spring from point A to the ring, and a second spring between the ring and point B. You can think of the layout of the springs as a potential path that light could take between A and B. To finagle things so that the potential energy in the springs equals the amount of time that light would take on that path, you just need to make sure that each spring has a constant tension which is inversely proportional to the speed of light in its medium. The only problem with this is that constant tension springs don't actually exist. That's right, they're unphysical springs, but there's still the aspect of the system wanting to minimize its total energy. That physical principle will hold even though these springs don't exist in the world as we know it. The reason springs make the problem simpler though, is that we can find the stable state just by balancing forces. The leftward component of the force in the top spring has to cancel out with the rightward component in the force of the bottom spring. In this case, the horizontal component in each spring is just the total force times the sine of the angle that that spring makes with the vertical. And from that, out pops this thing called Snell's law, which many of us learned in our first physics class. Snell's law says that sine of theta divided by the speed of light stays constant when light travels from one medium to another, where theta is the angle that beam of light makes with a line perpendicular to the interface between the two media. So there you go, no calculus necessary.

================================================================================
VIDEO ID: RU0wScIj36o
TITLE: Fractal charm: Space filling curves
URL: https://www.youtube.com/watch?v=RU0wScIj36o
PUBLISHED: 2016-01-17T01:43:18Z
STATUS: SUCCESS
================================================================================
â€”Musicâ€” you

================================================================================
VIDEO ID: cyW5z-M2yzw
TITLE: Music And Measure Theory
URL: https://www.youtube.com/watch?v=cyW5z-M2yzw
PUBLISHED: 2015-10-04T02:14:13Z
STATUS: SUCCESS
================================================================================
I have two seemingly unrelated challenges for you. The first relates to music, and the second gives a foundational result in measure theory,  which is the formal underpinning for how mathematicians define  integration and probability. The second challenge, which I'll get to about halfway through the video,  has to do with covering numbers with open sets, and is very counterintuitive. Or at least, when I first saw it, I was confused for a while. Foremost, I'd like to explain what's going on,  but I also plan to share a surprising connection that it has with music. Here's the first challenge. I'm going to play a musical note with a given frequency, let's say 220 Hz. Then I'm going to choose some number between 1 and 2, which we'll call R,  and play a second musical note whose frequency is R times the frequency of the first  note, 220. For some values of R, like 1.5, the two notes will sound harmonious together,  but for others, like the square root of 2, they sound cacophonous. Your task is to determine whether a given ratio R will give a pleasant sound or  an unpleasant one just by analyzing the number, and without listening to the notes. One way to answer, especially if your name is Pythagoras,  might be to say that two notes sound good together when the ratio is a rational number,  and bad when it's irrational. For instance, a ratio of 3 halves gives a musical fifth. 4 thirds gives a musical fourth. 8 fifths gives a major sixth, so on. Here's my best guess for why this is the case. A musical note is made up of beats played in rapid succession,  for instance 220 beats per second. When the ratio of frequencies of two notes is rational,  there's a detectable pattern in those beats, which when we slow it down,  we hear as a rhythm instead of as a harmony. Evidently, when our brains pick up on this pattern, the two notes sound nice together. However, most rational numbers actually sound pretty bad,  like 211 over 198, or 1093 divided by 826. The issue, of course, is that these rational numbers  are somehow more complicated than the other ones. Our ears don't pick up on the pattern of the beats. One simple way to measure complexity of rational numbers is to  consider the size of the denominator when it's written in reduced form. So we might edit our original answer to only admit fractions with low denominators,  say less than 10. Even still, this doesn't quite capture harmoniousness,  since plenty of notes sound good together even when the ratio of their  frequencies is irrational, so long as it's close to a harmonious rational number. And it's a good thing, too, because many instruments, such as pianos,  are not tuned in terms of rational intervals, but are tuned such that each half-step  increase corresponds with multiplying the original frequency by the 12th root of 2,  which is irrational. If you're curious about why this is done, Henry at MinutePhysics  recently did a video that gives a very nice explanation. This means that if you take a harmonious interval, like a fifth,  the ratio of frequencies when played on a piano will not be a nice rational number  like you expect, in this case 3 halves, but will instead be some power of the  12th root of 2, in this case 2 to the 7 over 12, which is irrational,  but very close to 3 halves. Similarly, a musical fourth corresponds to 2 to the 5 twelfths,  which is very close to 4 thirds. In fact, the reason it works so well to have 12 notes in the chromatic  scale is that powers of the 12th root of 2 have this strange tendency  to be within a 1% margin of error of simple rational numbers. So now you might say that a ratio R will produce a harmonious pair of notes if it  is sufficiently close to a rational number with a sufficiently small denominator. How close depends on how discerning your ear is,  and how small a denominator depends on the intricacy of harmonic patterns your  ear has been trained to pick up on. After all, maybe someone with a particularly acute musical sense would be able to  hear and find pleasure in the pattern resulting from more complicated fractions,  like 23 over 21, or 35 over 43, as well as numbers closely approximating those fractions. This leads me to an interesting question. Suppose there is a musical savant who finds pleasure in all  pairs of notes whose frequencies have a rational ratio,  even the super complicated ratios that you and I would find cacophonous. Is it the case that she would find all ratios R between 1 and 2 harmonious,  even the irrational ones? After all, for any given real number, you can always find a rational number  arbitrarily close to it, just like 3 halves is really close to 2 to the 7 over 12. Well, this brings us to challenge number 2. Mathematicians like to ask riddles about covering various sets with open intervals,  and the answers to these riddles have a strange tendency to become famous lemmas of  theorems. By open interval, I just mean the continuous stretch of real  numbers strictly greater than some number a, but strictly less than some other number b,  where b is of course greater than a. My challenge to you involves covering all of the  rational numbers between 0 and 1 with open intervals. When I say cover, all this means is that each particular  rational number lies inside at least one of your intervals. The most obvious way to do this is to just use the entire interval  from 0 to 1 itself and call it done, but the challenge here is that  the sum of the lengths of your intervals must be strictly less than 1. To aid you in this seemingly impossible task,  you're allowed to use infinitely many intervals. Even still, the task might feel impossible, since the rational  numbers are dense in the real numbers, meaning any stretch,  no matter how small, contains infinitely many rational numbers. So how could you possibly cover all of the rational numbers without just covering  the entire interval from 0 to 1 itself, which would mean the total length of your  open intervals has to be at least the length of the entire interval from 0 to 1? Then again, I wouldn't be asking if there wasn't a way to do it. First, we enumerate the rational numbers between 0 and 1,  meaning we organize them into an infinitely long list. There are many ways to do this, but one natural way that I'll choose is to start with 1  half, followed by 1 third and 2 thirds, then 1 fourth and 3 fourths,  we don't write down 2 fourths since it's already appeared as 1 half,  then all reduced fractions with denominator 5, all reduced fractions with denominator 6,  continuing on and on in this fashion. Every fraction will appear exactly once in this list in its reduced form,  and it gives us a meaningful way to talk about the first rational number,  the second rational number, the 42nd rational number, things like that. Next, to ensure that each rational is covered,  we're going to assign one specific interval to each rational. Once we remove the intervals from the geometry of our setup,  and just think of them in a list, each one responsible for one rational number,  it seems much clearer that the sum of their lengths can be less than 1,  since each particular interval can be as small as you want,  and still cover its designated rational. In fact, the sum can be any positive number. Just choose an infinite sum with positive terms that converges to 1,  like 1 half plus 1 fourth plus 1 eighth, on and on. Then choose any desired value of epsilon greater than 0, like 0.5,  and multiply all of the terms in the sum by epsilon so that you have an infinite sum  converging to epsilon. Now, scale the nth interval to have a length equal to the nth term in the sum. Notice, this means your intervals start getting really small really fast,  so small that you can't really see most of them in this animation,  but it doesn't matter, since each one is only responsible for covering one rational. I've said it already, but I'll say it again because it's so amazing. Epsilon can be whatever positive number we want,  so not only can our sum be less than 1, it can be arbitrarily small. This is one of those results where, even after seeing the proof,  it still defies intuition. The discord here is that the proof has us thinking analytically,  with the rational numbers in a list, but our intuition has us thinking geometrically,  with all the rational numbers as a dense set on the interval,  where you can't skip over any continuous stretch because that would contain  infinitely many rationals. So let's get a visual understanding for what's going on. Brief side note here, I had trouble deciding on how to illustrate small intervals,  since if I scale the parentheses with the interval,  you won't be able to see them at all, but if I just push the parentheses together,  they cross over in a way that's potentially confusing. Nevertheless, I decided to go with the ugly chromosomal cross, so keep in mind,  the interval this represents is that tiny stretch between the centers of each parentheses. Okay, back to the visual intuition. Consider when epsilon equals 0.3, meaning if I choose a number between 0 and 1 at random,  there's a 70% chance that it's outside those infinitely many intervals. What does it look like to be outside the intervals? The square root of 2 over 2 is among those 70%, and I'm going to zoom in on it. As I do so, I'll draw the first 10 intervals in our list within our scope of vision. As we get closer and closer to the square root of 2 over 2,  even though you will always find rationals within your field of view,  the intervals placed on top of those rationals get really small, really fast. One might say that for any sequence of rational numbers approaching  the square root of 2 over 2, the intervals containing the elements  of that sequence shrink faster than the sequence converges. Notice, intervals are really small if they show up late in the list,  and rationals show up late in the list when they have large denominators. So the fact that the square root of 2 over 2 is among the 70% not covered  by our intervals is, in a sense, a way to formalize the otherwise vague  idea that the only rational numbers close to it have a large denominator. That is to say, the square root of 2 over 2 is cacophonous. In fact, let's use a smaller epsilon, say 0.01,  and shift our setup to lie on top of the interval from 1 to 2 instead of from 0 to 1. Then which numbers fall among that elite 1% covered by our tiny intervals? Almost all of them are harmonious. For instance, the harmonious irrational number 2 to the 7 twelfths is very close  to 3 halves, which has a relatively fat interval sitting on top of it,  and the interval around 4 thirds is smaller but still fat enough to cover 2 to the  5 twelfths. Which members of the 1% are cacophonous? Well, the cacophonous rationals, meaning those with high denominators,  and irrationals that are very very very close to them. However, think of the savant who finds harmonic patterns in all rational numbers. You could imagine that for her, harmonious numbers are precisely  those 1% covered by the intervals, provided that her tolerance  for error goes down exponentially for more complicated rationals. In other words, the seemingly paradoxical fact that you can have a collection  of intervals densely populate a range while only covering 1% of its values  corresponds to the fact that harmonious numbers are rare, even for the savant. I'm not saying this makes the result more intuitive. In fact, I find it quite surprising that the savant  I defined could find 99% of all ratios cacophonous. But the fact that these two ideas are connected was simply too beautiful not to share.

================================================================================
VIDEO ID: 1SMmc9gQmHQ
TITLE: How to count to 1000 on two hands
URL: https://www.youtube.com/watch?v=1SMmc9gQmHQ
PUBLISHED: 2015-09-18T21:53:13Z
STATUS: SUCCESS
================================================================================
[There is just piano here.]

================================================================================
VIDEO ID: XFDM1ip5HdU
TITLE: What does it feel like to invent math?
URL: https://www.youtube.com/watch?v=XFDM1ip5HdU
PUBLISHED: 2015-08-14T01:20:50Z
STATUS: SUCCESS
================================================================================
Take 1 plus 2 plus 4 plus 8 and continue on and  on adding the next power of 2 up to infinity. This might seem crazy, but there's a sense in which this infinite sum equals negative 1. If you're like me, this feels strange or obviously false when you first see it,  but I promise you, by the end of this video you and I will make it make sense. To do this, we need to back up, and you and I will walk through what it  might feel like to discover convergent infinite sums,  those ones that at least seem to make sense, to define what they really mean,  then to discover this crazy equation and stumble upon new forms of math  where it makes sense. Imagine that you are an early mathematician in the process of discovering  that Â½ plus 1 fourth plus 1 eighth plus 1 sixteenth on and on up to infinity,  whatever that means, equals 1, and imagine that you needed to define what it  means to add infinitely many things for your friends to take you seriously. What would that feel like? Frankly, I have no idea, and I imagine that more than anything it  feels like being wrong or stuck most of the time,  but I'll give my best guess at one way that the successful parts of it might go. One day, you are pondering the nature of distances between objects,  and how no matter how close two things are, it seems that they can  always be brought a little bit closer together without touching. Fond of math as you are, you want to capture this paradoxical feeling with numbers,  so you imagine placing the two objects on the number line, the first at 0,  the second at 1. Then, you march the first object towards the second,  such that with each step, the distance between them is cut in half. You keep track of the numbers this object touches during its march,  writing down Â½, Â½ plus a fourth, Â½ plus a fourth plus an eighth, and so on. That is, each number is naturally written as a  slightly longer sum with one more power of 2 in it. As such, you're tempted to say that if these numbers approach anything,  we should be able to write this thing down as a sum that contains the reciprocal of  every power of 2. On the other hand, we can see geometrically that these numbers approach 1,  so what you want to say is that 1 and some kind of infinite sum are the same thing. If your education was too formal, you'd write the statement off as ridiculous. Clearly, you can't add infinitely many things. No human, computer, or physical thing ever could perform such a task. If, however, you approach math with a healthy irreverence,  you'll stand brave in the face of ridiculousness and try to make sense  out of this nonsense you wrote down, since it kind of feels like nature gave it to you. So how exactly do you, dear mathematician, go about defining infinite sums? Well practiced in math that you are, you know that finding the right  definitions is less about generating new thoughts than it is about dissecting  old thoughts, so you go back to how you came across this fuzzy discovery. At no point did you actually perform infinitely many operations. You had a list of numbers, a list that could keep going forever if you had the time,  and each number came from a perfectly reasonable finite sum. You noticed that the numbers in this list approach 1, but what do you mean by approach? It's not just that the distance between each number and 1 gets smaller,  because for that matter, the distance between each number and 2 also gets smaller. After thinking about it, you realize what makes 1 special is that your  numbers can get arbitrarily close to 1, which is to say,  no matter how small your desired distance, one one hundredth, one one millionth,  or one over the largest number you could write down,  if you go down your list long enough, the numbers will eventually fall  within that tiny tiny distance of 1. Retrospectively, this might seem like the clear way to solidify what you mean  by approach, but as a first-time endeavor, it's actually incredibly clever. Now you pull out your pin, and scribble down the definition for  what it means for an infinite sum to equal some number, say x. It means that when you generate a list of numbers by cutting off your  sum at finite points, the numbers in this list approach x in the sense  that no matter how small the distance you choose, at some point down the list,  all the numbers start falling within that distance of x. In doing this, you just invented some math, but it never felt like  you were pulling things out of thin air, you were just trying to  justify what it was that the universe gave you in the first place. You might wonder if you can find other, more general  truths about these infinite sums that you just invented. To do so, you look for where you made any arbitrary decisions. For instance, when you were shrinking the distance between your objects,  cutting the interval into pieces of size one half, one fourth,  etc., you could have chosen a proportion other than one half. You could have instead cut your interval into pieces of size 9 tenths and 1 tenth,  and then cut that rightmost piece into the same proportions,  giving you smaller pieces of size 9 one hundredths and one one hundredth,  then cut that tiny piece of size one one hundredth similarly. Continuing on and on, you'd see that nine tenths plus nine one  hundredths plus nine one thousandths on and on up to infinity equals one,  a fact more popularly written as point nine repeating equals one. To all of your friends who insist that this doesn't equal 1 and it just approaches it,  you can now just smile, because you know that with infinite sums,  to approach and to equal mean the same thing. To be general about it, let's say that you cut your interval into pieces of  size p and one minus p, where p represents any number between zero and one. Cutting the piece of size p in similar proportions,  we now get pieces of size p times 1-p and p squared. Continuing in this fashion, always cutting up the rightmost piece into those same  proportions, you'll find that one minus p plus p times one minus p plus p squared  times one minus p, on and on always adding p to the next power times one minus p,  equals one. Dividing both sides by 1-p, we get this nice formula. In this formula, the universe has offered a weird form of nonsense. Even though the way you discovered it only makes sense for values of p between 0 and 1,  the right hand side still makes sense when you replace p with any other number,  except maybe for 1. For instance, plugging in negative one, the equation reads one minus one  plus one minus one, on and on forever alternating between the two,  equals one half, which feels pretty silly and kind of like the only thing it could be. Plugging in two, the equation reads one plus two plus four plus eight,  on and on to infinity, equals negative one, something which doesn't even seem reasonable. On the one hand, Rigger would dictate that you ignore these,  since the definition of infinite sums doesn't apply in these cases. The list of numbers that you generate by cutting off  the sum at finite points doesn't approach anything. But you're a mathematician, not a robot, so you don't  let the fact that something is nonsensical stop you. I will leave this sum for another day, so that we can jump directly into this monster. First, to clean things up, notice what you get when you cut off the sum at finite points. One, three, seven, fifteen, thirty-one, they're all one less than a power of two. In general, when you add up the first n powers of 2,  you get 2 to the n plus 1 minus 1, which this animation hopefully makes clear. You decide to humor the universe and pretend that these numbers,  all 1 less than a power of 2, actually do approach negative 1. It will prove to be cleaner if we add 1 to everything  and say that the powers of 2 approach 0. Is there any way that this can make sense? In effect, what you're trying to do is make this formula more general,  by saying that it applies to all numbers, not just those between 0 and 1. Again, to make things more general, you look for  any place where you made an arbitrary choice. Here, that place turns out to be very sneaky, so sneaky in fact  that it took mathematicians until the 20th century to find it. It's the way that we define distance between two rational numbers. That is to say, organizing them on a line might  not be the only reasonable way to organize them. The notion of distance is essentially a function that takes in  two numbers and outputs a number indicating how far apart they are. You could come up with a completely random notion of distance,  where two is seven away from three, and one half is four fifths away from a hundred,  and all sorts of things. But if you want to actually use a new distance function  the way that you use the familiar distance function,  it should share some of the same properties. For example, the distance between two numbers shouldn't  change if you shift them both by the same amount. So zero and four should be the same distance away as one and five, or two and six,  even if that same distance is something other than four as we're used to. Keeping things general, the distance between two numbers  shouldn't change if you add the same amount to both of them. Let's call this property shift invariance. There are other properties that you want your notion of distance to have as well,  like the triangle inequality, but before we start worrying about those,  let's start imagining what notion of distance could possibly make  powers of two approach zero, and which is shift invariant. At first you might toil for a while to find a frame of mind where this doesn't  feel like utter nonsense, but with enough time and a bit of luck,  you might think to organize your numbers into rooms, subrooms, sub-subrooms, and so on. You think of zero as being in the same room as all of the powers of two greater than one.  As being in the same sub-room as all powers of two greater than two.  As being in the same sub-sub-room as powers of two greater than four,  and so on, with infinitely many smaller and smaller rooms. It's pretty hard to draw infinitely many things, so I'm only going to draw 4 room sizes,  but keep in the back of your mind that this process should be able to go on forever. If we think of every number as lying in a hierarchy of rooms, not just 0,  shift invariance will tell us where all of the numbers must fall. For instance, one should be as far away from three as two is from zero. Likewise, the distance between zero and four should be the same  as that between one and five, two and six, and three and seven. Continuing like this, you'll see which rooms, sub-rooms,  sub-sub-rooms, and so on, successive numbers must fall into. You can also deduce where negative numbers must fall. For example, negative one has to be in the same room as one,  in the same sub-room as three, the same sub-sub-room as seven, and so on,  always in smaller and smaller rooms with numbers one less than a power of two,  because zero is in smaller and smaller rooms with the powers of two. So, how do you turn this general idea of closeness based  on rooms and sub-rooms into an actual distance function? You can't take this drawing too literally, since it makes one look  very close to fourteen and zero very far from thirteen,  even though shift invariance should imply that they're the same distance away. Again, in the actual process of discovery, you might toil away,  scribbling through many sheets of paper, but if you have the idea that the  only thing which should matter in determining the distance between two  objects is the size of the smallest room they share, you might come up with the following. Any numbers lying in different large yellow rooms are a distance 1 from each other. Those which are in the same large room, but not in the  same orange sub-room are a distance Â½ from each other. And those that are in the same orange sub-room,  but not in the same sub-sub-room are a distance Â¼ from each other. And you continue like this, using the reciprocals of  larger and larger powers of 2 to indicate closeness. We won't do it in this video, but see if you can reason about which  rooms other rational numbers like one third and one half should fall into, And see if you can prove why this notion of distance satisfies many of the nice  properties we expect from a distance function, like the triangle inequality. Here, I'll just say that this notion of distance is a perfectly legitimate one,  we call it the 2-adic metric, and it falls into a general family of distance  functions called the p-adic metrics, where p stands for any prime number. These metrics give rise to a completely new type of number,  neither real nor complex, and have become a central notion in modern number theory. Using the 2-adic metric, the fact that the sum of all powers  of 2 equals negative 1 actually makes sense, because the numbers 1,  3, 7, 15, 31, and so on, genuinely approach negative 1. This parable does not actually portray the historical trajectory of discoveries,  but nevertheless, I still think it's a good illustration of a  recurring pattern in the discovery of math. First, nature hands you something that's ill-defined or even nonsensical. Then you define new concepts that make this fuzzy discovery make sense,  and these new concepts tend to yield genuinely useful math and broaden your mind about  traditional notions. So, in answer to the age-old question of whether math is invention or discovery,  my personal belief is that discovery of non-rigorous truths is what  leads us to the construction of rigorous terms that are useful,  opening the door for more fuzzy discoveries continuing the cycle.

================================================================================
VIDEO ID: -9OUyo8NFZg
TITLE: Euler's Formula and Graph Duality
URL: https://www.youtube.com/watch?v=-9OUyo8NFZg
PUBLISHED: 2015-06-21T06:05:43Z
STATUS: SUCCESS
================================================================================
In my video on the circle division problem, I referenced Euler's characteristic formula, and here I would like to share a particularly nice proof of this fact. It's very different from the inductive proof, typically given, but I'm not trying to argue that this is somehow better or easier to understand than other proofs. Instead, I chose this topic to illustrate one example of the incredible notion of duality, and how it can produce wonderfully elegant math. First, let's go over what the theorem states. If you draw some dots and some lines between them, that is, a graph, and if none of these lines intersect, which is to say you have a planar graph, and if your drawing is connected, then Euler's formula tells us that the number of dots minus the number of lines plus the number of regions these lines cut the plane into, including that outer region, will always be 2. Because Euler was originally talking about 3D polyhedra when he found this formula, which was only later reframed in terms of planar graphs, instead of saying dots, we say vertices, instead of saying lines, we say edges, and instead of saying regions, we say faces. Hence, we write Euler's discovery as V minus E plus F equals 2. Before describing the proof, I need to go through three pieces of graph theory terminology. Cycles, spanning trees, and dual graphs. If you are already familiar with some of these topics and don't care to see how I describe them, feel free to click the appropriate annotation and skip ahead. Imagine a tiny creature sitting on one of the vertices. Let's name him Randolph. If we think of edges as something Randolph might travel along from one vertex to the next, we can sensibly talk about a path as being a sequence of edges that Randolph could travel along, where we don't allow him to backtrack on the same edge. A cycle is simply a path that ends on the same vertex where it begins. You might be able to guess how cycles will be important for our purposes, since they will always enclose a set of faces. Now imagine that Randolph wants access to all other vertices, but edges are expensive, so he'll only buy access to an edge if it gives him a path to an untouched vertex. This frugality will leave him with a set of edges without any cycles, since the edge finishing off a cycle would always be unnecessary. In general, a connected graph without cycles is called a tree, so named because we can move things around and make it look like a system of branches, and any tree inside a graph which touches all the vertices is called a spanning tree. Before defining the dual graph, which runs the risk of being confusing, it's important to remember why people actually care about graphs in the first place. I was actually lying earlier when I said a graph is a set of dots and lines. Really, it's a set of anything with any notion of connection, but we typically represent those things with dots and those connections with lines. For instance, Facebook stores an enormous graph where vertices are accounts and edges are friendships. Although we could use drawings to represent this graph, the graph itself is the abstract set of accounts and friendships, completely distinct from the drawing. All sorts of things are undrawn graphs, the set of English words considered connected when they differ by one letter, mathematicians considered connected if they've written a paper together, neurons connected by synapses. Or, maybe, for those of us reasoning about the actual drawing of a graph on the plane, we can take the set of faces this graph cuts the plane into and consider two of them connected if they share an edge. In other words, if you can draw a graph on the plane without intersecting edges, you automatically get a second, as of yet undrawn, graph whose vertices are the faces and whose edges are, well, edges of the original graph. We call this the dual of the original graph. If you want to represent the dual graph with dots and lines, first put a dot inside each one of the faces. I personally like to visualize the dot for that outer region as being a point somewhere at infinity where you can travel in any direction to get there. Next, connect these new dots with new lines that pass through the centers of the old lines, where lines connected to that point at infinity can go off the screen in any direction, as long as it's understood that they all meet up at the same one point. But keep in mind, this is just the drawing of the dual graph, just like the representation of Facebook accounts and friendships with dots and lines is just a drawing of the social graph. The dual graph itself is the collection of faces and edges. The reason I stress this point is to emphasize that edges of the original graph and edges of the dual graph are not just related, they're the same thing. You see, what makes the dual graph all kinds of awesome is the many ways that it relates to the original graph. For example, cycles in the original graph correspond to connected components of the dual graph, and likewise, cycles in the dual graph correspond with connected components in the original graph. Now for the cool part. Suppose our friend Randolph has an alter ego, Mortimer, living in the dual graph, traveling from face to face instead of from vertex to vertex, passing over edges as he does so. Let's say Randolph has bought all the edges of a spanning tree and that Mortimer is forbidden from crossing those edges. It turns out the edges that Mortimer has available to him are guaranteed to form a spanning tree of the dual graph. To see why, we only need to check the two defining properties of spanning trees. They must give Mortimer access to all faces and there can be no cycles. The reason he still has access to all faces is that it would take a cycle in Randolph's spanning tree to insulate him from a face, but trees cannot have cycles. The reason Mortimer cannot traverse a cycle in the dual graph feels completely symmetric. If he could, he would separate one set of Randolph's vertices from the rest, so the spanning tree from which he is banned could not have spanned the whole graph. So not only does the planar graph have a dual graph, any spanning tree within that graph always has a dual spanning tree in the dual graph. Here's the kicker. The number of vertices in any tree is always one more than the number of edges. To see this, note that after you start with the root vertex, each new edge gives exactly one new vertex. Alternatively, within our narrative, you could think of Randolph as starting with one vertex and gaining exactly one more for each edge in what will become a spanning tree. Since this tree covers all vertices in our graph, the number of vertices is one more than the number of edges owned by Randolph. Moreover, since the remaining edges make up a spanning tree for Mortimer's dual graph, the number of edges he gets is one more than the number of vertices in the dual graph, which are faces of the original graph. Putting this together, it means the total number of edges is two more than the number of vertices plus the number of faces, which is exactly what Euler's formula states.

================================================================================
VIDEO ID: zLzLxVeqdQg
TITLE: Euler's Formula Poem
URL: https://www.youtube.com/watch?v=zLzLxVeqdQg
PUBLISHED: 2015-03-05T06:15:23Z
STATUS: SUCCESS
================================================================================
E raised to pi with an i. We've been taught by a lot that you've got minus one. Can we glean what this means? For such words are absurd. How to treat the repeat of a feat pi i times. This is bound to confound till your mind redefines these amounts one can't count which surmount our friend E. Numbers act as abstract functions which slide the ridge to the space in its place with a grace when they sum. They slide, they don't slide. Acting a second way, they rotate and dilate but keep straight this same plane. Now what we write as E to the X won't perplex when you know it's for show that X goes up and right. It does not, as you thought, repeat E product E. It functions with gumption on functions we have now seen. It turns slide side to side into growths and shrinks both. Up and downs come around as turns round which is key. This is why pi times i which slides north is brought forth and returned, we have learned, is a turn halfway round. This one, matched by none, turns this way and we're done.

================================================================================
VIDEO ID: F_0yfvm0UoU
TITLE: e to the pi i, a nontraditional take (old version)
URL: https://www.youtube.com/watch?v=F_0yfvm0UoU
PUBLISHED: 2015-03-05T06:15:22Z
STATUS: SUCCESS
================================================================================
E to the pi i equals negative one is one of the most famous equations in math, but it's also one of the most confusing. Those watching this video likely fall into one of three categories. One, you know what each term means, but the statement as a whole seems nonsensical. Two, you were lucky enough to see what this means, and some long formulas explaining why it works in a calculus class, but it still feels like black magic. Or three, it's not entirely clear what the terms themselves are. Those in this last category might be in the best position to understand the explanation I'm about to give, since it doesn't require any calculus or advanced math, but will instead require an open-mindedness to reframing how we think about numbers. Once we do this, it will become clear what the equation means, why it's true, and most importantly why it makes intuitive sense. First, let's get one thing straight. What we write as e to the x is not repeated multiplication. That would only make sense when x is a number that we can count, one, two, three, and so on, and even then you'd have to define the number e first. To understand what this function actually does, we first need to learn how to think about numbers as actions. We are first taught to think about numbers as counting things, and addition and multiplication are thought of with respect to counting. However, this mode of thinking becomes tricky when we talk about fractional amounts, very tricky when we talk about irrational amounts, and downright nonsensical when we introduce things like the square root of negative one. Instead, we should think of each number as simultaneously being three things, a point on an infinitely extending line, an action which slides that line along itself, in which case we call it an adder, and an action which stretches the line, in which case we call it a multiplier. When you think about a number as an adder, you could imagine adding it with all numbers as points on the line all at once, but instead forget that you already know anything about addition so that we can reframe how you think about it. Think of adders purely as sliding the line with the following rule. You slide until the point corresponding to zero ends up where the point corresponding with the adder itself started. When you successively apply two adders, the effect will be the same as just applying some other adder. This is how we define their sum. Likewise, forget that you already know anything about multiplication, and think of a multiplier purely as a way to stretch the line. Now, the rule is to fix zero in place, and bring the point corresponding with one to where the point corresponding with the multiplier itself started off, keeping everything evenly spaced as you do so. Just as with adders, we can now redefine multiplication as the successive application of two different actions. The life's ambition of e to the x is to transform adders into multipliers, and to do so as naturally as possible. For instance, if you take two adders, successively apply them, then pump the resulting sum through the function, it's the same as first putting each adder through the function separately, then successively applying the two multipliers you get. More succinctly, e to the x plus y equals e to the x times e to the y. If e to the x was thought of as repeated multiplication, this property would be a consequence, but really it goes the other way around. You should think of this property as defining e to the x, and the fact that the special case of counting numbers has anything to do with repeated multiplication is a consequence of the property. Multiple functions satisfy this property, but when you try to define one explicitly, one stands out as being the most natural, and we express it with this infinite sum. By the way, the number e is just defined to be the value of this function at one, the number isn't nearly as special as the function as a whole, and the convention to write this function as e to the x is a vestige of its relationship with repeated multiplication. The other, less natural function satisfying this property are the exponentials with different bases. Now the expression e to the pi i at least seems to have some meaning, but you shouldn't think about this infinite sum when trying to make sense of it, you only need to think about turning adders into multipliers. You see, we can also play this game of sliding and stretching in the 2D plane, and this is what complex numbers are. Each number is simultaneously a point on the plane, an adder which slides the plane so that the point for 0 lands on the point for the number, and a multiplier which fixes 0 in place and brings the point for 1 to the point for the number while keeping everything evenly spaced. These can now include rotating along with some stretching and shrinking. All of the actions of the real numbers still apply, sliding side to side and stretching, but now we have a whole host of new actions. For instance, take this point here, we call it i, as an adder it slides the plane up, and as a multiplier it turns it a quarter of the way around. Since multiplying it by itself gives negative 1, which is to say, applying this action twice is the same as the action of negative 1 as a multiplier, it is the square root of negative 1. All adding is some combination of sliding sideways and sliding up or down, and all multiplication is some combination of stretching and rotating. Since we already know that e to the x turns slide side to side into stretches, the most natural thing you might expect is for it to turn this new dimension of adders, slides up and down, directly into the new dimension of multipliers, rotations. In terms of points on the plane, this would mean e to the x takes points on this vertical line which correspond to adders that slide the plane up and down, and puts them on the circle with radius 1, which corresponds with the multipliers that rotate the plane. The most natural way you could imagine doing this is to wrap the line around the circle without stretching or squishing it, which would mean it takes a length of 2 pi to go completely around the circle, since by definition this is the ratio of the circumference of a circle to its radius. This means going up pi would translate to going exactly halfway around the circle. When in doubt, if there's a natural way to do things, this is exactly what e to the x will do, and this case is no exception. If you want to see a full justification for why e to the x behaves this way, see this additional video here. So there you have it. This function e to the x takes the adder pi i to the multiplier negative 1. Thank you. Thank you.

