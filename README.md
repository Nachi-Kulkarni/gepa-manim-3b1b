# Manim GEPA Video Pipeline: AI-Powered 3Blue1Brown-Style Animation Generator

This repository contains an advanced, AI-powered system for generating Manim animation code and educational video transcripts in the distinctive style of 3Blue1Brown. It leverages the **GEPA (Generative Error-driven Prompt Adaptation)** framework from DSPy to iteratively optimize the quality of generated content, creating a full pipeline from a simple topic to a complete, narrated video.

## 🎬 Example Output

A final animation generated by the pipeline, `manimfinalll.mp4`, is included in the root directory of this repository. It showcases the 3Blue1Brown-style visuals, smooth transitions, and synchronized narration produced by the system.

**[Click here to view the final video output: manimfinalll.mp4](https://github.com/nachi-kulkarni/gepa-manim-3b1b/blob/main/manimfinalll.mp4)**

## 🚀 Key Features

*   **Dual AI Generation Systems**:
    *   **Code Generator**: Produces high-quality Manim Python code from a video title and transcript, achieving high accuracy by following an extensive, GEPA-optimized prompt that includes 3Blue1Brown's stylistic principles.
    *   **Transcript Generator**: Creates engaging, educational video transcripts from a video title and Manim code, ensuring the narration aligns with the on-screen visuals.
*   **GEPA Optimization Pipeline**:
    *   Includes a full `training_pipeline.py` to automatically refine and improve the core generation prompts using AI-driven feedback.
    *   Utilizes sophisticated `code_judge` and `transcript_judge` modules to evaluate content quality across multiple dimensions like mathematical accuracy, style consistency, and educational clarity.
*   **End-to-End Video Production**:
    *   **Text-to-Speech**: Integrates with the `Kokoro-82M` model for high-quality, natural-sounding narration.
    *   **Automated Rendering**: `generate_video.py` script to run the entire pipeline from a single command.
    *   **Synchronization**: Tools like `resync_subtitles.py` and `animation_timing_analysis.md` ensure tight synchronization between narration, animation, and subtitles.
*   **Self-Refinement and Debugging**:
    *   A self-correction loop (`debug_refinement.py`, `test_refinement.py`) attempts to automatically fix errors in the generated Manim code, improving the success rate of video rendering.
*   **3Blue1Brown Style Emulation**: The core prompts are meticulously engineered to replicate 3Blue1Brown's visual and narrative style, focusing on:
    *   Intuitive, visual explanations of complex topics.
    *   Smooth, meaningful animations and transitions.
    *   A consistent, high-quality aesthetic (color palette, timing, etc.).

## 📁 Directory Structure

```
└── nachi-kulkarni-gepa-manim-3b1b/
    ├── manimfinalll.mp4             # Example video output
    ├── animation_timing_analysis.md # Report on animation pacing and visual density.
    ├── code_generator.py            # Core script for Manim code generation using DSPy/GEPA.
    ├── config.py                    # Configuration for API keys and language models.
    ├── debug_refinement.py          # Script to test the self-correction code refinement process.
    ├── generate_video.py            # High-level wrapper to run the entire video generation pipeline.
    ├── kokoro_tts_integration.py    # Handles Text-to-Speech generation for narration.
    ├── resume_pipeline.py           # Utility to resume a failed or partial video generation run.
    ├── resync_subtitles.py          # Tool to regenerate subtitles to match animation timing.
    ├── test_refinement.py           # Tests the self-refinement system on problematic code.
    ├── training_pipeline.py         # Main script to run GEPA optimization for both code and transcripts.
    ├── transcript_generator.py      # Core script for generating video transcripts from code.
    │
    ├── docsa/                       # Documentation and project resources.
    │   ├── README.md                # Detailed project documentation.
    │   ├── CLAUDE.md                # Guidance for AI assistants working with the codebase.
    │   ├── SETUP.md                 # Setup and installation instructions.
    │   ├── ultimate_gepa_optimized_prompt.md # The master prompt for code generation.
    │   └── video_list.txt           # A list of video ideas or targets.
    │
    └── manim_gepa/                  # Core modules for the GEPA system.
        ├── __init__.py
        ├── code_judge.py            # AI-based system to evaluate the quality of generated Manim code.
        ├── config.py                # Configuration for the manim_gepa module.
        └── transcript_judge.py      # AI-based system to evaluate the quality of generated transcripts.
```
## ⚙️ How It Works

The system operates in a multi-stage pipeline:

1.  **Transcript Generation**: Given a video topic, the `transcript_generator.py` creates an educational script.
2.  **Narration Generation**: The generated transcript is fed into `kokoro_tts_integration.py` to produce a `.wav` audio file for narration.
3.  **Code Generation**: The transcript and topic are passed to `code_generator.py`, which uses its ultimate GEPA-optimized prompt to produce Manim animation code that is visually synchronized with the narration script.
4.  **Self-Refinement (Optional)**: If the initial code fails to render, the `debug_refinement.py` system analyzes the error and attempts to automatically fix the code.
5.  **Video Rendering**: The validated Manim code is rendered into a silent video file.
6.  **Final Assembly**: The silent video, narration audio, and synchronized subtitles are merged to produce the final video file.

The entire process can be initiated by running `python3 generate_video.py "Your Video Topic"`.

## 🛠️ Setup and Usage

### Prerequisites
*   Python 3.10+
*   An OpenRouter API key (for accessing models like Gemini and others).
*   Manim and its dependencies (`ffmpeg`, `LaTeX`).

### Installation

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/nachi-kulkarni/gepa-manim-3b1b.git
    cd gepa-manim-3b1b
    ```

2.  **Create a virtual environment:**
    ```bash
    python3 -m venv venv
    source venv/bin/activate
    ```

3.  **Install dependencies:**
    ```bash
    pip install -r docsa/requirements.txt
    ```

4.  **Configure API Keys:**
    Create a `.env` file in the root directory and add your OpenRouter API key:
    ```
    OPENROUTER_API_KEY="your-api-key-here"
    ```

### Running the Pipeline

To generate a complete video from a topic:
```bash
python3 generate_video.py "The Pythagorean Theorem"
```

To run the GEPA training process (requires a configured dataset):
```bash
python3 training_pipeline.py
```
